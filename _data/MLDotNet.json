{"Data":{"GitHub":{"Issues":[{"Id":"3542258183","IsPullRequest":true,"CreatedAt":"2025-10-22T20:16:20","Actor":"github-actions[bot]","Number":"7528","RawContent":null,"Title":"[release/4.0] Improve unique directory generation for temp files","State":"open","Body":"Backport of #7520 to release/4.0\r\n\r\n/cc @ericstj\r\n\r\n## Customer Impact\r\nFor each model opened ML.NET would leave behind a temp folder which would slowly accumulate in the temp directory.  It also had an algorithm for temp folder creation which would linearly degrade with each new folder.\r\n\r\n## Testing\r\nTested fix that the folder is deleted and the creation algorithm does not degrade linearly if folders happen to be left behind because it uses GetTempFileName to produce significantly random folder name candidates.\r\n\r\n## Risk\r\nThis fix doesn't clean up past folders, we should release-note that users may want to do this manually.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7528","RelatedDescription":"Open PR \"[release/4.0] Improve unique directory generation for temp files\" (#7528)"},{"Id":"3485693378","IsPullRequest":true,"CreatedAt":"2025-10-22T01:18:47","Actor":"dotnet-maestro[bot]","Number":"7521","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\n\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\n## From https://github.com/dotnet/arcade\n- **Subscription**: [c692823c-b896-437f-4f57-08dc434cc8f6](https://maestro.dot.net/subscriptions?search=c692823c-b896-437f-4f57-08dc434cc8f6)\n- **Build**: [20251009.1](https://dev.azure.com/dnceng/internal/_build/results?buildId=2811863) ([286336](https://maestro.dot.net/channel/2/github:dotnet:arcade/build/286336))\n- **Date Produced**: October 9, 2025 12:35:11 PM UTC\n- **Commit**: [488413fe104056170673a048a07906314e101e5d](https://github.com/dotnet/arcade/commit/488413fe104056170673a048a07906314e101e5d)\n- **Branch**: [main](https://github.com/dotnet/arcade/tree/main)\n\n[DependencyUpdate]: <> (Begin)\n\n- **Updates**:\n  - From [11.0.0-beta.25502.2 to 11.0.0-beta.25509.1][2]\n     - Microsoft.DotNet.Arcade.Sdk\n     - Microsoft.DotNet.Build.Tasks.Feed\n     - Microsoft.DotNet.Helix.Sdk\n     - Microsoft.DotNet.SignTool\n     - Microsoft.DotNet.SwaggerGenerator.MSBuild\n     - Microsoft.DotNet.XliffTasks\n     - Microsoft.DotNet.XUnitExtensions\n\n[2]: https://github.com/dotnet/arcade/compare/bac4c2c4ad...488413fe10\n\n[DependencyUpdate]: <> (End)\n\n\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\n\n\n\n\n\n","Url":"https://github.com/dotnet/machinelearning/pull/7521","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#7521)"},{"Id":"3481890706","IsPullRequest":true,"CreatedAt":"2025-10-21T21:26:56","Actor":"ericstj","Number":"7520","RawContent":null,"Title":"Improve unique directory generation for temp files","State":"closed","Body":"Refactor unique directory creation logic to use random file names.\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/7485\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7520","RelatedDescription":"Closed or merged PR \"Improve unique directory generation for temp files\" (#7520)"},{"Id":"3420501783","IsPullRequest":false,"CreatedAt":"2025-10-20T02:12:26","Actor":"williamlzw","Number":"7507","RawContent":null,"Title":"vocab.json of qwen3 model cannot be loaded into Tokenizer","State":"closed","Body":"The vocab.json of the qwen3 model does not contain \"added_tokens\" and cannot be loaded into the Tokenizer.\n\n<img width=\"420\" height=\"647\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/938bce80-4d52-46dd-bd90-39ab82a59095\" />","Url":"https://github.com/dotnet/machinelearning/issues/7507","RelatedDescription":"Closed issue \"vocab.json of qwen3 model cannot be loaded into Tokenizer\" (#7507)"},{"Id":"3420170018","IsPullRequest":false,"CreatedAt":"2025-10-20T02:12:18","Actor":"williamlzw","Number":"7506","RawContent":null,"Title":"It's recommended that base classes use fewer internal methods.","State":"closed","Body":"It's recommended that base classes use fewer internal methods. I need to write a Qwen3Tokenizer class based on the CodeGenTokenizer class. I've noticed that many methods are internal. I'm forced to define a CodeGenTokenizerA class to write the Qwen3Tokenizer class.","Url":"https://github.com/dotnet/machinelearning/issues/7506","RelatedDescription":"Closed issue \"It's recommended that base classes use fewer internal methods.\" (#7506)"},{"Id":"3521518834","IsPullRequest":false,"CreatedAt":"2025-10-16T11:45:46","Actor":"ste-agolabs","Number":"7527","RawContent":null,"Title":"ML.NET LightGBM linear-tree","State":"open","Body":"Is LightGBM linear-tree option going to be supported in ML.NET future releases (e.g 5.0)?","Url":"https://github.com/dotnet/machinelearning/issues/7527","RelatedDescription":"Open issue \"ML.NET LightGBM linear-tree\" (#7527)"},{"Id":"3480645030","IsPullRequest":true,"CreatedAt":"2025-10-13T16:32:40","Actor":"krwq","Number":"7518","RawContent":null,"Title":"Modify expiration dates in .gdnbaselines","State":"closed","Body":"Updated expiration dates for baseline results - those should still be suppressed in order for BinSkim to not complain. We do not have control over external components.","Url":"https://github.com/dotnet/machinelearning/pull/7518","RelatedDescription":"Closed or merged PR \"Modify expiration dates in .gdnbaselines\" (#7518)"},{"Id":"3509194074","IsPullRequest":true,"CreatedAt":"2025-10-13T15:22:02","Actor":"krwq","Number":"7526","RawContent":null,"Title":"Remove baselines","State":"closed","Body":"Me & @rokonec came into conclusions that removing these should re-create BinSkim issues and not cause issues with other tooling. Baselines should contain entries for all active issues or issues already fixed since last baseline. Since we currently only have BinSkim entries in there we expect that after merging following will happen:\r\n- automatic PR with baselines update\r\n- BinSkim issues created\r\n\r\nafter this we should move permanent errors into suppression file and close out the issues\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7526","RelatedDescription":"Closed or merged PR \"Remove baselines\" (#7526)"},{"Id":"3506687290","IsPullRequest":true,"CreatedAt":"2025-10-12T05:16:20","Actor":"asp2286","Number":"7525","RawContent":null,"Title":"🧩 Add pluggable SIMD-accelerated random generator (Mersenne Twister) and RNG abstraction for deterministic ML pipelines","State":"open","Body":"### 📖 Overview\r\nThis PR introduces a new **pluggable random number generation (RNG) infrastructure** into ML.NET, replacing the previous `System.Random` dependency with a **deterministic, high-performance SIMD-accelerated Mersenne Twister (MT19937)** implementation.\r\n\r\nThe goal is to provide a **faster, deterministic, and cross-platform reproducible** RNG foundation for all stochastic algorithms (e.g., Random Forest, KMeans++, Isolation Forest, etc.) while maintaining full backward compatibility.\r\n\r\n---\r\n\r\n### 🚀 Key Changes\r\n- **New interfaces:**\r\n  - `IRandomSource` — unified, injectable RNG abstraction  \r\n  - `IRandomBulkSource` — efficient vectorized bulk fill API  \r\n\r\n- **New RNG backend:**\r\n  - `MersenneTwister` — pure C# MT19937 implementation  \r\n  - `MersenneTwisterRandomSource` — SIMD-optimized version using  \r\n    - `System.Runtime.Intrinsics.X86.Avx2`  \r\n    - `System.Runtime.Intrinsics.Arm.AdvSimd`  \r\n    with automatic scalar fallback  \r\n\r\n- **Integration:**\r\n  - Updated `HostEnvironmentBase`, `ConsoleEnvironment`, `LocalEnvironment`, and `MLContext`  \r\n  - New `RandomSource` property available on all `IHost` and `MLContext` instances  \r\n  - Backward-compatible `Rand` property retained and wired through adapters  \r\n\r\n- **Adapters for compatibility:**\r\n  - `RandomSourceAdapter`  \r\n  - `RandomFromRandomSource`  \r\n  - `RandomShim`  \r\n\r\n- **Testing and validation:**\r\n  - Determinism tests for same-seed consistency  \r\n  - Mixed consumption tests (`Rand` + `RandomSource`)  \r\n  - Cross-platform reproducibility (Windows/macOS/ARM64)  \r\n  - Performance microbenchmarks  \r\n\r\n---\r\n\r\n### ⚡ Performance Impact\r\nThe new RNG is up to **5× faster** in real workloads.  \r\nIt eliminates per-call allocations and leverages vectorized bit-generation via SIMD instructions.\r\n\r\n<details>\r\n<summary>📊 Benchmark results (Isolation Forest prototype)</summary>\r\n\r\n| Environment | Library | Mean Fit Time | Speedup |\r\n|--------------|----------|---------------|----------|\r\n| .NET 9 + ML.NET (SIMD MT19937) | C# | **0.21 s** | 🟢 **5× faster** |\r\n| Python 3.11 + scikit-learn 1.5 | C/Python | 1.05 s | — |\r\n\r\nAll benchmarks use identical seeds and datasets.  \r\nDeterministic equivalence confirmed across runs and architectures.\r\n</details>\r\n\r\n---\r\n\r\n### 🔬 Determinism & Reproducibility\r\n- Bit-for-bit identical sequences across architectures (x86 ↔ ARM64)  \r\n- Fallback to scalar path ensures deterministic output when SIMD unavailable  \r\n- Each `IHost` and `MLContext` obtains an independent deterministic stream  \r\n- Legacy `IHost.Rand` remains functional and maps to new RNG internally  \r\n\r\n---\r\n\r\n### 🧠 Motivation\r\nThis refactor lays the foundation for future high-performance stochastic algorithms in ML.NET.  \r\nReliable, cross-platform determinism and reproducible random streams are critical for modern ML workloads, testing, and research reproducibility.\r\n\r\nIt also unlocks future optimizations for:\r\n- Tree-based ensembles (RandomForest, IsolationForest, GBDT)\r\n- Sampling-based learners (KMeans++, NaiveBayes)\r\n- Data shuffling, augmentation, and stochastic pipelines\r\n\r\n---\r\n\r\n### 🔜 Next Steps\r\nIn the **next PR**, I will introduce a **native Isolation Forest implementation** built entirely in C# using this RNG backend.\r\n\r\nPreliminary testing shows the Isolation Forest algorithm using `MersenneTwisterRandomSource` performs **~5× faster** than scikit-learn’s Python version while producing numerically consistent anomaly scores.\r\n\r\nThis follow-up contribution will:\r\n- Add the new `IsolationForestTrainer` to ML.NET  \r\n- Include SHAP-style explainability support  \r\n- Extend anomaly detection benchmarks and documentation\r\n\r\n---\r\n\r\n### ✅ Checklist\r\n- [x] Added RNG abstraction layer (`IRandomSource`, `IRandomBulkSource`)  \r\n- [x] Implemented SIMD-accelerated Mersenne Twister (MT19937)  \r\n- [x] Integrated with host environments and `MLContext`  \r\n- [x] Ensured deterministic results across platforms  \r\n- [x] Added backward-compatibility adapters (`Rand`, `RandomShim`, etc.)  \r\n- [x] Added extensive unit tests  \r\n- [x] Benchmarked vs scikit-learn  \r\n- [ ] **Upcoming:** Isolation Forest algorithm using this RNG  \r\n\r\n---\r\n\r\n### 🧾 References\r\n- Matsumoto & Nishimura, *Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator*, ACM TOMS 1998  \r\n- .NET Hardware Intrinsics Docs: <https://learn.microsoft.com/en-us/dotnet/api/system.runtime.intrinsics>  \r\n- Internal discussions and performance notes related to RNG determinism in ML.NET #7502 \r\n\r\n---\r\n\r\n### 🧩 Example usage\r\n```csharp\r\nvar mlContext = new MLContext(seed: 2024);\r\nvar rng = mlContext.RandomSource;\r\n\r\n// deterministic sequence\r\nuint a = rng.NextUInt();\r\nuint b = rng.NextUInt();","Url":"https://github.com/dotnet/machinelearning/pull/7525","RelatedDescription":"Open PR \"🧩 Add pluggable SIMD-accelerated random generator (Mersenne Twister) and RNG abstraction for deterministic ML pipelines\" (#7525)"},{"Id":"3505684392","IsPullRequest":true,"CreatedAt":"2025-10-11T11:50:37","Actor":"asp2286","Number":"7524","RawContent":null,"Title":"Qwe","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7524","RelatedDescription":"Closed or merged PR \"Qwe\" (#7524)"},{"Id":"3504967250","IsPullRequest":false,"CreatedAt":"2025-10-11T01:41:47","Actor":"syp10000","Number":"7523","RawContent":null,"Title":"text tokenizer EncodeToTokens repeat","State":"open","Body":"input text：\"如果此时在位检测传感器的橙色LED灯熄灭\"\nEncodes input text to a list of EncodedTokens.  offset value repeat\n\n<img width=\"1249\" height=\"678\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/042c5280-aff0-457c-a29e-ad11ce808391\" />","Url":"https://github.com/dotnet/machinelearning/issues/7523","RelatedDescription":"Open issue \"text tokenizer EncodeToTokens repeat\" (#7523)"},{"Id":"3493050985","IsPullRequest":false,"CreatedAt":"2025-10-07T21:09:28","Actor":"AngeloAtCadence","Number":"7522","RawContent":null,"Title":"MulticlassClassificationExperiment preFeaturizer not acting on the schema","State":"open","Body":"**System Information (please complete the following information):**\n - OS & Version: Windows 11\n - ML.NET Version: ML.NET v4.0.2 & Auto ML.NET v0.22.2\n - .NET Version:  .NET 10\n\n**Describe the bug**\nWhen using a transform like DropColumns or CustomMapping the resulting transform is not taken into account as the new schema. This causes Schema validation errors with our even applying the transforms. For instance, with the following code applied outside of the will work when passed outside of the preFeaturizer, but when used as an input it fails saying it cannot find the column. If a custom mapper is used the reverse problems happen where an output schema is not seen and the columns type is rejected.\n\"`csharp\nvar transformedData = ctx.Transforms.DropColumns([HybridClassifierInputModel.imageSource]).Fit(fullData).Transform(fullData);`\"\n\nThis will also result in errors after training where you will need to manually apply the transform before the predictor.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Create a IDataView with a schema\n2. Set up an experiment for the MulticlassExperimentSettings\n3. Try any preFeaturizer where you would drop a column or try to change the schema too much. DropColumns or SelectColumns are perfect examples\n\n**Expected behavior**\nI would expect the transformer in preFeaturizer to be applied before the validation. Thus, it would allow for column drops or when working with data that must be massaged, or you are using in multiple ways. \n\n**Screenshots, Code, Sample Projects**\n\n```csharp\nMulticlassExperimentSettings textModelSettings = new MulticlassExperimentSettings()\n{\n\tOptimizingMetric = OptimizingMetric,\n\tMaxExperimentTimeInSeconds = maxTrainTimeInSeconds,\n\t//CacheBeforeTrainer = CacheBeforeTrainer.On,\n\tCacheDirectoryName = Environment.CurrentDirectory, // Skip the disk and store in-memory\n};\n\n//var transformedData = ctx.Transforms.DropColumns([HybridClassifierInputModel.imageSource]).Fit(fullData).Transform(fullData);\nMulticlassClassificationExperiment experiment = ctx.Auto().CreateMulticlassClassificationExperiment(textModelSettings);\n\nTrainTestData trainValidationData = ctx.Data.TrainTestSplit(ctx.Data.ShuffleRows(transformedData), testFraction: 0.2);\n\nExperimentResult <MulticlassClassificationMetrics> result = experiment.Execute(trainData: trainValidationData.TrainSet,\n\t\t\t\t\t\t\t\t//preFeaturizer: ctx.Transforms.CustomMapping<HybridClassifierInputModel, TextClassifierInputModel>(HybridToTextCustomAction.CustomAction, nameof(HybridToTextCustomAction), outputSchemaDefinition: SchemaDefinition.Create(typeof(TextClassifierInputModel))),\n\t\t\t\t\t\t\t\tpreFeaturizer: ctx.Transforms.DropColumns([HybridClassifierInputModel.imageSource]),\n\t\t\t\t\t\t\t\tvalidationData: trainValidationData.TestSet,\n\t\t\t\t\t\t\t\tlabelColumnName: HybridClassifierInputModel.target,\n\t\t\t\t\t\t\t\tprogressHandler: new TextCPUMlClassifierProgressHandler<IHybridMlClassifierService>(Logger)); \n```\n\n**Additional context**\nI would have like to use the data to train more than one model, but it needs some small data changes for either one. I have a custom IDataView that attaches to a DbLite. It would be good if the preFeature worked so that it could stream the data.\n","Url":"https://github.com/dotnet/machinelearning/issues/7522","RelatedDescription":"Open issue \"MulticlassClassificationExperiment preFeaturizer not acting on the schema\" (#7522)"},{"Id":"3479576251","IsPullRequest":true,"CreatedAt":"2025-10-03T19:58:29","Actor":"ericstj","Number":"7516","RawContent":null,"Title":"Improve native build and mark our official build as CFS Clean","State":"closed","Body":"The CFS Clean marking will prevent our build from accessing public packaging endpoints (like NuGet.org, myget.org, etc).\r\nSee https://eng.ms/docs/cloud-ai-platform/devdiv/one-engineering-system-1es/1es-build/cloudbuild/resolving-cfs-s360-items\r\n\r\nThe other settings are just various native toolchain improvements like deterministic build, source linking, etc.  I also enabled the repo to build with Dev18 while I was at it.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7516","RelatedDescription":"Closed or merged PR \"Improve native build and mark our official build as CFS Clean\" (#7516)"},{"Id":"3481545966","IsPullRequest":true,"CreatedAt":"2025-10-03T17:02:36","Actor":"dotnet-maestro[bot]","Number":"7519","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\n\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\n## From https://github.com/dotnet/arcade\n- **Subscription**: [c692823c-b896-437f-4f57-08dc434cc8f6](https://maestro.dot.net/subscriptions?search=c692823c-b896-437f-4f57-08dc434cc8f6)\n- **Build**: [20251002.2](https://dev.azure.com/dnceng/internal/_build/results?buildId=2807056) ([285551](https://maestro.dot.net/channel/2/github:dotnet:arcade/build/285551))\n- **Date Produced**: October 2, 2025 7:59:28 PM UTC\n- **Commit**: [bac4c2c4add004bbce35ff5d17bc295dd4ebcd57](https://github.com/dotnet/arcade/commit/bac4c2c4add004bbce35ff5d17bc295dd4ebcd57)\n- **Branch**: [main](https://github.com/dotnet/arcade/tree/main)\n\n[DependencyUpdate]: <> (Begin)\n\n- **Updates**:\n  - From [11.0.0-beta.25477.2 to 11.0.0-beta.25502.2][1]\n     - Microsoft.DotNet.Arcade.Sdk\n     - Microsoft.DotNet.Build.Tasks.Feed\n     - Microsoft.DotNet.Helix.Sdk\n     - Microsoft.DotNet.SignTool\n     - Microsoft.DotNet.SwaggerGenerator.MSBuild\n     - Microsoft.DotNet.XliffTasks\n     - Microsoft.DotNet.XUnitExtensions\n\n[1]: https://github.com/dotnet/arcade/compare/e19df00378...bac4c2c4ad\n\n[DependencyUpdate]: <> (End)\n\n\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\n\n","Url":"https://github.com/dotnet/machinelearning/pull/7519","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#7519)"},{"Id":"3420510489","IsPullRequest":false,"CreatedAt":"2025-10-03T16:24:13","Actor":"williamlzw","Number":"7508","RawContent":null,"Title":"Hope to simplify torchsharp's Tokenizer to facilitate expansion","State":"closed","Body":"https://github.com/dotnet/machinelearning/issues/7507","Url":"https://github.com/dotnet/machinelearning/issues/7508","RelatedDescription":"Closed issue \"Hope to simplify torchsharp's Tokenizer to facilitate expansion\" (#7508)"},{"Id":"3479824904","IsPullRequest":false,"CreatedAt":"2025-10-03T05:16:45","Actor":"ntoan69","Number":"7517","RawContent":null,"Title":"Support 16 KB page sizes","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\n\n16 KB Google Play compatibility requirement\nStarting November 1st, 2025, all new apps and updates to existing apps submitted to Google Play and targeting Android 15+ devices must support 16 KB page sizes on 64-bit devices.\n\n**Describe the solution you'd like**\n\nCompile 16 KB-aligned shared libraries\n\n**Describe alternatives you've considered**\n\n\n**Additional context**\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7517","RelatedDescription":"Open issue \"Support 16 KB page sizes\" (#7517)"},{"Id":"3479076528","IsPullRequest":true,"CreatedAt":"2025-10-03T01:22:49","Actor":"tarekgh","Number":"7514","RawContent":null,"Title":"BpeTokenizer Cleanup","State":"closed","Body":"This change is a simple clean-up for the BPE tokenizer:\r\n\r\n* Adds support for `BeginningOfSentenceToken` and `EndOfSentenceToken` when these tokens are not present in the vocabulary but are instead provided as special tokens by the tokenizer.\r\n* Simplifies the implementation of the `Decode` method.","Url":"https://github.com/dotnet/machinelearning/pull/7514","RelatedDescription":"Closed or merged PR \"BpeTokenizer Cleanup\" (#7514)"},{"Id":"3479297049","IsPullRequest":true,"CreatedAt":"2025-10-03T00:42:55","Actor":"ericstj","Number":"7515","RawContent":null,"Title":"Update Windows image, fix mac build","State":"closed","Body":"Public CI doesn't test this.  Will kick off official build\r\n\r\nhttps://dev.azure.com/dnceng/internal/_build/results?buildId=2807210&view=results","Url":"https://github.com/dotnet/machinelearning/pull/7515","RelatedDescription":"Closed or merged PR \"Update Windows image, fix mac build\" (#7515)"},{"Id":"3396447200","IsPullRequest":true,"CreatedAt":"2025-10-01T22:36:03","Actor":"JoshuaSloan","Number":"7499","RawContent":null,"Title":"Added NumberOfLeaves to FastForestRegression and FastForestOva options","State":"closed","Body":"`Fixes #7498`\r\n\r\nThe NumberOfLeaves hyperparameter was not updating in FastForest AutoML experiments for regression and multiclass classification tasks (see regression example in the associated [issue](https://github.com/dotnet/machinelearning/issues/7498), which was trained on the California Housing [dataset](https://www.kaggle.com/datasets/camnugent/california-housing-prices) and optimizing for root mean squared error).\r\n\r\nConsequently, the trial parameters reported via an experiment monitor's final ReportBestTrial() method were not aligning with the actual model produced by the experiment. Additionally, model performance was hurt due to the static hyperparameter constraint.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7499","RelatedDescription":"Closed or merged PR \"Added NumberOfLeaves to FastForestRegression and FastForestOva options\" (#7499)"},{"Id":"3413997722","IsPullRequest":false,"CreatedAt":"2025-10-01T22:35:03","Actor":"artl93","Number":"7503","RawContent":null,"Title":"Initialize es-metadata.yml for inventory","State":"closed","Body":"Please add a file named `es-metadata.yml` to the root of this repository with the following contents:\n\n```\nschemaVersion: 0.0.1\nisProduction: false\naccountableOwners:\n  service: 7a9b52f6-7805-416c-9390-343168c0cdb3\nrouting:\n  defaultAreaPath:\n    org: devdiv\n    path: DevDiv\\NET Libraries\n```\n\nThis file will help initialize inventory metadata for the repository.","Url":"https://github.com/dotnet/machinelearning/issues/7503","RelatedDescription":"Closed issue \"Initialize es-metadata.yml for inventory\" (#7503)"},{"Id":"3414003004","IsPullRequest":true,"CreatedAt":"2025-10-01T22:35:02","Actor":"Copilot","Number":"7504","RawContent":null,"Title":"Initialize es-metadata.yml for inventory","State":"closed","Body":"This PR adds the required `es-metadata.yml` file to the root of the repository to initialize inventory metadata. The file contains the necessary configuration for service ownership and routing information as specified in the issue.\n\nThe file includes:\n- Schema version 0.0.1\n- Production flag set to false\n- Accountable owners service GUID for proper service ownership tracking\n- Default routing configuration for the DevDiv\\.NET Libraries area path\n\nThis metadata file will enable proper inventory tracking and management for the repository.\n\nFixes #7503.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\n✨ Let Copilot coding agent [set things up for you](https://github.com/dotnet/machinelearning/issues/new?title=✨+Set+up+Copilot+instructions&body=Configure%20instructions%20for%20this%20repository%20as%20documented%20in%20%5BBest%20practices%20for%20Copilot%20coding%20agent%20in%20your%20repository%5D%28https://gh.io/copilot-coding-agent-tips%29%2E%0A%0A%3COnboard%20this%20repo%3E&assignees=copilot) — coding agent works faster and does higher quality work when set up for your repo.\n","Url":"https://github.com/dotnet/machinelearning/pull/7504","RelatedDescription":"Closed or merged PR \"Initialize es-metadata.yml for inventory\" (#7504)"},{"Id":"3465721926","IsPullRequest":false,"CreatedAt":"2025-10-01T22:34:41","Actor":"tarekgh","Number":"7512","RawContent":null,"Title":"Added Tokenizer's APIs for v2","State":"closed","Body":"This issue tracks the APIs added to the tokenizer library.\n\n## Proposal\n\n### BpeTokenizer \n\nWe’ve already established a pattern for creating tokenizers using `Tokenizer.Create(...)`. When multiple parameters are required, we wrap them in an `Options` object. For example, `BertTokenizer.Create` accepts a `BertOptions` parameter.\n\nFollowing this pattern, we’re adding a new `Create` method to `BpeTokenizer` and introducing the `BpeOptions` class to encapsulate the parameters passed to `Create`. Currently, `BpeTokenizer` has a `Create` method that takes flat parameters:\n\n```C#\n        public static BpeTokenizer Create(\n                                string vocabFile,\n                                string? mergesFile,\n                                PreTokenizer? preTokenizer = null,\n                                Normalizer? normalizer = null,\n                                IReadOnlyDictionary<string, int>? specialTokens = null,\n                                string? unknownToken = null,\n                                string? continuingSubwordPrefix = null,\n                                string? endOfWordSuffix = null,\n                                bool fuseUnknownTokens = false)\n```\n\nThe proposal here is wrapping all parameters into `BpeOptions` object. \n\n```diff\n\n  namespace Microsoft.ML.Tokenizers\n  {\n      public sealed class BpeTokenizer : Tokenizer\n      {\n+         public static BpeTokenizer Create(BpeOptions options);\n         \n+          public bool? ByteLevel { get; }\n+           public string? BeginningOfSentenceToken { get; }\n\n      }\n\n+     public sealed class BpeOptions\n+     {\n+         public BpeOptions(System.Collections.Generic.IEnumerable<(string, int)> vocabulary);\n+\n+         public string? BeginningOfSentenceToken { get; set; }\n+         public string? ContinuingSubwordPrefix { get; set; }\n+         public string? EndOfSentenceToken { get; set; }\n+         public string? EndOfWordSuffix { get; set; }\n+         public bool? FuseUnknownTokens { get; set; }\n+         public IEnumerable<string>? Merges { get; set; }\n+         public Normalizer? Normalizer { get; set; }\n+         public PreTokenizer? PreTokenizer { get; set; }\n+         public IReadOnlyDictionary<string, int> SpecialTokens { get; set; }\n+         public string? UnknownToken { get; set; }\n+         public IEnumerable<(string, int)> Vocabulary { get; }\n+         public bool? ByteLevel { get; set; }\n+     }\n```\n\n**Notes**\n\n* Added a new `ByteLevel` property to enable BPE tokenizer support for [`ByteLevel`](https://github.com/huggingface/tokenizers/blob/916df542684d5f2333c0ba1140deda64efa5cf91/bindings/python/py_src/tokenizers/implementations/byte_level_bpe.py#L10). This handles vocabularies stored as bytes (typically UTF-8 encoded) and ensures text is pre-tokenized accordingly.\n* Introduced `BeginningOfSentenceToken`, an optional token that can be inserted at the start when encoding text.\n* `Vocab` and `Merges` are now passed as `IEnumerable` to provide flexibility, since these data sources may come from different origins.\n\n### SentencePieceTokenizer \n\nWe already have `LlamaTokenizer.Create`, with `LlamaTokenizer` subclassing `SentencePieceTokenizer`. Since `SentencePieceTokenizer` now supports multiple internal models (`Bpe` and `Unigram`), we should expose the `Create` method directly from `SentencePieceTokenizer` rather than exposing separate classes for each model. The model type is already embedded in the tokenizer file passed to `Create`.\n\n```C#\n        public static new LlamaTokenizer.Create(Stream modelStream, bool addBeginOfSentence = true, bool addEndOfSentence = false, IReadOnlyDictionary<string, int>? specialTokens = null)\n```\n\nThe proposal is to have the following Create method:\n\n```diff\n  namespace Microsoft.ML.Tokenizers\n  {\n\n      public class SentencePieceTokenizer : Microsoft.ML.Tokenizers.Tokenizer\n      {\n+         public static SentencePieceTokenizer Create(Stream modelStream, bool addBeginOfSentence = true, bool addEndOfSentence = false, IReadOnlyDictionary<string, int> specialTokens = null);\n      }\n   }\n```\n\n### CompositePreTokenizer\n\nA pre-tokenizer is used to split input text into smaller chunks before tokenization and encoding. In some scenarios, such as DeepSeek, multiple pre-tokenizers are required to run in sequence. To support this, the proposal is to introduce a `CompositePreTokenizer`, which implements the `PreTokenizer` abstraction.\n\n```diff\n  namespace Microsoft.ML.Tokenizers\n  {\n+     public class CompositePreTokenizer : PreTokenizer\n+     {\n+         public CompositePreTokenizer(IReadOnlyList<Tokenizers.PreTokenizer> preTokenizers, IReadOnlyDictionary<string, int> specialTokens = null);\n+         public IReadOnlyList<PreTokenizer> PreTokenizers { get; }\n\n           public override IEnumerable<(int, int)> PreTokenize(System.ReadOnlySpan<char> text);\n           public override IEnumerable<(int, int)> PreTokenize(string text);\n+     }\n   }\n```","Url":"https://github.com/dotnet/machinelearning/issues/7512","RelatedDescription":"Closed issue \"Added Tokenizer's APIs for v2\" (#7512)"},{"Id":"3474798955","IsPullRequest":true,"CreatedAt":"2025-10-01T22:34:40","Actor":"tarekgh","Number":"7513","RawContent":null,"Title":"Address the design review feedback","State":"closed","Body":"Fixes https://github.com/dotnet/machinelearning/issues/7512","Url":"https://github.com/dotnet/machinelearning/pull/7513","RelatedDescription":"Closed or merged PR \"Address the design review feedback\" (#7513)"},{"Id":"3428821552","IsPullRequest":false,"CreatedAt":"2025-10-01T17:32:09","Actor":"asp2286","Number":"7509","RawContent":null,"Title":"MacOS_x64 Debug/Release build jobs fail in MachineLearning-CI: “Bash exited with code '1' – Install MacOS build dependencies”","State":"closed","Body":" - OS & Version: macOS hosted agents (Azure Pipelines), osx.13 (macOS 13.x), x64 only\n - ML.NET Version: current main (MachineLearning-CI)\n - .NET Version: per repo global.json (targets .NET 8)\n\nIn the MachineLearning-CI pipeline, only the macOS x64 jobs fail at the Install MacOS build dependencies step with:\nBash exited with code '1'\n\nSteps to reproduce the behavior:\n1. Azure DevOps → Pipelines → MachineLearning-CI.\n2. Queue on main with defaults.\n3. Observe MacOS_x64 Debug_Build and MacOS_x64 Release_Build.\n4. See error\n\nExpected behavior\nmacOS x64 Debug/Release should install dependencies and proceed to build/tests like other jobs.\n\nScreenshots\n<img width=\"1709\" height=\"1029\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bc1c9f24-56b5-4f0b-a79b-3d64ce81e38b\" />\n\nAdditional context\nLikely macOS dependency bootstrap issue, possibly due to:\nHomebrew formula drift (OpenMP): libomp standalone formula may be missing/renamed on current images","Url":"https://github.com/dotnet/machinelearning/issues/7509","RelatedDescription":"Closed issue \"MacOS_x64 Debug/Release build jobs fail in MachineLearning-CI: “Bash exited with code '1' – Install MacOS build dependencies”\" (#7509)"},{"Id":"3429005106","IsPullRequest":true,"CreatedAt":"2025-10-01T17:32:08","Actor":"asp2286","Number":"7510","RawContent":null,"Title":"macOS x64 CI: fix dependency install and OpenMP runtime copy (use Homebrew libomp, adjust Helix payload)","State":"closed","Body":"# PR: macOS x64 CI: fix dependency install and OpenMP runtime copy\r\n\r\n### Summary\r\nThis PR fixes **MachineLearning-CI** failures on **macOS x64** where jobs stop at *Install MacOS build dependencies* with:\r\n\r\n```\r\nBash exited with code '1'\r\n```\r\n\r\nThe breakage comes from two areas:\r\n1. **Dependency install**: The pipeline relied on a custom `libomp.rb` path that no longer works on hosted macOS images.\r\n2. **Helix payload**: The script attempted to copy both `libomp.dylib` and `libiomp5.dylib`, but `libiomp5.dylib` is not available when installing `libomp` from Homebrew core.\r\n\r\n**Fixes #7509**\r\n\r\n---\r\n\r\n### Changes\r\n#### `build/ci/job-template.yml`\r\n- Replace custom `brew install …/build/libomp.rb` with standard Homebrew:\r\n  ```bash\r\n  brew update\r\n  brew install -f --overwrite python@3.13\r\n  brew install libomp\r\n  brew link libomp --force\r\n  ```\r\n- Note added: Homebrew ≥4.6 rejects installing formulae from raw paths.\r\n\r\n#### `eng/helix.proj`\r\n- macOS **x64 only**:\r\n  - Set `DYLD_LIBRARY_PATH` so Helix can find `libomp.dylib`.\r\n  - Copy only `/usr/local/opt/libomp/lib/libomp.dylib` into the publish folder.\r\n  - Remove copying of `libiomp5.dylib` (not present with `libomp` from Homebrew).\r\n  - Add install-name fix so binaries reference `@loader_path/libomp.dylib`.\r\n\r\n---\r\n\r\n### Why\r\n- Hosted macOS runners changed: raw formula paths are blocked, and only `libomp` is available via core.\r\n- Ensures reliable dependency install and payload runtime linking.\r\n- Other platforms (Linux, Windows, macOS arm64) are unaffected.\r\n\r\n---\r\n\r\n### Testing\r\n- Reproduced failure on `osx.13.amd64.open` queue.\r\n- With these changes:\r\n  - Dependency install step completes successfully.\r\n  - `libomp.dylib` is present in publish folder.\r\n  - Helix payload runs with `DYLD_LIBRARY_PATH` set correctly.\r\n- Validated in a test run: both macOS x64 Debug/Release proceed past dependency install and build succeeds.\r\n\r\n---\r\n\r\n### Risk / Impact\r\n- **Low**: scoped only to macOS x64 build dependencies and Helix payload.\r\n- No product code changes, only CI infra adjustments.\r\n\r\n---\r\n\r\n### Additional Notes\r\n- Linux and Windows jobs were already green.\r\n- If maintainers prefer `llvm` over `libomp` as the OpenMP provider, happy to adjust.\r\n\r\n---\r\n\r\n### PR Checklist\r\n- [x] **CLA signed**\r\n- [x] **Tests**: N/A (CI infra only)\r\n- [x] **Docs**: N/A (no public-facing change)\r\n- [x] **Breaking change**: No\r\n- [x] **Linked issue**: #7509\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7510","RelatedDescription":"Closed or merged PR \"macOS x64 CI: fix dependency install and OpenMP runtime copy (use Homebrew libomp, adjust Helix payload)\" (#7510)"},{"Id":"3455354145","IsPullRequest":true,"CreatedAt":"2025-09-26T01:24:01","Actor":"tarekgh","Number":"7511","RawContent":null,"Title":"Mark internal classes as internal","State":"closed","Body":"We unintentionally marked two internal classes as public. The change is to mark them back as internal. ","Url":"https://github.com/dotnet/machinelearning/pull/7511","RelatedDescription":"Closed or merged PR \"Mark internal classes as internal\" (#7511)"},{"Id":"3403171990","IsPullRequest":true,"CreatedAt":"2025-09-18T07:21:00","Actor":"asp2286","Number":"7501","RawContent":null,"Title":"CI(macOS x64): install libomp from Homebrew Core (drop local libomp.rb)","State":"closed","Body":"# Fix macOS x64 CI: install `libomp` via Homebrew tap (no local formula)\r\n\r\n**Branch:** `fix-macos-libomp`  \r\n**Scope:** CI only – changes limited to `build/ci/job-template.yml` (macOS x64 job)\r\n\r\n---\r\n\r\n## What & Why\r\n\r\nOn **macOS x64** jobs, our pipeline tries to install OpenMP via a *local* Homebrew formula:\r\n\r\n```bash\r\nbrew install $(Build.SourcesDirectory)/build/libomp.rb --build-from-source --formula\r\n```\r\n\r\nRecent Homebrew (4.6+) rejects local, untapped formulae and fails with:\r\n\r\n```\r\nHomebrew requires formulae to be in a tap, rejecting:\r\n  /Users/runner/work/1/s/build/libomp.rb\r\nTo create a tap, run e.g. brew tap-new <user|org>/<repository>\r\n```\r\n\r\nThis does **not** affect `macOS_cross_arm64` jobs because they already use the official `homebrew/core` formula (`brew install libomp`).\r\n\r\n### The fix\r\n\r\nFor **macOS x64** only, switch to the official tap-hosted formula and force a link so the headers and libs are discoverable by our native builds:\r\n\r\n```yaml\r\n# Before (failing; local .rb file)\r\nexport HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=TRUE && brew install $(Build.SourcesDirectory)/build/libomp.rb --build-from-source --formula\r\n\r\n# After (working; official tap)\r\nbrew update && brew install libomp && brew link libomp --force\r\n```\r\n\r\nNo product/code changes; **CI infra-only**.\r\n\r\n---\r\n\r\n## Validation\r\n\r\n- ✅ Verified the failing step is isolated to `macOS_x64` with the error above.\r\n- ✅ `macOS_cross_arm64` continues to use the official tap and succeeds.\r\n- ✅ Local repro on a GitHub-hosted macOS runner using the new commands installs `libomp` and exposes headers (`/usr/local/opt/libomp/include`) and libs (`/usr/local/opt/libomp/lib`).\r\n\r\n> Note: Homebrew marks `libomp` as *keg-only*. The `brew link ... --force` step ensures the toolchain sees it without extra flags. If we ever want to avoid `--force`, we can export:\r\n>\r\n> ```bash\r\n> export CPPFLAGS=\"-I/usr/local/opt/libomp/include\"\r\n> export LDFLAGS=\"-L/usr/local/opt/libomp/lib\"\r\n> ```\r\n\r\n---\r\n\r\n## Risk & Impact\r\n\r\n- **Risk:** Low. The change only affects the CI macOS x64 dependency-install step.\r\n- **Impact:** Unblocks native builds on macOS x64 by ensuring OpenMP is available.\r\n- **No Changes** to shipping packages, versioning, public APIs, or runtime behavior.\r\n\r\n---\r\n\r\n## Alternative considered\r\n\r\n- Creating and maintaining a custom Homebrew tap for `libomp.rb`. Rejected to avoid long‑term maintenance overhead when the official formula suffices.\r\n\r\n---\r\n\r\n## Change summary\r\n\r\n- Update `build/ci/job-template.yml` macOS x64 path:\r\n  - Replace local formula install with `brew update && brew install libomp && brew link libomp --force`.\r\n  - **No changes** to the ARM cross path (already uses official tap).\r\n\r\n---\r\n\r\n## How to verify in CI\r\n\r\n1. Queue the pipeline for `macOS_x64 Debug_Build`.\r\n2. Confirm the step **Install MacOS build dependencies** succeeds, showing:\r\n   - *“Pouring libomp…”, “Linking … 6 symlinks created”*\r\n3. Validate native build succeeds (CpuMathNative, FastTreeNative, etc.).\r\n4. Ensure no downstream targets rely on `OneDalNative` on macOS unless explicitly provided (unrelated to this PR).\r\n\r\n---\r\n\r\n## Notes for maintainers\r\n\r\n- This PR **does not** modify any source under `src/` or packaging. It is safe to service‑merge.\r\n- If future runners transition to Apple Silicon-only, this step remains valid (Homebrew tap still provides `libomp`).\r\n\r\n---\r\n\r\n## Checklist (author)\r\n\r\n- [x] CI-only change; no product code.\r\n- [x] macOS x64 path updated; ARM path unchanged.\r\n- [x] Verified the new commands succeed on a runner.\r\n- [x] Added rationale & reproduction details in this PR description.\r\n\r\n<!--\r\nMaintainer checklist (adapted from Reviewer_Checklist.md). Keep collapsed in the PR body.\r\n\r\n- [ ] CI is green on all required legs.\r\n- [ ] Affected area scoped to CI; no shipping assets changed.\r\n- [ ] No public API changes; no breaking changes.\r\n- [ ] Build/install steps use supported, tap-hosted Homebrew formulae (no local .rb files).\r\n- [ ] Windows/Linux pipelines unaffected.\r\n- [ ] No additional credentials, secrets, or taps required.\r\n- [ ] If later backported, the YAML path exists in the target branch.\r\n- [ ] PR title and labels reflect “infra/CI” nature.\r\n-->\r\n\r\n---\r\n\r\n### Screenshots / logs (for context)\r\n\r\n**Failure (before):**\r\n```\r\nError: Homebrew requires formulae to be in a tap, rejecting:\r\n  /Users/runner/work/1/s/build/libomp.rb\r\n```\r\n\r\n**Success (after):**\r\n```\r\n==> Fetching downloads for: libomp\r\n==> Pouring libomp--<version>.ventura.bottle.tar.gz\r\nLinking /usr/local/Cellar/libomp/<version>... 6 symlinks created.\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7501","RelatedDescription":"Closed or merged PR \"CI(macOS x64): install libomp from Homebrew Core (drop local libomp.rb)\" (#7501)"},{"Id":"3401672315","IsPullRequest":true,"CreatedAt":"2025-09-18T07:20:27","Actor":"asp2286","Number":"7500","RawContent":null,"Title":"macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)","State":"closed","Body":"# macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)\r\n\r\n**Problem**\r\nOn macOS x64, building `src/Native` fails with:\r\n```\r\nfatal error: 'daal.h' file not found\r\n```\r\nThe oneDAL “devel” (headers) package is not available via NuGet for `osx-x64`, so locally `ONEDAL_DEVEL_PATH` is not present and `OneDalNative` cannot compile. Today the native CMake unconditionally includes `OneDalNative` on x64, which makes a default macOS developer build fail.\r\n\r\n**What this PR changes**\r\n- Gate `add_subdirectory(OneDalNative)` behind explicit configuration:\r\n  - Only include `OneDalNative` when both `ONEDAL_DEVEL_PATH` and `ONEDAL_REDIST_PATH` are defined **and** `${ONEDAL_DEVEL_PATH}/include/daal.h` exists.\r\n  - Otherwise, print an informative `message(STATUS ...)` and skip `OneDalNative`.\r\n\r\n**Why this is safe**\r\n- Windows/Linux CI builds that pass `ONEDAL_*` continue to build `OneDalNative` unchanged.\r\n- macOS builds (where oneDAL headers aren’t available via NuGet by default) no longer fail—they build the rest of the native components and skip `OneDalNative`.\r\n- No changes to `build.sh` are required. The script already sets `-DONEDAL_*` only when callers pass the corresponding command-line switches.\r\n\r\n**Repro (before)**\r\n```\r\n# macOS x64 without oneDAL headers\r\ncmake ... && make\r\n# -> OneDalNative/OneDalAlgorithms.cpp: fatal error: 'daal.h' file not found\r\n```\r\n\r\n**Behavior (after)**\r\n- If `ONEDAL_*` not provided: CMake prints `Skipping OneDalNative: ONEDAL_DEVEL_PATH/ONEDAL_REDIST_PATH not set` and the rest builds fine.\r\n- If `ONEDAL_*` provided and `${ONEDAL_DEVEL_PATH}/include/daal.h` exists: `OneDalNative` builds as before.\r\n\r\n**Test matrix**\r\n- ✅ macOS x64 (Intel): builds successfully; `OneDalNative` skipped by default; other native targets build.\r\n- ✅ macOS arm64 (Apple Silicon): previously didn’t include `OneDalNative` (arch guard); behavior unchanged.\r\n- ✅ Linux/Windows (CI): when `ONEDAL_*` are set (as in existing pipelines), behavior unchanged and `OneDalNative` builds.\r\n\r\n**Notes**\r\n- This PR intentionally doesn’t alter OpenMP handling or `SymSgdNative`. On macOS x64, developers who need `SymSgdNative` can use Homebrew LLVM (`brew install llvm libomp`) or provide appropriate OpenMP flags; that is orthogonal to oneDAL headers availability.\r\n- We can later add an explicit `-DMLNET_BUILD_ONEDAL=ON/OFF` flag for stricter control if maintainers prefer.","Url":"https://github.com/dotnet/machinelearning/pull/7500","RelatedDescription":"Closed or merged PR \"macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)\" (#7500)"},{"Id":"3420060036","IsPullRequest":false,"CreatedAt":"2025-09-16T02:09:14","Actor":"williamlzw","Number":"7505","RawContent":null,"Title":"The ph3 model decodes Chinese characters and displays garbled characters.","State":"open","Body":"<img width=\"434\" height=\"112\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2baa0814-0334-42a4-99f0-8b96fe53da14\" />\n\n```\nusing Microsoft.ML.Tokenizers;\nusing Microsoft.ML.GenAI.Phi;\nusing Microsoft.ML.GenAI.Core;\nusing Microsoft.Extensions.AI;\n\n\npublic class Program\n{\n    public async static void TestPhi3()\n    {\n        string device = \"cuda\";\n        var weightFolder = @\"G:\\model\\Phi-3-mini-128k-instruct\";\n        var model = Phi3ForCausalLM.FromPretrained(weightFolder, \"config.json\", layersOnTargetDevice: -1, quantizeToInt4: true, targetDevice: device);\n        var modelPath = Path.Join(weightFolder, \"tokenizer.model\");\n        var tokenizer = Phi3TokenizerHelper.FromPretrained(modelPath);\n        var pipeline = new CausalLMPipeline<Tokenizer, Phi3ForCausalLM>(tokenizer, model, device);\n        var client = new Phi3CausalLMChatClient(pipeline);\n        var task = \"\"\"\n            你能讲一个有趣的笑话吗?\n            \"\"\";\n        List<ChatMessage> _chatHistory = new();\n        _chatHistory.Add(new ChatMessage(ChatRole.System, \"你是一个助手,用中文回答用户的问题\"));\n        _chatHistory.Add(new ChatMessage(ChatRole.User, task));\n        var options = new ChatOptions\n        {\n            StopSequences = [\"<|end_of_text|>\"],//phi3\n            AdditionalProperties = new() { { \"max_length\", 2048 } },\n        };\n        await foreach (var response in client.GetStreamingResponseAsync(_chatHistory, options))\n        {\n            Console.Write(response.Text);\n        }\n\n        Console.WriteLine();\n        Console.WriteLine(\"End!\");\n    }\n\n    public static void Main()\n    {\n        TestPhi3();\n    }\n}\n```\n\n<img width=\"477\" height=\"125\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f53c2e65-8c32-4e91-8010-f567baa66bef\" />","Url":"https://github.com/dotnet/machinelearning/issues/7505","RelatedDescription":"Open issue \"The ph3 model decodes Chinese characters and displays garbled characters.\" (#7505)"},{"Id":"3413291798","IsPullRequest":false,"CreatedAt":"2025-09-13T11:55:48","Actor":"asp2286","Number":"7502","RawContent":null,"Title":"Proposal: Pluggable RNG in MLContext (enable deterministic, portable RNGs like MT19937)","State":"open","Body":"## Summary\n\nI propose adding a minimal extension point to let users inject a custom RNG into `MLContext`, without changing defaults or breaking back-compat. This enables deterministic, portable randomness across platforms and languages (e.g., align with C++ `std::mt19937`), and allows advanced users to choose an RNG that matches their reproducibility requirements.\n\n## Motivation\n\n- **Reproducibility across ecosystems**: Many data science stacks standardize on MT19937 (e.g., C++ `std::mt19937`, NumPy’s legacy PCG/MT usage), making it easier to compare experiments when the same PRNG is available in ML.NET.\n- **Zero impact by default**: Default behavior remains unchanged and backwards compatible.\n- **Testability**: Easier to write bitwise-stable tests that don’t depend on underlying `System.Random` variations.\n\n## Design\n\nAdd a small interface and an optional parameter to `MLContext`:\n\n```csharp\npublic interface IRandomSource\n{\n    int Next();\n    int Next(int maxValue);\n    int Next(int minValue, int maxValue);\n    long NextInt64();\n    long NextInt64(long maxValue);\n    long NextInt64(long minValue, long maxValue);\n    double NextDouble();\n    float NextSingle();\n    void NextBytes(Span<byte> buffer);\n}\n\n// Existing constructor remains\npublic sealed class MLContext\n{\n    public MLContext(int? seed = null) : this(seed, rng: null) { }\n\n    public MLContext(int? seed, IRandomSource? rng)\n    {\n        _rng = rng ?? new RandomSourceAdapter(seed is null ? Random.Shared : new Random(seed.Value));\n        // ... existing initialization\n    }\n\n    internal IRandomSource RandomSource => _rng;\n    private readonly IRandomSource _rng;\n}\n\ninternal sealed class RandomSourceAdapter : IRandomSource\n{\n    private readonly Random _rand;\n    public RandomSourceAdapter(Random rand) => _rand = rand;\n    public int Next() => _rand.Next();\n    public int Next(int maxValue) => _rand.Next(maxValue);\n    public int Next(int minValue, int maxValue) => _rand.Next(minValue, maxValue);\n    public long NextInt64() => _rand.NextInt64();\n    public long NextInt64(long maxValue) => _rand.NextInt64(maxValue);\n    public long NextInt64(long minValue, long maxValue) => _rand.NextInt64(minValue, maxValue);\n    public double NextDouble() => _rand.NextDouble();\n    public float NextSingle() => _rand.NextSingle();\n    public void NextBytes(Span<byte> buffer) => _rand.NextBytes(buffer);\n}\n","Url":"https://github.com/dotnet/machinelearning/issues/7502","RelatedDescription":"Open issue \"Proposal: Pluggable RNG in MLContext (enable deterministic, portable RNGs like MT19937)\" (#7502)"}],"ResultType":"GitHubIssue"}},"RunOn":"2025-10-24T03:30:22.4279668Z","RunDurationInMilliseconds":639}