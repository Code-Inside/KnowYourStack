{"Data":{"GitHub":{"Issues":[{"Id":"1901058511","IsPullRequest":true,"CreatedAt":"2023-09-18T14:21:54","Actor":"asmirnov82","Number":"6830","RawContent":null,"Title":"Simplify tt files for PrimitiveDataFrameColumnAritmetics","State":"open","Body":"Simplify tt files for PrimitiveDataFrameColumnAritmetics, reduce amount of code lines in PrimitiveDataFrameColumnArithmetic.cs","Url":"https://github.com/dotnet/machinelearning/pull/6830","RelatedDescription":"Open PR \"Simplify tt files for PrimitiveDataFrameColumnAritmetics\" (#6830)"},{"Id":"1900842922","IsPullRequest":false,"CreatedAt":"2023-09-18T12:35:50","Actor":"novelhawk","Number":"6829","RawContent":null,"Title":"[DataFrame] Null Reference on ElementwiseEquals on DateTime columns from DataFrame ","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] Windows 10\r\n - ML.NET Version: [e.g. ML.NET v1.5.5] N/A\r\n - Microsoft.Data.Analysis Version: 0.20.1\r\n - .NET Version: [e.g. .NET 5.0]: 7.0.110\r\n\r\n**Describe the bug**\r\nInvoking ElementwiseEquals on a PrimitiveDataFrameColumn<DateTime> obtained by accessing DataFrame[\"ColumnName\"] throws NullReferenceException\r\n\r\n**To Reproduce**\r\n1. Create a PrimitiveDataFrameColumn<DateTime> with some values\r\n2. Create a dataframe with the column using its constructor\r\n3. Access the dataframe's column by using the `this[string column]` getter, es: `df[\"ColumnName\"]`\r\n4. Call the ElementwiseEquals method on the column obtained through the DataFrame\r\n5. Observe that a NullReferenceException is thrown.\r\n6. Call the same method on the column passed to the DataFrame constructor.\r\n7. Observe that no exceptions are thrown\r\n\r\n**Expected behavior**\r\n`df[\"Test\"]` should behave like `column` and should not throw exceptions.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nReproduction example:\r\n```\r\n#r \"nuget: Microsoft.Data.Analysis, 0.20.1\"\r\nusing Microsoft.Data.Analysis;\r\n\r\nvar column = new DateTimeDataFrameColumn(\"Test\");\r\ncolumn.Append(DateTime.Today);\r\nvar df = new DataFrame(column);\r\nConsole.WriteLine(column == df[\"Test\"]); // true\r\nConsole.WriteLine(column.ElementwiseEquals(DateTime.Today).Any()); // True\r\ndf[\"Test\"].ElementwiseEquals(DateTime.Today) // Throws NullReferenceException\r\n```\r\n\r\n**Stack trace**\r\nError: System.NullReferenceException: Object reference not set to an instance of an object.\r\nat Microsoft.Data.Analysis.PrimitiveDataFrameColumn`1.ElementwiseEqualsImplementation[U](U value)\r\nat Microsoft.Data.Analysis.PrimitiveDataFrameColumn`1.ElementwiseEquals[U](U value)\r\nat Submission#6.<<Initialize>>d__0.MoveNext()\r\n--- End of stack trace from previous location ---\r\nat Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6829","RelatedDescription":"Open issue \"[DataFrame] Null Reference on ElementwiseEquals on DateTime columns from DataFrame \" (#6829)"},{"Id":"1896762412","IsPullRequest":false,"CreatedAt":"2023-09-14T14:59:35","Actor":"luisquintanilla","Number":"6828","RawContent":null,"Title":"[Tokenizers] BPE Optional Arguments Required","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 0.21.0-preview.23266.6\r\n - .NET Version: .NET 7\r\n\r\n**Describe the bug**\r\n\r\nThe `mergeFile` is set as an optional argument in the BPE model class. \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/09b80f8a08340dc7d79ac75e13c722313f0845eb/src/Microsoft.ML.Tokenizers/Model/BPE.cs#L91-L138\r\n\r\nHowever, when I initialize the BPE model without a merges file, it throws an error. \r\n\r\n```csharp\r\nvar tokenizer = new Tokenizer(new Bpe(@\"C:\\Dev\\torchsharp-playground\\assets\\vocab\\e5-small-v2-vocab.txt\"));\r\n```\r\n\r\n```text\r\nError: (1,35): error CS7036: There is no argument given that corresponds to the required parameter 'mergesFile' of 'Bpe.Bpe(string, string?, string?, string?, string?)'\r\n```\r\n\r\nVocab file used: [https://huggingface.co/intfloat/e5-small-v2/raw/main/vocab.txt](https://huggingface.co/intfloat/e5-small-v2/raw/main/vocab.txt)\r\n\r\n**Expected behavior**\r\nNew tokenizer is created using only vocab file.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6828","RelatedDescription":"Open issue \"[Tokenizers] BPE Optional Arguments Required\" (#6828)"},{"Id":"1896480246","IsPullRequest":true,"CreatedAt":"2023-09-14T12:34:07","Actor":"asmirnov82","Number":"6827","RawContent":null,"Title":"Add performance benchmarks for dataframe arithmetic operations ","State":"open","Body":"fixes #6826 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6827","RelatedDescription":"Open PR \"Add performance benchmarks for dataframe arithmetic operations \" (#6827)"},{"Id":"1896366911","IsPullRequest":false,"CreatedAt":"2023-09-14T11:27:08","Actor":"asmirnov82","Number":"6826","RawContent":null,"Title":"Add performance benchmarks for dataframe arithmetic operations","State":"open","Body":"Add performance benchmarks for dataframe arithmetic operations\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6826","RelatedDescription":"Open issue \"Add performance benchmarks for dataframe arithmetic operations\" (#6826)"},{"Id":"1896015153","IsPullRequest":false,"CreatedAt":"2023-09-14T08:22:05","Actor":"asmirnov82","Number":"6825","RawContent":null,"Title":"Improve Nullable support during dataframe arithmetic operations and avoid excessive cloning of the left side","State":"open","Body":"In arithmetic operation we perform cloning the left side column into result to have validity bitmap and than check the right side validity bitmap to check for NULL values.\r\n\r\nFor example for Multiply we do cloning if inPlace is set to false (default behavior):\r\n\r\n```\r\nPrimitiveDataFrameColumn<U> newColumn = inPlace ? primitiveColumn : primitiveColumn.Clone();\r\nnewColumn._columnContainer.Multiply(column._columnContainer);\r\n```\r\nand inside container for each value we check validity:\r\n\r\n```\r\n for (int i = 0; i < span.Length; i++)\r\n {\r\n     if (BitmapHelper.IsValid(right.NullBitMapBuffers[b].ReadOnlySpan, i))\r\n     {\r\n         span[i] = (double)(span[i] * otherSpan[i]);\r\n     }\r\n     else\r\n     {\r\n         left[index] = null;\r\n     }\r\n\r\n     index++;\r\n }\r\n```\r\n\r\nThis is very slow operation. Instead we can create new empty column for results to avoid cloning. Also we can calculate Raw values and then use logic and for the left and the right bitmaps for calculating result validity:\r\n\r\n```\r\n//calculate raw values\r\nfor (int i = 0; i < span.Length; i++)\r\n{                \r\n    resultSpan[i] =  (double)(span[i] * otherSpan[i]);\r\n}\r\n\r\n//Calculate validity (nulls)\r\nresultValidityBitmap = Bitmap.ElementWiseAnd(validityBitmap, otherValidityBitmap));\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6825","RelatedDescription":"Open issue \"Improve Nullable support during dataframe arithmetic operations and avoid excessive cloning of the left side\" (#6825)"},{"Id":"1895944157","IsPullRequest":false,"CreatedAt":"2023-09-14T07:45:24","Actor":"asmirnov82","Number":"6824","RawContent":null,"Title":"Improve DataFrame Performance","State":"open","Body":"DataFrame performance is relatively slow and can be improved. \r\n\r\nAs this is a complex issue, it has sence to split it into several independent steps. This Issue is a container for related changes to keep it accessible from one place. Here is the list of proposed changes:\r\n </br>\r\n**Improve Performance of DataFrame Arithmetic Operations**\r\n- [ ]  Improve the speed of  binary Arithmetic operations on columns with the same underlying data type. \r\n\r\n  This can be achived by improving  PrimitiveDataFrame.Clone method to use memory block coping. Avoid using CloneAs method, that involves type conversion for columns with the same data type\r\n\r\n  PR: https://github.com/dotnet/machinelearning/pull/6814\r\n \r\n- [ ] Reduce the number of copies in binary operations for columns with different type of underlying data (for example In32DataFrameColumn + Int16DataframeColumn). \r\n\r\n  We make copies of columns in the binary operation APIs mostly to reuse existing code. This is a wellknown issue. there are already tasks for eliminate excessive coping and g the binary operations behavior when types mismatch\r\n\r\n  Issue: https://github.com/dotnet/machinelearning/issues/5663\r\n  Issue: https://github.com/dotnet/machinelearning/issues/5665\r\n \r\n- [ ] Increase speed of PrimitiveDataFrameColumn initialization, by fixing AppendMany(value, count) method, that is used in all PrimitiveDataFrameColumn constructors\r\n\r\n  PR: https://github.com/dotnet/machinelearning/pull/6822\r\n\r\n- [ ] Improve Nullable support during arithmetic operations\r\n \r\n  Issue: https://github.com/dotnet/machinelearning/issues/6825\r\n\r\n- [ ] Consider how to implement Nullable support in Elementwise operations without any decrease in performance\r\n\r\n  Issue: https://github.com/dotnet/machinelearning/issues/6820\r\n\r\n- [ ] Use Simd vectorization\r\n\r\n  Issue: https://github.com/dotnet/machinelearning/issues/5695\r\n\r\n- [ ] Add performance benchmarks\r\n\r\n  Issue: https://github.com/dotnet/machinelearning/issues/6826\r\n  PR: https://github.com/dotnet/machinelearning/pull/6827\r\n</br>\r\n\r\n**Improve Performance of Filtering**\r\n\r\n- [ ] Faster way to Filter\r\n\r\n  Issue: https://github.com/dotnet/machinelearning/issues/6164\r\n </br>\r\n\r\n**Improve Performance of Indexing** \r\n\r\n- [ ] Accessing DataFramePrimitiveColumn elements by index involve converting Memory<byte> to Span<T> on each operation. That is very slow operation. we can consider using unmanaged memory in DataFrameBuffer instead. This also solves the issue with converting To/From Apache Arrow and heavy load on GC\r\n\r\n  Issue: https://github.com/dotnet/machinelearning/issues/5966\r\n  Issue: https://github.com/dotnet/machinelearning/issues/6715\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6824","RelatedDescription":"Open issue \"Improve DataFrame Performance\" (#6824)"},{"Id":"1895004059","IsPullRequest":false,"CreatedAt":"2023-09-13T18:00:29","Actor":"andrei-faber","Number":"6823","RawContent":null,"Title":"The project won't build","State":"open","Body":"**System Information (please complete the following information):**\r\nWindows 11 x64\r\n.NET 7.0.111, latest source code\r\n\r\n**Describe the bug**\r\nBuild error:\r\n```\r\nD:\\Projects.Ext\\machinelearning\\src\\Native\\Native.proj(133,5): error MSB3073: The command \"\"D:\\Projects.Ext\\machinelearning\\src\\Native\\build.cmd\" Debug x64 --mkllibpath C:\\Users\\andreifaber\\.nuget\\packages\\mlnetmkldeps\\0. 0.0.12\\runtimes\\win-x64\\native --onedaldevelpath C:\\Users\\andreifaber\\.nuget\\packages\\inteldal.devel.win-x64\\2023.0.0.23189\\build\\native\\daal\\latest --onetbbdevelpath C:\\Users\\andreifaber\\.nuget\\packages\\inteltbb.devel.wi n\\2021.7.1.15305\\lib\\native\\win-x64\" exited with code 1.\r\nD:\\Projects.Ext\\machinelearning\\Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"D:\\Projects.Ext\\machinelearning\\artifacts\\bin\\Native\\x64.Debug\\CpuMathNative.dll\" because it was not found. [D:\\Projec ts.Ext\\machinelearning\\test\\Microsoft.ML.CpuMath.PerformanceTests\\Microsoft.ML.CpuMath.PerformanceTests.csproj::TargetFramework=net6.0]\r\nD:\\Projects.Ext\\machinelearning\\Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"D:\\Projects.Ext\\machinelearning\\artifacts\\bin\\Native\\x64.Debug\\LdaNative.dll\" because it was not found. [D:\\Projects.E xt\\machinelearning\\src\\Microsoft.ML\\Microsoft.ML.csproj]\r\n    0 Warning(s)\r\n    3 Error(s)\r\n```\r\n\r\n**To Reproduce**\r\nbuild.cmd -configuration Debug /p:TargetArchitecture=x64\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6823","RelatedDescription":"Open issue \"The project won't build\" (#6823)"},{"Id":"1894936714","IsPullRequest":true,"CreatedAt":"2023-09-13T17:12:30","Actor":"asmirnov82","Number":"6822","RawContent":null,"Title":"PrimitiveDataFrameColumn.Clone method crashes when is used with IEnumerable mapIndices argument","State":"open","Body":"In frame of this PR:\r\n\r\n1) Cover PrimitiveDataFrameColumn.Clone method with additional unit tests\r\n2) Use Span.Fill method to init null validity buffer instead of setting individual bits  in a cycle inside AppendMany (value, count) method\r\n\r\n`lastNullBitMapBuffer.RawSpan.Slice(lastNullBitMapBuffer.Length - nullBufferAllocatable, nullBufferAllocatable).Fill(value.HasValue ? (byte)0xFF : (byte)0x0);`\r\n\r\n3) Fixes #6821 \r\n\r\nRoot cause: \r\nusing of _ret[curRow] = value;_ for empty column. \r\nchanged to _ret.Append(value);_\r\n\r\nAdditionaly fix returning columns with parent column type for inheritors of PrimitiveDataFrame<T> in Clone method\r\n\r\n4) Refactoring: Fixing 3 and 2 allowed to get rid of _internal bool _modifyNullCountWhileIndexing_ field.","Url":"https://github.com/dotnet/machinelearning/pull/6822","RelatedDescription":"Open PR \"PrimitiveDataFrameColumn.Clone method crashes when is used with IEnumerable mapIndices argument\" (#6822)"},{"Id":"1894905497","IsPullRequest":false,"CreatedAt":"2023-09-13T16:49:38","Actor":"asmirnov82","Number":"6821","RawContent":null,"Title":"Primitive DataFrame Column Clone method crashes with IEnumerable argument","State":"open","Body":"public PrimitiveDataFrameColumn<T> Clone(IEnumerable<long> mapIndices) - crashes with _**System.ArgumentOutOfRangeException: 'rowIndex Parameter name: Index cannot be greater than the Column's Length'**_ exception\r\n\r\nSimple unti test:\r\n\r\n```\r\n[Fact]\r\npublic void TestNotNullableColumnCloneWithIndicesMapAsEnumerable()\r\n{\r\n    //Arrange\r\n    var column = new Int32DataFrameColumn(\"Int column\", values: new[] { 0, 5, 2, 4, 1, 3 });\r\n    var indicesMap = new long[] { 0, 1, 2, 5, 3, 4 };\r\n\r\n    //Act\r\n    var clonedColumn = column.Clone(indicesMap);\r\n\r\n    //Assert\r\n    Assert.NotSame(column, clonedColumn);\r\n    Assert.Equal(column.Name, clonedColumn.Name);\r\n    Assert.Equal(column.DataType, clonedColumn.DataType);\r\n    Assert.Equal(column.NullCount, clonedColumn.NullCount);\r\n    Assert.Equal(indicesMap.Length, clonedColumn.Length);\r\n\r\n    for (int i = 0; i < indicesMap.Length; i++)\r\n        Assert.Equal(column[indicesMap[i]], clonedColumn[i]);\r\n}\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6821","RelatedDescription":"Open issue \"Primitive DataFrame Column Clone method crashes with IEnumerable argument\" (#6821)"},{"Id":"1894429353","IsPullRequest":false,"CreatedAt":"2023-09-13T12:31:52","Actor":"asmirnov82","Number":"6820","RawContent":null,"Title":"All DataFrame Elementwise methods uncorrectly work with NULL values","State":"open","Body":"**Describe the bug**\r\nPrimitiveColumn ElementwiseEquals, ElementwizeNotEquals and other Elementwise method ignore validity information\r\n\r\nFor example. this unit test fails as it ElementWizeEquals return true for the first item ( as 0 == null):\r\n\r\n```\r\n[Fact]\r\npublic void TestElementWiseEquals()\r\n{\r\n    PrimitiveDataFrameColumn<int> intColumn1 = new PrimitiveDataFrameColumn<int>(\"Int1\", new int?[] { 0, 2, 3 });\r\n    PrimitiveDataFrameColumn<int> intColumn2 = new PrimitiveDataFrameColumn<int>(\"Int2\", new int?[] { null, 2, 3 });\r\n\r\n    var results = intColumn1.ElementwiseEquals(intColumn2);\r\n\r\n    Assert.False(results[0]);\r\n}\r\n```\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6820","RelatedDescription":"Open issue \"All DataFrame Elementwise methods uncorrectly work with NULL values\" (#6820)"},{"Id":"1892257616","IsPullRequest":false,"CreatedAt":"2023-09-12T10:54:55","Actor":"superichmann","Number":"6819","RawContent":null,"Title":"estimator save not working","State":"open","Body":"when trying to save `EstimatorChain<NormalizingTransformer>` with the save function I get: \r\n`BinaryFormatter serialization and deserialization are disabled within this application`\r\nCan you please fix the code in such a way that it will actually work?","Url":"https://github.com/dotnet/machinelearning/issues/6819","RelatedDescription":"Open issue \"estimator save not working\" (#6819)"},{"Id":"1891370080","IsPullRequest":false,"CreatedAt":"2023-09-11T22:32:26","Actor":"kayhustle","Number":"6818","RawContent":null,"Title":"Does ML .net support Z Score Normalization?","State":"open","Body":"I'm trying to calculate the z score normalized transform using ML.net TransformsCatalog. In Python this is achieved using the StandardScaler transform. I don't see this mentioned in the list of transforms. Is this type of transformation supported via one of the supported transformations?\r\nThanks","Url":"https://github.com/dotnet/machinelearning/issues/6818","RelatedDescription":"Open issue \"Does ML .net support Z Score Normalization?\" (#6818)"},{"Id":"1889071285","IsPullRequest":false,"CreatedAt":"2023-09-10T09:29:09","Actor":"Ceeeeed","Number":"6817","RawContent":null,"Title":"LightGMB bad allocation crash","State":"open","Body":" - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET v2.0.1 & AutoML v0.20.1\r\n - .NET Version: .NET 7.0\r\n - 16gb ram\r\n - 4 cores\r\n \r\nHello, \r\nduring an AutoML regression training session, after more than three hours of training and successful training of 5 models `[LightGBM] [Warning] bad allocation` warnings shows in the console, and after a while the program crashes.\r\n\r\n### About my dataset:\r\n111 275 columns and 872 rows (including label column). Contains only floats from -1 to 1.\r\n\r\n### Code responsible for training the model:\r\n```cs\r\npublic async Task<IEnumerable<TrialResult>> TrainModel(DataOperationsCatalog.TrainTestData trainValidationData)\r\n{\r\n    Logger.Log($\"Running the experiment...\");\r\n\r\n    AutoMLExperiment experiment = MLContext.Auto().CreateExperiment();\r\n\r\n    experiment\r\n        .SetPipeline(pipeline)\r\n        .SetRegressionMetric(RegressionMetric.MeanAbsoluteError)\r\n        .SetTrainingTimeInSeconds(maxTrainingTime)\r\n        .SetDataset(trainValidationData);\r\n\r\n    CancellationTokenSource cts = new();\r\n\r\n    AutoMLMonitor monitor = new(pipeline, maxTrainingTime, maxTrainingIterations, cts);\r\n    experiment.SetMonitor(monitor);\r\n\r\n    await experiment.RunAsync(cts.Token);\r\n    return monitor.GetCompletedTrials();\r\n}\r\n```\r\n\r\n### My pipeline is simple:\r\n```cs\r\npipeline = MLContext.Auto().Regression(useFastForest: false, useFastTree: false, useLbfgs: false, useLgbm: true, useSdca: false);\r\n```\r\n\r\n### Logs: \r\n(In the timestamp, the first number is the application running time (hh:mm) and the second number is the local time (hh:mm:ss))\r\n```\r\n[0:00 - 06:59:59] Loading data set...\r\n[0:01 - 07:01:09] Creating data view...\r\n[0:01 - 07:01:11] Running the experiment...\r\n[0:01 - 07:01:11] Model 1 started training using LightGbmRegression algorithm\r\n[0:01 - 07:01:20] 10s/80000s (0.01 %) - Model finished training in 9.44s using LightGbmRegression algorithm (CPU: 95.51 %, RAM: 1828.41) - result: 15.08 %\r\n[0:01 - 07:01:20] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (15.08 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[0:01 - 07:01:20] Model 2 started training using LightGbmRegression algorithm\r\n[0:03 - 07:02:42] 91s/80000s (0.11 %) - Model finished training in 81.75s using LightGbmRegression algorithm (CPU: 102.15 %, RAM: 1971.35) - result: 8.46 %\r\n[0:03 - 07:02:42] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (8.46 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[0:03 - 07:02:42] Model 3 started training using LightGbmRegression algorithm\r\n[0:10 - 07:09:56] 526s/80000s (0.66 %) - Model finished training in 434.11s using LightGbmRegression algorithm (CPU: 101.56 %, RAM: 2008.12) - result: 6.49 %\r\n[0:10 - 07:09:56] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (6.49 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[0:10 - 07:09:56] Model 4 started training using LightGbmRegression algorithm\r\n[3:09 - 10:08:58] 11267s/80000s (14.08 %) - Model finished training in 10741.15s using LightGbmRegression algorithm (CPU: 104.30 %, RAM: 5345.96) - result: 5.58 %\r\n[3:09 - 10:08:58] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (5.58 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[3:09 - 10:08:58] Model 5 started training using LightGbmRegression algorithm\r\n[3:21 - 10:20:58] 11987s/80000s (14.98 %) - Model finished training in 720.38s using LightGbmRegression algorithm (CPU: 102.34 %, RAM: 2526.46) - result: 8.69 %\r\n[3:21 - 10:20:58] Model 6 started training using LightGbmRegression algorithm\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] [LightGBM] [Warning] bad allocation\r\nbad allocation\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] bad allocation\r\n(...) more of those\r\n```\r\n[full log.txt](https://github.com/dotnet/machinelearning/files/12567896/full.log.txt)","Url":"https://github.com/dotnet/machinelearning/issues/6817","RelatedDescription":"Open issue \"LightGMB bad allocation crash\" (#6817)"},{"Id":"1888932369","IsPullRequest":true,"CreatedAt":"2023-09-10T02:00:23","Actor":"feiyun0112","Number":"6816","RawContent":null,"Title":"use HingeLoss as default loss function","State":"open","Body":"#6815 \r\n\r\n[StandardTrainersCatalog.AveragedPerceptron](https://github.com/dotnet/machinelearning/blob/09b80f8a08340dc7d79ac75e13c722313f0845eb/src/Microsoft.ML.StandardTrainers/StandardTrainersCatalog.cs#L429C13-L429C196) factory method uses LogLoss as its default loss function, which contradicts method documentation and defaults.AveragedPerceptronTrainer.Options","Url":"https://github.com/dotnet/machinelearning/pull/6816","RelatedDescription":"Open PR \"use HingeLoss as default loss function\" (#6816)"},{"Id":"1888804877","IsPullRequest":false,"CreatedAt":"2023-09-09T16:26:14","Actor":"KirillShlenskiy","Number":"6815","RawContent":null,"Title":"AveragedPerceptron factory method uses wrong default loss function","State":"open","Body":"**System Information:**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 3.0.0-preview.23266.6\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\n[StandardTrainersCatalog.AveragedPerceptron](https://github.com/dotnet/machinelearning/blob/09b80f8a08340dc7d79ac75e13c722313f0845eb/src/Microsoft.ML.StandardTrainers/StandardTrainersCatalog.cs#L429C13-L429C196) factory method uses LogLoss as its default loss function, which contradicts method documentation and `AveragedPerceptronTrainer.Options` defaults.\r\n\r\n`AveragedPerceptron` method summary states:\r\n> `<param name=\"lossFunction\">`The <a href=\"https://en.wikipedia.org/wiki/Loss_function\">loss</a> function minimized in the training process. If null, HingeLoss would be used and lead to a max-margin averaged perceptron trainer.`</param>`\r\n\r\nThis results in the following inconsistency in behaviour:\r\n```CSharp\r\n// Uses LogLoss:\r\nMLContext.BinaryClassification.Trainers.AveragedPerceptron(\"Label\");\r\n\r\n// Uses HingeLoss:\r\nMLContext.BinaryClassification.Trainers.AveragedPerceptron(new AveragedPerceptronTrainer.Options { LabelColumnName = \"Label\" });\r\n```\r\n\r\n**Expected behavior**\r\n2 options:\r\n- Make the non-options `AveragedPerceptron` factory method overload use `HingeLoss` as its default loss function (breaking change).\r\n- Amend the method documentation.","Url":"https://github.com/dotnet/machinelearning/issues/6815","RelatedDescription":"Open issue \"AveragedPerceptron factory method uses wrong default loss function\" (#6815)"},{"Id":"1888195901","IsPullRequest":true,"CreatedAt":"2023-09-08T19:16:42","Actor":"asmirnov82","Number":"6814","RawContent":null,"Title":"Improve performance of column cloning inside DataFrame arithmetics","State":"open","Body":"The goal of this PR is to perform Arithmetics operation on columns with the same underlying data type approximately 3 times faster.\r\n\r\nDetail of changes:\r\n\r\n1) Fix PrimitiveColumnContainer Clone() method to use memory block coping for internal buffer instead of appending values one by one (with memory reallocation on each buffer resizing cycle). Do similar changes for CloneNullBitMapBuffers() method\r\n\r\n2)  Improve BinaryOperation.Implementation methods for all Arithmetic operations that happen not in place (default behavior). \r\nBefore the change autogenerated code looked like this:\r\n\r\n```\r\npublic partial class SingleDataFrameColumn\r\n{\r\n    internal SingleDataFrameColumn AddImplementation(SingleDataFrameColumn column, bool inPlace = false)\r\n    {\r\n        if (column.Length != Length)\r\n        {\r\n            throw new ArgumentException(Strings.MismatchedColumnLengths, nameof(column));\r\n        }\r\n        SingleDataFrameColumn newColumn = inPlace ? this : CloneAsSingleColumn();\r\n        newColumn.ColumnContainer.Add(column.ColumnContainer);\r\n        return newColumn;\r\n    }\r\n}\r\n```\r\n\r\nAfter PR https://github.com/dotnet/machinelearning/pull/6677 CloneAsSingleColumn can be changed to just this.Clone(). This allow to avoid unnecessary type conversion, that happens inside CloneAs... method and use fast Clone() method with bulk memory copy for internal buffers. For example. for Single:\r\n\r\n```\r\ninternal PrimitiveColumnContainer<float> CloneAsFloatContainer()\r\n{\r\n ...\r\n    for (int i = 0; i < span.Length; i++)\r\n   {\r\n          newBuffer.Append(SingleConverter<T>.Instance.GetSingle(span[i]);\r\n   }\r\n}\r\n```\r\n\r\n3) Fix DataFrameBuffer constructor. \r\nDataFrameBuffer overrides parent ReadOnlyDataFrameBuffer ReadOnlyBuffer to return own new field _memory instead of parent _readOnlyBuffer (after this parent _readonlybuffer is ignored and never used). However in constructor _memory is not created, instead base constructor is called to allocate _readonlybuffer (which is ignored). So after creating Capacity of such buffer is always 0 (ignoring the actual parameter passed to the constructor) and additional memory is allocated\r\n\r\n4) After 3 is fixed, changed code to use DataFrameBuffer constructor with capacity instead of creating empty dataframe buffer and than reallocating memory by calling EnsureCapacity \r\n\r\n___________________________\r\n\r\nResult:\r\n\r\nSimple tests for 1 million of rows:\r\n\r\n```\r\n[GlobalSetup]\r\npublic void SetUp()\r\n{\r\n    var values = Enumerable.Range(0, ItemsCount);\r\n    _column1 = new Int32DataFrameColumn(\"Column1\", values);\r\n    _column2 = new Int32DataFrameColumn(\"Column2\", values);\r\n}\r\n\r\n[Benchmark]\r\npublic void Sum()\r\n{\r\n    var column = _column1 + _column2;\r\n}\r\n```\r\n\r\n```\r\nBefore PR:\r\n| Method |    Mean |     Error |   StdDev |\r\n|    Sum | 18.02 ms | 0.090 ms | 0.080 ms |\r\n\r\nAfter PR:\r\n| Method |     Mean |     Error |    StdDev |\r\n|    Sum | 6.896 ms | 0.1363 ms | 0.1673 ms |\r\n```\r\n\r\nPart of #6824 issue","Url":"https://github.com/dotnet/machinelearning/pull/6814","RelatedDescription":"Open PR \"Improve performance of column cloning inside DataFrame arithmetics\" (#6814)"},{"Id":"1884483922","IsPullRequest":true,"CreatedAt":"2023-09-08T19:13:01","Actor":"michaelgsharp","Number":"6811","RawContent":null,"Title":"removed codecov token","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6811","RelatedDescription":"Closed or merged PR \"removed codecov token\" (#6811)"},{"Id":"1888170048","IsPullRequest":true,"CreatedAt":"2023-09-08T18:53:48","Actor":"michaelgsharp","Number":"6813","RawContent":null,"Title":"added in win-arm64","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6813","RelatedDescription":"Open PR \"added in win-arm64\" (#6813)"},{"Id":"1884875445","IsPullRequest":false,"CreatedAt":"2023-09-06T23:17:17","Actor":"andrewtek","Number":"6812","RawContent":null,"Title":"Need a supported way to get Eigenvectors from PrincipalComponentAnalysisTransformer","State":"open","Body":"I am wanting to evaluate the Eigenvectors when performing Principal Component Analysis. Unfortunately, these appear to locked away inside a private field of PrincipalComponentAnalysisTransformer. \r\n\r\nUsing reflection, I can get the private _transformInfos field from my fitted instance of PrincipalComponentAnalysisTransformer. This provides me with an array of the private internal class TransformInfo. From here, I can use reflection to get the first array entry's Eigenvectors field which will return my float[][] array.\r\n\r\nWould it be possible to add a \"GetEigenvectors\" method to PrincipalComponentAnalysisTransformer that returns this float[][] data? ","Url":"https://github.com/dotnet/machinelearning/issues/6812","RelatedDescription":"Open issue \"Need a supported way to get Eigenvectors from PrincipalComponentAnalysisTransformer\" (#6812)"},{"Id":"1881808819","IsPullRequest":false,"CreatedAt":"2023-09-05T11:45:19","Actor":"ogoun","Number":"6810","RawContent":null,"Title":"Fault convert to ONNX object detection model","State":"open","Body":"**System Information:**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET v3.0.0-preview.23266.6\r\n - .NET Version: .NET 7.0\r\n\r\n**Describe the bug**\r\nFault conversion to ONNX\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Train object detection model by tutorial (https://devblogs.microsoft.com/dotnet/object-detection-ml-dotnet-model-builder/)\r\n2. Try convert model\r\n```charp\r\npublic class ModelInput\r\n        {\r\n            [LoadColumn(0)]\r\n            [ColumnName(@\"Labels\")]\r\n            public string[] Labels { get; set; }\r\n\r\n            [LoadColumn(1)]\r\n            [ColumnName(@\"Image\")]\r\n            [Microsoft.ML.Transforms.Image.ImageType(640, 640)]\r\n            public MLImage Image { get; set; }\r\n\r\n            [LoadColumn(2)]\r\n            [ColumnName(@\"Box\")]\r\n            public float[] Box { get; set; }\r\n\r\n        }\r\n\r\npublic static void Export()\r\n        {\r\n            var onnxPath = \"test.onnx\";\r\n            var mlContext = new MLContext();\r\n            ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var _);\r\n\r\n            var input = new ModelInput[30];\r\n            for (int i = 0; i < input.Length; i++)\r\n            {\r\n                input[i] = new ModelInput\r\n                {\r\n                    Image = MLImage.CreateFromFile(@\"demo.jpg\")\r\n                };\r\n            }\r\n            IDataView trainingData = mlContext.Data.LoadFromEnumerable(input);\r\n            using (var onnx = File.Open(onnxPath, FileMode.OpenOrCreate))\r\n            {\r\n                mlContext.Model.ConvertToOnnx(mlModel, trainingData, onnx);\r\n            }\r\n        }\r\n```\r\n3. Got error\r\nSystem.InvalidOperationException: 'Unsupported type: Microsoft.ML.Data.MLImage'\r\n\r\n**Expected behavior**\r\nGot onnx model\r\n\r\n**Additional context**\r\nIf I try to represent the input as an array [B,3,W,H], it says that it expects an image, when I pass the image, it says that it does not support it.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6810","RelatedDescription":"Open issue \"Fault convert to ONNX object detection model\" (#6810)"},{"Id":"1878973631","IsPullRequest":false,"CreatedAt":"2023-09-03T07:24:30","Actor":"Chiragjasuja","Number":"6809","RawContent":null,"Title":"Add support for Apache.Arrow.Types.TimestampType","State":"open","Body":"**System Information (please complete the following information):**\r\n - Win 10\r\n - Microsoft.Data.Analysis v0.20.1\r\n - .NET Version: .NET 6\r\n\r\n**Describe the bug**\r\nI am getting below exception \r\n\r\nUnhandled exception. System.NotImplementedException: timestamp\r\n   at Microsoft.Data.Analysis.DataFrame.AppendDataFrameColumnFromArrowArray(Field field, IArrowArray arrowArray, DataFrame ret, String fieldNamePrefix)\r\n   at Microsoft.Data.Analysis.DataFrame.FromArrowRecordBatch(RecordBatch recordBatch)\r\n   at Program.<Main>$(String[] args) in C:\\Users\\mrchi\\source\\repos\\ApacheArrowExample\\ApacheArrowExample\\Program.cs:line 17\r\n   at Program.<Main>(String[] args)\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Take a .arrow file with one column of type Apache.Arrow.Types.TimestampType\r\n2. var dataframe = DataFrame.FromArrowRecordBatch(recordBatch);\r\n3. It will throw above exception\r\n\r\n**Expected behavior**\r\nThe record batch should transform to Dataframe with appropriate tye to handle timestamp (Datetime maybe)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6809","RelatedDescription":"Open issue \"Add support for Apache.Arrow.Types.TimestampType\" (#6809)"},{"Id":"1865835159","IsPullRequest":false,"CreatedAt":"2023-09-02T04:06:56","Actor":"pi-curst","Number":"6806","RawContent":null,"Title":"Append Datafarmes","State":"closed","Body":"**System Information (please complete the following information):**\r\n - .NET Version: [e.g. .NET 6.0.301]\r\n\r\n**Describe the bug**\r\n\r\nHi, Appending Dataframes (DataFrame.Append Method) doesn't seem to append based on column names, but appends based on the position. Is this normal?\r\n\r\n**To Reproduce**\r\n\r\n`var data = new DataFrame(); \r\n\r\nvar col1 = new StringDataFrameColumn(\"ColumnA\", new string[] { \"a\", \"b\", \"c\", \"d\", \"e\" });\r\nvar col2 = new Int32DataFrameColumn(\"ColumnB\", new int[] { 1, 2, 3, 4, 5 });\r\nvar col3 = new Int32DataFrameColumn(\"ColumnC\", new int[] { 10, 20, 30, 40, 50 });\r\nvar col4 = new StringDataFrameColumn(\"ColumnA\", new string[] { \"f\", \"g\", \"c\", \"d\", \"e\" });\r\nvar col5 = new Int32DataFrameColumn(\"ColumnB\", new int[] { 6, 7, 3, 4, 5 });\r\nvar col6 = new Int32DataFrameColumn(\"ColumnC\", new int[] { 100, 200, 300, 400, 500 });\r\n\r\nvar dataFrame1 = new DataFrame(col1, col2, col3);\r\nvar dataFrame2 = new DataFrame(col4, col6, col5);\r\n\r\nvar dataFrames = new List<DataFrame> { dataFrame1, dataFrame2 };\r\nvar resultDataFrame = dataFrame1.Append(dataFrame2.Rows);`\r\n\r\n\r\n**Exhibited behavior**\r\n\r\nindex | ColumnA | ColumnB | ColumnC\r\n-- | -- | -- | --\r\n0 | a | 1 | 10\r\n1 | b | 2 | 20\r\n2 | c | 3 | 30\r\n3 | d | 4 | 40\r\n4 | e | 5 | 50\r\n5 | f | 100 | 6\r\n6 | g | 200 | 7\r\n7 | c | 300 | 3\r\n8 | d | 400 | 4\r\n9 | e | 500 | 5\r\n\r\n\r\n**Expected behavior**\r\n\r\nindex | ColumnA | ColumnB | ColumnC\r\n-- | -- | -- | --\r\n0 | a | 1 | 10\r\n1 | b | 2 | 20\r\n2 | c | 3 | 30\r\n3 | d | 4 | 40\r\n4 | e | 5 | 50\r\n5 | f | 6 | 100\r\n6 | g | 7 | 200\r\n7 | c | 3 | 300\r\n8 | d | 4 | 400\r\n9 | e | 5 | 500\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6806","RelatedDescription":"Closed issue \"Append Datafarmes\" (#6806)"},{"Id":"1877864231","IsPullRequest":true,"CreatedAt":"2023-09-02T04:06:55","Actor":"asmirnov82","Number":"6808","RawContent":null,"Title":"Append dataframe rows based on column names","State":"closed","Body":"Fixes #6806 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6808","RelatedDescription":"Closed or merged PR \"Append dataframe rows based on column names\" (#6808)"},{"Id":"1875097039","IsPullRequest":false,"CreatedAt":"2023-08-31T09:02:58","Actor":"CodedBeard","Number":"6807","RawContent":null,"Title":"GC pause caused by Tuple<int, int> on model load","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nMy app is quite sensitive to GC pauses, so I've been doing allocation profiling. I noticed that a lot of GC pauses are being caused by the usage of `Tuple<int, int>` within the `Attention` class when the model is loaded.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/aaf226c7e7c359edf27e663362e928e02c8b9d0f/src/Microsoft.ML.TorchSharp/AutoFormerV2/Attention.cs#L72-L79\r\n\r\n**Describe the solution you'd like**\r\nIn my own fork, I've switched to using `ValueTuple`, which has removed the allocations and thus GC pauses\r\n\r\n**Describe alternatives you've considered**\r\nI don't think there's an easier/cleaner fix for this.\r\n\r\n**Additional context**\r\nUsing `Microsoft.ML.TorchSharp` version `0.21.0-preview.23266.6`, I observed 240k allocations of `Tuple<int, int>` during model loading, coming in just after `Tensor`.\r\n\r\n<img width=\"364\" alt=\"ml-allocations\" src=\"https://github.com/dotnet/machinelearning/assets/4446559/532508f8-9bdb-48dc-82da-9ff0be517fb2\">\r\n\r\nAfter switching to `ValueTuple` on my own fork, these allocations were removed, resulting in a significant reduction in CG pauses during model loading.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6807","RelatedDescription":"Open issue \"GC pause caused by Tuple<int, int> on model load\" (#6807)"},{"Id":"1864410786","IsPullRequest":false,"CreatedAt":"2023-08-27T22:18:38","Actor":"l3aalteshuva","Number":"6804","RawContent":null,"Title":"ITransform","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/6804","RelatedDescription":"Closed issue \"ITransform\" (#6804)"},{"Id":"1865657667","IsPullRequest":true,"CreatedAt":"2023-08-24T19:56:15","Actor":"michaelgsharp","Number":"6805","RawContent":null,"Title":"removed deprecated yosemite brew","State":"closed","Body":"Removed the deprecated reference to yosemite in the mac os brew file.","Url":"https://github.com/dotnet/machinelearning/pull/6805","RelatedDescription":"Closed or merged PR \"removed deprecated yosemite brew\" (#6805)"},{"Id":"1864090498","IsPullRequest":false,"CreatedAt":"2023-08-23T22:17:19","Actor":"saibaldas","Number":"6803","RawContent":null,"Title":"Using Roberta-base fine-tuned for boolq exported to ONNX in ML.NET ","State":"open","Body":"Roberta-base fine-tuned for the boolq dataset uses the tokenizer encode_plus to encode both the question and context. When exported to ONNX , the inputs are \r\n\r\nname: input_ids\r\ntensor: int64[batch_size,sequence_length]\r\n\r\nname: attention_mask\r\ntensor: int64[batch_size,sequence_length]\r\n\r\nPlease suggest the steps to run the ONNX for inference in ML.NET . The BertTokenizer can't be used as the tokenizer is BPE\r\nTried to use the https://gist.github.com/luisquintanilla/bc91de8668cfa7c3755b20329fadd027 without much success \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6803","RelatedDescription":"Open issue \"Using Roberta-base fine-tuned for boolq exported to ONNX in ML.NET \" (#6803)"},{"Id":"1863686875","IsPullRequest":false,"CreatedAt":"2023-08-23T16:49:02","Actor":"torronen","Number":"6802","RawContent":null,"Title":"AutoML: consider adding precision in checkpoint file","State":"open","Body":"Nightly, VS 2022, .NET 7.0\r\n\r\nThe checkpoint file has columns with 3-digit precision. In some cases I see loss being exactly the same on every run in the checkpoint file. I would like to confirm it it is exactly (or almost) same prediction. Therefore I would like to see 5-digit values in this file. \r\n\r\nI think, in difficult problems it may also help the tuner to go to correct direction. \r\n\r\nI know it is a minor issue to go 0.01% level but I also think there is no downside to adding precision to this file.\r\n\r\n**Example**\r\nCost-frugal tuner. Are these results not improving because of the type of the data, or because the changes to params are too small? \r\n![image](https://github.com/dotnet/machinelearning/assets/26261427/aefb41af-5ca0-4171-ae65-57b8fdd8b1bd)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6802","RelatedDescription":"Open issue \"AutoML: consider adding precision in checkpoint file\" (#6802)"},{"Id":"1862684347","IsPullRequest":false,"CreatedAt":"2023-08-23T06:52:19","Actor":"superichmann","Number":"6801","RawContent":null,"Title":"Predicted values are not at original scale after applying preFeaturizer","State":"open","Body":"When applying a preFeaturizer on the target column\r\n`var logTransformer = mlContext.Transforms.NormalizeMinMax(\"Label\",fixZero:true);`\r\nwithin a regression experiment, the predicted values\r\n`IDataView preds = result.Model.Transform(predictMe);`\r\nare in the wrong scale.\r\n\r\nOriginal values:\r\n10\r\n22\r\n33\r\n12\r\n6\r\n6\r\n5\r\n\r\nPredictions **without** preFeaturizer:\r\n8.593365\r\n19.133606\r\n19.094164\r\n11.576735\r\n11.040246\r\n10.156776\r\n9.546574\r\n\r\nPredictions **with** preFeaturizer:\r\n0.06661523\r\n0.14832252\r\n0.14801677\r\n0.08974213\r\n0.08558331\r\n0.0787347\r\n0.07400444\r\n\r\nas you can see, the predictions with the preFeaturizer applied are in a totally different scale.\r\n\r\nHow can I actually get the predicted values in the scale of the original target column and not in the scale of the applied transformer? ","Url":"https://github.com/dotnet/machinelearning/issues/6801","RelatedDescription":"Open issue \"Predicted values are not at original scale after applying preFeaturizer\" (#6801)"}],"ResultType":"GitHubIssue"}},"RunOn":"2023-09-19T03:30:19.5569664Z","RunDurationInMilliseconds":496}