{"Data":{"GitHub":{"Issues":[{"Id":"2164114809","IsPullRequest":false,"CreatedAt":"2024-03-01T20:21:08","Actor":"ericstj","Number":"7044","RawContent":null,"Title":"Helix test failures are double counted","State":"open","Body":"**Describe the bug**\r\nWhen a helix test fails *gracefully* the failure should be reported and the runner should return 0.\r\n\r\n**To Reproduce**\r\nExamine a normal test failure for a build.  You'll see the test failure reported and the \"work item\" for the test.  The latter is reported as a failure since the runner returned a non-zero exit value.\r\n\r\n**Expected behavior**\r\nOnly the failing test is reported.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n<img width=\"720\" alt=\"image\" src=\"https://github.com/dotnet/machinelearning/assets/8918108/1957457c-3b22-445b-a762-952125d75f9d\">.\r\n\r\nExample build: https://dev.azure.com/dnceng-public/public/_build/results?buildId=583517&view=ms.vss-test-web.build-test-results-tab&runId=14034000&resultId=100083&paneView=debug\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7044","RelatedDescription":"Open issue \"Helix test failures are double counted\" (#7044)"},{"Id":"2164011427","IsPullRequest":false,"CreatedAt":"2024-03-01T19:05:57","Actor":"tarekgh","Number":"7043","RawContent":null,"Title":"Add more Tokenizer functionality","State":"open","Body":"We need to incorporate the following enhancements into the tokenizer:\r\n\r\n- Enable the creation of tokenizers with streaming capability to avoid on-demand downloading of vocabulary files.\r\n- Introduce an API to facilitate encoding up to a specified maximum token count.\r\n- Introduce API to support encoding text from the end up to the maximum count.","Url":"https://github.com/dotnet/machinelearning/issues/7043","RelatedDescription":"Open issue \"Add more Tokenizer functionality\" (#7043)"},{"Id":"2163714282","IsPullRequest":false,"CreatedAt":"2024-03-01T16:09:02","Actor":"hannespreishuber","Number":"7042","RawContent":null,"Title":"ONNX Vision ","State":"open","Body":".NET 8 ML.NET 3 \r\n\r\nrunning out of ideas exception\r\n\r\ndid a training with customvision.ai - exported and download the onnx.model. Use the ZIP attached cs file and created a UWP app within minutes- works.\r\n\r\nTry to rebuild this stuff with console app. Nothing detected\r\nRepro https://github.com/hannespreishuber/MLNETONNX\r\n\r\n\r\n![onnx1](https://github.com/dotnet/machinelearning/assets/3587156/3f76b858-103d-45c0-8469-59451d40e4fe)\r\n\r\n\r\n```using Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Transforms.Image;\r\nusing Microsoft.ML.Transforms.Onnx;\r\nusing MLNETONNX;\r\n\r\n\r\nstring assetsPath = @\"C:\\\\stateof\\\\MLNETONNX\\\\MLNETONNX\\\\assets\";\r\nvar modelFilePath = Path.Combine(assetsPath, \"model.onnx\");\r\n\r\nvar mlContext = new MLContext();\r\n\r\n//var imageData = new ImageData\r\n//{\r\n//    Image = File.ReadAllBytes(@\"c:\\temp\\test.png\"),\r\n//    ImagePath = @\"c:\\temp\\test.png\"\r\n//};\r\n\r\n\r\n//B\r\nvar imageData = new ImageData\r\n{\r\n    Image = MLImage.CreateFromFile(@\"c:\\temp\\test.png\")\r\n  \r\n};\r\nvar dataView = mlContext.Data.LoadFromEnumerable(new List<ImageData>() );\r\n\r\n//var pipeline =\r\n//    mlContext.Transforms.LoadImages(outputColumnName: \"data\", imageFolder: \"\", inputColumnName: nameof(ImageData.ImagePath))\r\n//    .Append(mlContext.Transforms.ResizeImages(\r\n//                   inputColumnName: \"data\",\r\n//                   outputColumnName: \"data\",\r\n//                   imageWidth: 416,\r\n//                   imageHeight: 416,\r\n//                   resizing: ImageResizingEstimator.ResizingKind.Fill))\r\n//    .Append(mlContext.Transforms.ExtractPixels(inputColumnName:\"data\",\r\n//                   outputColumnName: \"data\"))\r\n//    .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: modelFilePath,\r\n//    outputColumnNames: new[] { \"model_outputs0\" }, \r\n//      inputColumnNames: new[] { \"data\" }));\r\n\r\n//B\r\nvar pipeline =  mlContext.Transforms.ResizeImages(\"data\", 416,416, nameof(ImageData.Image))\r\n        .Append(mlContext.Transforms.ExtractPixels( \"data\",  \"data\"))\r\n        .Append(mlContext.Transforms.ApplyOnnxModel(\"model_outputs0\", \"data\", modelFilePath));\r\n\r\nvar model = pipeline.Fit(dataView);\r\n\r\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<ImageData, List<PredictionModel>>(model);\r\nvar prediction = predictionEngine.Predict(imageData);\r\n\r\nConsole.WriteLine($\"Vorhersage: \");\r\n\r\n\r\n\r\npublic sealed class BoundingBox\r\n{\r\n    public BoundingBox(float left, float top, float width, float height)\r\n    {\r\n        this.Left = left;\r\n        this.Top = top;\r\n        this.Width = width;\r\n        this.Height = height;\r\n    }\r\n\r\n    public float Left { get; private set; }\r\n    public float Top { get; private set; }\r\n    public float Width { get; private set; }\r\n    public float Height { get; private set; }\r\n}\r\n\r\npublic sealed class PredictionModel\r\n{\r\n    public PredictionModel(float[] probability, string tagName, BoundingBox boundingBox)\r\n    {\r\n        this.Probability = probability;\r\n        this.TagName = tagName;\r\n        this.BoundingBox = boundingBox;\r\n    }\r\n   \r\n    public float[] Probability { get; private set; }\r\n    public string TagName { get; private set; }\r\n    public BoundingBox BoundingBox { get; private set; }\r\n}\r\n\r\n//public class ImageData\r\n//{\r\n//    [ImageType(416, 416)]\r\n//    [ColumnName(\"data\")]\r\n//    public byte[] Image { get; set; }\r\n//    public string ImagePath { get; set; }\r\n    \r\n//}\r\n\r\n\r\n//B\r\npublic class ImageData\r\n{\r\n    [ImageType(416, 416)]\r\n    public MLImage Image { get; set; }\r\n\r\n\r\n}`\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7042","RelatedDescription":"Open issue \"ONNX Vision \" (#7042)"},{"Id":"2163659046","IsPullRequest":false,"CreatedAt":"2024-03-01T15:38:44","Actor":"maurice-cote","Number":"7041","RawContent":null,"Title":"Help text for fields are in the source code yet are not present here","State":"open","Body":"\r\nThere is help provided for these fields directly in the source code, I wonder why it wasn't used even in this templated topic\r\n\r\n- Threshold  = \"The threshold to determine anomaly, score larger than the threshold is considered as anomaly.\"\r\n- BatchSize = \"The number of data points to be detected in each batch. It should be at least 12. Set this parameter to -1 to detect anomaly on the entire series.\"\r\n- Sensitivity  = \"This parameter is used in AnomalyAndMargin mode the determine the range of the boundaries.\"\r\n- DetectMode = \"Specify the detect mode as one of AnomalyOnly, AnomalyAndExpectedValue and AnomalyAndMargin.\"\r\n- Period = \"If there is circular pattern in the series, set this value to the number of points in one cycle.\"\r\n- DeseasonalityMode = \"Specify the deseasonality mode as one of stl, mean and median.\"\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for learn.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 3bf2c1e4-4042-be7d-c072-8ee9e0690e48\r\n* Version Independent ID: 0406e897-a227-2397-d4e1-fde038e743c5\r\n* Content: [SrCnnEntireAnomalyDetectorOptions.Threshold Field (Microsoft.ML.TimeSeries)](https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.timeseries.srcnnentireanomalydetectoroptions.threshold?view=ml-dotnet-2.0.0&source=docs)\r\n* Content Source: [dotnet/xml/Microsoft.ML.TimeSeries/SrCnnEntireAnomalyDetectorOptions.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.TimeSeries/SrCnnEntireAnomalyDetectorOptions.xml)\r\n* Service: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/7041","RelatedDescription":"Open issue \"Help text for fields are in the source code yet are not present here\" (#7041)"},{"Id":"2162750436","IsPullRequest":false,"CreatedAt":"2024-03-01T07:07:16","Actor":"harry-hathorn","Number":"7040","RawContent":null,"Title":"ML.Net: System.OutOfMemoryException: 'Exception of type 'System.OutOfMemoryException' was thrown.' on small dataset","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: Microsoft.ML 3.0.1\r\n - .NET Version: 6.0\r\n\r\n**Describe the bug**\r\nAttempt to train model and run into out-of-memory exception, PC doesn't even use 20% of memory. Build for any CPU.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Load data text-based set with 700 000 rows (60mb) and 2 columns (feature and label)\r\n2. Run Transforms.Conversion.MapValueToKey for the Label\r\n3. Run Transforms.Text.FeaturizeText on the Features\r\n4. Append a mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(\"Label\", \"Features\") prediction\r\n5. Attempt to Fit the model\r\n6. Receive an out of memory exception on trainingPipeline.Fit(trainData)\r\n```\r\nSystem.OutOfMemoryException\r\n  HResult=0x8007000E\r\n  Message=Exception of type 'System.OutOfMemoryException' was thrown.\r\n  Source=Microsoft.ML.Core\r\n  StackTrace:\r\n   at Microsoft.ML.Internal.Utilities.VBufferUtils.CreateDense[T](Int32 length)\r\n   at Microsoft.ML.Trainers.SdcaTrainerBase`3.TrainCore(IChannel ch, RoleMappedData data, LinearModelParameters predictor, Int32 weightSetCount)\r\n   at Microsoft.ML.Trainers.StochasticTrainerBase`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Program.<Main>$(String[] args) in C:\\Ml.Product.2\\Ml.Product.2\\Program.cs:line 29\r\n```\r\n\r\n**Expected behavior**\r\nI have a 60mb CSV with 700000 rows, IMO this is not a huge amount. My machine has 32 GB of memory and doesn't even use 20% of my memory when I watch performance. I tried to build a release build on 64bit and still ran into the out-of-memory exception. Please could someone advise me on what I am doing wrong, this seems like a bug? Eventually, I want to train much larger data sets, surely ML.Net should be able to do that? \r\n\r\n**Screenshots, Code, Sample Projects**\r\n```\r\nMLContext _mlContext;\r\nPredictionEngine<MlProduct, MlProductPrediction> _predictionEngine;\r\nITransformer _trainedModel;\r\nIDataView _trainingDataView;\r\n\r\n\r\n_mlContext = new MLContext();\r\n\r\n_trainingDataView = LoadDataFromCSV();\r\n\r\nTrainTestData dataSplit = _mlContext.Data.TrainTestSplit(_trainingDataView, testFraction: 0.2);\r\nIDataView trainData = dataSplit.TrainSet;\r\nIDataView testData = dataSplit.TestSet;\r\n\r\nvar pipeline = _mlContext.Transforms.Conversion.MapValueToKey(inputColumnName: \"CategoryName\", outputColumnName: \"Label\")\r\n           .Append(_mlContext.Transforms.Text.FeaturizeText(\"Features\", \"ProductName\"));\r\n\r\nvar trainingPipeline = pipeline.Append(_mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(\"Label\", \"Features\"))\r\n       .Append(_mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n\r\n_trainedModel = trainingPipeline.Fit(trainData);\r\n\r\nIDataView transformTest = _trainedModel.Transform(testData);\r\n\r\npublic class MlProduct\r\n{\r\n\r\n    [LoadColumn(0)]\r\n    [ColumnName(\"ProductName\")]\r\n    public string ProductName { get; set; }\r\n    [LoadColumn(1)]\r\n    [ColumnName(\"CategoryName\")]\r\n    public string CategoryName { get; set; }\r\n}\r\n\r\npublic class MlProductPrediction\r\n{\r\n    [ColumnName(\"PredictedLabel\")]\r\n    public string CategoryName;\r\n\r\n    [ColumnName(\"PredictionScore\")]\r\n    public float Score { get; set; }\r\n}\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7040","RelatedDescription":"Open issue \"ML.Net: System.OutOfMemoryException: 'Exception of type 'System.OutOfMemoryException' was thrown.' on small dataset\" (#7040)"},{"Id":"2157950944","IsPullRequest":true,"CreatedAt":"2024-03-01T02:01:13","Actor":"tarekgh","Number":"7035","RawContent":null,"Title":"Add Span support in tokenizer's Model abstraction","State":"closed","Body":"This change is adding Span support to the Tokenizer's Model abstraction. This will help in performance and not restrict us in the future to use spans without to worry about more memory allocations. ","Url":"https://github.com/dotnet/machinelearning/pull/7035","RelatedDescription":"Closed or merged PR \"Add Span support in tokenizer's Model abstraction\" (#7035)"},{"Id":"2161745693","IsPullRequest":false,"CreatedAt":"2024-02-29T17:18:52","Actor":"ericstj","Number":"7039","RawContent":null,"Title":"API review of Tensors design","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/7039","RelatedDescription":"Open issue \"API review of Tensors design\" (#7039)"},{"Id":"2160092346","IsPullRequest":false,"CreatedAt":"2024-02-29T00:10:26","Actor":"thomasd3","Number":"7038","RawContent":null,"Title":"What is the best way to represent N/A if a value is not available?","State":"open","Body":"I'm using a binary classifier.\r\n\r\nMy feature list has a list of columns representing various states in my model. The range of values is -1 to +1.\r\nBut, in some cases, some states are simply not present, in some rows.\r\n\r\nFor example:\r\n```\r\n0, 1, 1, 1, 0, 0, 1\r\n1, 0, 0, 1, 1, 0, 0\r\n1, X, 1, 1, 1, 0, 1\r\n1, 0, 0, 0, 0, 1, 1\r\n```\r\n\r\nNotice the X? which really means, in my model, that there is an absence of data there.\r\nThe model is supposed to classify a specific situation based on the states of various systems. And sometimes that data is not present, shouldn't be interpolated from neighbors either, it really means that this signal does not exist at that time.\r\n\r\nWhat is the best way to represent this?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7038","RelatedDescription":"Open issue \"What is the best way to represent N/A if a value is not available?\" (#7038)"},{"Id":"2159384547","IsPullRequest":true,"CreatedAt":"2024-02-28T20:55:27","Actor":"ericstj","Number":"7037","RawContent":null,"Title":"Remove SourceLink SDK references","State":"closed","Body":"@ViktorHofer let me know that we no longer need to have explicit SDK references to these source-link packages.\r\n\r\nI'm removing them and also testing the behavior of build to ensure we still have source-link info in our binaries per https://learn.microsoft.com/en-us/dotnet/standard/library-guidance/sourcelink.","Url":"https://github.com/dotnet/machinelearning/pull/7037","RelatedDescription":"Closed or merged PR \"Remove SourceLink SDK references\" (#7037)"},{"Id":"2143516236","IsPullRequest":true,"CreatedAt":"2024-02-28T18:55:01","Actor":"stephentoub","Number":"7018","RawContent":null,"Title":"Prototype using spans in Model","State":"closed","Body":"@tarekgh, this isn't for merging, but it shows appx what I had in mind for incorporating spans into Model (I know you're currently revising the surface area, so take this with a grain of salt). This eliminates a majority of the remaining allocation that occurs when using Tokenizer.CountTokens/EncodeToIds, as it avoids allocating strings for each token that's already in the cache.\r\n\r\nFeel free to crib liberally from the second commit and close this PR.  Ignore the first commit, which I submitted separately.","Url":"https://github.com/dotnet/machinelearning/pull/7018","RelatedDescription":"Closed or merged PR \"Prototype using spans in Model\" (#7018)"},{"Id":"2158910023","IsPullRequest":false,"CreatedAt":"2024-02-28T12:56:00","Actor":"chuongmep","Number":"7036","RawContent":null,"Title":"Best way to convert Datatable to Dataframe","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nHi, \r\nDo we have any way to fast convert from `System.Data.Datatable` to `Microsoft.Data.Analysis.DataFrame` ?\r\n\r\nI tried with my solution but it still too slow\r\n\r\n**Describe the solution you'd like**\r\n\r\n```csharp\r\npublic static Microsoft.Data.Analysis.DataFrame ToDataFrame(this DataTable dataTable)\r\n    {\r\n        Microsoft.Data.Analysis.DataFrame dataFrame = new Microsoft.Data.Analysis.DataFrame();\r\n\r\n        foreach (DataColumn column in dataTable.Columns)\r\n        {\r\n            // get values from column cast as string\r\n            string[] values = dataTable.AsEnumerable().Select(r => r.Field<object>(column.ColumnName)?.ToString()).ToArray();\r\n            DataFrameColumn dataFrameColumn = DataFrameColumn.Create(column.ColumnName, values);\r\n            dataFrame.Columns.Add(dataFrameColumn);\r\n        }\r\n        return dataFrame;\r\n    }\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- I want keep format column type and quick convert between them.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7036","RelatedDescription":"Open issue \"Best way to convert Datatable to Dataframe\" (#7036)"},{"Id":"2157810214","IsPullRequest":true,"CreatedAt":"2024-02-27T23:49:40","Actor":"michaelgsharp","Number":"7034","RawContent":null,"Title":"Helix queue testing","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7034","RelatedDescription":"Open PR \"Helix queue testing\" (#7034)"},{"Id":"2157709761","IsPullRequest":true,"CreatedAt":"2024-02-27T22:19:11","Actor":"michaelgsharp","Number":"7033","RawContent":null,"Title":"M1 helix testing","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7033","RelatedDescription":"Open PR \"M1 helix testing\" (#7033)"},{"Id":"2155085067","IsPullRequest":true,"CreatedAt":"2024-02-27T22:13:03","Actor":"michaelgsharp","Number":"7029","RawContent":null,"Title":"Make MlImage tests not block file for reading","State":"closed","Body":"Makes ML-Image tests not block the image file for reading as this is causing some test failures.","Url":"https://github.com/dotnet/machinelearning/pull/7029","RelatedDescription":"Closed or merged PR \"Make MlImage tests not block file for reading\" (#7029)"},{"Id":"2157499570","IsPullRequest":false,"CreatedAt":"2024-02-27T19:58:17","Actor":"scott19896","Number":"7032","RawContent":null,"Title":"Calling predict from LightGBM model file load","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: 6\r\n\r\n### Issue\r\n\r\nFollowing on from https://github.com/dotnet/machinelearning/pull/6569\r\n\r\nAre there any examples of how to load the LGBM model file and call predict on an entry by entry basis?\r\n\r\nLooking at the Booster wrapper, the GetModel call is private and so the only interface I could see to access the model is through the trainer. This only provides that access when calling Fit however, which is not needed from what I can tell when loading a pre-trained model.\r\n\r\nWould you know if this is something that is supported?  In other words, load a pre-trained LGBM model text file and access the Booster to call predicts \r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/7032","RelatedDescription":"Open issue \"Calling predict from LightGBM model file load\" (#7032)"},{"Id":"2157465678","IsPullRequest":false,"CreatedAt":"2024-02-27T19:38:20","Actor":"elvinsomon","Number":"7031","RawContent":null,"Title":"When we have all support without limitations for ARM devises for use all ML.NET models?","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/7031","RelatedDescription":"Open issue \"When we have all support without limitations for ARM devises for use all ML.NET models?\" (#7031)"},{"Id":"2155826542","IsPullRequest":true,"CreatedAt":"2024-02-27T07:06:57","Actor":"michaelgsharp","Number":"7030","RawContent":null,"Title":"Fix global.json to work better on non x64 hardware","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7030","RelatedDescription":"Open PR \"Fix global.json to work better on non x64 hardware\" (#7030)"},{"Id":"2150148900","IsPullRequest":true,"CreatedAt":"2024-02-26T18:57:18","Actor":"tarekgh","Number":"7024","RawContent":null,"Title":"Address the feedback on the tokenizer's library","State":"closed","Body":"This fix address the feedback reported in the issues:\r\n\r\n- https://github.com/dotnet/machinelearning/issues/7004\r\n- https://github.com/dotnet/machinelearning/issues/7005\r\n- https://github.com/dotnet/machinelearning/issues/7006\r\n- https://github.com/dotnet/machinelearning/issues/7008\r\n- https://github.com/dotnet/machinelearning/issues/7010\r\n- https://github.com/dotnet/machinelearning/issues/7011\r\n- https://github.com/dotnet/machinelearning/issues/7013\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7024","RelatedDescription":"Closed or merged PR \"Address the feedback on the tokenizer's library\" (#7024)"},{"Id":"2152373689","IsPullRequest":false,"CreatedAt":"2024-02-24T15:53:49","Actor":"OldManUnderTheHill","Number":"7028","RawContent":null,"Title":"Object detection training using CUDA gives decent results, while using CPU always returns nothing or inferior results","State":"open","Body":"**System Information (please complete the following information):**\r\n\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 16.18.2\r\n - .NET Version: 8.0\r\n\r\n**Describe the bug**\r\nI have a self created training set where I want to detect small marked passages of text (with a text marker). If I use CUDA for object detection training I get like the following result (using these parameters: --epoch 10 --device gpu0 -b 1 -st 0.3 -it 0.5 --width 600 --height 800)\r\n\r\n-> ObjectDetectionMulti                0.6115    \r\n\r\nIf I switch to CPU training while keeping all other parameters the result is always 0.0%. Testing the CPU model with some test images will never return any boxes, while the model from GPU training generates nice hits.\r\nAs a workaround I temporarily use the GPU model with CPU code.\r\n\r\nI know what I try to do is a bit strange, but it seems to work out if the GPU is used for training. A similar thing happens when I use the stop sign tutorial data set. Results when using the CPU for 5 epochs gives approx. 0.53 as result, while using the GPU on the same set with the same parameters 0.63.\r\n\r\nI added my dataset for further analysis, all used documents are public available on the internet.\r\n\r\n[LetterMarkerAnnot.zip](https://github.com/dotnet/machinelearning/files/14393399/LetterMarkerAnnot.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7028","RelatedDescription":"Open issue \"Object detection training using CUDA gives decent results, while using CPU always returns nothing or inferior results\" (#7028)"},{"Id":"2151210047","IsPullRequest":false,"CreatedAt":"2024-02-23T14:30:11","Actor":"abbottdev","Number":"7026","RawContent":null,"Title":"Add support/examples for Google Gemma lightweight LLM models","State":"open","Body":"**Is your feature request related to a problem? **\r\nSupport complex LLM reasoning tasks with ML .NET. My specific use case here is structured data extraction into a known format.\r\n\r\nBeing able to take this models and fine tune them using the ML .NET training/pipeline APIs would be a huge benefit.\r\n\r\n**Describe the solution you'd like**\r\nGoogle have opened sourced their base model Gemma which is a lightlight deriviative of the Gemini LLM. There is a keras implementation of it, a TensorFlow implementation. There are other options available but they havent been instruction tuned so the model would need more work for say, pytorch?\r\n\r\n**Additional context**\r\nhttps://blog.google/technology/developers/gemma-open-models/\r\nhttps://www.kaggle.com/models/google/gemma\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7026","RelatedDescription":"Open issue \"Add support/examples for Google Gemma lightweight LLM models\" (#7026)"},{"Id":"2150573552","IsPullRequest":false,"CreatedAt":"2024-02-23T08:02:21","Actor":"bettwedder","Number":"7025","RawContent":null,"Title":"Unable to remove SdcaLogisticRegressionOva from AutoML Multiclassification Experiment","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version:  v3.0.1 & AutoML 0.21.1\r\n - .NET Version: 8.0\r\n\r\n**Describe the bug**\r\nWhen creating an AutoML Multiclassification Experiment, you are unable to remove the trainer \"SdcaLogisticRegressionOva\".  \r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.  Create a Multiclass experiment settings object\r\n2.  Iterate on settings.Trainers and remove all trainers that are not \"LightGbm\" or \"FastForest\"\r\n3.  Create a Multiclass Progress Reporter that will output the TrainerName used.  \r\n4.  Use this replace command to remove the currently bugged (3.0.1 and 0.21.1) TrainerName value:  \r\n`TrainerName.Replace(\"Multi\", \"\").Replace(\"ReplaceMissingValues\", \"\").Replace(\"Concatenate\", \"\").Replace(\"Unknown\", \"\").Replace(\"=>\", \"\"); `\r\n5.  Run experiment and monitor names.\r\n\r\n\r\n**Expected behavior**\r\nOne of the first three models will include the unremovable trainer.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\n```\r\n  \r\n               MulticlassExperimentSettings settings = new MulticlassExperimentSettings()\r\n                {\r\n                    OptimizingMetric = optimizeMetric,\r\n                    MaxExperimentTimeInSeconds = experimentTime,\r\n                    CacheDirectoryName = cacheDir,\r\n                    CancellationToken = cts.Token,\r\n                    CacheBeforeTrainer = CacheBeforeTrainer.On\r\n                    \r\n                };\r\n\r\n                bool keptLightGBM = false;\r\n                foreach (var trainer in settings.Trainers.ToList())\r\n                {\r\n\r\n                    if (!trainer.ToString().ToUpperInvariant().Contains(\"LIGHTGBM\") && !trainer.ToString().ToUpperInvariant().Contains(\"FASTFOREST\"))\r\n                    {\r\n                        settings.Trainers.Remove(trainer);\r\n                        Console.WriteLine(\"Removed Trainer: \" + trainer.ToString());\r\n                    }\r\n                    //else\r\n                    //{\r\n                    //    if (keptLightGBM)\r\n                    //    {\r\n                    //        settings.Trainers.Remove(trainer);\r\n                    //        Console.WriteLine(\"Removed Extra \"LightGbm\" Trainer: \" + trainer.ToString());\r\n                    //    }\r\n                    //    else\r\n                    //        keptLightGBM = true;\r\n                    //}\r\n                }\r\n\r\n                MulticlassClassificationExperiment experiment = context.Auto().CreateMulticlassClassificationExperiment(settings);\r\n                ExperimentResult<MulticlassClassificationMetrics> result;\r\n\r\n                result = experiment.Execute(trainData, splitTestData, columnInformation, null, new MulticlassProgressReporter() { labelColumnName = label, CacheDir = cacheDir, ExperimentTime = DateTime.Now });\r\n\r\n```\r\n\r\nThis code produces this output: \r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/40208910/00b0f1ab-a208-4ad2-845f-8e72627a74ea)\r\n\r\n\r\n\r\n**Additional context**\r\nIf you only leave one LightGbm as the only trainer, then AutoML uses the \"SdcaLogisticRegressionOva\" every other time.\r\n\r\nThe trainer \"SdcaLogisticRegressionOva\" does not appear in the list after creating a settings object which is supposed to populate the list with all values.  Also, if you iterate on list of auto populated trainers, two items appear with the name \"LightGbm\".  \r\n\r\nLast, when I peek the definition of Microsoft.ML.AutoML.MulticlassClassificationTrainer, I get this list which also doesn't have \"SdcaLogisticRegressionOva\" in the list. \r\n\r\n```\r\n// Decompiled with JetBrains decompiler\r\n// Type: Microsoft.ML.AutoML.MulticlassClassificationTrainer\r\n// Assembly: Microsoft.ML.AutoML, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\r\n// MVID: 5D7A79B7-CF20-433B-A534-1ED92C335230\r\n// Assembly location: C:\\Users\\xxxx\\.nuget\\packages\\microsoft.ml.automl\\0.21.1\\lib\\netstandard2.0\\Microsoft.ML.AutoML.dll\r\n// XML documentation location: C:\\Users\\xxxx\\.nuget\\packages\\microsoft.ml.automl\\0.21.1\\lib\\netstandard2.0\\Microsoft.ML.AutoML.xml\r\n\r\n#nullable disable\r\nnamespace Microsoft.ML.AutoML\r\n{\r\n  /// <summary>\r\n  /// Enumeration of ML.NET multiclass classification trainers used by AutoML.\r\n  /// </summary>\r\n  public enum MulticlassClassificationTrainer\r\n  {\r\n    /// <summary>\r\n    /// <see cref=\"T:Microsoft.ML.Trainers.OneVersusAllTrainer\" /> using <see cref=\"T:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer\" />.\r\n    /// </summary>\r\n    FastForestOva,\r\n    /// <summary>\r\n    /// <see cref=\"T:Microsoft.ML.Trainers.OneVersusAllTrainer\" /> using <see cref=\"T:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer\" />.\r\n    /// </summary>\r\n    FastTreeOva,\r\n    /// <summary>\r\n    /// See <see cref=\"T:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer\" />.\r\n    /// </summary>\r\n    LightGbm,\r\n    /// <summary>\r\n    /// See <see cref=\"T:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer\" />.\r\n    /// </summary>\r\n    LbfgsMaximumEntropy,\r\n    /// <summary>\r\n    /// <see cref=\"T:Microsoft.ML.Trainers.OneVersusAllTrainer\" /> using <see cref=\"T:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer\" />.\r\n    /// </summary>\r\n    LbfgsLogisticRegressionOva,\r\n    /// <summary>\r\n    /// See <see cref=\"T:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer\" />.\r\n    /// </summary>\r\n    SdcaMaximumEntropy,\r\n  }\r\n}\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/7025","RelatedDescription":"Open issue \"Unable to remove SdcaLogisticRegressionOva from AutoML Multiclassification Experiment\" (#7025)"},{"Id":"2145442937","IsPullRequest":true,"CreatedAt":"2024-02-23T00:41:24","Actor":"stephentoub","Number":"7020","RawContent":null,"Title":"Optimize regexes used in tiktoken","State":"closed","Body":"This ports the tweaks in https://github.com/openai/tiktoken/pull/234. I noticed the differences as they also show up in the source for https://www.youtube.com/watch?v=zduSFxRajkE.\r\n\r\n@tarekgh, if this conflicts with any of your changes, feel free to close this and I can re-make them after your changes land.","Url":"https://github.com/dotnet/machinelearning/pull/7020","RelatedDescription":"Closed or merged PR \"Optimize regexes used in tiktoken\" (#7020)"},{"Id":"2147660741","IsPullRequest":true,"CreatedAt":"2024-02-22T21:49:28","Actor":"michaelgsharp","Number":"7023","RawContent":null,"Title":"Fix formatting that fails in VS","State":"closed","Body":"Fixes minor formatting that fails in VS but not with command line.","Url":"https://github.com/dotnet/machinelearning/pull/7023","RelatedDescription":"Closed or merged PR \"Fix formatting that fails in VS\" (#7023)"},{"Id":"2146099505","IsPullRequest":true,"CreatedAt":"2024-02-21T20:14:45","Actor":"michaelgsharp","Number":"7021","RawContent":null,"Title":"Temp fix for the race condition during the tests.","State":"closed","Body":"Temporarily fixes the race condition that seems to be happening during the tests by making the offending tests run sequentially.","Url":"https://github.com/dotnet/machinelearning/pull/7021","RelatedDescription":"Closed or merged PR \"Temp fix for the race condition during the tests.\" (#7021)"},{"Id":"2146116326","IsPullRequest":true,"CreatedAt":"2024-02-21T08:33:30","Actor":"michaelgsharp","Number":"7022","RawContent":null,"Title":"Working on memory issue during tests for TorchSharp","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7022","RelatedDescription":"Open PR \"Working on memory issue during tests for TorchSharp\" (#7022)"},{"Id":"2143381151","IsPullRequest":true,"CreatedAt":"2024-02-20T20:08:18","Actor":"stephentoub","Number":"7015","RawContent":null,"Title":"Tweak CreateByModelNameAsync","State":"closed","Body":"- Add a CancellationToken to CreateByModelNameAsync, allowing the download and parsing to be canceled.\r\n- Use ReadLineAsync(cancellationToken), which not only allows it to be canceled, but avoids ~100K task allocations\r\n- Fix Helpers.FromBase64String to support lines longer than 300 chars\r\n\r\ncc: @tarekgh ","Url":"https://github.com/dotnet/machinelearning/pull/7015","RelatedDescription":"Closed or merged PR \"Tweak CreateByModelNameAsync\" (#7015)"},{"Id":"2143488085","IsPullRequest":true,"CreatedAt":"2024-02-20T19:02:04","Actor":"stephentoub","Number":"7017","RawContent":null,"Title":"Tweak Tiktoken's BytePairEncode for improved perf","State":"closed","Body":"- Stackalloc the indices/ranks when feasible\r\n- Use a span to eliminate bounds checks and allow for directly updating ranks\r\n\r\n```C#\r\n[Benchmark]\r\npublic int CountTokens() => _tokenizer.CountTokens(Poem);\r\n```\r\nwith the same Poem as in https://github.com/dotnet/machinelearning/pull/7012, and setting the LruCache size to 0 in order to skip the cache and measure what's being changed here...\r\n\r\nBefore:\r\n\r\n| Method      | Mean     | Allocated |\r\n|------------ |---------:|----------:|\r\n| CountTokens | 61.11 us |  19.52 KB |\r\n\r\nAfter:\r\n\r\n| Method      | Mean     | Allocated\r\n|------------ |---------:|----------:\r\n| CountTokens | 58.82 us |  11.27 KB\r\n\r\ncc: @tarekgh ","Url":"https://github.com/dotnet/machinelearning/pull/7017","RelatedDescription":"Closed or merged PR \"Tweak Tiktoken's BytePairEncode for improved perf\" (#7017)"},{"Id":"2143402003","IsPullRequest":true,"CreatedAt":"2024-02-20T18:34:11","Actor":"stephentoub","Number":"7016","RawContent":null,"Title":"Avoid LruCache in Tiktoken when cacheSize specified is 0","State":"closed","Body":"cc: @tarekgh ","Url":"https://github.com/dotnet/machinelearning/pull/7016","RelatedDescription":"Closed or merged PR \"Avoid LruCache in Tiktoken when cacheSize specified is 0\" (#7016)"},{"Id":"2144814227","IsPullRequest":false,"CreatedAt":"2024-02-20T16:41:24","Actor":"stephentoub","Number":"7019","RawContent":null,"Title":"Ensure tiktoken implementation up-to-date with OpenAI reference implementation","State":"open","Body":"The implementation at https://github.com/openai/tiktoken/commits/main/src/lib.rs has seen several improvements in the last year (eg https://github.com/openai/tiktoken/pull/255), including a couple that claim perf wins around algorithmic complexity for long inputs. The comments in the source also cite ways of avoiding needing an LRU cache.  We should ensure the C# implementation has all the corresponding goodness.","Url":"https://github.com/dotnet/machinelearning/issues/7019","RelatedDescription":"Open issue \"Ensure tiktoken implementation up-to-date with OpenAI reference implementation\" (#7019)"},{"Id":"2141079387","IsPullRequest":false,"CreatedAt":"2024-02-18T16:38:11","Actor":"amitchaudhary","Number":"7014","RawContent":null,"Title":"Add metrices calculation for model performance review.  ","State":"open","Body":"Especially, the key metrices like -\r\n1) Mean Absolute Error (MAE)\r\n2) Mean Squared Error (MSE)\r\n3) Root Mean Squared Error (RMSE) etc. ","Url":"https://github.com/dotnet/machinelearning/issues/7014","RelatedDescription":"Open issue \"Add metrices calculation for model performance review.  \" (#7014)"}],"ResultType":"GitHubIssue"}},"RunOn":"2024-03-02T03:30:15.6910029Z","RunDurationInMilliseconds":398}