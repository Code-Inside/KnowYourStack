{"Data":{"GitHub":{"Issues":[{"Id":"1059206306","IsPullRequest":false,"CreatedAt":"2021-11-20T18:48:30","Actor":"dharmatech","Number":"6008","RawContent":null,"Title":"Add the equivalent of pandas.DataFrame.shift","State":"open","Body":"# Documentation\r\n\r\nDocumentation and examples of `shift`:\r\n\r\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html\r\n\r\nI posted a question on stackoverflow about `shift` here:\r\n\r\nhttps://stackoverflow.com/questions/70042849/equivalent-of-shift-from-pandas\r\n\r\nI also posted an answer that illustrates a very kludgy workaround. :-)","Url":"https://github.com/dotnet/machinelearning/issues/6008","RelatedDescription":"Open issue \"Add the equivalent of pandas.DataFrame.shift\" (#6008)"},{"Id":"1041533056","IsPullRequest":true,"CreatedAt":"2021-11-19T18:29:08","Actor":"LittleLittleCloud","Number":"5990","RawContent":null,"Title":"use default column with index if columnName[i] is empty or null","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n## Related issue\r\n\r\n#5979 ","Url":"https://github.com/dotnet/machinelearning/pull/5990","RelatedDescription":"Closed or merged PR \"use default column with index if columnName[i] is empty or null\" (#5990)"},{"Id":"1058427794","IsPullRequest":false,"CreatedAt":"2021-11-19T11:27:54","Actor":"dsavch","Number":"6007","RawContent":null,"Title":"Multiclass text classification: training consume a lot of RAM","State":"open","Body":"[ds example.txt](https://github.com/dotnet/machinelearning/files/7569870/ds.example.txt)\r\n### System information\r\n\r\n- **Windows 10 Home Single Language**\r\n- **.NET Version 5.0.400**\r\n- **Microsoft.ML 1.6.0**\r\n\r\n### Issue\r\n\r\nI'm trying to train model with some dataset. Dataset is about 60 Mb (example in attachments, can't provide full data set because of privacy). It contains some text descriptions about 50-200 chars in each row. Total labels count - 84. There are about 100K rows in dataset for training. After 16-18 hours of training application consume about 32 Gb RAM and terminate with System.OutOfMemory exception (I have only 32 Gb free RAM on my PC). Is this RAM consumption is ok for such kind of task or maybe I'm doing something wrong?\r\n\r\n### Source code / logs\r\nMy data class:\r\n```csharp\r\npublic class SkuInfo\r\n{\r\n  [ColumnName(\"Category\")]\r\n  public string CategoryCode { get; set; }\r\n  \r\n  [ColumnName(\"ManufacturerId\")]\r\n  public float ManufacturerId { get; set; }\r\n  \r\n  [ColumnName(\"ManufacturerPn\")]\r\n  public string ManufacturerPn { get; set; }\r\n  \r\n  [ColumnName(\"Description\")]\r\n  public string Description { get; set; }\r\n}\r\n```\r\n\r\nMy trainig pipeline:\r\n```csharp\r\nprivate IEstimator<ITransformer> BuildPipeline(MLContext mlContext)\r\n{\r\n\tvar pipeline = mlContext.Transforms.ReplaceMissingValues(@\"ManufacturerId\", @\"ManufacturerId\")\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Text.FeaturizeText(@\"ManufacturerPn\", @\"ManufacturerPn\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Text.FeaturizeText(@\"Description\", @\"Description\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Concatenate(@\"Features\", new[] { @\"ManufacturerId\", \"ManufacturerPn\", @\"Description\" }))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Conversion.MapValueToKey(@\"Category\", @\"Category\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.NormalizeMinMax(@\"Features\", @\"Features\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(l1Regularization: 0.455F, l2Regularization: 0.034F, labelColumnName: @\"Category\", featureColumnName: @\"Features\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Conversion.MapKeyToValue(@\"PredictedLabel\", \"PredictedLabel\"));\r\n\r\n\treturn pipeline;\r\n}\r\n```\r\nTraining method:\r\n```csharp\r\npublic void TrainFromCollection(IEnumerable<SkuInfo> trainData, string outputModelPath)\r\n{\r\n\tvar mlContext = new MLContext(seed: 1);\r\n\tvar dataView = mlContext.Data.LoadFromEnumerable(trainData);\r\n\tvar pipeline = BuildPipeline(mlContext);\r\n\tvar model = pipeline.Fit(dataView);\r\n\tmlContext.Model.Save(model, dataView.Schema, outputModelPath);\r\n}\r\n```\r\n[ds example.txt](https://github.com/dotnet/machinelearning/files/7569878/ds.example.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6007","RelatedDescription":"Open issue \"Multiclass text classification: training consume a lot of RAM\" (#6007)"},{"Id":"1051090293","IsPullRequest":true,"CreatedAt":"2021-11-19T00:15:03","Actor":"x-danma","Number":"6001","RawContent":null,"Title":"Remove Excessive Logging from SymSgdClassificationTrainer","State":"closed","Body":"Fixes #5598 \r\n\r\nI have removed the logging statement as suggested by the issue reporter, and have adjusted the affected BaseLineOutput files for Microsoft.ML.Predictor.Tests.\r\n\r\n\r\nWe are excited to review your PR.\r\n\r\nThe lo\r\nSo we can do the best job, please check:\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [X] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6001","RelatedDescription":"Closed or merged PR \"Remove Excessive Logging from SymSgdClassificationTrainer\" (#6001)"},{"Id":"1044172741","IsPullRequest":true,"CreatedAt":"2021-11-18T23:09:37","Actor":"michaelgsharp","Number":"5994","RawContent":null,"Title":"Fixed Nuget Pack warning.","State":"closed","Body":"We were including a file in a NuGet package to designate an empty folder. The folder, however, actually included other files so the `pack` command was throwing an error. This PR removes the file that was causing that error.","Url":"https://github.com/dotnet/machinelearning/pull/5994","RelatedDescription":"Closed or merged PR \"Fixed Nuget Pack warning.\" (#5994)"},{"Id":"1052534757","IsPullRequest":true,"CreatedAt":"2021-11-17T21:36:30","Actor":"michaelgsharp","Number":"6003","RawContent":null,"Title":"Multi-targeting with TargetFrameworks","State":"closed","Body":"With .NET Core 2 no longer in support, we needed to fix the build configurations and frameworks.\r\n\r\nThis PR includes all the changes to switch from the way we used build configuration to specify the target framework for the tests and removes .NET Core 2.1. These changes include:\r\n* No longer using the build configuration to specify the framework (Debug-netcoreapp3_1/Debug-netfx for their associated frameworks) to just using `<TargetFrameworks>` for the test projects. \r\n* Removing all build configurations beyond Debug/Release.\r\n* Removing .NET Core 2.1 as part of this process, so currently only .NET Framework 4.6.1 and  .NET Core 3.1 are used. (.NET 6 will be added in a later PR as it changes some test results slightly).","Url":"https://github.com/dotnet/machinelearning/pull/6003","RelatedDescription":"Closed or merged PR \"Multi-targeting with TargetFrameworks\" (#6003)"},{"Id":"1056379157","IsPullRequest":false,"CreatedAt":"2021-11-17T17:07:17","Actor":"eerhardt","Number":"6006","RawContent":null,"Title":"Remove System.CodeDom reference in Microsoft.ML nuget package","State":"open","Body":"Today Microsoft.ML has a dependency on System.CodeDom, but I don't see anything actually requiring this reference:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ea647f43246989334bad69f35b5d60d15171c57e/src/Microsoft.ML/Microsoft.ML.csproj#L44\r\n\r\nThe only references to `System.CodeDom` in the code is to use IndentedTextWriter, which doesn't require a reference to System.CodeDom.\r\n\r\nWe should remove this reference from our core NuGet package.\r\n\r\ncc @ericstj @michaelgsharp ","Url":"https://github.com/dotnet/machinelearning/issues/6006","RelatedDescription":"Open issue \"Remove System.CodeDom reference in Microsoft.ML nuget package\" (#6006)"},{"Id":"1056120535","IsPullRequest":false,"CreatedAt":"2021-11-17T13:16:56","Actor":"ddobric","Number":"6005","RawContent":null,"Title":"TensorFlow model runs in timeout when executed in container","State":"open","Body":"## System Information \r\n - Linux Docker container running on Windows 10 / 11\r\n - ML.NET v1.4.0\r\n - .NET Version: .NET 6.0\r\n\r\n## Problem description\r\nWe have an application that utilizes image classification by using TensorFlow, based on the sample provided in .NET ML. The application executes the following code, which correctly starts, runs, but never completes when running in the Linux docker container on the Windows 10 host.\r\n\r\nWhen the container is started from the command line it simply exists without showing any error. However, when we run the container in VS (F5) the container shows the error in the output window.\r\n\r\n>  TensorFlow .. metaoprimizer.cc 499 ..model_runner exceeded deadline\r\n\r\nHere is the simplified code that fails (crashes) in line N+0. \r\n~~~\r\ntry\r\n{\r\n(N+0) var cvResults = mlContext.MulticlassClassification.CrossValidate(cvDataView, pipeline, numberOfFolds: numOfFolds, labelColumnName: \"LabelAsKey\", seed: 8881);\r\n\r\n(N+1)  Console.Write(\"Never executed\");\r\n}\r\ncatch\r\n{\r\n(N+2)\r\n}\r\n~~~\r\n\r\nThe container simply exists without throwing any exception. The lines N+1 and N+2 are never reached.\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/142205156-cca5a3fa-3194-441f-bf98-c68f94ec6cce.png)\r\n\r\nThe same code works well when executed on the Windows host. We also have been able to execute the same code in the Linux container on Windows 11. We have tested it on multiple machines (same environment setup). The same code at some hosts is sometimes running correctly even if the execution time is longer (see image above).\r\n\r\n## Recap\r\n\r\nQuestion: Is there a way to set the timeout for TensorFlow via ML.NET?\r\n\r\nHowever, this behaviour also raises another question. Is this .NET + Docker + TensorFlow reliable at all if it doesn't show any error and stops the execution?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6005","RelatedDescription":"Open issue \"TensorFlow model runs in timeout when executed in container\" (#6005)"},{"Id":"1038170118","IsPullRequest":false,"CreatedAt":"2021-11-16T18:43:55","Actor":"tankhar","Number":"5987","RawContent":null,"Title":"Following code fails in .Net Core 5.0 single file application ->Repository.cs ->FileVersionInfo.GetVersionInfo(typeof(RepositoryWriter).Assembly.Location) ","State":"closed","Body":"https://github.com/dotnet/machinelearning/blob/1dfccca85d4ab87f1238b8554e0a49f8f6a20e8e/src/Microsoft.ML.Core/Data/Repository.cs#L288\r\n\r\nWe are using ML.Net API in our .Net Core Worker service project.\r\nEverything works fine as long as we execute the worker \"exe\" manually.\r\n\r\nIn order to use the same as Windows Service, we are publishing the .Net Core exe to **single file** and then using sc.exe to convert this to windows service\r\n\r\nWhen we run the same as windows service (pointing to single file exe)we get following exception when we try to \"Save\" our trained model:\r\n\r\n**CoreCLR Version: 5.0.120.57516\r\n.NET Version: 5.0.1\r\nDescription: The process was terminated due to an unhandled exception.\r\nException Info: System.ArgumentException: The path is empty. (Parameter 'path')\r\n   at System.IO.Path.GetFullPath(String path)\r\n   at System.Diagnostics.FileVersionInfo.GetVersionInfo(String fileName)\r\n   at Microsoft.ML.RepositoryWriter.CreateNew(Stream stream, IExceptionContext ectx, Boolean useFileSystem)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, Stream stream)**\r\n\r\nWe found that publishing an app as single file gives following warning(which one can easily miss reading!):\r\n**warning IL3000: 'System.Reflection.Assembly.Location' always returns an empty string for assemblies embedded in a single-file app. If the path to the app directory is needed, consider calling 'System.AppContext.BaseDirectory'.**\r\n  \r\nWhich means ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, Stream stream) will always fail in .Net Core single file app.\r\n\r\nPlease let look into and guide us next step, we want to run this as a single file and windows service","Url":"https://github.com/dotnet/machinelearning/issues/5987","RelatedDescription":"Closed issue \"Following code fails in .Net Core 5.0 single file application ->Repository.cs ->FileVersionInfo.GetVersionInfo(typeof(RepositoryWriter).Assembly.Location) \" (#5987)"},{"Id":"1052668299","IsPullRequest":false,"CreatedAt":"2021-11-13T12:13:42","Actor":"juwens","Number":"6004","RawContent":null,"Title":"Why no Polynomial (SVM) Kernel?","State":"open","Body":"Every decent ML lib contains a set of non linear SVM Kernels.\r\n\r\n- RBF\r\n- Polynomial\r\n- CosineSimilarity\r\n- Fourier\r\n- Spline\r\n\r\nIt seems ML.Net contains only Linear and LD.","Url":"https://github.com/dotnet/machinelearning/issues/6004","RelatedDescription":"Open issue \"Why no Polynomial (SVM) Kernel?\" (#6004)"},{"Id":"1052441350","IsPullRequest":false,"CreatedAt":"2021-11-12T22:07:37","Actor":"juwens","Number":"6002","RawContent":null,"Title":"Add ECOC (Error correcting output codes)","State":"open","Body":"**Describe the solution you'd like**\r\nECOC is available as  Trainer/Classifier\r\n\r\n**Describe alternatives you've considered**\r\nUsing other frameworks like scikit-learn via dllimport\r\n\r\n**Additional context**\r\nit might appear under a different name in some sources, for example: (error  correcting) multiclass SVM.\r\n\r\nhttps://machinelearningmastery.com/error-correcting-output-codes-ecoc-for-machine-learning/","Url":"https://github.com/dotnet/machinelearning/issues/6002","RelatedDescription":"Open issue \"Add ECOC (Error correcting output codes)\" (#6002)"},{"Id":"1048060187","IsPullRequest":true,"CreatedAt":"2021-11-11T20:48:59","Actor":"michaelgsharp","Number":"5997","RawContent":null,"Title":"Fixes for ssh cert","State":"closed","Body":"`Hosted MacOs` pool, the old way of specifying your vm image, is having issues with SSH certs. Our CI build had switched entirely to the new way to specify vm image, but the official build hadn't. This PR switches to the new format so that we can fix the SSH issue.\r\n\r\nHosted MacOs is using 10.14, which went out of service about a week ago which is why the cert is expiring now. Switching to 10.15, which is still in support fixes this.","Url":"https://github.com/dotnet/machinelearning/pull/5997","RelatedDescription":"Closed or merged PR \"Fixes for ssh cert\" (#5997)"},{"Id":"1048571465","IsPullRequest":false,"CreatedAt":"2021-11-09T12:52:30","Actor":"MiroslavKabat","Number":"6000","RawContent":null,"Title":" MS ML.NET doesn't work with latest GPU!","State":"open","Body":"I was using station with `Geforce RTX 2080 Ti` (Cuda Compute Capability 7.5) for development and everything was fine and works pretty well. \r\nNow we are publishing our solution on station with `RTX A6000` Cuda Compute Capability 8.6) and MS Model Builder, MS ML.NET and direct programming in python (tensorflow) is super slow or stuck without any error message with same configuration like in dev station. \r\n(for example loading onnx model takes 6 minutes instead of 2 seconds and prediction never start instead of calculate task is several milliseconds)\r\n\r\nTensorflow in python with cuda 11.2 & cudnn 8.1 works fine.\r\nTensorflow in python with cuda 10.1 & cudnn 7.6.4 (which is nessesary for MS ML.NET!) is slow or stuck in TF & MS ML.NET.\r\n\r\nI am not only one with those issues [nvidia - dev forum](https://forums.developer.nvidia.com/t/slow-startup-and-model-loading-time/173398)\r\n\r\nI just wanna ensure if MS ML.NET supports latest GPUs or how can I solve those issues? \r\nThank you for answer.\r\n\r\n```\r\nConfiguration:\r\nWindows 10 Pro - 21H1\r\n\r\nML.NET 1.6 | 1.5.5 | 1.7-Preview\r\nSciSharp.TensorFlow.Redist-Windows-GPU 2.3.1\r\nPython 3.8.10, pip 21.3.1, tensorflow 2.3.1 or 2.7.0\r\n\r\ncuda_10.1.105_418.96_win10\r\ncudnn-10.1-windows10-x64-v7.6.4.38\r\n\r\nor \r\n\r\ncuda_11.2.2_461.33_win10\r\ncudnn-11.2-windows-x64-v8.1.1.33\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6000","RelatedDescription":"Open issue \" MS ML.NET doesn't work with latest GPU!\" (#6000)"},{"Id":"1048170349","IsPullRequest":false,"CreatedAt":"2021-11-09T04:14:28","Actor":"AbhayGaur","Number":"5999","RawContent":null,"Title":"Binary classification : Tune the model/algorithms to give higher positive recall instead of negative recall","State":"open","Body":"I have a binary classification problem on my hand and on using various models like LBFGS logistic regression, LightGBM, FastTree etc I am getting accuracy above 85% but a positive recall close to 0.7 with a precision of 99% with a negative recall greater than 0.99 with 80% precision.\r\n\r\nTraining Dataset consists of roughly 38% positive class and 62% negative class with 200k rows. Test dataset also has 38% positive class and 62% negative class.\r\n\r\nIdeally, I would like the model to give me decent accuracy but with higher positive recall. I would like to have some method through which I can experiment a bit with accuracy and positive recall.","Url":"https://github.com/dotnet/machinelearning/issues/5999","RelatedDescription":"Open issue \"Binary classification : Tune the model/algorithms to give higher positive recall instead of negative recall\" (#5999)"},{"Id":"1048062410","IsPullRequest":true,"CreatedAt":"2021-11-09T01:21:41","Actor":"michaelgsharp","Number":"5998","RawContent":null,"Title":"Fixes for ssh cert","State":"closed","Body":"`Hosted MacOs` pool, the old way of specifying your vm image, is having issues with SSH certs. Our CI build had switched entirely to the new way to specify vm image, but the official build hadn't. This PR switches to the new format so that we can fix the SSH issue.\r\n\r\nHosted MacOs is using 10.14, which went out of service about a week ago which is why the cert is expiring now. Switching to 10.15, which is still in support fixes this.","Url":"https://github.com/dotnet/machinelearning/pull/5998","RelatedDescription":"Closed or merged PR \"Fixes for ssh cert\" (#5998)"},{"Id":"1047662527","IsPullRequest":false,"CreatedAt":"2021-11-08T16:34:14","Actor":"briacht","Number":"5996","RawContent":null,"Title":"Virtual ML.NET Hackathon: November 11 - 19","State":"open","Body":"All experience levels welcome!\r\n\r\nSolve a unique business problem with ML.NET, contribute to the repo, create your own ML.NET tooling... collaborate with others in the .NET community to create any project using ML.NET!\r\n\r\nLearn more and sign up at [aka.ms/mlnet-hack](https://aka.ms/mlnet-hack).","Url":"https://github.com/dotnet/machinelearning/issues/5996","RelatedDescription":"Open issue \"Virtual ML.NET Hackathon: November 11 - 19\" (#5996)"},{"Id":"1046157432","IsPullRequest":false,"CreatedAt":"2021-11-05T19:07:39","Actor":"torronen","Number":"5995","RawContent":null,"Title":"Suggestion: store optimized hyperparameters in the zip file","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nDuring various AutoML runs I have generated multiple models with slightly different datasets. After using them in simulations I notice some perform better than others. I would like to re-train the model with slightly improved datasets. However, not all algorithms can be [retrained](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net). As I understand trees, for example, require me to create a new model. To create the new model I would like to use the hyperparameters from the earlier model.\r\n\r\n**Describe the solution you'd like**\r\nI might be confused and just unable to find how to do it. If this is already possible, mention at end of https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net would be nice.\r\n\r\nIf the parameters are not stored at the moment, then I would suggest providing a way to store them to the zip file. At the moment, I did not notice any way to access them outside AutoML code. I can access them in Experiment.cs and PipelineSuggester.cs, but my current understanding is that I need customize the library myself to store them. \r\n\r\nIdeally, ExperimentResult would include HyperParameters in the same way as the metrics.\r\n\r\n**Additional context**\r\nGetting the hyperparameters from AutoML experiments would be useful also for manual fine-tuning. \r\n\r\nModel Builder does similar functionality already by creating the training file.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5995","RelatedDescription":"Open issue \"Suggestion: store optimized hyperparameters in the zip file\" (#5995)"},{"Id":"1038940822","IsPullRequest":true,"CreatedAt":"2021-11-05T04:48:51","Actor":"michaelgsharp","Number":"5988","RawContent":null,"Title":"dotnet format/spellchecking","State":"closed","Body":"Ran the `dotnet format` command now that we have the Rosalyn editor config.\r\n\r\nAlso did various spell checking.\r\n\r\nI manually went through the files after the tool ran to make sure nothing looking crazy.","Url":"https://github.com/dotnet/machinelearning/pull/5988","RelatedDescription":"Closed or merged PR \"dotnet format/spellchecking\" (#5988)"},{"Id":"1042824705","IsPullRequest":true,"CreatedAt":"2021-11-02T21:02:55","Actor":"LittleLittleCloud","Number":"5993","RawContent":null,"Title":"Proposal: Sweepable API","State":"open","Body":"This is the initial design/proposal doc for a Sweepable API.\r\n\r\nI would appreciate it if you could each review it and give me your feedback.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5993","RelatedDescription":"Open PR \"Proposal: Sweepable API\" (#5993)"},{"Id":"1042817236","IsPullRequest":false,"CreatedAt":"2021-11-02T20:59:12","Actor":"LittleLittleCloud","Number":"5992","RawContent":null,"Title":"Proposal: AutoML Sweepable API","State":"closed","Body":"# AutoML.Net Sweepable API proposal\r\n## Overview\r\nSweepable api allows mlnet users to create their own search space and pipeline for hyper-parameter optimization (HPO). It comes with three major part: `search space`, `sweepable estimator/pipeline` and `tuner`. And all API lives under `Sweepable()` extension (for now).\r\n\r\n## search space\r\nSearch space defines a range of hyper-parameter for tuner to search from. Sweepable API provides two way to create a search space.\r\n\r\nvia attribute\r\n```csharp\r\npublic class Option\r\n{\r\n    [Range(2, 32768, init: 2, logBase: true)]\r\n    public int WindowSize {get; set;}\r\n\r\n    // one of [2, 3, 4]\r\n    [Choice(2, 3, 4)]\r\n    public int SeriesLength {get; set;}\r\n\r\n    // one of [true, false]\r\n    [Choice]\r\n    public bool UseSoftmax {get; set;}\r\n\r\n    // nested search space\r\n    [Option]\r\n    public Option AnotherOption {get;set;}\r\n}\r\n\r\nvar ss = new SearchSpace<Option>();\r\n\r\n// each search space has a 1-d feature space where each feature is [0, 1). And search space will handle the mapping between hpo space and feature space so that tuner only needs to perform search on feature space, which both dimension and range are known.\r\nvar parameter = ss.SampleFromFeatureSpace(new []{0,0,0,0,0,0});\r\n\r\n// auto-binding\r\nparameter.WindowSize.Should().Be(2);\r\nparameter.SeriesLength.Should().Be(2);\r\nparameter.UseSoftmax.Should().BeTrue();\r\nparameter.AnotherOption.WindowSize.Should().Be(2);\r\n\r\n// search space can also map parameter back to feature space\r\nss.MappingToFeatureSpace(parameter).Should().BeEquivalantTo(0.0, 0.0, 0.0, 0.0, 0.0, 0.0);\r\n```\r\n\r\nor correspondingly, via scratch\r\n``` csharp\r\nvar ss = new SearchSpace();\r\nss.Add(\"WindowSize\", new UniformIntOption(2, 32768, true, 2));\r\nss.Add(\"SeriesLength\", new ChoiceOption(2,3,4));\r\nss.Add(\"UseSoftmax\", new ChoiceOption(true, false));\r\nss.Add(\"AnotherOption\", ss.Clone());\r\n\r\nvar parameter = ss.SampleFromFeatureSpace(new []{0,0,0,0,0,0});\r\n\r\n// auto-binding doesn't exist for scratch api\r\nparameter[\"WindowSize\"].AsType<int>.Should().Be(2);\r\nparameter[\"SeriesLength\"].AsType<int>.Should().Be(2);\r\nparameter[\"UseSoftmax\"].AsType<bool>.Should().BeTrue();\r\nparameter[\"AnotherOption\"][\"WindowSize\"].AsType<int>.Should().Be(2);\r\n\r\n// search space can also map parameter back to feature space\r\nss.MappingToFeatureSpace(parameter).Should().BeEquivalantTo(0.0, 0.0, 0.0, 0.0, 0.0, 0.0);\r\n```\r\n\r\nCurrently, in order to make auto-binding work, there's a limitation on the parameter type that can be added to search space, which has to be either a Json primitive type or a nested search space.\r\n\r\n## sweepable estimator\r\nsweepable estimator allows user to combine search space with estimators in a similar way how ml.net estimator/pipeline are created. You use `CreateSweepableEstimator`, which accepts a lambda function and a search space to create a sweepable estimator. And it also provides `.Append` extension method so you can append sweepable estimator similiar with how you append other ml.net extimator. The bellow example presents how to create a pipeline with two sweepable estimators, one for text featurizor and the other for fast tree, for `titanic` dataset via `Sweepable()` extension.\r\n\r\n``` csharp\r\nvar context = new MLContext();\r\nvar fastTreeSS = new SearchSpace<FastTreeOption>();\r\nvar textFeaturizeSS = new SearchSpace<FeaturizeTextOption>();\r\n\r\nvar pipeline = context.Transforms.Categorical.OneHotEncoding(new[] { new InputOutputColumnPair(@\"Sex\", @\"Sex\"), new InputOutputColumnPair(@\"Embarked\", @\"Embarked\") })\r\n                .Append(context.Transforms.Concatenate(@\"TextFeature\", @\"Name\", \"Ticket\", \"Cabin\"))\r\n                .Append(context.Sweepable().CreateSweepableEstimator(\r\n                    (mlContext, option) =>\r\n                    {\r\n                        var textOption = new TextFeaturizingEstimator.Options\r\n                        {\r\n                            CaseMode = option.CaseMode,\r\n                            KeepDiacritics = option.KeepDiacritics,\r\n                            KeepNumbers = option.KeepNumbers,\r\n                            KeepPunctuations = option.KeepPunctuations,\r\n                            CharFeatureExtractor = new WordBagEstimator.Options()\r\n                            {\r\n                                NgramLength = option.WordBagEstimatorOption.NgramLength,\r\n                                UseAllLengths = option.WordBagEstimatorOption.UseAllLengths,\r\n                                Weighting = option.WordBagEstimatorOption.WeightingCriteria,\r\n                            },\r\n                        };\r\n\r\n                        return mlContext.Transforms.Text.FeaturizeText(\"TextFeature\", textOption);\r\n                    },\r\n                    textFeaturizeSS))\r\n                .Append(context.Transforms.Concatenate(@\"Features\", new[] { @\"Sex\", @\"Embarked\", @\"Pclass\", @\"Age\", @\"SibSp\", @\"Parch\", @\"Fare\", \"TextFeature\" }))\r\n                .Append(context.Transforms.Conversion.ConvertType(\"Survived\", \"Survived\", Data.DataKind.Boolean))\r\n                .Append(context.Sweepable().CreateSweepableEstimator(\r\n                    (mlContext, option) => mlContext.BinaryClassification.Trainers.FastForest(labelColumnName: \"Survived\", featureColumnName: \"Features\", numberOfLeaves: option.NumberOfLeavenumberOfTrees: option.NumberOfTrees),\r\n                    fastTreeSS))\r\n                .Append(context.BinaryClassification.Calibrators.Naive(labelColumnName: @\"Survived\", scoreColumnName: @\"Score\"));\r\n```\r\n\r\nAfter sweepable pipeline is created, one can call `BuildTrainingPipeline` to convert it to a ml.net pipeline.\r\n\r\n## tuner\r\n\r\ntuner takes in a search space and performs hpo algos. There're a few default tuning alogs provided by Sweepable API (grid search/random search), and there'll be more smart hpo algos coming soon.\r\n\r\nThe way to use a tuner is quite similar with the way to use an enumerator. The code below shows how tuner works with search space and sweepable estimator/pipeline\r\n\r\n```csharp\r\nvar ss = pipeline.SearchSpace\r\nvar tuner = new GridSearchTuner(ss);\r\nvar df = DataFrame.LoadCsv(@\"titanic.csv\");\r\nvar trainTestSplit = context.Data.TrainTestSplit(df, 0.1);\r\nvar bestAccuracy = 0.0;\r\nvar i = 0;\r\nforeach (var param in tuner.Propose())\r\n{\r\n    Console.WriteLine($\"trial {i++}\");\r\n\r\n    // convert sweepable pipeline to ml.net pipeline\r\n    var trainingPipeline = pipeline.BuildTrainingPipeline(context, param);\r\n    var model = trainingPipeline.Fit(trainTestSplit.TrainSet);\r\n    var eval = model.Transform(trainTestSplit.TestSet);\r\n    var accuracy = context.BinaryClassification.Evaluate(eval, \"Survived\").Accuracy;\r\n    if (accuracy > bestAccuracy)\r\n    {\r\n        Console.WriteLine(\"Found best accuracy\");\r\n        Console.WriteLine(\"Current best parameter\");\r\n        Console.WriteLine(JsonConvert.SerializeObject(param));\r\n        bestAccuracy = accuracy;\r\n\r\n        Console.WriteLine($\"Trial {i}: Current Best Accuracy {bestAccuracy}, Current Accuracy {accuracy}\");\r\n    }\r\n}\r\n\r\n```\r\n\r\nYou can visit [here](https://github.com/dotnet/machinelearning-tools/blob/main/src/Microsoft.ML.ModelBuilder.AutoMLService.Example/Program.cs) to try out the complete training code.\r\n\r\n## The difference between sweepable api and existing api in AutoML.Net\r\nThe exsiting API in AutoML.Net performs hpo on pre-defined search space and learners with smac tuning algo while sweepable api allows user to customize those settings: they can define their own search space, they can create pipeline similarly with how it is created in ml.net, and they can pick the tuner which suit their experiment the best.\r\n\r\n## Q & A\r\n\r\nWhat's the difference between Sweepable API and AutoML.Net experiments\r\n- AutoML.Net experiments provide an oobe experience for automl with fixed hpo-related option, while Sweepable API requires user to set up those options (search space, pipeline, tuner) manually before training. Sweepable API is not aimed to replace existing AutoML.Net API, but to provide another options for those customers whose request can't be satified by default automl experiment.\r\n\r\nWill AutoML.Net benefits from Sweepable API\r\n- Yes it will, along with sweepable API, we can also leverage [flaml](https://github.com/microsoft/FLAML) technique in the tuning algothrim, which helps improves tuning speed and performance.\r\n\r\nWhy do we need sweepable API, who will be the beneficaries, what's the most common user-case.\r\n- Sweepable API is prepared for HPO, which is a feature required by community from ever since mlnet being released. ([#613](https://github.com/dotnet/machinelearning/issues/613), [#2260](https://github.com/dotnet/machinelearning/issues/2260), [#5930](https://github.com/dotnet/machinelearning/issues/5930),[#1875](https://github.com/dotnet/machinelearning-modelbuilder/issues/1875) etc...). The major beneficiaries will be those who'd like to run automl on different search space or trainers other than the fixed parameters provided by AutoML.Net. The most common user-case, as I'm imagining, is on Notebook along with DataFrame API.\r\n\r\nWhat's the timeline for intergrating Sweepable API into ML.Net\r\n- it depends. Sweepable API has three major parts and all are available in model builder repo. On top of which is a thin layer which makes the three part work with ML.Net. So if the plan is only moving that thin layer into AutoML.Net first, and make the rest of three parts open source later, it will take 2-3 weeks. If we want to move all parts into mlnet all together, it will cost much more time.\r\n\r\n\r\n## Current feedback\r\n- the lambda function in `CreateSweepableEstimator` should not accept `MLContext` as first parameter.\r\n- Should provide a higher level API for training similar with Experiment API in AutoML.Net.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5992","RelatedDescription":"Closed issue \"Proposal: AutoML Sweepable API\" (#5992)"},{"Id":"1042746943","IsPullRequest":false,"CreatedAt":"2021-11-02T19:46:39","Actor":"luisquintanilla","Number":"5991","RawContent":null,"Title":"Issue Fit method when i am training the images datasets","State":"open","Body":"Moving issue from dotnet/docs\r\n\r\n## Original Issue\r\n\r\ndotnet/docs#20443\r\n\r\nWhen i run project it stops on Fit method  i am attaching project file , Images which one i am using for testing and screenshot of  #execution\r\n\r\n[TestMLNETImages.zip](https://github.com/dotnet/machinelearning/files/5158560/TestMLNETImages.zip)\r\n![ImageIssue](https://user-images.githubusercontent.com/49320278/91901259-991cd880-ecbd-11ea-89f0-d13f94d6eb73.PNG)\r\n\r\ni am not able attach packages folder \r\n![packages](https://user-images.githubusercontent.com/49320278/91901418-d2eddf00-ecbd-11ea-8e4c-b6b1db0b5cf8.PNG)\r\n\r\n\r\nPlease let me if i am missing anything or what is wrong with project file \r\n\r\nThanks your support advance  \r\n   ","Url":"https://github.com/dotnet/machinelearning/issues/5991","RelatedDescription":"Open issue \"Issue Fit method when i am training the images datasets\" (#5991)"},{"Id":"1040225996","IsPullRequest":false,"CreatedAt":"2021-10-30T15:25:07","Actor":"boffman","Number":"5989","RawContent":null,"Title":"mlnet classification fails if file is too big","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: mlnet tool 16.2.0\r\n - .NET Version: dotnet 5.0.402\r\n\r\n**Describe the bug**\r\nI have  a large semicolon-separated dataset with 1833 columns per row and 37437 rows in it. Running the cli tool mlnet on it fails with an error message if the file is too big:\r\n\r\n`One or more errors occurred. (Specified column index 1833 is out of range. This dataset has 1 columns and column index must be non-negative and less than the size of the collection.)`\r\n\r\nI have tried with running on the first 130 rows, and the last 130 rows of the dataset (= 1,067,118 bytes), and it starts. But if I run with the 140 (or more) first, or last, rows, it fails with the error. 140 rows makes the file 1,149,894 bytes in size.\r\n\r\nHowever, the same dataset (full sized) works with the ML Model Builder inside Visual Studio!\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Create a CSV file with 1833 columns per row, 8364 characters/row and 140 rows in total (test1.txt)\r\n2. Run command:\r\n`mlnet classification --dataset test1.txt --has-header false --ignore-cols 0 --label-col 1833 --train-time 1800 --name EcnML_test --output EcnML`\r\n3. mlnet aborts with the error after a few seconds\r\n\r\n**Expected behavior**\r\nThe classification should start and work the same with 140 rows, just as with 130 rows in the dataset.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nOne row of the dataset looks like this:\r\n```\r\n2017-12-25_27_1;2640;volte;1;0.7575757575757576;0.7329261521377013;0;0.1489;0.125;0.5344652812975165;0.5;0;0;0;short;5;auto;885;medium;0;auto;0;medium;0;auto;0;0.16140865737344093;medium;0;auto;0;medium;0;auto;0;medium;4;volte;900;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.02012072434607646;medium;0;auto;0;medium;0;auto;0;medium;0;volte;950;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;2;0.8254769921436588;0.8745141588006663;0.0882;0.2941;0.6;0.6130258489609731;0.5416666666666666;2;0;3;medium;0;auto;0;medium;0;auto;0;medium;5;auto;895;0.483492296404989;medium;0;auto;0;medium;0;auto;0;medium;6;volte;911;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;1;1;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.24949698189134809;medium;0;auto;0;medium;0;auto;0;medium;0;volte;909;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;3;0.8866442199775533;0.9039422543031649;0.1333;0.5333;0.885;0.7014698428788647;0.5416666666666666;2;3;3;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;1;medium;0;auto;0;medium;0;auto;0;medium;3;volte;883;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.02112676056338028;short;5;volte;968;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;4;0.8383838383838383;0.9694614103275958;0.0476;0.2142;0.175;0.6469842878864673;0.4166666666666667;1;0;2;short;0;auto;937;medium;0;auto;0;medium;0;auto;0;0.2164343360234776;medium;0;auto;0;medium;0;auto;0;medium;0;volte;893;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.13380281690140844;medium;0;auto;0;medium;0;auto;0;medium;4;volte;905;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;5;0.7323232323232324;0.714047751249306;0.035;0.1052;0.04;0.5674100354789661;0.4166666666666667;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;916;0.04475421863536317;medium;0;auto;0;medium;0;auto;0;medium;8;volte;916;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;7;auto;910;0.0613682092555332;medium;0;auto;0;medium;0;auto;0;medium;0;volte;908;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;6;0.8142536475869809;0.7978900610771793;0.0789;0.2368;0.943;0.6370755195134313;0.6666666666666666;1;2;2;medium;0;auto;0;medium;0;auto;0;medium;0;auto;901;0.32700660308143803;medium;0;auto;0;medium;0;auto;0;medium;2;volte;911;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;2;1;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.5482897384305835;short;0;volte;913;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;7;0.8473625140291807;0.7962243198223209;0.0555;0.5;0.103;0.6705524581855044;0.375;0;0;2;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.2413793103448276;medium;0;auto;0;medium;0;auto;0;medium;7;volte;906;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;1;1;5;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;1;medium;0;auto;0;medium;0;auto;0;medium;3;volte;902;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;8;0.8355780022446689;0.7867851193781232;0.0344;0.1206;0.466;0.7108464267612773;1;2;1;4;medium;0;auto;0;medium;0;auto;0;medium;4;auto;891;0.6522377109317682;medium;0;auto;0;medium;0;auto;0;medium;0;volte;883;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.22132796780684105;short;0;volte;918;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;9;1;0.7290394225430317;0.238;0.4761;0.875;1;0.6666666666666666;4;2;2;medium;0;auto;0;medium;0;auto;0;medium;2;auto;868;0.9889948642699926;medium;0;auto;0;medium;0;auto;0;medium;3;volte;876;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;1;1;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.6287726358148893;medium;0;auto;0;medium;0;auto;0;medium;0;volte;916;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;10;0.9365881032547699;0.9616879511382566;0.0263;0.3157;0.73;0.7698935631018753;0.7916666666666666;1;4;3;medium;0;auto;0;medium;0;auto;0;medium;4;auto;900;0.7307410124724871;medium;0;auto;0;long;3;volte;900;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;1;1;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.2625754527162978;medium;0;auto;0;medium;0;auto;0;medium;5;volte;928;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;11;0.9287317620650954;0.8833981121599112;0.1;0.4;1;0.9216928535225545;0.5;1;2;3;medium;0;auto;0;medium;0;auto;0;medium;7;auto;890;0.6082171680117389;medium;0;auto;0;medium;0;auto;0;medium;0;volte;880;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;2;4;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.8551307847082495;medium;0;auto;0;medium;0;auto;0;medium;2;volte;898;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;12;0.7194163860830527;0.9578012215435869;0.0508;0.1016;0.077;0.7835783071464775;0.08333333333333333;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.02347762289068232;medium;0;auto;0;medium;0;auto;0;medium;5;volte;914;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.02012072434607646;medium;0;auto;0;medium;0;auto;0;medium;8;volte;922;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;13;0.9354657687991021;1;0.0882;0.2941;0.526;0.8132285859097821;0.4166666666666667;0;2;0;medium;0;auto;0;medium;0;auto;0;medium;4;auto;904;0.28686720469552457;short;5;volte;895;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;2;3;1;medium;0;auto;0;medium;0;auto;0;medium;6;auto;933;0.744466800804829;medium;0;auto;0;medium;0;auto;0;medium;2;volte;902;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;14;0.8922558922558923;0.8184342032204331;0.3157;0.5263;0.765;0.9827673593512417;0.4583333333333333;5;0;1;short;3;auto;886;medium;0;auto;0;medium;0;auto;0;1;medium;0;auto;0;medium;0;auto;0;medium;6;volte;880;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;1;2;1;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0.579476861167002;medium;0;auto;0;medium;0;auto;0;medium;3;volte;906;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;0;0;0;0;0;0;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;medium;0;auto;0;0;0;0;0\r\n```\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5989","RelatedDescription":"Open issue \"mlnet classification fails if file is too big\" (#5989)"},{"Id":"1037583450","IsPullRequest":false,"CreatedAt":"2021-10-27T15:49:14","Actor":"nsulikowski","Number":"5986","RawContent":null,"Title":"Save auto ml results to MLFlow","State":"open","Body":"It would be great to save all the runs (models, metrics) produced by auto ml to an MLFlow experiment, for easy browsing\r\nThis is not my idea.. Databricks does this when you run their AutoML feature.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5986","RelatedDescription":"Open issue \"Save auto ml results to MLFlow\" (#5986)"},{"Id":"1036917329","IsPullRequest":false,"CreatedAt":"2021-10-27T02:54:01","Actor":"zcgg2zhmm","Number":"5985","RawContent":null,"Title":"how to use gpu? AddPredictionEnginePool","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: ubuntu 20.04\r\n - ML.NET Version: 1.6.0\r\n - .NET Version: .net core 3.1\r\n - Microsoft.Extensions.ML version: 1.6.0\r\n - webapi\r\n\r\n**Describe the bug**\r\ncpu work well, but, how to use gpu?\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\nStartup.cs:\r\n```\r\npublic void ConfigureServices(IServiceCollection services)\r\n{\r\n   services.AddControllers();\r\n   services.AddPredictionEnginePool<DeNoiseInput, DeNoiseOutput>().FromFile(\"./mlmodel/denoise_docs.zip\");\r\n}\r\n```\r\n\r\n\r\nController:\r\n```\r\npublic class DocsController : Controller\r\n{\r\n    private readonly PredictionEnginePool<DeNoiseInput, DeNoiseOutput> _denoiseEngine;\r\n\r\n    public DocsController(PredictionEnginePool<DeNoiseInput, DeNoiseOutput> denoiseEngine)\r\n    {\r\n        _denoiseEngine = denoiseEngine;\r\n    }\r\n    \r\n    public ActionResult<string> DeNoise([FromBody] DeNoiseRequest request)\r\n    {\r\n         ...\r\n         var outs = _denoiseEngine.Predict(imgExample);\r\n         ...\r\n    }\r\n}\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5985","RelatedDescription":"Open issue \"how to use gpu? AddPredictionEnginePool\" (#5985)"},{"Id":"1034095744","IsPullRequest":true,"CreatedAt":"2021-10-26T02:38:54","Actor":"CallumMcLoughlin","Number":"5983","RawContent":null,"Title":"Fix minor typos in RootCauseLocalizationType.cs","State":"closed","Body":"# Summary\r\n\r\nMinor typo fix, `libary` -> `library`\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5983","RelatedDescription":"Closed or merged PR \"Fix minor typos in RootCauseLocalizationType.cs\" (#5983)"},{"Id":"1034671417","IsPullRequest":false,"CreatedAt":"2021-10-25T04:41:43","Actor":"ooples","Number":"5984","RawContent":null,"Title":"Will Multivariate Time Series Forecasting Be Supported?","State":"open","Body":"I see that the forecasting only supports univariate time series unless I'm missing something but are there plans and/or release date planned to support multivariate time series forecasting?","Url":"https://github.com/dotnet/machinelearning/issues/5984","RelatedDescription":"Open issue \"Will Multivariate Time Series Forecasting Be Supported?\" (#5984)"},{"Id":"1030835890","IsPullRequest":true,"CreatedAt":"2021-10-20T21:06:08","Actor":"michaelgsharp","Number":"5982","RawContent":null,"Title":"Release notes for 1.7.0 preview","State":"closed","Body":"These are the release notes for the 1.7.0 preview. If/when more bugs are fixed I will add them to these release notes after.","Url":"https://github.com/dotnet/machinelearning/pull/5982","RelatedDescription":"Closed or merged PR \"Release notes for 1.7.0 preview\" (#5982)"},{"Id":"1030092054","IsPullRequest":false,"CreatedAt":"2021-10-19T09:45:45","Actor":"FlukeFan","Number":"5981","RawContent":null,"Title":"DetectIidSpike not finding spikes ...","State":"open","Body":" - OS & Version: Windows 10 Pro 64 bit \r\n - ML.NET Version: 1.6.0\r\n - .NET Version: .NET 5.0.402\r\n\r\nI forked the machinelearning-samples repository.  I generated a new product-sales.csv with 250 rows (instead of 36), and random values between 20K-30K.\r\n\r\nThere is one row in the file (at line 53) with an obvious spike of 60K.\r\n\r\nRunning the program does not pick up the spike.\r\n\r\n\r\n**To Reproduce**\r\nUsing the machine-learning-samples code:\r\n1. Replace the product-sales.csv with the one above:  https://github.com/FlukeFan/machinelearning-samples/blob/main/samples/csharp/end-to-end-apps/AnomalyDetection-Sales/SpikeDetectionE2EApp/Data/product-sales.csv#L53\r\n\r\n2. Set the number of entries in the file to 250:  https://github.com/FlukeFan/machinelearning-samples/blob/main/samples/csharp/end-to-end-apps/AnomalyDetection-Sales/SpikeDetectionE2EApp/SpikeDetection.ModelTrainer/Program.cs#L29\r\n\r\n3. Run the program - no spike is detected.\r\n\r\n\r\n**Expected behavior**\r\nI would expect the DetectIidSpike transform to identify the spike.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nThe code I used is a fork here:  https://github.com/FlukeFan/machinelearning-samples/tree/main/samples/csharp/end-to-end-apps/AnomalyDetection-Sales\r\n\r\nThere was a single commit to generate the test data:  https://github.com/FlukeFan/machinelearning-samples/commit/d838f17b16d5cce71397416a9481711e6089c600\r\n\r\n\r\n**Additional context**\r\nI notice that reducing the pvalueHistoryLength to about 50 highlights the spike, however I would expect larger values of the sliding window to also pick up the spike.\r\n\r\nI had originally observed this problem when trying the spike detection on a much much larger file (many thousands of records), but I have reduced it to the 250 line file the demonstrates the problem.","Url":"https://github.com/dotnet/machinelearning/issues/5981","RelatedDescription":"Open issue \"DetectIidSpike not finding spikes ...\" (#5981)"},{"Id":"1030044867","IsPullRequest":false,"CreatedAt":"2021-10-19T09:02:15","Actor":"Webreaper","Number":"5980","RawContent":null,"Title":"Create an ML.Net sample showing image classification using images already loaded in memory, rather than from disk","State":"open","Body":"I'm trying to put together an ML.Net image classification app. However, the [samples](https://github.com/dotnet/samples/tree/main/machine-learning/tutorials/TransferLearningTF) I can find all assume that the images being classified are a folder of disk-based image files. This doesn't really help when processing already-in-memory images (for example, streaming video frames, etc). \r\n\r\nI've tried adapting the example [here](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.tensorflowmodel.scoretensorflowmodel) to use bytes from a Bitmap pre-loaded from disk, but I don't seem to be getting the setup of the tensor data right, which means that I just get NaN results from the scoring.  \r\n\r\nIt would be really useful if the ML.Net team could put together a sample where the input was a binary image - so for example, in the `ScoreTensorFlowModel` example above, if the `GetTensorData` method loaded a couple of JPEGs from disk, and then passed back the `TensorData[]` structure as an array of binary data from the images. \r\n\r\nIt seems, while googling, that a **lot** of people would find such an example extremely helpful - as there's a lot of people trying (and failing) to image-process video streams and other in-memory images using ML.Net and TF.\r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/5980","RelatedDescription":"Open issue \"Create an ML.Net sample showing image classification using images already loaded in memory, rather than from disk\" (#5980)"},{"Id":"1029592118","IsPullRequest":false,"CreatedAt":"2021-10-18T21:01:31","Actor":"LittleLittleCloud","Number":"5979","RawContent":null,"Title":"DataFrame.LoadCsv fails when hasHeader=true","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Win11\r\n - ML.NET Version: ML.Net 1.6.0\r\n\r\n**Describe the bug**\r\ndataset: \r\n[spam.csv](https://github.com/dotnet/machinelearning/files/7368451/spam.csv)\r\n\r\ncode:\r\n```\r\nDataFrame.LoadCsv(/path/to/csv, hasHeader: true)\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5979","RelatedDescription":"Open issue \"DataFrame.LoadCsv fails when hasHeader=true\" (#5979)"}],"ResultType":"GitHubIssue"}},"RunOn":"2021-11-21T05:30:30.9356913Z","RunDurationInMilliseconds":517}