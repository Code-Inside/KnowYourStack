{"Data":{"GitHub":{"Issues":[{"Id":"1348605189","IsPullRequest":true,"CreatedAt":"2022-08-23T22:16:08","Actor":"dakersnar","Number":"6301","RawContent":null,"Title":"Add DataFrame.IO tests with separators in data","State":"open","Body":"https://github.com/dotnet/machinelearning/issues/5647 is no longer an issue, but there are no existing unit tests that confirm this behavior. Adding them here.","Url":"https://github.com/dotnet/machinelearning/pull/6301","RelatedDescription":"Open PR \"Add DataFrame.IO tests with separators in data\" (#6301)"},{"Id":"1347149536","IsPullRequest":true,"CreatedAt":"2022-08-23T00:16:02","Actor":"LittleLittleCloud","Number":"6300","RawContent":null,"Title":"use parameter to save choice object","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nfix #6299 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/6300","RelatedDescription":"Open PR \"use parameter to save choice object\" (#6300)"},{"Id":"1347027215","IsPullRequest":false,"CreatedAt":"2022-08-22T21:48:09","Actor":"LittleLittleCloud","Number":"6299","RawContent":null,"Title":"ChoiceAttribution doesn't work with int type.","State":"open","Body":"reproduction\r\n\r\n```csharp\r\nclass Param\r\n{\r\n   [Choice(1,2,3)]\r\n   public int Index {get; set;}\r\n}\r\n\r\n// throw exception\r\nvar ss = new SearchSpace<Param>();\r\nvar tuner = new RandomTuner(ss);\r\ntuner.Propose()\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6299","RelatedDescription":"Open issue \"ChoiceAttribution doesn't work with int type.\" (#6299)"},{"Id":"1343507056","IsPullRequest":false,"CreatedAt":"2022-08-22T19:54:35","Actor":"LittleLittleCloud","Number":"6291","RawContent":null,"Title":"AutoFeaturizer puts ReplacingMissingValue transformer to boolean column","State":"closed","Body":"The root cause is `InferColumn` API also infer a boolean column's column purpose as numeric. Which in some way makes sense as there's a direct way of mapping boolean to numeric.\r\n\r\nWhile in `AutoFeaturizer` API, it always put a `ReplacingMissingValue` transformer to numeric feature. This usually works if a column has numeric type. But when it comes to boolean type, `ReplacingMissingValue` won't work any more as there's no Default NA value for a boolean type.\r\n\r\nThe fix for this issue is in `AutoFeaturizer`, check if a column with numeric purpose is boolean type or not, if it is boolean, then use `ConvertType` transformer instead. ","Url":"https://github.com/dotnet/machinelearning/issues/6291","RelatedDescription":"Closed issue \"AutoFeaturizer puts ReplacingMissingValue transformer to boolean column\" (#6291)"},{"Id":"1345657959","IsPullRequest":false,"CreatedAt":"2022-08-22T01:04:15","Actor":"luisquintanilla","Number":"6298","RawContent":null,"Title":"NotebookMonitor doesn't display AutoML training progress.","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 0.20.0-preview.22356.1\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\n\r\nNotebookMonitor displays gray box in output window instead of AutoML training progress\r\n\r\n**To Reproduce**\r\n\r\nRun the following notebook https://github.com/dotnet/csharp-notebooks/blob/main/machine-learning/03-Training%20and%20AutoML.ipynb\r\n\r\n**Expected behavior**\r\n\r\nNotebookMonitor displays AutoML training progress\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/185819923-6b2a31e5-0d2c-4050-a9bc-1373a568d03d.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6298","RelatedDescription":"Open issue \"NotebookMonitor doesn't display AutoML training progress.\" (#6298)"},{"Id":"1343508939","IsPullRequest":true,"CreatedAt":"2022-08-21T02:38:07","Actor":"LittleLittleCloud","Number":"6292","RawContent":null,"Title":"transform boolean to numeric when column is numeric feature while is boolean type","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n#6291 ","Url":"https://github.com/dotnet/machinelearning/pull/6292","RelatedDescription":"Closed or merged PR \"transform boolean to numeric when column is numeric feature while is boolean type\" (#6292)"},{"Id":"1344711699","IsPullRequest":false,"CreatedAt":"2022-08-19T17:28:02","Actor":"wil70","Number":"6297","RawContent":null,"Title":"[Issue, ML.net C#] 330GB csv file of data cause a OutOfMemoryException (2/2)","State":"open","Body":"**System Information (please complete the following information):**\r\n\r\n-  OS & Version: Win8, latest version as of this bug entry\r\n- ML.NET Version: 16.13.9\r\n- .NET Version:6.0.303\r\n\r\n**Describe the bug**\r\nWhen I start c# AutoML in c# I get a OutOfMemoryException after the memory reach the maximum of 64GB.\r\nI have 64GB Ram, I have a 330GB csv file of data.\r\n\r\nNote: I couldn't do it with ML.net CLI due to this bug https://github.com/dotnet/machinelearning/issues/6288 so I tried to do it with c# AutoML package. I'm totally new at ML.NET, sorry in adavance for the code quality\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Generate a 330GB file with 4209 columns with random data\r\n2. create a c# project and paste the code below\r\n3. See error log at the end of this message with the OutOfMemoryException\r\n\r\n**Expected behavior**\r\nI expect to be able to be able to handle 2TB files and 100K columns without any issue with ML.Net CLI and also with c# on a 64GB ram computer by streaming the data instead of loading all in memeory.\r\n  \r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n\r\n\r\nI have a 330gb file (64 gb ram). I tried ML.NET CLI but hit a bug see.\r\nSo I'm now trying with c#, the bug is different than the ML.NET CLI issue as it seems to try to load everything in memory \r\n\r\nIDataView trainingData = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n                \"c:\\data.csv\", \r\n                separatorChar: ',', hasHeader: true, trimWhitespace: true);\r\n\r\n            var cts = new CancellationTokenSource();\r\n            var experimentSettings = new MulticlassExperimentSettings();\r\n            //experimentSettings.TrainingData = trainingData;\r\n            experimentSettings.MaxExperimentTimeInSeconds = 3600;\r\n            experimentSettings.CancellationToken = cts.Token;\r\n            experimentSettings.CacheBeforeTrainer = CacheBeforeTrainer.Auto;\r\n\r\n            // Cancel experiment after the user presses any key\r\n            //CancelExperimentAfterAnyKeyPress(cts);\r\n            experimentSettings.CacheDirectoryName = null;\r\n\r\n            MulticlassClassificationExperiment experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);\r\n            ExperimentResult<MulticlassClassificationMetrics> experimentResult = experiment.Execute(trainingData, \"Entry(Text)\");//, progressHandler: progressHandler);\r\n\r\n\r\n.....\r\n public class ModelInput\r\n        {\r\n            [LoadColumn(0), NoColumn]\r\n            public string _data0 { get; set; }\r\n\r\n            [LoadColumn(1), NoColumn]\r\n            public float ignoreData1 { get; set; }\r\n\r\n            [LoadColumn(2, 4205)]\r\n            public float _data { get; set; }\r\n\r\n            [LoadColumn(4206),NoColumn]//(4206,4208)]\r\n            public float _ignoreData4206 { get; set; }         \r\n\t\t[LoadColumn(4207), NoColumn]//(4206,4208)]\r\n            public float _ignoreData4207 { get; set; }\r\n            [LoadColumn(4208), NoColumn]//(4206,4208)]\r\n            public float _ignoreData4208 { get; set; }\r\n\r\n            [LoadColumn(4209),ColumnName(\"Entry(Text)\")]\r\n            public string _label { get; set; }\r\n        }\r\n\r\n------\r\n\r\nThere is a Exception of type 'System.OutOfMemoryException' was thrown.\r\n(new System.Collections.Generic.Mscorlib_CollectionDebugView<Microsoft.ML.AutoML.RunDetail<Microsoft.ML.Data.MulticlassClassificationMetrics>>(experimentResult.RunDetails).Items[0]).Exception.StackTrace\r\n   at Microsoft.ML.Internal.Utilities.OrderedWaiter.Wait(Int64 position, CancellationToken token)\r\n   at Microsoft.ML.Data.CacheDataView.GetPermutationOrNull(Random rand)\r\n   at Microsoft.ML.Data.CacheDataView.GetRowCursorSetWaiterCore[TWaiter](TWaiter waiter, Func`2 predicate, Int32 n, Random rand)\r\n   at Microsoft.ML.Data.CacheDataView.GetRowCursorSet(IEnumerable`1 columnsNeeded, Int32 n, Random rand)\r\n   at Microsoft.ML.Data.OneToOneTransformBase.GetRowCursorSet(IEnumerable`1 columnsNeeded, Int32 n, Random rand)\r\n   at Microsoft.ML.Data.DataViewUtils.TryCreateConsolidatingCursor(DataViewRowCursor& curs, IDataView view, IEnumerable`1 columnsNeeded, IHost host, Random rand)\r\n   at Microsoft.ML.Data.TransformBase.GetRowCursor(IEnumerable`1 columnsNeeded, Random rand)\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.FactoryBase`1.Create(Random rand, Int32[] extraCols)\r\n   at Microsoft.ML.Trainers.OnlineLinearTrainer`2.TrainCore(IChannel ch, RoleMappedData data, TrainStateBase state)\r\n   at Microsoft.ML.Trainers.OnlineLinearTrainer`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.TrainOne(IChannel ch, ITrainerEstimator`2 trainer, RoleMappedData data, Int32 cls)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String groupId, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n\r\n-----\r\nThere is a Exception of type 'System.OutOfMemoryException' was thrown.\r\n(new System.Collections.Generic.Mscorlib_CollectionDebugView<Microsoft.ML.AutoML.RunDetail<Microsoft.ML.Data.MulticlassClassificationMetrics>>(experimentResult.RunDetails).Items[0]).Exception.InnerException.StackTrace\r\n   at Microsoft.ML.Internal.Utilities.ArrayUtils.EnsureSize[T](T[]& array, Int32 min, Int32 max, Boolean keepOld, Boolean& resized)\r\n   at Microsoft.ML.Internal.Utilities.BigArray`1.AddRange(ReadOnlySpan`1 src)\r\n   at Microsoft.ML.Data.CacheDataView.ColumnCache.ImplVec`1.CacheCurrent()\r\n   at Microsoft.ML.Data.CacheDataView.Filler(DataViewRowCursor cursor, ColumnCache[] caches, OrderedWaiter waiter)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6297","RelatedDescription":"Open issue \"[Issue, ML.net C#] 330GB csv file of data cause a OutOfMemoryException (2/2)\" (#6297)"},{"Id":"1344421181","IsPullRequest":false,"CreatedAt":"2022-08-19T13:08:52","Actor":"prodanovic","Number":"6296","RawContent":null,"Title":"Support loading lightgbm model from a file","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nOur data scientists are training lightgbm models in python, and our inference runtime is in C#. We are very much interested in using ML.NET to run inference, however loading the model from a file is not yet supported in ML.NET. Is there an obstacle in adding this additional binding already available in lightgbm C++ API ?\r\n\r\n**Describe the solution you'd like**\r\nAdd LGBM_BoosterLoadModelFromString binding to [WrappedLightGbmInterface ()](https://github.com/dotnet/machinelearning/blob/510f0112d4fbb4d3ee233b9ca95c83fae1f9da91/src/Microsoft.ML.LightGbm/WrappedLightGbmInterface.cs#L189%7D) available in https://github.com/Microsoft/LightGBM/blob/master/include/LightGBM/c_api.h \r\n\r\n**Describe alternatives you've considered**\r\nAn alternative is to convert our models to ONNX and not use ML.NET runtime. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6296","RelatedDescription":"Open issue \"Support loading lightgbm model from a file\" (#6296)"},{"Id":"1344070012","IsPullRequest":false,"CreatedAt":"2022-08-19T07:41:33","Actor":"kitosd","Number":"6295","RawContent":null,"Title":"Model Builder Error","State":"open","Body":"Model Builder Version : 16.1.0.20.27905\r\nVisual Studio Version : 16.11.18\r\n\r\nBug description\r\nWith freshly-updated [as of today, 2022-08-19] VS2019 and model builder, I tried to use the new ML builder wizard \"Value prediction\". It failed with an exception: Method not found: 'System.Collections.Generic.IEnumerable1<System.ValueTuple2<Microsoft.ML.AutoML.RunDetail`1<!!0>,Int32>> Microsoft.ML.AutoML.BestResultUtil.GetTopNRunResults\r\n\r\nSteps to Reproduce\r\n\r\nInstalled latest VS 2019 and updated Model Builder to latest version\r\nCreate new project. Right click on project -> Add -> \"Machine Learning\"\r\nChoose image classification, \"Local ML\", Next.\r\nAs input, choose an appropriate folder, observe \"data preview\" looks like I expected, with images being shown under various classifications\r\nTrain, Start Training.\r\nExpected Experience\r\nPretty much what I'd expect from the tutorial, and of a wizard.\r\n\r\nActual Experience\r\nShortly after click \"start training\", I get this:\r\n\"GPU Service not found. Falling back to CPU AutoML Service.\"\r\n\r\nMoments later, this exception:\r\nMethod not found: 'System.Collections.Generic.IEnumerable1<System.ValueTuple2<Microsoft.ML.AutoML.RunDetail1<!!0>,Int32>> Microsoft.ML.AutoML.BestResultUtil.GetTopNRunResults(System.Collections.Generic.IEnumerable1<Microsoft.ML.AutoML.RunDetail1<!!0>>, Microsoft.ML.AutoML.IMetricsAgent1<!!0>, Int32, Boolean)'.\r\nat Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment3.d__21.MoveNext() at System.Runtime.CompilerServices.AsyncTaskMethodBuilder1.Start[TStateMachine](TStateMachine& stateMachine)\r\nat Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment3.ExecuteAsync(IDataView trainData, IDataView validateData, ColumnInformation columnInformation, Nullable1 userCancellationToken, Nullable`1 timeout)\r\nat Microsoft.ML.ModelBuilder.AutoMLEngine.d__30.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 147","Url":"https://github.com/dotnet/machinelearning/issues/6295","RelatedDescription":"Open issue \"Model Builder Error\" (#6295)"},{"Id":"1343739912","IsPullRequest":false,"CreatedAt":"2022-08-18T23:10:18","Actor":"luisquintanilla","Number":"6294","RawContent":null,"Title":"Convert TrialResult to DataFrame","State":"open","Body":"## Description\r\n\r\n[TrialResult](https://docs.microsoft.com/dotnet/api/microsoft.ml.automl.trialresult?view=ml-dotnet-preview) gives you important information about each trial AutoML runs as part of an experiment. Although today we have the NotebookMonitor for real-time visualizations and feedback during training, once training is done, to get similar information, users have to write their own code to access each of these pieces of information. \r\n\r\n## Proposal\r\n\r\nGiven an AutoML experiment called `experiment`, when training is done, users should be able to call `ToDataFrame` to convert the results of an AutoML experiment into a `DataFrame`.\r\n\r\n```csharp\r\nTrialResult experimentResults = await experiment.RunAsync();\r\nDataFrame results = experimentResults.ToDataFrame();\r\n```\r\n\r\nThe result should display columns with information for each of the trials in a DataFrame similar to the following:\r\n\r\n| TrialId | DurationInMilliseconds | Metric | Pipeline | Parameter |\r\n| --- | --- | --- | --- | --- |\r\n| 21 | 8.5 | 0.98 | ... | ... |\r\n| 5 | 3.8 | 0.83 | ... | ... |\r\n\r\nFrom there, if users to sort / query the results using the built-in DataFrame methods, they can. Additionally, they can export to CSV using the [WriteCsv](https://docs.microsoft.com/en-us/dotnet/api/microsoft.data.analysis.dataframe.writecsv?view=ml-dotnet-preview) method.","Url":"https://github.com/dotnet/machinelearning/issues/6294","RelatedDescription":"Open issue \"Convert TrialResult to DataFrame\" (#6294)"},{"Id":"1343697930","IsPullRequest":false,"CreatedAt":"2022-08-18T22:06:39","Actor":"LittleLittleCloud","Number":"6293","RawContent":null,"Title":"Add maximum memory usage limit to AutoML experiment","State":"open","Body":"We have a lot of users complaining about OOM error when using AutoML. This is because ML.Net AutoML tends to search larger model as time passes, so it's kind of necessary to put some hard limit on memory usages for AutoML training.","Url":"https://github.com/dotnet/machinelearning/issues/6293","RelatedDescription":"Open issue \"Add maximum memory usage limit to AutoML experiment\" (#6293)"},{"Id":"1343322491","IsPullRequest":false,"CreatedAt":"2022-08-18T16:10:49","Actor":"papyr","Number":"6290","RawContent":null,"Title":"Native ML.NET notebook","State":"open","Body":"Hello, can we get a native notebook inside Visual Studio or VS Code, since we already have a designer surface with all the drag and drop controls?","Url":"https://github.com/dotnet/machinelearning/issues/6290","RelatedDescription":"Open issue \"Native ML.NET notebook\" (#6290)"},{"Id":"1342920666","IsPullRequest":true,"CreatedAt":"2022-08-18T10:49:29","Actor":"aseemsahoo","Number":"6289","RawContent":null,"Title":"Update ApacheArrow from 2.0.0 to 3.0.0","State":"open","Body":"Updated ApacheArrow package from 2.0.0 to 3.0.0\r\n\r\n## ApacheArrow 3.0.0\r\n- [Release Notes](https://arrow.apache.org/release/3.0.0.html)\r\n- [Download and Install](https://www.apache.org/dyn/closer.lua/arrow/arrow-3.0.0/)\r\n\r\n\r\n## ApacheArrow 2.0.0\r\n- [Release Notes](https://arrow.apache.org/release/2.0.0.html)\r\n- [Download and Install](https://www.apache.org/dyn/closer.lua/arrow/arrow-2.0.0/)","Url":"https://github.com/dotnet/machinelearning/pull/6289","RelatedDescription":"Open PR \"Update ApacheArrow from 2.0.0 to 3.0.0\" (#6289)"},{"Id":"1342522914","IsPullRequest":false,"CreatedAt":"2022-08-18T03:42:03","Actor":"wil70","Number":"6288","RawContent":null,"Title":"[Issue, ML.net CLI] 330GB csv file of data cause a OutOfMemoryException (1/2)","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Win8, latest version as of this bug entry\r\n - ML.NET Version: 16.13.9\r\n - .NET Version:6.0.303\r\n\r\n**Describe the bug**\r\nWhen I start ML.net from CLI, I get a OutOfMemoryException \r\nI have 64GB Ram, I have a 330GB csv file of data.\r\n\r\nI tried with \r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Generate a 330GB file with 4209 columns with random data\r\n2. open prompt\r\n3. type in command line:\r\nmlnet classification --train-time 75600 --name SampleClassification --log-file-path c:\\Log_data.txt --has-header true --label-col 4209 --ignore-cols 0,1,4206,4207,4208 --dataset \"c:\\data.csv\" --test-dataset \"c:\\test_data.csv\"\r\n4. See error log at the end of this message with the OutOfMemoryException\r\n\r\n**Expected behavior**\r\nI expect ml.net to continue and feed the data as it stream it, so there should be no OutOfMemoryException\r\nWhen I monitor the mknet.exe prices with task manager, the mlnet.exe process doesn't go high at all, like less than ~14GB. So something is not right as I have 64GB and also it shouldn't matter isn't it as .\r\n\r\n**Screenshots, Code, Sample Projects**\r\n**Additional context**\r\nHere is the log\r\nStart Training\r\nstart nni training\r\nExperiment output folder: C:\\Users\\W\\AppData\\Local\\Temp\\AutoML-NNI\\Experiment-GET3JS\r\nSystem.FormatException: Parsing failed with an exception: Stream reading encountered exception\r\n ---> System.FormatException: Stream reading encountered exception\r\n ---> System.OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.\r\n   at System.Text.StringBuilder.ToString()\r\n   at System.IO.StreamReader.ReadLine()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.LineReader.ThreadProc()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.TextLoader.Cursor.LineReader.GetBatch()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParallelState.Parse(Int32 tid)\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParallelState.ThreadProc(Object obj)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParseParallel(ParallelState state)+MoveNext()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Proposer.Controller.CountRows(IDataView data, Int64 maxRows) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Proposer/Controller.cs:line 174\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Proposer.Controller.Initialize() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Proposer/Controller.cs:line 111\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Experiments.LocalAutoMLExperiment.ExecuteAsync(IDataView trainData, IDataView validateData, ColumnInformation columnInformation, CancellationToken cancellationToken, CancellationToken timeout) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Experiments/LocalAutoMLExperiment.cs:line 138\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.StartTrainingAsync(TrainingConfiguration config, PathConfiguration pathConfig, CancellationToken userCancellationToken) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 160\r\n   at Microsoft.ML.CLI.Runners.AutoMLRunner.ExecuteAsync() in /_/src/mlnet/Runners/AutoMLRunner.cs:line 88\r\n   at Microsoft.ML.CLI.Program.TrainAsync(TrainingConfiguration trainingConfiguration, PathConfiguration pathConfig, AutoMLServiceLogLevel logLevel) in /_/src/mlnet/Program.cs:line 348\r\n   at Microsoft.ML.CLI.Program.AutoMLCommandRunner(AutoMLCommand command, Boolean skipGenerateConsoleApp) in /_/src/mlnet/Program.cs:line 329\r\n   at Microsoft.ML.CLI.Program.<>c.<<CreateRootCommandLineBuilder>b__4_0>d.MoveNext() in /_/src/mlnet/Program.cs:line 89\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Invocation.CommandHandler.GetExitCodeAsync(Object value, InvocationContext context)\r\n   at System.CommandLine.Invocation.ModelBindingCommandHandler.InvokeAsync(InvocationContext context)\r\n   at System.CommandLine.Invocation.InvocationPipeline.<>c__DisplayClass4_0.<<BuildInvocationChain>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass23_0.<<UseParseErrorReporting>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass4_0.<<CreateRootCommandLineBuilder>b__9>d.MoveNext() in /_/src/mlnet/Program.cs:line 290\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c.<<UseSuggestDirective>b__24_0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass22_0.<<UseParseDirective>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass11_0.<<UseDebugDirective>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c.<<RegisterWithDotnetSuggest>b__10_0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass14_0.<<UseExceptionHandler>b__0>d.MoveNext()\r\nCheck out log file for more information: c:\\Log_data.txt\r\nExiting ...\r\n\r\nC:\\Users\\W>'\r\n\r\n\r\n\r\n****\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6288","RelatedDescription":"Open issue \"[Issue, ML.net CLI] 330GB csv file of data cause a OutOfMemoryException (1/2)\" (#6288)"},{"Id":"1341935641","IsPullRequest":false,"CreatedAt":"2022-08-17T15:21:35","Actor":"wil70","Number":"6287","RawContent":null,"Title":"[ML.net cli] Early stop and resume/continue","State":"open","Body":"Hello, is there a way to end earlier a long training? Like I put 600000 seconds, and I have good results already, so I would like to finish it sooner. How do I do this? \r\nA way to end earlier and also be able to resume/continue from there would be awesome (Like I could add x extra minutes of training)\r\nTY!\r\nw","Url":"https://github.com/dotnet/machinelearning/issues/6287","RelatedDescription":"Open issue \"[ML.net cli] Early stop and resume/continue\" (#6287)"},{"Id":"1341929992","IsPullRequest":false,"CreatedAt":"2022-08-17T15:17:07","Actor":"wil70","Number":"6286","RawContent":null,"Title":"[ML.net cli] Resume a cli training after a crash ","State":"open","Body":"Hello, is there a way to resume an ML.net cli training to where it was before a crash?\r\nI have a lot of data in the folder C:\\Users\\wwww\\AppData\\Local\\Temp\\AutoML-NNI\\Experiment-9K67B4 but I do not know how to make mlnet start from there.\r\n\r\n\r\nDetail:\r\nI used the cli, ie \"mlnet classicfiaction....\"\r\nI trained for a few days, but I made a mistake which used a lot of memory on my computer, which stopped the mlnet process. I would like to start mlnet to where it left so it can continue from there\r\n\r\nThanks\r\nw\r\n\r\n\r\n2022-08-10 15:03:24.3091 DEBUG System.InvalidOperationException: Event we were waiting on was subject to an exception\r\n ---> System.OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.\r\n   at System.Array.Resize[T](T[]& array, Int32 newSize)\r\n   at Microsoft.ML.Internal.Utilities.ArrayUtils.EnsureSize[T](T[]& array, Int32 min, Int32 max, Boolean keepOld, Boolean& resized)\r\n   at Microsoft.ML.Data.CacheDataView.ColumnCache.ImplOne`1.CacheCurrent()\r\n   at Microsoft.ML.Data.CacheDataView.Filler(DataViewRowCursor cursor, ColumnCache[] caches, OrderedWaiter waiter)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6286","RelatedDescription":"Open issue \"[ML.net cli] Resume a cli training after a crash \" (#6286)"},{"Id":"1341005843","IsPullRequest":true,"CreatedAt":"2022-08-17T00:18:13","Actor":"LittleLittleCloud","Number":"6285","RawContent":null,"Title":"Use SweepablePipeline","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n## Check out the spec for `SweepablePipeline` in https://github.com/dotnet/machinelearning/pull/6218\r\n\r\n `SweepablePipeline` is a combination of `MultiModelPipeline` and `SweepableEstimatorPipeline`, which supports a tree-like structure pipeline and support estimator-level search space using nested search space. \r\n\r\nIn another world, `SweepablePipeline` puts estimator candidates as part of its search space and makes it transparent to tuner. In this way, it decouples tuners from the detailed implementation of pipelines or trainers, and replacing them with `Parameter` and `SearchSpace`.  The hyper-parameter optimization process, with the help of `SweepablePipeline`, can be simplified to the following 3 steps\r\n\r\n- `ITuner` sample `parameter` from `search space`\r\n- `ITrialRunner` train model and calculate score from `parameter`\r\n- `ITuner` update associated `parameter` with score.\r\n\r\nAlso, it provides a uniform way to create pipeline that includes multiple estimator candidates with search space.\r\n\r\nAnd with this PR, the class that construct AutoML.Net Sweepable API is simplified to\r\n- `ISweepable`\r\n  - `SweepableEstimator`: Estimator with search space\r\n  - `SweepablePipeline` pipeline with search space\r\n ","Url":"https://github.com/dotnet/machinelearning/pull/6285","RelatedDescription":"Open PR \"Use SweepablePipeline\" (#6285)"},{"Id":"1340495894","IsPullRequest":false,"CreatedAt":"2022-08-16T15:04:09","Actor":"sportbilly21","Number":"6284","RawContent":null,"Title":"Are Resizing Layers supported in ML.Net?","State":"open","Body":"### System information\r\n\r\n- Windows 10 19044.1826\r\n-  VS 2019, Microsoft.ML 1.71,Microsoft.ML.OnnxRuntime.GPU 12.1\r\n\r\nI am have retrained a Tensorflow/Keras model with a resizing layer are part of the model.\r\nI converted to ONNX with opset 11. In python onnx works as expected. I am feeding with what ever size of image and models does the resizing (224, 224) and delivers the predictions.\r\n\r\nIn ML.Net I have created the pipeline and predictions engine. If I pass to the model with a 224x224 image I am getting the following error\r\nSystem.ArgumentException: 'Length of memory (150528) must match product of dimensions (3).' from DenseTensor.shared.cs\r\nIf I pass to the model any other size of image I am getting the following \r\nSystem.InvalidOperationException: 'Operation is not valid due to the current state of the object.' when try to run prediction engine,\r\n\r\nIs resizing layer not supported yes or I am doing something wrong.Please find below the code for the running the model\r\n\r\n### Source code / logs\r\n\r\n        public void GenerateModel(string modelLocation,string inputLayer, string outputLayer, List<string> cats, int gpuID = 0)\r\n        {\r\n            var pipeline = this.mlContext.Transforms.ExtractPixels(inputLayer, inputColumnName: nameof(ImageData.Image), colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Rgb, orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB, interleavePixelColors: false, outputAsFloatArray: true)\r\n              .Append(this.mlContext.Transforms.ApplyOnnxModel(outputLayer, inputLayer, modelLocation));\r\n\r\n            var data = this.mlContext.Data.LoadFromEnumerable(new List<ImageData>());\r\n   \r\n            this.model = pipeline.Fit(data); //;\r\n            this.categories = cats;\r\n            this.predictor = this.mlContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(this.model);\r\n\r\n       \r\n        }\r\n\r\n        public void ClassifySingleImage(ImageData imgClassify)\r\n        {\r\n\r\n            this.prediction = this.predictor.Predict(imgClassify);\r\n            this.predictions = this.prediction.Preds;\r\n\r\n        }\r\n\r\nMany thanks ","Url":"https://github.com/dotnet/machinelearning/issues/6284","RelatedDescription":"Open issue \"Are Resizing Layers supported in ML.Net?\" (#6284)"},{"Id":"1340321091","IsPullRequest":false,"CreatedAt":"2022-08-16T13:00:30","Actor":"aforoughi1","Number":"6283","RawContent":null,"Title":"Text Classification API (preview 0.20.0-preview.22313.1) Method not found","State":"open","Body":"**System Information (please complete the following information):**\r\n\r\n    <PackageReference Include=\"Microsoft.Data.Analysis\" Version=\"0.20.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML\" Version=\"2.0.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.AutoML\" Version=\"0.20.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.FastTree\" Version=\"2.0.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.LightGbm\" Version=\"2.0.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.TorchSharp\" Version=\"0.20.0-preview.22313.1\" />\r\n    <PackageReference Include=\"TorchSharp-cpu\" Version=\"0.97.3\" />\r\n\r\n**Describe the bug**\r\nWhen I call Fit to train the model, I get \r\n\r\nSystem.MissingMethodException\r\n  HResult=0x80131513\r\n  Message=Method not found: 'Void Module.train()'.\r\n  Source=Microsoft.ML.TorchSharp\r\n  StackTrace:\r\n   at Microsoft.ML.TorchSharp.NasBert.TextClassificationTrainer.Trainer..ctor(TextClassificationTrainer parent, IChannel ch)\r\n   at Microsoft.ML.TorchSharp.NasBert.TextClassificationTrainer.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n\r\n**To Reproduce**\r\n\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.AutoML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.TorchSharp;\r\nusing System.Linq;\r\nusing System.Threading.Tasks;\r\n\r\n    public class SentimentData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string Sentence { get; set; }\r\n\r\n        //Sentiment is a string: 'positive', 'negative' or 'neutral'\r\n        [LoadColumn(1)]\r\n        public string Sentiment { get; set; }\r\n\r\n        // Label = {0:'neutral', 1:'positive',-1:'negative'}\r\n        [LoadColumn(2)]\r\n        public float Label { get; set; }\r\n    }\r\n\r\n\r\n    class Program\r\n    {\r\n        static async Task Main(string[] args)\r\n        {\r\n            MLContext mlContext = new MLContext(seed: null);\r\n            IDataView data = mlContext.Data.LoadFromTextFile<SentimentData>(@\"..\\..\\..\\FinancialPhraseBank.txt\", separatorChar: '\\t', hasHeader: true);\r\n            var preview = data.Preview(6000);\r\n\r\n            var trainTestSplit = mlContext.Data.TrainTestSplit(data, testFraction: 0.2);\r\n            var trainSet = trainTestSplit.TrainSet;\r\n            var validationSet = trainTestSplit.TestSet;\r\n\r\n            //Sentence is input\r\n            //Sentiment is a string: 'positive', 'negative' or 'neutral'\r\n            //Label = {0:'neutral', 1:'positive',-1:'negative'}\r\n\r\n            var pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"KeyColumn\", \"Label\")\r\n                                     .Append(mlContext.MulticlassClassification.Trainers.TextClassification(3, labelColumnName: \"KeyColumn\", sentence1ColumnName: \"Sentence\"));\r\n\r\n\r\n            //it crashes here\r\n            var model = pipeline.Fit(trainSet);\r\n        }\r\n    }\r\n**Additional context**\r\n\r\n[FinancialPhraseBank.txt](https://github.com/dotnet/machinelearning/files/9351179/FinancialPhraseBank.txt)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6283","RelatedDescription":"Open issue \"Text Classification API (preview 0.20.0-preview.22313.1) Method not found\" (#6283)"},{"Id":"1336826615","IsPullRequest":false,"CreatedAt":"2022-08-12T06:55:42","Actor":"acrigney","Number":"6282","RawContent":null,"Title":"Permutation Feature Importance for MulticlassClassification still seems to have issues","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n - .NET Version: [e.g. .NET 5.0]\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nI see that new code for a new API for this has been released with the \r\nPermutationFeatureImportanceExtensions.cs extension \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/main/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs\r\n\r\nBut it uses MulticlassClassificationCatalog which is an internal class.\r\nSo I am trying to get the old way to work. But I have an error getting incompatible feature column types.\r\nHere is an example.\r\n\r\n'Incompatible features column type: 'Vector<Single, 2>' vs 'Vector<Single, 4>''\r\n\r\nHere is some example code, I get the same type of error with my actual code.\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add scree\r\n[PFI.txt](https://github.com/dotnet/machinelearning/files/9314310/PFI.txt)\r\nnshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6282","RelatedDescription":"Open issue \"Permutation Feature Importance for MulticlassClassification still seems to have issues\" (#6282)"},{"Id":"1329274445","IsPullRequest":true,"CreatedAt":"2022-08-10T21:43:13","Actor":"tarekgh","Number":"6272","RawContent":null,"Title":"Tokenizers Support","State":"closed","Body":"This PR introduces the first version of Tokenizers support. This version will include the following:\r\n\r\n- Tokenizer APIs (creation and encoding).\r\n- Abstraction for tokenizers Normalization, pre-processing, and models.\r\n- Bpe model including training support.\r\n-  EnglishRoberta model which is used with the text classification machine learning model.\r\n- Lower and upper casing normalization.\r\n- White space and English roberta pre-processors.\r\n- The integration of the tokenizer with the text classification model.\r\n\r\nFeatures to add later to teh tokenizers:\r\n- More tokenization models (e.g. WordPiece, Unigram,...etc.)\r\n- Save and Load the whole tokenizer. We support saving/loading models but not the whole tokenizer.\r\n- Post-Processing. We support pre-processing only for now. Supporting post processing is good to support too.\r\n- Batch Processing. Support encoding multiple sentences.\r\n- Adding more normalizers and pre-processors.","Url":"https://github.com/dotnet/machinelearning/pull/6272","RelatedDescription":"Closed or merged PR \"Tokenizers Support\" (#6272)"},{"Id":"1334580565","IsPullRequest":false,"CreatedAt":"2022-08-10T12:52:44","Actor":"ML-pixel","Number":"6281","RawContent":null,"Title":"Error while using Model.Save()","State":"open","Body":"**System Information (please complete the following information):**\r\n - Checked on multiple systems (win 10, win 2019,2021 server)\r\n - ML.NET Version: ML.NET 1.7.0\r\n\r\n\r\n - .NET Core 2.2.3\r\n\r\n**Describe the bug**\r\nWhen saving trained model of very large size, xx GB the exception is thrown with the inner exception \"The length cannot be greater than the capacity. ParameterName valueCount at System.Text.StringBuilder.Append() at Microsoft.Ml.Data.ReadOnlyMemoryUtils.AppendSpan ...etc \r\nWhat I think is that the Save() uses StringBuilder.Append(char*,Int32) method and the int32 is a problem. \r\n\r\n**To Reproduce**\r\n1.Train extra large model\r\n2.Try to save it with Model.Save()\r\n\r\n![error_Cut](https://user-images.githubusercontent.com/110897666/183905634-e9f78564-e360-4c76-8aa0-d9edd5f96d7b.png)","Url":"https://github.com/dotnet/machinelearning/issues/6281","RelatedDescription":"Open issue \"Error while using Model.Save()\" (#6281)"},{"Id":"1332838885","IsPullRequest":false,"CreatedAt":"2022-08-09T07:34:49","Actor":"rzechu","Number":"6280","RawContent":null,"Title":"How to make prediction of custom data with loaded model? Problem with Model.CreatePredictionEngine<TSrc, TDst> Is it possible to avoid strongly typed input/output","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET 4.8\r\n\r\n### Issue\r\n- **What did you do?** \r\n- Hello I'd like to implement \"model creator\" and \"dynamic model\" usage in our application to allow users to write SQL statements or use wizard to check database fields, prepare/train model (pick 3 columns and 1 as label - similiar to MLModelBuilder in VisualStudio), save model to disk/db, then use it later to predict values.\r\nI made dynamic model preparation with AutoML (I guess it works fine with just plain sql / sql schema creation).\r\nBut problem is with implementing predictions\r\nIts propably possible with dynamic data types (or not?) or reflection (I want to avoid this) \r\n\r\nModel.CreatePredictionEngine<**TSrc, TDst**> requires strongly typed input and outputs. Is there any workaround?\r\nI'd like to put predictions model on custom forms with custom fields. I can load it, I know the fields used to predict/label but Its not possible without developer writing custom methods for each form type and recompilling application. \r\n\r\n- **What did you expect?** Create dynamic input/output by adding columns with types. I guess it should be possible in similliar way to generating DataTable, columns and datatypes during runtime. \r\nOr something like Model.CreationPredictionEngine(model, inputschema, inputColumns, outputColumns)\r\nWhere columns are  column + type property + attributes if necessary","Url":"https://github.com/dotnet/machinelearning/issues/6280","RelatedDescription":"Open issue \"How to make prediction of custom data with loaded model? Problem with Model.CreatePredictionEngine<TSrc, TDst> Is it possible to avoid strongly typed input/output\" (#6280)"},{"Id":"1330377710","IsPullRequest":true,"CreatedAt":"2022-08-08T20:58:50","Actor":"ericstj","Number":"6277","RawContent":null,"Title":"Update Newtonsoft.Json to 13.0.1 (#6276)","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6277","RelatedDescription":"Closed or merged PR \"Update Newtonsoft.Json to 13.0.1 (#6276)\" (#6277)"},{"Id":"1332222082","IsPullRequest":true,"CreatedAt":"2022-08-08T18:14:46","Actor":"jordi1215","Number":"6279","RawContent":null,"Title":"Bringing Fairlearn - GridSearch to ML.NET","State":"open","Body":"\r\nRelated to: #1912  \r\nRelated to: [Issue 1091 on the Fairlearn Repo](https://github.com/fairlearn/fairlearn/issues/1091)\r\n\r\nAs part of my summer internship project, I have created several classes that will provide a foundation for the further inclusion of Fairlearn algorithms into ML.NET.\r\n\r\nFor the first PR, I have included an end-to-end working solution for the gridSearch method in Fairlearn which leverages AutoML for parameter searching. The example is included in the Unit test.\r\n\r\n\r\nWe are excited to review your PR.\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6279","RelatedDescription":"Open PR \"Bringing Fairlearn - GridSearch to ML.NET\" (#6279)"},{"Id":"1331038288","IsPullRequest":false,"CreatedAt":"2022-08-07T15:37:17","Actor":"mandar1jn","Number":"6278","RawContent":null,"Title":"ML.net trainer keeps going back to bottleneck computation","State":"closed","Body":"### System information\r\n\r\n- **Windows 10**:\r\n- **Dotnet 6.0.302**: \r\n\r\n### Issue\r\n\r\n- **I tried to create an image classification model**\r\n- **ML.net goes to Bottleneck Computation, then to Training, then logs a lot of things about channels, and then restarts. this continues in an infinite log**\r\n- **I expected it to continue training instead of going back to the start**\r\n\r\nThis happened on windows with the visual studio 2022 model builder and on Linux with the ml.net cli\r\n\r\n### Source code / logs\r\n\r\n[ImageModel-R4IFKW.txt](https://github.com/dotnet/machinelearning/files/9276989/ImageModel-R4IFKW.txt)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6278","RelatedDescription":"Closed issue \"ML.net trainer keeps going back to bottleneck computation\" (#6278)"},{"Id":"1330177826","IsPullRequest":true,"CreatedAt":"2022-08-05T20:30:56","Actor":"ericstj","Number":"6276","RawContent":null,"Title":"Update Newtonsoft.Json to 13.0.1","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6276","RelatedDescription":"Closed or merged PR \"Update Newtonsoft.Json to 13.0.1\" (#6276)"},{"Id":"1330173792","IsPullRequest":false,"CreatedAt":"2022-08-05T17:09:54","Actor":"luisquintanilla","Number":"6275","RawContent":null,"Title":"[DataFrame] Head should return min(DF length, param)","State":"open","Body":"## Problem\r\n\r\nGiven a DataFrame with 3 rows, calling `Head(5)` throws an error. \r\n\r\n![image](https://user-images.githubusercontent.com/46974588/183127094-cb6b8a88-b0b0-4412-a871-faa3f8691fcb.png)\r\n\r\n\r\n## Suggested solution\r\n\r\nHead should return the minimum of the number provided as a parameter and the length of a DataFrame","Url":"https://github.com/dotnet/machinelearning/issues/6275","RelatedDescription":"Open issue \"[DataFrame] Head should return min(DF length, param)\" (#6275)"},{"Id":"1330167887","IsPullRequest":false,"CreatedAt":"2022-08-05T17:02:59","Actor":"luisquintanilla","Number":"6274","RawContent":null,"Title":"[DataFrame] Info method display should be the same for DataFrame and DataFrameColumn","State":"open","Body":"The `Info` method on a `DataFrame` behaves different from that of a `DataFrameColumn`. The DataFrame displays an `Info` column with labels for each column's data point (DataType, Length). The DataFrameColumn displays the same information, without the labels. Update `DataFrameColumn.Info()` method to display data with labels like `DataFrame`\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/183125945-4a4da61b-716b-4d6f-9662-bd72eaaf9005.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6274","RelatedDescription":"Open issue \"[DataFrame] Info method display should be the same for DataFrame and DataFrameColumn\" (#6274)"},{"Id":"1329597995","IsPullRequest":false,"CreatedAt":"2022-08-05T08:06:19","Actor":"acrigney","Number":"6273","RawContent":null,"Title":"Help with Custom VarVector to Vector mapping (does it have to so hard?)","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nML.NET v4.0.30319\r\n### Issue\r\n\r\n- **What did you do?**\r\n- I have a data class that contains single fields and fields that are arrays\r\n- **What happened?**\r\n- How to custom map the the varvector generated into a single vector\r\n- similar to https://github.com/dotnet/machinelearning/issues/4977\r\n- \r\n- **What did you expect?**\r\n-  Easy way to convert the varvectors into a single vector\r\n- \r\n### Source code / logs\r\n\r\n\t// Code abbreviated\r\n\r\n\tMLContext mlContext = new MLContext();\r\n\r\n    SchemaDefinition definedSchema;            \r\n\r\n    // For fixed array dimension sizes use\r\n    definedSchema = SchemaDefinition.Create(typeof(MLDataForAnalysisFactored));\r\n\r\n    // If we can use variable array dimension sizes we can use this\r\n    int featuresCount = SetFeatureArrayDimensions(mlDataList, out definedSchema);\r\n\r\n    IDataView trainDataView = mlContext.Data.LoadFromEnumerable<MLDataForAnalysisFactored>(mlDataList, definedSchema);\r\n\r\n    // The label must not be in the input features\r\n    string[] features = typeof(MLDataForAnalysisFactored).GetProperties().ToList().\r\n            Where(p => p.Name != labelColumnName).Select(x => x.Name).ToArray();\r\n\r\n    var estimatorChain = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"Label\", inputColumnName: \r\n        nameof(MLDataForAnalysisFactored.Call))\r\n        .Append(mlContext.Transforms.Concatenate(\"Features\", features));\r\n\r\n    var transformedTrainData = estimatorChain.Fit(trainDataView);\r\n\r\n    trainDataView = transformedTrainData.Transform(trainDataView);\r\n\r\n    // check the data\r\n    var rowEnumerable = mlContext.Data\r\n        .CreateEnumerable<MLDataForAnalysisFactored>(trainDataView,\r\n        reuseRowObject: true).ToList();\r\n   \r\n    var schema = trainDataView.Schema;\r\n\r\n    //var featureColumns = trainDataView.GetColumn<float[]>(trainDataView.Schema[\"Features\"]).Take(4);\r\n\r\n    //create a custom schema-definition that overrides the type for the Values field...  \r\n\tvar singleVectorSchemaDef = SchemaDefinition.Create(typeof(SingleVector));\r\n\tsingleVectorSchemaDef[nameof(SingleVector.Values)].ColumnType\r\n                  = new VectorDataViewType(NumberDataViewType.Single, featuresCount);\r\n\r\n    // How to do a custom transform to map the varvectors to a single vector?\r\n    // otherwise you have to do this.\r\n    ////use that schema definition when creating the training dataview  \r\n    //trainDataView = mlContext.Data.LoadFromEnumerable(mlDataList, singleVectorSchemaDef);\r\n\r\n    // check the data\r\n\r\n    //        var someRows = mlContext.Data.  // Convert to an enumerable of user-defined type. \r\n    //                .CreateEnumerable<MLDataForAnalysisFactored>(trainDataView, reuseRowObject: false)\r\n    //// Take a couple values as an array.\r\n    //.Take(4).ToArray();\r\n\r\n    // Extract the 'AllFeatures' column.\r\n    // This will give the entire dataset: make sure to only take several row\r\n    // in case the dataset is huge. The is similar to the static API, except\r\n    // you have to specify the column name and type.\r\n\r\n    //var featureColumns = estimatorChain.GetColumn<float[]>(trainDataView.Schema[\"Features\"]);\r\n    \r\n    // STEP 2: Run AutoML experiment\r\n    Console.WriteLine($\"Running AutoML multiclass classification experiment for {ExperimentTime} seconds...\");            \r\n\r\n    ExperimentResult<MulticlassClassificationMetrics> experimentResult = mlContext.Auto()\r\n        .CreateMulticlassClassificationExperiment(ExperimentTime)\r\n        .Execute(trainDataView, LabelColumnName, null, estimatorChain);\r\n\r\nwhere SingleVector is\r\n\r\n\t  public class SingleVector\r\n\t  {\r\n\t      //it's not required to specify the type here since we will override in our custom schema \r\n\t      public float[] Values;\r\n\t  }\r\n\t  // Above function SetFeatureArrayDimensions\r\n\t  // You would expect that once the size of the var vectors has been set then that is all you should have to do but ML.NET needs\r\n\t  // a single vector.\r\n\t  private int SetFeatureArrayDimensions(List<MLDataForAnalysisFactored> mlDataList, out SchemaDefinition definedSchema)\r\n\t      {\r\n\t          int totalFeatureCount = 0;\r\n\t          // STEP 1: Load data\r\n\t  \r\n\t          // The feature dimension (typically this will be the Count of the array \r\n\t          // of the features vector known at runtime).\r\n\t          int featureArrayDimension = 0;\r\n\t          definedSchema = SchemaDefinition.Create(typeof(MLDataForAnalysisFactored));\r\n\t  \r\n\t          var properties = typeof(MLDataForAnalysisFactored).GetProperties();\r\n\t  \r\n\t          foreach (var property in properties)\r\n\t          {\r\n\t              if (property.PropertyType.IsArray)\r\n\t              {\r\n\t                  Array array = property.GetValue(mlDataList[0]) as Array;\r\n\t                  featureArrayDimension = array.Length;\r\n\t                  totalFeatureCount += featureArrayDimension;\r\n\t  \r\n\t                  //// Set the column type to be a known-size vector.\r\n\t                  var vectorItemType = ((VectorDataViewType)definedSchema[property.Name].ColumnType)\r\n\t                              .ItemType;\r\n\t  \r\n\t                  definedSchema[property.Name].ColumnType = new VectorDataViewType(vectorItemType,\r\n\t                      featureArrayDimension);\r\n\t  \r\n\t                  var featureColumn = definedSchema[property.Name]\r\n\t                  .ColumnType as VectorDataViewType;\r\n\t  \r\n\t                  Diag.Debug.WriteLine($\"Is the size of the Feature array {property.Name} column known: \" +\r\n\t                      $\"{featureColumn.IsKnownSize}.\\nSize: {featureColumn.Size}\");\r\n\t              }\r\n\t              else\r\n\t              {\r\n\t                  totalFeatureCount++;\r\n\t              }\r\n\t          }\r\n\t          return (totalFeatureCount);\r\n\t      }        \r\n\r\nAnyway I can get away with using fixed array sizes.\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6273","RelatedDescription":"Open issue \"Help with Custom VarVector to Vector mapping (does it have to so hard?)\" (#6273)"}],"ResultType":"GitHubIssue"}},"RunOn":"2022-08-24T03:30:24.5911308Z","RunDurationInMilliseconds":708}