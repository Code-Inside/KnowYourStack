{"Data":{"GitHub":{"Issues":[{"Id":"3008739816","IsPullRequest":true,"CreatedAt":"2025-04-28T19:44:18","Actor":"luisquintanilla","Number":"7445","RawContent":null,"Title":"Update Tokenizer conceptual doc link in package docs","State":"closed","Body":"Replaces placeholder with link to tokens documentation in Learn docs.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7445","RelatedDescription":"Closed or merged PR \"Update Tokenizer conceptual doc link in package docs\" (#7445)"},{"Id":"3018328490","IsPullRequest":false,"CreatedAt":"2025-04-28T15:55:02","Actor":"dgxhubbard","Number":"7448","RawContent":null,"Title":"Remove Newtonsoft.Json dependency and use System.Text.Json","State":"closed","Body":"**System Information (please complete the following information):**\n - Windows 11\n - ML.NET Version: 4.0.2\n - .NET Version: 8\n\n**Describe the bug**\nWhen running with ML.Net and trying to run model generation method, get the error that \nNewtonSoft.Json version 13.0.0.0 is required. I am using 13.0.3. Version 13.0.0 cannot be downloaded.\nIs there a way to fix this. One way I would suggest is to replace NewtonSoft.Json with System.Text.Json, because\nit is faster.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Go to '...'\n2. Click on '....'\n3. Scroll down to '....'\n4. See error\n\n**Expected behavior**\nBeing able to run my code\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7448","RelatedDescription":"Closed issue \"Remove Newtonsoft.Json dependency and use System.Text.Json\" (#7448)"},{"Id":"2923758107","IsPullRequest":true,"CreatedAt":"2025-04-28T15:53:36","Actor":"dotnet-maestro[bot]","Number":"7423","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\n\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\n## From https://github.com/dotnet/arcade\n- **Subscription**: [c692823c-b896-437f-4f57-08dc434cc8f6](https://maestro.dot.net/subscriptions?search=c692823c-b896-437f-4f57-08dc434cc8f6)\n- **Build**: [20250425.4](https://dev.azure.com/dnceng/internal/_build/results?buildId=2695688)\n- **Date Produced**: April 25, 2025 7:03:43 PM UTC\n- **Commit**: [5fb72aaffeff9c6f2ce46d3b226a84772fb72f55](https://github.com/dotnet/arcade/commit/5fb72aaffeff9c6f2ce46d3b226a84772fb72f55)\n- **Branch**: refs/heads/main\n\n[DependencyUpdate]: <> (Begin)\n\n- **Updates**:\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n  - **Microsoft.DotNet.Helix.Sdk**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n  - **Microsoft.DotNet.SignTool**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n  - **Microsoft.DotNet.XliffTasks**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n  - **Microsoft.DotNet.XUnitExtensions**: [from 10.0.0-beta.25157.1 to 10.0.0-beta.25225.4][8]\n\n[8]: https://github.com/dotnet/arcade/compare/1ec6078c26...5fb72aaffe\n\n[DependencyUpdate]: <> (End)\n\n\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","Url":"https://github.com/dotnet/machinelearning/pull/7423","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#7423)"},{"Id":"3022205862","IsPullRequest":false,"CreatedAt":"2025-04-26T18:37:06","Actor":"Lavshyak","Number":"7449","RawContent":null,"Title":"Add docs (tutorial) about transfer image from RAM to pipeline (model)","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\nWhen I started learning ML.NET, it was hard to understand how to adequately transfer an image from RAM (byte[], SKImage, MLImage) to a pipeline (model) (which automatically resizes the image and classifies it). I couldn't find this in the documentation, and I couldn't find any clear ways on the Internet.\n\n**Describe the solution you'd like**\nMaybe you could add information about this to the documentation?\nI have some code that just needs to be adapted for use in documentation: https://github.com/Lavshyak/MLNetImageFromRamStrange/tree/master/ImageFromRamStrange\nAnd it's worth mentioning, it was a non-intuitive moment: https://github.com/Lavshyak/MLNetImageFromRamStrange/blob/788d67d05e0ebb00d4db0753ac3298a9507a5805/ImageFromRamStrange/DataModels.cs#L12\nAnd may be you can copy some code from there: https://github.com/Lavshyak/MLNetImageDisposingProblem/blob/master/MLNetImageDisposingProblem/Reproduction.cs\n\nAnd don't forget about that): https://github.com/dotnet/machinelearning/issues/7444","Url":"https://github.com/dotnet/machinelearning/issues/7449","RelatedDescription":"Open issue \"Add docs (tutorial) about transfer image from RAM to pipeline (model)\" (#7449)"},{"Id":"3015910221","IsPullRequest":false,"CreatedAt":"2025-04-24T04:09:23","Actor":"richlander","Number":"7447","RawContent":null,"Title":"Legacy images need to be updated","State":"open","Body":"This repo has references to CentOS 8, Ubuntu 18.04, and Ubuntu 20.04. We don't support any of those versions any longer.\n\nPlease consider moving to CentOS Stream 10 and Ubuntu 24.04.\n\nWe don't produce the `mlnet` images any longer. It would be good to understand what the need is for that image flavor.\n\n@ilyas1974 @ericstj ","Url":"https://github.com/dotnet/machinelearning/issues/7447","RelatedDescription":"Open issue \"Legacy images need to be updated\" (#7447)"},{"Id":"2989435708","IsPullRequest":true,"CreatedAt":"2025-04-23T16:52:13","Actor":"michaelgsharp","Number":"7443","RawContent":null,"Title":"update cmake mac","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7443","RelatedDescription":"Closed or merged PR \"update cmake mac\" (#7443)"},{"Id":"3011819767","IsPullRequest":false,"CreatedAt":"2025-04-22T18:27:56","Actor":"dgxhubbard","Number":"7446","RawContent":null,"Title":"Remove Newtonsoft.Json dependency and use System.Text.Json","State":"open","Body":"Microsoft.ML uses Newtonsoft.Json, and when run without it  causes an exception. Then we need to import Newtonsoft.Json, that has been replaced by System.Text.Json.\nSystem.Text.Json is faster, why is Newtonsoft.Json still required","Url":"https://github.com/dotnet/machinelearning/issues/7446","RelatedDescription":"Open issue \"Remove Newtonsoft.Json dependency and use System.Text.Json\" (#7446)"},{"Id":"2975056786","IsPullRequest":false,"CreatedAt":"2025-04-21T17:27:53","Actor":"geoionescu","Number":"7436","RawContent":null,"Title":"NLP Question Answering - How to use another pretrained model?","State":"closed","Body":"Hello everyone,\n\nPlaying with the Question Answering scenario, I noticed that you're using [pretrained_Roberta_encoder.tsm](https://aka.ms/mlnet-resources/models/pretrained_Roberta_encoder.tsm) file; I guess this is the English model (but cannot tell for sure).\n\nMy question is twofold:\n1. What is that tsm file (I didn't see any tsm files in the 'usual' models from Hugging Face, for example)\n2. How can one produce a tsm file from a RoBERTa model (e.g. the one from here: https://huggingface.co/FacebookAI/xlm-roberta-large)?","Url":"https://github.com/dotnet/machinelearning/issues/7436","RelatedDescription":"Closed issue \"NLP Question Answering - How to use another pretrained model?\" (#7436)"},{"Id":"2975058970","IsPullRequest":false,"CreatedAt":"2025-04-21T17:25:10","Actor":"geoionescu","Number":"7437","RawContent":null,"Title":"NLP Question Answering - Creating a pretrained RoBERTa model from scratch.","State":"closed","Body":"I know this is a huge task, but I'll ask it anyhow.\n\nPresuming I do have a large text corpus for a language, how does one train a new model from scratch?\nAny current code doing this in the existing codebase, or should I try to search for [some](https://medium.com/analytics-vidhya/create-a-tokenizer-and-train-a-huggingface-roberta-model-from-scratch-f3ed1138180c) [python](https://huggingface.co/blog/how-to-train) [sources](https://github.com/sv-v5/train-roberta-ua) to do that?","Url":"https://github.com/dotnet/machinelearning/issues/7437","RelatedDescription":"Closed issue \"NLP Question Answering - Creating a pretrained RoBERTa model from scratch.\" (#7437)"},{"Id":"2980968470","IsPullRequest":true,"CreatedAt":"2025-04-21T17:01:12","Actor":"jozkee","Number":"7439","RawContent":null,"Title":"Update to M.E.AI 9.4.0-preview.1.25207.5","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7439","RelatedDescription":"Closed or merged PR \"Update to M.E.AI 9.4.0-preview.1.25207.5\" (#7439)"},{"Id":"2993059874","IsPullRequest":false,"CreatedAt":"2025-04-14T13:19:49","Actor":"Lavshyak","Number":"7444","RawContent":null,"Title":"MLImage disposes in some cases after CreateEnumerable .ToArray() if there is ResizeImages in the pipeline","State":"open","Body":"**System Information:**\n - OS & Version: Windows 11\n - ML.NET Version: ML.NET v4.0.2\n - .NET Version: .NET 9.0\n\n**Describe the bug**\nIn some cases MLImage disposes after CreateEnumerable .ToArray() if there is ResizeImages in the pipeline.\nIf SourceImage size == ResizedImage size, after CreateEnumerable .ToArray() SourceImage disposes.\nIf SourceImage size != ResizedImage size, after CreateEnumerable .ToArray() SourceImage doesn't dispose.\n\n**To Reproduce**\nProject with xUnit and reproduction:\nhttps://github.com/Lavshyak/MLNetImageDisposingProblem\n\n**Expected behavior**\nProvide a choice whether to dispose or not. If not, then SourceImage doesn't dispose. \nOr just never dispose.\nOr just write about it in red text in the documentation.\n\n**Screenshots, Code, Sample Projects**\nProject with xUnit and reproduction:\nhttps://github.com/Lavshyak/MLNetImageDisposingProblem\n","Url":"https://github.com/dotnet/machinelearning/issues/7444","RelatedDescription":"Open issue \"MLImage disposes in some cases after CreateEnumerable .ToArray() if there is ResizeImages in the pipeline\" (#7444)"},{"Id":"2984505791","IsPullRequest":false,"CreatedAt":"2025-04-10T07:13:52","Actor":"Lavshyak","Number":"7442","RawContent":null,"Title":"Do not validate MLImage height and width in mlContext.Transforms.ExtractPixels if no values ​​are specified in ImageTypeAttribute","State":"closed","Body":"**Is your feature request related to a problem? Please describe.**\nWhen i use mlContext.Transforms.LoadImages, mlContext.Transforms.ResizeImages and mlContext.Transforms.ExtractPixels, it is not need to specify ResizedImage property and ImageTypeAttribute with height and width:\n```\n[ImageType(Constants.Height, Constants.Width)]\npublic MLImage ResizedImage { get; set; } = null!;\n```\nI just specify height and width in mlContext.Transforms.ResizeImages, i take height and width from appsettings.json.\n\nBut when i want to load image from RAM, i exclude mlContext.Transforms.LoadImages and mlContext.Transforms.ResizeImages from pipeline, i create property ResizedImage in my input class and create instanse of MLImage myself. And mlContext.Transforms.ExtractPixels throw exception if i did not specify ImageTypeAttribute with height and width.\nSo if i want to use another model (with another image sizes), it is not enough to simply change the configuration, i also need to rebuild my project with different Constants.Height and Constants.Width.\n\n**Describe the solution you'd like**\nDo not do this `Host.Check(src.Height == height && src.Width == width);` in 349 line in ImagePixelExtractor.cs (in GetGetterCore in Mapper in ImagePixelExtractingTransformer) if height and width are not specified in ImageTypeAttribute.\nAnd do not do this in other classes in the same situation.\n","Url":"https://github.com/dotnet/machinelearning/issues/7442","RelatedDescription":"Closed issue \"Do not validate MLImage height and width in mlContext.Transforms.ExtractPixels if no values ​​are specified in ImageTypeAttribute\" (#7442)"},{"Id":"2981989932","IsPullRequest":false,"CreatedAt":"2025-04-09T08:23:01","Actor":"williamlzw","Number":"7441","RawContent":null,"Title":"Phi3Model support phi4 and phi4-mini","State":"open","Body":"Phi3Model support phi4 and phi4-mini\nhttps://github.com/dotnet/machinelearning/blob/main/src/Microsoft.ML.GenAI.Phi/Module/Phi3Model.cs","Url":"https://github.com/dotnet/machinelearning/issues/7441","RelatedDescription":"Open issue \"Phi3Model support phi4 and phi4-mini\" (#7441)"},{"Id":"2981986536","IsPullRequest":false,"CreatedAt":"2025-04-09T08:21:38","Actor":"williamlzw","Number":"7440","RawContent":null,"Title":"Phi3Tokenizer Chinese garbled code","State":"open","Body":"Microsoft.ML.GenAI.Phi  0.23.0-preview.1.25127.4\nMicrosoft.ML.Tokenizers  2.0.0-preview.1.25127.4\nMicrosoft.ML.Tokenizers.Data.Cl100kBase 2.0.0-preview.1.25127.4\n\n```\npublic async static void Test2()\n{\n    string device = \"cuda\";\n    var weightFolder = @\"D:\\model\\Phi-3-mini-128k-instruct\";\n    var model = Phi3ForCasualLM.FromPretrained(weightFolder, \"config.json\", layersOnTargetDevice: -1, quantizeToInt4: true, targetDevice: device);\n\n    var modelPath = Path.Join(weightFolder, \"tokenizer.model\");\n    var tokenizer = Phi3TokenizerHelper.FromPretrained(modelPath);\n\n    var pipeline = new CausalLMPipeline<Tokenizer, Phi3ForCasualLM>(tokenizer, model, device);\n    var client = new Phi3CausalLMChatClient(pipeline);\n    var task = \"\"\"\n        你能讲一个有趣的笑话吗?\n        \"\"\";\n   \n    List<ChatMessage> _chatHistory = new();\n    _chatHistory.Add(new ChatMessage(ChatRole.System, \"你是一个助手,用中文回答用户的问题\"));\n    _chatHistory.Add(new ChatMessage(ChatRole.User, task));\n    var options = new ChatOptions\n    {\n        StopSequences = [\"<|end_of_text|>\"],//phi3\n        AdditionalProperties = new() { { \"max_length\", 2048 } },\n    };\n\n    await foreach (var response in client.GetStreamingResponseAsync(_chatHistory, options))\n    {\n        Console.Write(response.Text);\n    }\n\n    Console.WriteLine();\n    Console.WriteLine(\"End!\");\n    \n}\n```\noutput:\n当然可以。有一位老???问一个小???：“???子们","Url":"https://github.com/dotnet/machinelearning/issues/7440","RelatedDescription":"Open issue \"Phi3Tokenizer Chinese garbled code\" (#7440)"},{"Id":"2967087060","IsPullRequest":true,"CreatedAt":"2025-04-07T17:54:08","Actor":"carlossanlop","Number":"7433","RawContent":null,"Title":"Update maintenance-dependencies","State":"closed","Body":"These are the latest package versions.\r\n\r\n@michaelgsharp These dependencies are weird enough that I think we should have them separated from the rest. But please let me know if you prefer to have a single property group and have the maintenance-packages sections divided by comments instead.","Url":"https://github.com/dotnet/machinelearning/pull/7433","RelatedDescription":"Closed or merged PR \"Update maintenance-dependencies\" (#7433)"},{"Id":"2970920152","IsPullRequest":true,"CreatedAt":"2025-04-07T16:41:08","Actor":"GrabYourPitchforks","Number":"7434","RawContent":null,"Title":"Fix incorrect IntPtr null check in FftUtils","State":"closed","Body":"Caught by prototype CodeQL rule.\r\n\r\nWe should not compare an IntPtr value to null since it will always result as _not equal_. We should compare to `IntPtr.Zero` instead.","Url":"https://github.com/dotnet/machinelearning/pull/7434","RelatedDescription":"Closed or merged PR \"Fix incorrect IntPtr null check in FftUtils\" (#7434)"},{"Id":"2975615732","IsPullRequest":false,"CreatedAt":"2025-04-07T04:52:41","Actor":"superichmann","Number":"7438","RawContent":null,"Title":"Expose all LightGbm Metrics","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\nno\n\n**Describe the solution you'd like**\nAdd all metrics as stated [here](https://lightgbm.readthedocs.io/en/latest/Parameters.html#metric)\n\n\n**Describe alternatives you've considered**\nmigrate to python\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n","Url":"https://github.com/dotnet/machinelearning/issues/7438","RelatedDescription":"Open issue \"Expose all LightGbm Metrics\" (#7438)"},{"Id":"2974806364","IsPullRequest":false,"CreatedAt":"2025-04-06T08:48:54","Actor":"superichmann","Number":"7435","RawContent":null,"Title":"FastTreeRegressionTrainer leaves memory allocation happens before actually yes knowing how many leaves are actually yes needed by the model","State":"open","Body":"my purpose is to allow the model to create as many leaves as it wants. is there a way to achieve that without allocating 8gb of memory for each tree trainer?\n```\nvar options = new FastTreeRegressionTrainer.Options\n{\nNumberOfLeaves=int.MaxValue\n}\n```\n```\nSystem.OutOfMemoryException: Array dimensions exceeded supported range.\n   at Microsoft.ML.Trainers.FastTree.DocumentPartitioning..ctor(Int32 numDocuments, Int32 maxLeaves)\n   at Microsoft.ML.Trainers.FastTree.TreeLearner..ctor(Dataset trainData, Int32 numLeaves)\n   at Microsoft.ML.Trainers.FastTree.LeastSquaresRegressionTreeLearner..ctor(Dataset trainData, Int32 numLeaves, Int32 minDocsInLeaf, Double entropyCoefficient, Double featureFirstUsePenalty, Double featureReusePenalty, Double softmaxTemperature, Int32 histogramPoolSize, Int32 randomSeed, Double splitFraction, Boolean filterZeros, Boolean allowEmptyTrees, Double gainConfidenceLevel, Int32 maxCategoricalGroupsPerNode, Int32 maxCategoricalSplitPointPerNode, Double bsrMaxTreeOutput, IParallelTraining parallelTraining, Double minDocsPercentageForCategoricalSplit, Bundle bundling, Int32 minDocsForCategoricalSplit, Double bias, IHost host)\n   at Microsoft.ML.Trainers.FastTree.BoostingFastTreeTrainerBase`3.ConstructTreeLearner(IChannel ch)\n   at Microsoft.ML.Trainers.FastTree.BoostingFastTreeTrainerBase`3.ConstructOptimizationAlgorithm(IChannel ch)\n   at Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer.ConstructOptimizationAlgorithm(IChannel ch)\n   at Microsoft.ML.Trainers.FastTree.FastTreeTrainerBase`3.Initialize(IChannel ch)\n   at Microsoft.ML.Trainers.FastTree.FastTreeTrainerBase`3.TrainCore(IChannel ch)\n   at Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer.TrainModelCore(TrainContext context)\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.Fit(IDataView input)\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\n```","Url":"https://github.com/dotnet/machinelearning/issues/7435","RelatedDescription":"Open issue \"FastTreeRegressionTrainer leaves memory allocation happens before actually yes knowing how many leaves are actually yes needed by the model\" (#7435)"},{"Id":"2964657904","IsPullRequest":true,"CreatedAt":"2025-04-01T21:56:21","Actor":"michaelgsharp","Number":"7432","RawContent":null,"Title":"Build analysis testing","State":"open","Body":"additional logging and forced failed test.","Url":"https://github.com/dotnet/machinelearning/pull/7432","RelatedDescription":"Open PR \"Build analysis testing\" (#7432)"},{"Id":"2962450528","IsPullRequest":true,"CreatedAt":"2025-04-01T19:46:07","Actor":"michaelgsharp","Number":"7431","RawContent":null,"Title":"Fixed light gbm update","State":"closed","Body":"Fixes #7320.\r\nFixes #7045.\r\nUpdated light GBM to the latest version.","Url":"https://github.com/dotnet/machinelearning/pull/7431","RelatedDescription":"Closed or merged PR \"Fixed light gbm update\" (#7431)"},{"Id":"2952372794","IsPullRequest":false,"CreatedAt":"2025-03-31T19:38:33","Actor":"superichmann","Number":"7429","RawContent":null,"Title":"Clustering.Trainers.KMeans does not comply to MLContext seed","State":"closed","Body":"same data, same mlcontext seed, run KMeans twice and get different results. why?\nplease do not ask me for a reproducer as this is an easy task to reproduce, just try yourself and see it.","Url":"https://github.com/dotnet/machinelearning/issues/7429","RelatedDescription":"Closed issue \"Clustering.Trainers.KMeans does not comply to MLContext seed\" (#7429)"},{"Id":"2953234386","IsPullRequest":false,"CreatedAt":"2025-03-31T17:21:25","Actor":"andreak-sdl","Number":"7430","RawContent":null,"Title":"Known vulnerability in LightGBM (CVE-2024-43598)","State":"closed","Body":"There is a known vulnerability in LightGBM <= 4.5.0 (see microsoft/LightGBM#6750), which is fixed with version 4.6.0. As it seems that the current version of Microsoft.ML.LightGbm is not compatible with newer versions of LightGBM (see https://github.com/dotnet/machinelearning/issues/7320), it would be good to handle this ticket with high priority. ","Url":"https://github.com/dotnet/machinelearning/issues/7430","RelatedDescription":"Closed issue \"Known vulnerability in LightGBM (CVE-2024-43598)\" (#7430)"},{"Id":"2934642077","IsPullRequest":false,"CreatedAt":"2025-03-25T20:20:29","Actor":"Dharam090909","Number":"7428","RawContent":null,"Title":"my application stuck at pipeline.fit()","State":"closed","Body":"I have developed application using windows form application by using ML.net but during pipeline.fit() application hang without error.I have already tested same code into other CPU that having same issue.\n\nMy code only running good with visual studio developer system only .","Url":"https://github.com/dotnet/machinelearning/issues/7428","RelatedDescription":"Closed issue \"my application stuck at pipeline.fit()\" (#7428)"},{"Id":"2926408304","IsPullRequest":true,"CreatedAt":"2025-03-24T17:45:06","Actor":"LittleLittleCloud","Number":"7424","RawContent":null,"Title":"Increase cancelling waiting time for AutoMLExperiment_return_current_best_trial_when_ct_is_canceled_with_trial_completed_Async","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n#7418 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7424","RelatedDescription":"Closed or merged PR \"Increase cancelling waiting time for AutoMLExperiment_return_current_best_trial_when_ct_is_canceled_with_trial_completed_Async\" (#7424)"},{"Id":"2933342658","IsPullRequest":true,"CreatedAt":"2025-03-20T17:46:26","Actor":"tarekgh","Number":"7427","RawContent":null,"Title":"Cleanup SentencePiece tokenizer","State":"closed","Body":"Removing creating sentence piece tokenizer creation with options as it is not needed at least from now. Also, address some older comment https://github.com/dotnet/machinelearning/pull/7409#pullrequestreview-2658950261 for checking the special tokens before storing them in the vocabulary reverse array.","Url":"https://github.com/dotnet/machinelearning/pull/7427","RelatedDescription":"Closed or merged PR \"Cleanup SentencePiece tokenizer\" (#7427)"},{"Id":"2930059473","IsPullRequest":true,"CreatedAt":"2025-03-20T15:41:16","Actor":"GrabYourPitchforks","Number":"7426","RawContent":null,"Title":"Reduce usage of unsafe constructs throughout codebase","State":"closed","Body":"This reduces the use of raw pointers and replaces them with safer constructs where possible. In some cases, `MemoryMarshal.Read<T>`, `MemoryMarshal.Write<T>`, and `MemoryMarshal.AsBytes<T>` are used.\r\n\r\nThough these three methods are normally unsafe-equivalent APIs, they are guaranteed safe when _T_ is a primitive integral or floating point type, char, or an enum thereof. (That is, it's guaranteed safe when _T_ is byte, sbyte, short, ushort, char, int, uint, long, ulong, int128, uint128, nint, nuint, float, double, Half, or an enum of any of these.)\r\n\r\nI've left code comments where things couldn't be made fully safe. I've also opted _not_ to touch some code in VectorUtils.cs. I only touched code where the loop logic is simple enough for the JIT (even the older netfx JIT!) to always elide bounds checks. I didn't touch code paths where multiple buffers were being touched at once since the JIT doesn't yet properly elide bounds checks in those cases, and I didn't want to risk a possible perf regression.","Url":"https://github.com/dotnet/machinelearning/pull/7426","RelatedDescription":"Closed or merged PR \"Reduce usage of unsafe constructs throughout codebase\" (#7426)"},{"Id":"2929950255","IsPullRequest":true,"CreatedAt":"2025-03-19T20:50:54","Actor":"tarekgh","Number":"7425","RawContent":null,"Title":"Support ByteLevel encoding in Bpe tokenizer to support DeepSeek model","State":"closed","Body":"This change includes:  \r\n\r\n- Adding support for **ByteLevel encoding** in the BPE tokenizer.  \r\n- Introducing a new `BpeTokenizer.Create` method that allows creating a tokenizer using the newly introduced `BpeOptions` type. This enables users to obtain tokenizer data from various sources (e.g., `tokenizer.json` files) and instantiate the tokenizer using this new factory method.  \r\n- Expanding test coverage to validate ByteLevel support.  \r\n- Adding a test that loads the real [tokenizer.json](https://huggingface.co/deepseek-ai/DeepSeek-R1/blob/main/tokenizer.json) for the **DeepSeek R1** model and verifies its functionality. Since the DeepSeek tokenizer utilizes ByteLevel encoding, it serves as an ideal test case for this feature.  \r\n- Providing test code for loading `tokenizer.json`, which can be used as a template for loading other models' tokenizers when needed.\r\n- Introducing the CompositePreTokenizer to support the DeepSeek pre-tokenization scenario.","Url":"https://github.com/dotnet/machinelearning/pull/7425","RelatedDescription":"Closed or merged PR \"Support ByteLevel encoding in Bpe tokenizer to support DeepSeek model\" (#7425)"},{"Id":"2914446806","IsPullRequest":true,"CreatedAt":"2025-03-13T15:17:03","Actor":"ericstj","Number":"7421","RawContent":null,"Title":"Switch to AwesomeAssertions","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7421","RelatedDescription":"Closed or merged PR \"Switch to AwesomeAssertions\" (#7421)"},{"Id":"2915299025","IsPullRequest":true,"CreatedAt":"2025-03-12T22:25:59","Actor":"dotnet-maestro[bot]","Number":"7422","RawContent":null,"Title":"[release/4.0] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\n\n[marker]: <> (Begin:a547de0d-c7ea-4682-b0d2-c8a549cede14)\n## From https://github.com/dotnet/arcade\n- **Subscription**: [a547de0d-c7ea-4682-b0d2-c8a549cede14](https://maestro.dot.net/subscriptions?search=a547de0d-c7ea-4682-b0d2-c8a549cede14)\n- **Build**: [20250425.6](https://dev.azure.com/dnceng/internal/_build/results?buildId=2695696)\n- **Date Produced**: April 25, 2025 7:23:04 PM UTC\n- **Commit**: [bfbc858ba868b60fffaf7b2150f1d2165b01e786](https://github.com/dotnet/arcade/commit/bfbc858ba868b60fffaf7b2150f1d2165b01e786)\n- **Branch**: refs/heads/release/9.0\n\n[DependencyUpdate]: <> (Begin)\n\n- **Updates**:\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n  - **Microsoft.DotNet.Helix.Sdk**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n  - **Microsoft.DotNet.SignTool**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n  - **Microsoft.DotNet.XliffTasks**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n  - **Microsoft.DotNet.XUnitExtensions**: [from 9.0.0-beta.25111.5 to 9.0.0-beta.25225.6][5]\n\n[5]: https://github.com/dotnet/arcade/compare/5da211e1c4...bfbc858ba8\n\n[DependencyUpdate]: <> (End)\n\n\n[marker]: <> (End:a547de0d-c7ea-4682-b0d2-c8a549cede14)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","Url":"https://github.com/dotnet/machinelearning/pull/7422","RelatedDescription":"Open PR \"[release/4.0] Update dependencies from dotnet/arcade\" (#7422)"},{"Id":"2913414356","IsPullRequest":false,"CreatedAt":"2025-03-12T10:08:07","Actor":"TheJanzap","Number":"7420","RawContent":null,"Title":"Better display of DataFrame in IEnumerable Visualizer","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\nCurrently, it is quite inconvenient to look at data inside of a DataFrame during debugging. It is possible to view the data via the \"Results View\" of the \"Rows\"/\"Columns\" properties, but with a lot of data, this gets inconvenient\n\nVisual Studio added the [IEnumerable Visualizer](https://devblogs.microsoft.com/visualstudio/view-net-collections-with-the-new-ienumerable-debugger-visualizer/) a while ago and I think it could significantly increase the debug experience, since it also allows to export data to CSV.\n\nCurrently, it is possible to have a view like this of the data:\n\n![Image](https://github.com/user-attachments/assets/779e215f-cd9d-4704-bec5-b4edaff3c162)\n\nThis is not ideal, as in every row the whole DataFrame is inserted in the `._dataFrame` column.\n\n**Describe the solution you'd like**\nI'd like to see better support for the IEnumerable Visualizer, so when viewing rows in it, every column has its own field.\n\n**Describe alternatives you've considered**\nIf this is impractical, it would also help to just remove the `_dataFrame` column from the IEnumerable view to make CSV exports a lot more digestable.","Url":"https://github.com/dotnet/machinelearning/issues/7420","RelatedDescription":"Open issue \"Better display of DataFrame in IEnumerable Visualizer\" (#7420)"}],"ResultType":"GitHubIssue"}},"RunOn":"2025-04-29T03:30:19.2166909Z","RunDurationInMilliseconds":537}