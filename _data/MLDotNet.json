{"Data":{"GitHub":{"Issues":[{"Id":"2584159813","IsPullRequest":true,"CreatedAt":"2024-10-13T18:08:37","Actor":"LittleLittleCloud","Number":"7270","RawContent":null,"Title":"[GenAI] Introduce CausalLMPipelineChatClient for MEAI.IChatClient","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis PR implements `CausalLMPipelineChatClient<TTokenizer, TCausalLMModel>` class for MEAI.IChatClient's intergration.\r\n\r\nThis PR also refactors the AutoGen and semantic kernel intergretion for Phi3, which pulls out the prompt template parts into an individual `Phi3ChatTemplateBuilder` class.\r\n\r\nThis PR also update `STJ` to 8.0.5 to address a security warning for that package\r\n\r\nThe `CausalLMPipelineChatClient` is used as the abstract class for all `IChatClient` implementation in GenAI models. For now, the following implementations are available\r\n- Phi3CausalLMChatClient\r\n- Llama3CausalLMChatClient\r\n\r\nThe `MistralCausalLMChatClient` will come in the following PR with additional support for tool call.\r\n\r\n## Usage\r\nCheckout the `MEAI` folder under Microsoft.ML.GenAI.Samples` for examples. The following examples are added\r\n- Llama3_1\r\n- Phi3\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7270","RelatedDescription":"Open PR \"[GenAI] Introduce CausalLMPipelineChatClient for MEAI.IChatClient\" (#7270)"},{"Id":"2583158851","IsPullRequest":false,"CreatedAt":"2024-10-12T15:13:59","Actor":"thomasd3","Number":"7269","RawContent":null,"Title":"mlnet finds duplicate columns where they don't exist","State":"open","Body":"I use this command:\n\n```\nmlnet classification --dataset training.csv  --validation-dataset validating.csv --train-time 100 --label-col 0 --ignore-cols 1 2 3 -has-header true --name test\n```\n\nand I get this error:\n```\nStart Training\n[Source=TextLoader; Binding, Kind=Info] Duplicate name(s) specified - later columns will hide earlier ones\nSystem.ArgumentException: An item with the same key has already been added. Key: 22742.3                                                                                                                                                                         at System.Collections.Generic.Dictionary`2.TryInsert(TKey key, TValue value, InsertionBehavior behavior)                                                                                                                                                      at System.Collections.Generic.Dictionary`2.Add(TKey key, TValue value)\n```\n\nBut there are absolutely no duplicate names in the columns.\n\nThis is the (very long) header:\n```\nlabel_score_long_1005,label_score_short_1005,timestamp,interval,high0,high0_h1,high0_p03,high0_p05,high0_p10,high_raw0,high_raw0_h1,high_raw0_p03,high_raw0_p05,high_raw0_p10,low0,low0_h1,low0_p03,low0_p05,low0_p10,low_raw0,low_raw0_h1,low_raw0_p03,low_raw0_p05,low_raw0_p10,close0,close0_h1,close0_p03,close0_p05,close0_p10,close_raw0,close_raw0_h1,close_raw0_p03,close_raw0_p05,close_raw0_p10,volume0,volume0_h1,volume0_p03,volume0_p05,volume0_p10,volume_raw0,volume_raw0_h1,volume_raw0_p03,volume_raw0_p05,volume_raw0_p10,volume_ema0,volume_ema0_h1,volume_ema0_p03,volume_ema0_p05,volume_ema0_p10,adx0,adx0_h1,adx0_p03,adx0_p05,adx0_p10,adx_r0,adx_r0_h1,adx_r0_p03,adx_r0_p05,adx_r0_p10,adx_mdi0,adx_mdi0_h1,adx_mdi0_p03,adx_mdi0_p05,adx_mdi0_p10,adx_pdi0,adx_pdi0_h1,adx_pdi0_p03,adx_pdi0_p05,adx_pdi0_p10,adl_money_flow_multiplier0,adl_money_flow_multiplier0_h1,adl_money_flow_multiplier0_p03,adl_money_flow_multiplier0_p05,adl_money_flow_multiplier0_p10,ao0,ao0_h1,ao0_p03,ao0_p05,ao0_p10,aroon_down0,aroon_down0_h1,aroon_down0_p03,aroon_down0_p05,aroon_down0_p10,aroon_up0,aroon_up0_h1,aroon_up0_p03,aroon_up0_p05,aroon_up0_p10,aroon_oscillator0,aroon_oscillator0_h1,aroon_oscillator0_p03,aroon_oscillator0_p05,aroon_oscillator0_p10,atrp0,atrp0_h1,atrp0_p03,atrp0_p05,atrp0_p10,atr_buystop0,atr_buystop0_h1,atr_buystop0_p03,atr_buystop0_p05,atr_buystop0_p10,atr_sellstop0,atr_sellstop0_h1,atr_sellstop0_p03,atr_sellstop0_p05,atr_sellstop0_p10,bop0,bop0_h1,bop0_p03,bop0_p05,bop0_p10,cci0,cci0_h1,cci0_p03,cci0_p05,cci0_p10,chaikinmoney_flow_multiplier0,chaikinmoney_flow_multiplier0_h1,chaikinmoney_flow_multiplier0_p03,chaikinmoney_flow_multiplier0_p05,chaikinmoney_flow_multiplier0_p10,chand_exit0,chand_exit0_h1,chand_exit0_p03,chand_exit0_p05,chand_exit0_p10,choppiness0,choppiness0_h1,choppiness0_p03,choppiness0_p05,choppiness0_p10,cmf0,cmf0_h1,cmf0_p03,cmf0_p05,cmf0_p10,cmf_money_flow_multiplier0,cmf_money_flow_multiplier0_h1,cmf_money_flow_multiplier0_p03,cmf_money_flow_multiplier0_p05,cmf_money_flow_multiplier0_p10,cmo0,cmo0_h1,cmo0_p03,cmo0_p05,cmo0_p10,connor_rank0,connor_rank0_h1,connor_rank0_p03,connor_rank0_p05,connor_rank0_p10,connor_rsi0,connor_rsi0_h1,connor_rsi0_p03,connor_rsi0_p05,connor_rsi0_p10,connor_rsi_streak0,connor_rsi_streak0_h1,connor_rsi_streak0_p03,connor_rsi_streak0_p05,connor_rsi_streak0_p10,elderray_bearpower0,elderray_bearpower0_h1,elderray_bearpower0_p03,elderray_bearpower0_p05,elderray_bearpower0_p10,elderray_bullpower0,elderray_bullpower0_h1,elderray_bullpower0_p03,elderray_bullpower0_p05,elderray_bullpower0_p10,gator_lower0,gator_lower0_h1,gator_lower0_p03,gator_lower0_p05,gator_lower0_p10,gator_lower_is_expanding0,gator_lower_is_expanding0_h1,gator_lower_is_expanding0_p03,gator_lower_is_expanding0_p05,gator_lower_is_expanding0_p10,gator_upper0,gator_upper0_h1,gator_upper0_p03,gator_upper0_p05,gator_upper0_p10,gator_upper_is_expanding0,gator_upper_is_expanding0_h1,gator_upper_is_expanding0_p03,gator_upper_is_expanding0_p05,gator_upper_is_expanding0_p10,hurst_exponent0,hurst_exponent0_h1,hurst_exponent0_p03,hurst_exponent0_p05,hurst_exponent0_p10,hvz_score0,hvz_score0_h1,hvz_score0_p03,hvz_score0_p05,hvz_score0_p10,ichimoku_kijunsen0,ichimoku_kijunsen0_h1,ichimoku_kijunsen0_p03,ichimoku_kijunsen0_p05,ichimoku_kijunsen0_p10,ichimoku_senkou_span_a0,ichimoku_senkou_span_a0_h1,ichimoku_senkou_span_a0_p03,ichimoku_senkou_span_a0_p05,ichimoku_senkou_span_a0_p10,ichimoku_senkou_span_b0,ichimoku_senkou_span_b0_h1,ichimoku_senkou_span_b0_p03,ichimoku_senkou_span_b0_p05,ichimoku_senkou_span_b0_p10,ichimoku_tenkansen0,ichimoku_tenkansen0_h1,ichimoku_tenkansen0_p03,ichimoku_tenkansen0_p05,ichimoku_tenkansen0_p10,macd0,macd0_h1,macd0_p03,macd0_p05,macd0_p10,marubozu_match0,marubozu_match0_h1,marubozu_match0_p03,marubozu_match0_p05,marubozu_match0_p10,mfi0,mfi0_h1,mfi0_p03,mfi0_p05,mfi0_p10,parabolic_sar0,parabolic_sar0_h1,parabolic_sar0_p03,parabolic_sar0_p05,parabolic_sar0_p10,pivots_high_line0,pivots_high_line0_h1,pivots_high_line0_p03,pivots_high_line0_p05,pivots_high_line0_p10,pivots_high_trend0,pivots_high_trend0_h1,pivots_high_trend0_p03,pivots_high_trend0_p05,pivots_high_trend0_p10,pivots_low_line0,pivots_low_line0_h1,pivots_low_line0_p03,pivots_low_line0_p05,pivots_low_line0_p10,pivots_low_trend0,pivots_low_trend0_h1,pivots_low_trend0_p03,pivots_low_trend0_p05,pivots_low_trend0_p10,pmo0,pmo0_h1,pmo0_p03,pmo0_p05,pmo0_p10,pmo_signal0,pmo_signal0_h1,pmo_signal0_p03,pmo_signal0_p05,pmo_signal0_p10,pvo0,pvo0_h1,pvo0_p03,pvo0_p05,pvo0_p10,roc0,roc0_h1,roc0_p03,roc0_p05,roc0_p10,rsi0,rsi0_h1,rsi0_p03,rsi0_p05,rsi0_p10,schaff_stc0,schaff_stc0_h1,schaff_stc0_p03,schaff_stc0_p05,schaff_stc0_p10,smi0,smi0_h1,smi0_p03,smi0_p05,smi0_p10,srsi_signal0,srsi_signal0_h1,srsi_signal0_p03,srsi_signal0_p05,srsi_signal0_p10,srsi_stoch_rsi0,srsi_stoch_rsi0_h1,srsi_stoch_rsi0_p03,srsi_stoch_rsi0_p05,srsi_stoch_rsi0_p10,stoch_a0,stoch_a0_h1,stoch_a0_p03,stoch_a0_p05,stoch_a0_p10,stoch_a_zone0,stoch_a_zone0_h1,stoch_a_zone0_p03,stoch_a_zone0_p05,stoch_a_zone0_p10,stoch_a_cross_top0,stoch_a_cross_top0_h1,stoch_a_cross_top0_p03,stoch_a_cross_top0_p05,stoch_a_cross_top0_p10,stoch_a_cross_bottom0,stoch_a_cross_bottom0_h1,stoch_a_cross_bottom0_p03,stoch_a_cross_bottom0_p05,stoch_a_cross_bottom0_p10,stoch_b0,stoch_b0_h1,stoch_b0_p03,stoch_b0_p05,stoch_b0_p10,stoch_b_zone0,stoch_b_zone0_h1,stoch_b_zone0_p03,stoch_b_zone0_p05,stoch_b_zone0_p10,stoch_b_cross_top0,stoch_b_cross_top0_h1,stoch_b_cross_top0_p03,stoch_b_cross_top0_p05,stoch_b_cross_top0_p10,stoch_b_cross_bottom0,stoch_b_cross_bottom0_h1,stoch_b_cross_bottom0_p03,stoch_b_cross_bottom0_p05,stoch_b_cross_bottom0_p10,stoch_c0,stoch_c0_h1,stoch_c0_p03,stoch_c0_p05,stoch_c0_p10,stoch_c_zone0,stoch_c_zone0_h1,stoch_c_zone0_p03,stoch_c_zone0_p05,stoch_c_zone0_p10,stoch_c_cross_top0,stoch_c_cross_top0_h1,stoch_c_cross_top0_p03,stoch_c_cross_top0_p05,stoch_c_cross_top0_p10,stoch_c_cross_bottom0,stoch_c_cross_bottom0_h1,stoch_c_cross_bottom0_p03,stoch_c_cross_bottom0_p05,stoch_c_cross_bottom0_p10,stoch_d0,stoch_d0_h1,stoch_d0_p03,stoch_d0_p05,stoch_d0_p10,stoch_d_zone0,stoch_d_zone0_h1,stoch_d_zone0_p03,stoch_d_zone0_p05,stoch_d_zone0_p10,stoch_d_cross_top0,stoch_d_cross_top0_h1,stoch_d_cross_top0_p03,stoch_d_cross_top0_p05,stoch_d_cross_top0_p10,stoch_d_cross_bottom0,stoch_d_cross_bottom0_h1,stoch_d_cross_bottom0_p03,stoch_d_cross_bottom0_p05,stoch_d_cross_bottom0_p10,supertrend_lower0,supertrend_lower0_h1,supertrend_lower0_p03,supertrend_lower0_p05,supertrend_lower0_p10,supertrend_upper0,supertrend_upper0_h1,supertrend_upper0_p03,supertrend_upper0_p05,supertrend_upper0_p10,tsi_signal0,tsi_signal0_h1,tsi_signal0_p03,tsi_signal0_p05,tsi_signal0_p10,tsi0,tsi0_h1,tsi0_p03,tsi0_p05,tsi0_p10,ulcer_index0,ulcer_index0_h1,ulcer_index0_p03,ulcer_index0_p05,ulcer_index0_p10,uo_ultimate0,uo_ultimate0_h1,uo_ultimate0_p03,uo_ultimate0_p05,uo_ultimate0_p10,volstop_lower0,volstop_lower0_h1,volstop_lower0_p03,volstop_lower0_p05,volstop_lower0_p10,volstop_upper0,volstop_upper0_h1,volstop_upper0_p03,volstop_upper0_p05,volstop_upper0_p10,vortex_nvi0,vortex_nvi0_h1,vortex_nvi0_p03,vortex_nvi0_p05,vortex_nvi0_p10,vortex_pvi0,vortex_pvi0_h1,vortex_pvi0_p03,vortex_pvi0_p05,vortex_pvi0_p10,willfract_bear0,willfract_bear0_h1,willfract_bear0_p03,willfract_bear0_p05,willfract_bear0_p10,willfract_bull0,willfract_bull0_h1,willfract_bull0_p03,willfract_bull0_p05,willfract_bull0_p10,tgn_tunnel_high0,tgn_tunnel_high0_h1,tgn_tunnel_high0_p03,tgn_tunnel_high0_p05,tgn_tunnel_high0_p10,tgn_tunnel_low0,tgn_tunnel_low0_h1,tgn_tunnel_low0_p03,tgn_tunnel_low0_p05,tgn_tunnel_low0_p10,tgn_tunnel_high_price0,tgn_tunnel_high_price0_h1,tgn_tunnel_high_price0_p03,tgn_tunnel_high_price0_p05,tgn_tunnel_high_price0_p10,tgn_tunnel_low_price0,tgn_tunnel_low_price0_h1,tgn_tunnel_low_price0_p03,tgn_tunnel_low_price0_p05,tgn_tunnel_low_price0_p10,tgn_tunnel_high_price_change0,tgn_tunnel_high_price_change0_h1,tgn_tunnel_high_price_change0_p03,tgn_tunnel_high_price_change0_p05,tgn_tunnel_high_price_change0_p10,tgn_tunnel_low_price_change0,tgn_tunnel_low_price_change0_h1,tgn_tunnel_low_price_change0_p03,tgn_tunnel_low_price_change0_p05,tgn_tunnel_low_price_change0_p10,tgn_node_last_type0,tgn_node_last_type0_h1,tgn_node_last_type0_p03,tgn_node_last_type0_p05,tgn_node_last_type0_p10,tgn_node_price_hh0,tgn_node_price_hh0_h1,tgn_node_price_hh0_p03,tgn_node_price_hh0_p05,tgn_node_price_hh0_p10,tgn_node_price_lh0,tgn_node_price_lh0_h1,tgn_node_price_lh0_p03,tgn_node_price_lh0_p05,tgn_node_price_lh0_p10,tgn_node_price_hl0,tgn_node_price_hl0_h1,tgn_node_price_hl0_p03,tgn_node_price_hl0_p05,tgn_node_price_hl0_p10,tgn_node_price_ll0,tgn_node_price_ll0_h1,tgn_node_price_ll0_p03,tgn_node_price_ll0_p05,tgn_node_price_ll0_p10,tgn_gap_countAbove0,tgn_gap_countAbove0_h1,tgn_gap_countAbove0_p03,tgn_gap_countAbove0_p05,tgn_gap_countAbove0_p10,tgn_gap_countBelow0,tgn_gap_countBelow0_h1,tgn_gap_countBelow0_p03,tgn_gap_countBelow0_p05,tgn_gap_countBelow0_p10,tgn_gap_distanceClosestAbove0,tgn_gap_distanceClosestAbove0_h1,tgn_gap_distanceClosestAbove0_p03,tgn_gap_distanceClosestAbove0_p05,tgn_gap_distanceClosestAbove0_p10,tgn_gap_distanceClosestBelow0,tgn_gap_distanceClosestBelow0_h1,tgn_gap_distanceClosestBelow0_p03,tgn_gap_distanceClosestBelow0_p05,tgn_gap_distanceClosestBelow0_p10,tgn_gap_sizeClosestAbove0,tgn_gap_sizeClosestAbove0_h1,tgn_gap_sizeClosestAbove0_p03,tgn_gap_sizeClosestAbove0_p05,tgn_gap_sizeClosestAbove0_p10,tgn_gap_sizeClosestBelow0,tgn_gap_sizeClosestBelow0_h1,tgn_gap_sizeClosestBelow0_p03,tgn_gap_sizeClosestBelow0_p05,tgn_gap_sizeClosestBelow0_p10,tgn_gap_directionClosestAbove0,tgn_gap_directionClosestAbove0_h1,tgn_gap_directionClosestAbove0_p03,tgn_gap_directionClosestAbove0_p05,tgn_gap_directionClosestAbove0_p10,tgn_gap_directionClosestBelow0,tgn_gap_directionClosestBelow0_h1,tgn_gap_directionClosestBelow0_p03,tgn_gap_directionClosestBelow0_p05,tgn_gap_directionClosestBelow0_p10,tgn_gap_avgDistanceAbove0,tgn_gap_avgDistanceAbove0_h1,tgn_gap_avgDistanceAbove0_p03,tgn_gap_avgDistanceAbove0_p05,tgn_gap_avgDistanceAbove0_p10,tgn_gap_avgDistanceBelow0,tgn_gap_avgDistanceBelow0_h1,tgn_gap_avgDistanceBelow0_p03,tgn_gap_avgDistanceBelow0_p05,tgn_gap_avgDistanceBelow0_p10,tgn_LL_countAbove0,tgn_LL_countAbove0_h1,tgn_LL_countAbove0_p03,tgn_LL_countAbove0_p05,tgn_LL_countAbove0_p10,tgn_LL_countBelow0,tgn_LL_countBelow0_h1,tgn_LL_countBelow0_p03,tgn_LL_countBelow0_p05,tgn_LL_countBelow0_p10,tgn_ll_distanceClosestAbove0,tgn_ll_distanceClosestAbove0_h1,tgn_ll_distanceClosestAbove0_p03,tgn_ll_distanceClosestAbove0_p05,tgn_ll_distanceClosestAbove0_p10,tgn_ll_distanceClosestBelow0,tgn_ll_distanceClosestBelow0_h1,tgn_ll_distanceClosestBelow0_p03,tgn_ll_distanceClosestBelow0_p05,tgn_ll_distanceClosestBelow0_p10,tgn_ll_directionClosestAbove0,tgn_ll_directionClosestAbove0_h1,tgn_ll_directionClosestAbove0_p03,tgn_ll_directionClosestAbove0_p05,tgn_ll_directionClosestAbove0_p10,tgn_ll_directionClosestBelow0,tgn_ll_directionClosestBelow0_h1,tgn_ll_directionClosestBelow0_p03,tgn_ll_directionClosestBelow0_p05,tgn_ll_directionClosestBelow0_p10,tgn_ll_avgDistanceAbove0,tgn_ll_avgDistanceAbove0_h1,tgn_ll_avgDistanceAbove0_p03,tgn_ll_avgDistanceAbove0_p05,tgn_ll_avgDistanceAbove0_p10,tgn_ll_avgDistanceBelow0,tgn_ll_avgDistanceBelow0_h1,tgn_ll_avgDistanceBelow0_p03,tgn_ll_avgDistanceBelow0_p05,tgn_ll_avgDistanceBelow0_p10,tgn_coc_last_distance0,tgn_coc_last_distance0_h1,tgn_coc_last_distance0_p03,tgn_coc_last_distance0_p05,tgn_coc_last_distance0_p10,tgn_coc_last_direction0,tgn_coc_last_direction0_h1,tgn_coc_last_direction0_p03,tgn_coc_last_direction0_p05,tgn_coc_last_direction0_p10,tgn_coc_count_last_5_hours0,tgn_coc_count_last_5_hours0_h1,tgn_coc_count_last_5_hours0_p03,tgn_coc_count_last_5_hours0_p05,tgn_coc_count_last_5_hours0_p10,tgn_coc_count_last_10_hours0,tgn_coc_count_last_10_hours0_h1,tgn_coc_count_last_10_hours0_p03,tgn_coc_count_last_10_hours0_p05,tgn_coc_count_last_10_hours0_p10,tgn_coc_time_since_last_event0,tgn_coc_time_since_last_event0_h1,tgn_coc_time_since_last_event0_p03,tgn_coc_time_since_last_event0_p05,tgn_coc_time_since_last_event0_p10,tgn_coc_avg_interval_dist_between0,tgn_coc_avg_interval_dist_between0_h1,tgn_coc_avg_interval_dist_between0_p03,tgn_coc_avg_interval_dist_between0_p05,tgn_coc_avg_interval_dist_between0_p10,tgn_coc_avg_price_dist_between0,tgn_coc_avg_price_dist_between0_h1,tgn_coc_avg_price_dist_between0_p03,tgn_coc_avg_price_dist_between0_p05,tgn_coc_avg_price_dist_between0_p10,tgn_coc_long_count0,tgn_coc_long_count0_h1,tgn_coc_long_count0_p03,tgn_coc_long_count0_p05,tgn_coc_long_count0_p10,tgn_coc_short_count0,tgn_coc_short_count0_h1,tgn_coc_short_count0_p03,tgn_coc_short_count0_p05,tgn_coc_short_count0_p10,tgn_mss_last_distance0,tgn_mss_last_distance0_h1,tgn_mss_last_distance0_p03,tgn_mss_last_distance0_p05,tgn_mss_last_distance0_p10,tgn_mss_last_direction0,tgn_mss_last_direction0_h1,tgn_mss_last_direction0_p03,tgn_mss_last_direction0_p05,tgn_mss_last_direction0_p10,tgn_mss_count_last_5_hours0,tgn_mss_count_last_5_hours0_h1,tgn_mss_count_last_5_hours0_p03,tgn_mss_count_last_5_hours0_p05,tgn_mss_count_last_5_hours0_p10,tgn_mss_count_last_10_hours0,tgn_mss_count_last_10_hours0_h1,tgn_mss_count_last_10_hours0_p03,tgn_mss_count_last_10_hours0_p05,tgn_mss_count_last_10_hours0_p10,tgn_mss_time_since_last_event0,tgn_mss_time_since_last_event0_h1,tgn_mss_time_since_last_event0_p03,tgn_mss_time_since_last_event0_p05,tgn_mss_time_since_last_event0_p10,tgn_mss_avg_interval_dist_between0,tgn_mss_avg_interval_dist_between0_h1,tgn_mss_avg_interval_dist_between0_p03,tgn_mss_avg_interval_dist_between0_p05,tgn_mss_avg_interval_dist_between0_p10,tgn_mss_avg_price_dist_between0,tgn_mss_avg_price_dist_between0_h1,tgn_mss_avg_price_dist_between0_p03,tgn_mss_avg_price_dist_between0_p05,tgn_mss_avg_price_dist_between0_p10,tgn_mss_long_count0,tgn_mss_long_count0_h1,tgn_mss_long_count0_p03,tgn_mss_long_count0_p05,tgn_mss_long_count0_p10,tgn_mss_short_count0,tgn_mss_short_count0_h1,tgn_mss_short_count0_p03,tgn_mss_short_count0_p05,tgn_mss_short_count0_p10,tgn_fair_price0,tgn_fair_price0_h1,tgn_fair_price0_p03,tgn_fair_price0_p05,tgn_fair_price0_p10,tgn_tunnel_breakout0,tgn_tunnel_breakout0_h1,tgn_tunnel_breakout0_p03,tgn_tunnel_breakout0_p05,tgn_tunnel_breakout0_p10,tgn_tunnel_break_from_price0,tgn_tunnel_break_from_price0_h1,tgn_tunnel_break_from_price0_p03,tgn_tunnel_break_from_price0_p05,tgn_tunnel_break_from_price0_p10,tgn_compression_zone_breakout0,tgn_compression_zone_breakout0_h1,tgn_compression_zone_breakout0_p03,tgn_compression_zone_breakout0_p05,tgn_compression_zone_breakout0_p10,tgn_compression_zone_break_from_price0,tgn_compression_zone_break_from_price0_h1,tgn_compression_zone_break_from_price0_p03,tgn_compression_zone_break_from_price0_p05,tgn_compression_zone_break_from_price0_p10,tgn_in_zone0,tgn_in_zone0_h1,tgn_in_zone0_p03,tgn_in_zone0_p05,tgn_in_zone0_p10\n```\n\nwhen I don't specify that the file has a header, I get this error instead:\n\n```\nStart Training\nSystem.Exception: Train dataset and validate dataset schema is not compatible. Column(s) col0, col4, col5, col6, col7, col8, col9, col10, col11, col12, col13, col14, col15, col16, col17, col18, col19, col20, col21, col22, col23, col24, col25, col26, col27, col28, col29, col30, col31, col32, col33, col34, col35, col36, col37, col38, col39, col40, col41, col42, col43, col44, col45, col46, col47, col48, col49, col50, col51, col52, col53, col54, col55, col56, col57, col58, col59, col60, col61, col62, col63, col64, col65, col66, col67, col68, col69, col70, col71, col72, col73, col74, col75, col76, col77, col78, col79, col80, col81, col82, col83, col84, col85, col86, col87, col88, col89, col90, col91, col92, col93, col94, col95, col96, col97, col98, col99, col100, col101, col102, col103, col104, col105, col106, col107, col108, col109, col110, col111, col112, col113, col114, col115, col116, col117, col118, col119, col120, col121, col122, col123, col124, col125, col126, col127, col128, col129, col130, col131, col132, col133, col134, col135, col136, col137, col138, col139, col140, col141, col142, col143, col144, col145, col146, col147, col148, col149, col150, col151, col152, col153, col154, col155, col156, col157, col158, col159, col160, col161, col162, col163, col164, col165, col166, col167, col168, col169, col170, col171, col172, col173, col174, col175, col176, col177, col178, col179, col180, col181, col182, col183, col184, col185, col186, col187, col188, col189, col190, col191, col192, col193, col194, col195, col196, col197, col198, col199, col200, col201, col202, col203, col204, col205, col206, col207, col208, col209, col210, col211, col212, col213, col214, col215, col216, col217, col218, col219, col220, col221, col222, col223, col224, col225, col226, col227, col228, col229, col230, col231, col232, col233, col234, col235, col236, col237, col238, col239, col240, col241, col242, col243, col244, col245, col246, col247, col248, col249, col250, col251, col252, col253, col254, col255, col256, col257, col258, col259, col260, col261, col262, col263, col264, col265, col266, col267, col268, col269, col270, col271, col272, col273, col274, col275, col276, col277, col278, col279, col280, col281, col282, col283, col284, col285, col286, col287, col288, col289, col290, col291, col292, col293, col294, col295, col296, col297, col298, col299, col300, col301, col302, col303, col304, col305, col306, col307, col308, col309, col310, col311, col312, col313, col314, col315, col316, col317, col318, col319, col320, col321, col322, col323, col324, col325, col326, col327, col328, col329, col330, col331, col332, col333, col334, col335, col336, col337, col338, col339, col340, col341, col342, col343, col344, col345, col346, col347, col348, col349, col350, col351, col352, col353, col354, col355, col356, col357, col358, col359, col360, col361, col362, col363, col364, col365, col366, col367, col368, col369, col370, col371, col372, col373, col374, col375, col376, col377, col378, col379, col380, col381, col382, col383, col384, col385, col386, col387, col388, col389, col390, col391, col392, col393, col394, col395, col396, col397, col398, col399, col400, col401, col402, col403, col404, col405, col406, col407, col408, col409, col410, col411, col412, col413, col414, col415, col416, col417, col418, col419, col420, col421, col422, col423, col424, col425, col426, col427, col428, col429, col430, col431, col432, col433, col434, col435, col436, col437, col438, col439, col440, col441, col442, col443, col444, col445, col446, col447, col448, col449, col450, col451, col452, col453, col454, col455, col456, col457, col458, col459, col460, col461, col462, col463, col464, col465, col466, col467, col468, col469, col470, col471, col472, col473, col474, col475, col476, col477, col478, col479, col480, col481, col482, col483, col484, col485, col486, col487, col488, col489, col490, col491, col492, col493, col494, col495, col496, col497, col498, col499, col500, col501, col502, col503, col504, col505, col506, col507, col508, col509, col510, col511, col512, col513, col514, col515, col516, col517, col518, col519, col520, col521, col522, col523, col524, col525, col526, col527, col528, col529, col530, col531, col532, col533, col534, col535, col536, col537, col538, col539, col540, col541, col542, col543, col544, col545, col546, col547, col548, col549, col550, col551, col552, col553, col554, col555, col556, col557, col558, col559, col560, col561, col562, col563, col564, col565, col566, col567, col568, col569, col570, col571, col572, col573, col574, col575, col576, col577, col578, col579, col580, col581, col582, col583, col584, col585, col586, col587, col588, col589, col590, col591, col592, col593, col594, col595, col596, col597, col598, col599, col600, col601, col602, col603, col604, col605, col606, col607, col608, col609, col610, col611, col612, col613, col614, col615, col616, col617, col618, col619, col620, col621, col622, col623, col624, col625, col626, col627, col628, col629, col630, col631, col632, col633, col634, col635, col636, col637, col638, col639, col640, col641, col642, col643, col644, col645, col646, col647, col648, col649, col650, col651, col652, col653, col654, col655, col656, col657, col658, col659, col660, col661, col662, col663, col664, col665, col666, col667, col668, col669, col670, col671, col672, col673, col674, col675, col676, col677, col678, col679, col680, col681, col682, col683, col684, col685, col686, col687, col688, col689, col690, col691, col692, col693, col694, col695, col696, col697, col698, col699, col700, col701, col702, col703, col704, col705, col706, col707, col708, col709, col710, col711, col712, col713 are not found in validate dataset.\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.GetValidateDatasetLoaderOption(ITrainingConfiguration config, IEnumerable`1 validateColumnInfo, Char decimalSeparator, String delimiter, Boolean hasHeader) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 307\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.GetValidateDatasetTextLoaderOptionAsync(ITrainingConfiguration config) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 398\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.StartTrainingAsync(ITrainingConfiguration config, PathConfiguration pathConfig, CancellationToken userCancellationToken) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 106\n\n```\n","Url":"https://github.com/dotnet/machinelearning/issues/7269","RelatedDescription":"Open issue \"mlnet finds duplicate columns where they don't exist\" (#7269)"},{"Id":"2574492091","IsPullRequest":true,"CreatedAt":"2024-10-11T23:06:23","Actor":"tarekgh","Number":"7264","RawContent":null,"Title":"Misc Changes","State":"closed","Body":"The changes here include the following:\r\n\r\n- Support `o1` model labels in the Tiktoken tokenizer\r\n- Replace the usage of the Tuple in the `EncodedToken` with the `Range` and remove the `TorchSharp` `Range/Index` implementation\r\n- Rename the `SentencePieceBpeTokenizer` to allow adding more models to it in the future\r\n- Make the `Tokenizer.Decode` method return a non-nullable string\r\n- Add support for added tokens in the BPE tokenizer\r\n\r\nEvery commit in the PR is representing one of the listed changes. Reviewing every commit separately will make it easier to have a clear understanding of the changes.","Url":"https://github.com/dotnet/machinelearning/pull/7264","RelatedDescription":"Closed or merged PR \"Misc Changes\" (#7264)"},{"Id":"2579529412","IsPullRequest":false,"CreatedAt":"2024-10-10T18:18:51","Actor":"tarekgh","Number":"7268","RawContent":null,"Title":"[Tracking] Clean up item related to Tokenizers","State":"open","Body":"In the PR https://github.com/dotnet/machinelearning/pull/7264 we have added dependency on the `Microsoft.Bcl.Memory` which was not released as GA yet. This issue is tracking the tracking to clean up the following two items:\n\n- `Microsoft.Bcl.Memory` will produce a warning in any project targeting net6. As we still have some projects targeting net6, we had to add the property `<SuppressTfmSupportBuildWarnings>true</SuppressTfmSupportBuildWarnings>` in the projects to avoid the warning. When we do the retargeting/upgrade such projects, we need to remove the added property.\n- As `Microsoft.Bcl.Memory` not released and we are referencing the preview version of this package, we need to change that after the package became GA.","Url":"https://github.com/dotnet/machinelearning/issues/7268","RelatedDescription":"Open issue \"[Tracking] Clean up item related to Tokenizers\" (#7268)"},{"Id":"2579485994","IsPullRequest":true,"CreatedAt":"2024-10-10T17:54:28","Actor":"dotnet-maestro[bot]","Number":"7267","RawContent":null,"Title":"[release/3.0] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:45c6fd49-3a4f-4675-f3da-08dc0c527e17)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 45c6fd49-3a4f-4675-f3da-08dc0c527e17\r\n- **Build**: 20241008.1\r\n- **Date Produced**: October 8, 2024 6:38:56 PM UTC\r\n- **Commit**: e5b13e054339e41d422212a0ecaf24fec20cb5a1\r\n- **Branch**: refs/heads/release/8.0\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 8.0.0-beta.24360.5 to 8.0.0-beta.24508.1][1]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 8.0.0-beta.24360.5 to 8.0.0-beta.24508.1][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 8.0.0-beta.24360.5 to 8.0.0-beta.24508.1][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 8.0.0-beta.24360.5 to 8.0.0-beta.24508.1][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 8.0.0-beta.24360.5 to 8.0.0-beta.24508.1][1]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 8.0.0-beta.24360.5 to 8.0.0-beta.24508.1][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/c9efa53517...e5b13e0543\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n- **Updates to .NET SDKs:**\r\n  - Updates tools.dotnet to 8.0.110\r\n\r\n[marker]: <> (End:45c6fd49-3a4f-4675-f3da-08dc0c527e17)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7267","RelatedDescription":"Open PR \"[release/3.0] Update dependencies from dotnet/arcade\" (#7267)"},{"Id":"2579455275","IsPullRequest":true,"CreatedAt":"2024-10-10T17:39:15","Actor":"dotnet-maestro[bot]","Number":"7266","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: c692823c-b896-437f-4f57-08dc434cc8f6\r\n- **Build**: 20241010.1\r\n- **Date Produced**: October 10, 2024 3:02:03 PM UTC\r\n- **Commit**: 380002a14775d7f68f098c7e6b7d1c3638bd4c5d\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n  - **Microsoft.DotNet.XliffTasks**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 10.0.0-beta.24504.4 to 10.0.0-beta.24510.1][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/f209a925b1...380002a147\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n- **Updates to .NET SDKs:**\r\n  - Updates tools.dotnet to 9.0.100-rc.2.24474.11\r\n\r\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7266","RelatedDescription":"Open PR \"[main] Update dependencies from dotnet/arcade\" (#7266)"},{"Id":"2577356926","IsPullRequest":false,"CreatedAt":"2024-10-10T02:24:00","Actor":"asyura","Number":"7265","RawContent":null,"Title":"Monotone constraint still not support for LightGBM 3.0.1","State":"open","Body":"I readed this #1651 and #2330, but monotone constraint still not support for LightGBM 3.0.1\n\nany idea?\n\nthanks\n","Url":"https://github.com/dotnet/machinelearning/issues/7265","RelatedDescription":"Open issue \"Monotone constraint still not support for LightGBM 3.0.1\" (#7265)"},{"Id":"2562584478","IsPullRequest":true,"CreatedAt":"2024-10-09T17:07:21","Actor":"michaelgsharp","Number":"7254","RawContent":null,"Title":"Load onnx model from Stream of bytes","State":"closed","Body":"Fixes #6591 by adding an overload API to allow the ONNX model to be passed in as a Stream of bytes.","Url":"https://github.com/dotnet/machinelearning/pull/7254","RelatedDescription":"Closed or merged PR \"Load onnx model from Stream of bytes\" (#7254)"},{"Id":"2538660347","IsPullRequest":true,"CreatedAt":"2024-10-09T15:46:43","Actor":"asmirnov82","Number":"7242","RawContent":null,"Title":"Fix dataframe incorrectly parse CSV when renameDuplicatedColumns is true","State":"closed","Body":"Fixes #7240\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7242","RelatedDescription":"Closed or merged PR \"Fix dataframe incorrectly parse CSV when renameDuplicatedColumns is true\" (#7242)"},{"Id":"2560059313","IsPullRequest":true,"CreatedAt":"2024-10-07T21:33:42","Actor":"ericstj","Number":"7253","RawContent":null,"Title":"Update wording in LDA docs","State":"closed","Body":"Update the wording mentioning countries.  This is actually a quote, but it need not mention `countries`  - the actual source of this quote has since been updated.  \r\nhttps://en.wikipedia.org/w/index.php?title=Earth_Day&oldid=824511329 (which was pulled from an old version of earthday.org).\r\n\r\nI didn't bother updating the values in the comment - I'm not sure if they need to be accurate to get the point across.  @michaelgsharp if you think they should be updated please let me know and help me recompute them.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7253","RelatedDescription":"Closed or merged PR \"Update wording in LDA docs\" (#7253)"},{"Id":"2564792599","IsPullRequest":true,"CreatedAt":"2024-10-07T19:39:15","Actor":"stephentoub","Number":"7255","RawContent":null,"Title":"Update tiktoken regexes","State":"closed","Body":"This updates two of the regexes to match the changes made in https://github.com/openai/tiktoken/commit/9f7f69d62d6052dcc2fd54357df6ae9ae2590518.\r\n\r\nOn .NET Core, these changes are mostly nops, as the main thing they're doing is changing some loops to be atomic, and the auto-atomicity logic in the regex optimizer was already noticing that could be done and doing it automatically. On .NET Framework, it's a bigger deal, as those loops will now be atomic where they weren't previously.\r\n\r\nIf nothing else, it keeps the regexes in sync with the reference implementation.","Url":"https://github.com/dotnet/machinelearning/pull/7255","RelatedDescription":"Closed or merged PR \"Update tiktoken regexes\" (#7255)"},{"Id":"2571146644","IsPullRequest":false,"CreatedAt":"2024-10-07T18:22:55","Actor":"luisquintanilla","Number":"7263","RawContent":null,"Title":"Enable custom token counting","State":"open","Body":"Currently, Tokenizer returns counts strictly based on tokens.\r\n\r\nHowever, there are scenarios where library authors may want / need to implement their own custom token counting function. \r\n\r\nOne such scenario is providing token counts for image inputs. In such cases, AI service providers provide an arbitrary way of calculating cost based on a fixed token count. \r\n\r\n| Provider | Cost calculations | Does tokenization |  Link |\r\n| --- | --- | --- | --- |\r\n| OpenAI | Fixed | No | https://platform.openai.com/docs/guides/vision/calculating-costs | \r\n| Claude | Fixed | No | https://docs.anthropic.com/en/docs/build-with-claude/vision#calculate-image-costs |\r\n| Gemini | Fixed | No | https://ai.google.dev/gemini-api/docs/tokens?lang=python#multimodal-tokens | \r\n| Cohere | N/A | N/A | https://docs.cohere.com/docs/tokens | \r\n| Mistral | N/A | N/A | https://docs.mistral.ai/guides/tokenization/#tokens-count | \r\n","Url":"https://github.com/dotnet/machinelearning/issues/7263","RelatedDescription":"Open issue \"Enable custom token counting\" (#7263)"},{"Id":"2568882983","IsPullRequest":true,"CreatedAt":"2024-10-06T20:34:06","Actor":"vthemelis","Number":"7262","RawContent":null,"Title":"Add support for Arrow Timestamp and Date32 in DataFrame","State":"open","Body":"Fixes: https://github.com/dotnet/machinelearning/issues/7260 \r\nFixes: https://github.com/dotnet/machinelearning/issues/7261\r\n\r\nTimestamp contains UTC information so it makes sense to capture it in `DateTimeOffset` rather than `DateTime`.\r\n\r\nAlso, capture `Date32` as a `DateOnly` if we're in .NET 6 (`DateOnly` is missing from .NET standard at this point).\r\n\r\n\r\n\r\n--------------------------------------------------\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7262","RelatedDescription":"Open PR \"Add support for Arrow Timestamp and Date32 in DataFrame\" (#7262)"},{"Id":"2568882915","IsPullRequest":false,"CreatedAt":"2024-10-06T20:33:57","Actor":"vthemelis","Number":"7261","RawContent":null,"Title":"Decode Date32 arrow type in DataFrame","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nAt the moment, it looks like it's not possible to read `RecordBatch`es of `Date32`s:\r\n\r\n```csharp\r\nusing Apache.Arrow;\r\nusing Microsoft.Data.Analysis;\r\n\r\nvar batch = new RecordBatch.Builder()\r\n    .Append(\"DateColumn\", false, new Date32Array.Builder().AppendRange(Enumerable.Repeat(DateTime.Now, 10)).Build())\r\n    .Build();\r\n\r\nDataFrame.FromArrowRecordBatch(batch);\r\n```\r\n\r\ngives:\r\n```\r\nUnhandled exception. System.NotImplementedException: date32\r\n   at Microsoft.Data.Analysis.DataFrame.AppendDataFrameColumnFromArrowArray(Field field, IArrowArray arrowArray, DataFrame ret, String fieldNamePrefix)\r\n   at Microsoft.Data.Analysis.DataFrame.FromArrowRecordBatch(RecordBatch recordBatch)\r\n   at Program.<Main>$(String[] args)\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/7261","RelatedDescription":"Open issue \"Decode Date32 arrow type in DataFrame\" (#7261)"},{"Id":"2568861973","IsPullRequest":false,"CreatedAt":"2024-10-06T19:51:50","Actor":"vthemelis","Number":"7260","RawContent":null,"Title":"Decode and roundtrip Timestamp fields from Arrow into DataFrame.","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nAt the moment, it looks like it's not possible to read `RecordBatch`es of `Timestamp`s:\r\n\r\n```csharp\r\nusing Apache.Arrow;\r\nusing Microsoft.Data.Analysis;\r\n\r\nvar batch = new RecordBatch.Builder()\r\n    .Append(\"TimestampColumn\", false, new TimestampArray.Builder().AppendRange(Enumerable.Repeat(DateTimeOffset.Now, 10)).Build())\r\n    .Build();\r\n\r\nDataFrame.FromArrowRecordBatch(batch);\r\n```\r\n\r\ngives:\r\n```\r\nUnhandled exception. System.NotImplementedException: timestamp\r\n   at Microsoft.Data.Analysis.DataFrame.AppendDataFrameColumnFromArrowArray(Field field, IArrowArray arrowArray, DataFrame ret, String fieldNamePrefix)\r\n   at Microsoft.Data.Analysis.DataFrame.FromArrowRecordBatch(RecordBatch recordBatch)\r\n   at Program.<Main>$(String[] args)\r\n```\r\n\r\n**Describe the solution you'd like**\r\nThe above should pass and read the `RecordBatch` into a `DateTimeOffset` type.\r\n\r\nTried with:\r\n```bash\r\ndotnet add package Microsoft.Data.Analysis --version 0.21.1\r\n```\r\n\r\n\r\n-----------------------------------------------------\r\nWith the current pre-release version\r\n```bash\r\ndotnet add package Microsoft.Data.Analysis --version 0.22.0-preview.24378.1\r\n```\r\n\r\nthe above passes but doesn't roundtrip:\r\n```csharp\r\nusing Apache.Arrow;\r\nusing Microsoft.Data.Analysis;\r\n\r\nvar batch = new RecordBatch.Builder()\r\n    .Append(\"TimestampColumn\", false, new TimestampArray.Builder().AppendRange(Enumerable.Repeat(DateTimeOffset.Now, 10)).Build())\r\n    .Build();\r\n\r\nvar df = DataFrame.FromArrowRecordBatch(batch);\r\n\r\nvar newBatch = df.ToArrowRecordBatches();\r\n\r\nConsole.WriteLine($\"Original datatype: {batch.Schema.GetFieldByIndex(0).DataType}\");\r\nConsole.WriteLine($\"Final datatype: {newBatch.First().Schema.GetFieldByIndex(0).DataType}\");\r\n```\r\n\r\n```\r\n> dotnet run\r\nOriginal datatype: Apache.Arrow.Types.TimestampType\r\nFinal datatype: Apache.Arrow.Types.Date64Type\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7260","RelatedDescription":"Open issue \"Decode and roundtrip Timestamp fields from Arrow into DataFrame.\" (#7260)"},{"Id":"2568746330","IsPullRequest":false,"CreatedAt":"2024-10-06T16:33:38","Actor":"superichmann","Number":"7259","RawContent":null,"Title":"sending no seed to mlcontext does not actually randomize stuff","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: windows 10\r\n - ML.NET Version: 4.0.0-preview.24271.1\r\n - .NET Version: 8.0.8\r\n\r\n**Describe the bug**\r\ninitializing mlcontext without any seed (`new MLContext()`) and training on the same data does not actually results in different models created by `Regression.Trainers.FastForest()` or `Regression.Trainers.LightGbm()`.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. initialize mlcontext without a seed.\r\n2. create a model on data with FastForest.\r\n3. initialize a different mlcontext without a seed.\r\n4. create a model on the same exact data with FastForest.\r\n5. Compare the predictions of both models (in my case, I compared 23645 predictions)\r\n\r\nrepeat the process with lgbm.\r\n\r\n**Expected behavior**\r\nAs I see it, first FastForest predictions should be different then the second FastForest predictions. same in lightgbm.\r\n\r\nEven the slightest change in randomness for the bootstrapped dataset selection should end up in different results.\r\n\r\nIt seems like the FastForest or LightGbm under ml.net are not so random.. :{\r\n\r\n**Further Research** **PLZ READ ME TOO**\r\nI played with LightGbm on python and I was able to introduce randomness into it with feat these params:\t\t`'feature_fraction': 0.2,'seed': rand_num`. removing one of them removes also the randomness in the results, see code:\r\n```\r\nimport lightgbm as lgb\r\nimport pandas as pd\r\nimport numpy as np\r\nnp.random.seed(42)\r\nnum_train_samples = 1000\r\nnum_test_samples = 10\r\nnum_features = 10\r\nX = np.random.rand(num_train_samples + num_test_samples, num_features)\r\ny = np.random.uniform(0, 2, num_train_samples + num_test_samples)\r\ny = y + np.random.normal(0, 0.2, num_train_samples + num_test_samples)\r\nX_train, X_test = X[:num_train_samples], X[num_train_samples:]\r\ny_train, y_test = y[:num_train_samples], y[num_train_samples:]\r\nparams1 = {\r\n    'objective': 'regression',\r\n    'verbose': -1,\r\n    'feature_fraction': 0.2,\r\n    'seed': 42\r\n}\r\nparams2 = {\r\n    'objective': 'regression',\r\n    'verbose': -1,\r\n    'feature_fraction': 0.2,\r\n    'seed': 43\r\n}\r\nmodel1 = lgb.train(params1, lgb.Dataset(X_train, y_train), num_boost_round=1000)  # Increase boosting rounds\r\nmodel2 = lgb.train(params2, lgb.Dataset(X_train, y_train), num_boost_round=1000)\r\ny_pred1 = model1.predict(X_test)\r\ny_pred2 = model2.predict(X_test)\r\nresults = pd.DataFrame({'true_value': y_test, 'model1_pred': y_pred1, 'model2_pred': y_pred2})\r\nprint(results)\r\n\r\n```\r\n**WorkArounds**\r\nA workaround for lightgbm would be to add `FeatureFraction` into the params.\r\nsending `Seed` as a part of `FastForestRegressionTrainer.Options` is a workaround for FastForest.","Url":"https://github.com/dotnet/machinelearning/issues/7259","RelatedDescription":"Open issue \"sending no seed to mlcontext does not actually randomize stuff\" (#7259)"},{"Id":"2568599425","IsPullRequest":false,"CreatedAt":"2024-10-06T11:01:48","Actor":"superichmann","Number":"7258","RawContent":null,"Title":"expose LearningRate","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nno\r\n\r\n**Describe the solution you'd like**\r\nexpose LearningRate on TreeOptions and FastForestRegressionTrainer.Options\r\n\r\n**Describe alternatives you've considered**\r\nmove to python\r\n\r\n**Additional context**\r\nmaybe expose all params of lgbm and ff plz?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7258","RelatedDescription":"Open issue \"expose LearningRate\" (#7258)"},{"Id":"2551465408","IsPullRequest":true,"CreatedAt":"2024-10-06T07:16:37","Actor":"LittleLittleCloud","Number":"7245","RawContent":null,"Title":"[GenAI] Support Llama 3.2 1B and 3B model","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n#7169 ","Url":"https://github.com/dotnet/machinelearning/pull/7245","RelatedDescription":"Closed or merged PR \"[GenAI] Support Llama 3.2 1B and 3B model\" (#7245)"},{"Id":"2568178701","IsPullRequest":false,"CreatedAt":"2024-10-05T15:18:29","Actor":"mehdihadeli","Number":"7257","RawContent":null,"Title":"How To use Phi-3.5-mini tokenizer","State":"open","Body":"Hi,\r\nHow can I create a tokenizer based on [microsoft/Phi-3.5-mini-instruct](https://huggingface.co/microsoft/Phi-3.5-mini-instruct) model?\r\nShould I load [tokenzier.model](https://huggingface.co/microsoft/Phi-3.5-mini-instruct/blob/main/tokenizer.model)?\r\n\r\nI saw similar approach for llama in the [documentation](https://learn.microsoft.com/en-us/dotnet/machine-learning/whats-new/overview#additional-tokenizer-support):\r\n\r\n``` csharp\r\n// Create the Tokenizer.\r\nstring modelUrl = @\"https://huggingface.co/hf-internal-testing/llama-llamaTokenizer/resolve/main/llamaTokenizer.model\";\r\nusing Stream remoteStream = File.OpenRead(modelUrl);\r\nTokenizer llamaTokenizer = Tokenizer.CreateLlama(remoteStream);\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/7257","RelatedDescription":"Open issue \"How To use Phi-3.5-mini tokenizer\" (#7257)"},{"Id":"2565205062","IsPullRequest":false,"CreatedAt":"2024-10-04T22:05:20","Actor":"ericstj","Number":"7256","RawContent":null,"Title":"Microsoft.ML.Tokenizers.Tests.TiktokenTests.TestTokenizerUsingExternalVocab failing to download gpt2.tiktoken","State":"closed","Body":"### Build\n\nhttps://dev.azure.com/dnceng-public/public/_build/results?buildId=823668\n\n### Build leg reported\n\nMicrosoft.ML.Tokenizers.Tests.TiktokenTests.TestTokenizerUsingExternalVocab\n\n### Pull Request\n\nhttps://github.com/dotnet/machinelearning/pull/7252\n\n### Known issue core information\n\nFill out the known issue JSON section by following the [step by step documentation on how to create a known issue](https://github.com/dotnet/arcade/blob/main/Documentation/Projects/Build%20Analysis/KnownIssueJsonStepByStep.md#how-to-create-a-known-issue-step-by-step)\r\n\r\n```json\r\n {\r\n    \"ErrorMessage\" : [\"Microsoft.ML.Tokenizers.Tests.TiktokenTests.TestTokenizerUsingExternalVocab\", \"File not found\"],\r\n    \"BuildRetry\": false,\r\n    \"ErrorPattern\": \"\",\r\n    \"ExcludeConsoleLog\": false\r\n }\r\n ```\r\n\r\n @dotnet/dnceng\r\n\r\n<!-- DO NOT DELETE -->\r\n<!-- For internal use only; put release notes here. -->\r\n<!-- For guidance on writing good release notes, please see documentation here: https://dev.azure.com/dnceng/internal/_wiki/wikis/DNCEng%20Services%20Wiki/983/ReleaseNotesGuidance -->\r\n<!-- Additionally, please specify the note category below. -->\r\n### Release Note Category\r\n- [ ] Feature changes/additions \r\n- [ ] Bug fixes\r\n- [x] Internal Infrastructure Improvements\r\n### Release Note Description\r\n\n\n### Additional information about the issue reported\n\nIt looks to me like this file no longer exists:\r\nhttps://github.com/dotnet/machinelearning/blob/be1e428d41b5936903172855f7f30861ca7eb49a/test/Microsoft.ML.Tokenizers.Tests/TitokenTests.cs#L100C136-L100C149\r\n<!-- Known issue validation start -->\r\n ### Known issue validation\r\n**Build: :mag_right:** https://dev.azure.com/dnceng-public/public/_build/results?buildId=823668\r\n**Error message validated:** `[Microsoft.ML.Tokenizers.Tests.TiktokenTests.TestTokenizerUsingExternalVocab File not found`]\r\n**Result validation:** :white_check_mark: Known issue matched with the provided build.\r\n**Validation performed at:** 10/4/2024 12:37:23 AM UTC\r\n<!-- Known issue validation end -->\r\n<!--Known issue error report start -->\r\n\r\n### Report\r\n\r\n|Build|Definition|Test|Pull Request|\r\n|---|---|---|---|\r\n|[823668](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823668)|dotnet/machinelearning|[Microsoft.ML.Tokenizers.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823668&view=ms.vss-test-web.build-test-results-tab&runId=21398774&resultId=101001)|dotnet/machinelearning#7252|\r\n#### Summary\r\n|24-Hour Hit Count|7-Day Hit Count|1-Month Count|\r\n|---|---|---|\r\n|0|1|1|\r\n<!--Known issue error report end -->","Url":"https://github.com/dotnet/machinelearning/issues/7256","RelatedDescription":"Closed issue \"Microsoft.ML.Tokenizers.Tests.TiktokenTests.TestTokenizerUsingExternalVocab failing to download gpt2.tiktoken\" (#7256)"},{"Id":"2553873915","IsPullRequest":true,"CreatedAt":"2024-10-04T21:47:38","Actor":"tarekgh","Number":"7248","RawContent":null,"Title":"Move the Tokenizer's data into separate packages.","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7248","RelatedDescription":"Closed or merged PR \"Move the Tokenizer's data into separate packages.\" (#7248)"},{"Id":"2553592883","IsPullRequest":true,"CreatedAt":"2024-10-01T17:38:15","Actor":"ericstj","Number":"7247","RawContent":null,"Title":"Enable SDL tools","State":"closed","Body":"I'll schedule an internal build to validate this.\r\n\r\nInternal build https://dev.azure.com/dnceng/internal/_build/results?buildId=2548168&view=results","Url":"https://github.com/dotnet/machinelearning/pull/7247","RelatedDescription":"Closed or merged PR \"Enable SDL tools\" (#7247)"},{"Id":"2559710818","IsPullRequest":true,"CreatedAt":"2024-10-01T17:37:34","Actor":"ericstj","Number":"7252","RawContent":null,"Title":"Add Service Tree ID for .NET Libraries","State":"closed","Body":"This uses the .NET Libraries Service Tree ID - https://microsoftservicetree.com/services/7a9b52f6-7805-416c-9390-343168c0cdb3, @artl93 - can you double check?\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7252","RelatedDescription":"Closed or merged PR \"Add Service Tree ID for .NET Libraries\" (#7252)"},{"Id":"2557281416","IsPullRequest":false,"CreatedAt":"2024-09-30T17:35:55","Actor":"tarekgh","Number":"7251","RawContent":null,"Title":"Microsoft.ML.TorchSharp.Tests.QATests.TestSimpleQA timeout failure","State":"open","Body":"## Build Information\r\nBuild: https://dev.azure.com/dnceng-public/cbb18261-c48f-4abb-8651-8cdcb5474649/_build/results?buildId=821016\r\nBuild error leg or test failing: Ubuntu_x64_Net60 / Ubuntu_x64_Net60 Debug_Build / Run Helix Tests\r\nPull request: https://github.com/dotnet/machinelearning/pull/7248\r\n<!-- Error message template  -->\r\n## Error Message\r\n\r\nFill the error message using [step by step known issues guidance](https://github.com/dotnet/arcade/blob/main/Documentation/Projects/Build%20Analysis/KnownIssueJsonStepByStep.md).\r\n\r\n<!-- Use ErrorMessage for String.Contains matches. Use ErrorPattern for regex matches (single line/no backtracking). Set BuildRetry to `true` to retry builds with this error. Set ExcludeConsoleLog to `true` to skip helix logs analysis. -->\r\n\r\n```json\r\n{\r\n  \"ErrorMessage\": [\"Starting test: Microsoft.ML.TorchSharp.Tests.QATests.TestSimpleQA\", \"Killed\"],\r\n  \"ErrorPattern\": \"\",\r\n  \"BuildRetry\": false,\r\n  \"ExcludeConsoleLog\": false\r\n}\r\n```\r\n\r\n\r\n<!-- Known issue validation start -->\r\n ### Known issue validation\r\n**Build: :mag_right:** https://dev.azure.com/dnceng-public/public/_build/results?buildId=821016\r\n**Error message validated:** `[Starting test: Microsoft.ML.TorchSharp.Tests.QATests.TestSimpleQA Killed`]\r\n**Result validation:** :white_check_mark: Known issue matched with the provided build.\r\n**Validation performed at:** 9/30/2024 7:52:41 PM UTC\r\n<!-- Known issue validation end -->\r\n<!--Known issue error report start -->\r\n\r\n### Report\r\n\r\n|Build|Definition|Test|Pull Request|\r\n|---|---|---|---|\r\n|[838723](https://dev.azure.com/dnceng-public/public/_build/results?buildId=838723)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=838723&view=ms.vss-test-web.build-test-results-tab&runId=21728416&resultId=102050)|dotnet/machinelearning#7264|\r\n|[835918](https://dev.azure.com/dnceng-public/public/_build/results?buildId=835918)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=835918&view=ms.vss-test-web.build-test-results-tab&runId=21675476&resultId=102049)||\r\n|[835868](https://dev.azure.com/dnceng-public/public/_build/results?buildId=835868)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=835868&view=ms.vss-test-web.build-test-results-tab&runId=21670734&resultId=102049)|dotnet/machinelearning#7264|\r\n|[830027](https://dev.azure.com/dnceng-public/public/_build/results?buildId=830027)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=830027&view=ms.vss-test-web.build-test-results-tab&runId=21590324&resultId=102047)||\r\n|[825226](https://dev.azure.com/dnceng-public/public/_build/results?buildId=825226)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=825226&view=ms.vss-test-web.build-test-results-tab&runId=21584976&resultId=102048)|dotnet/machinelearning#7254|\r\n|[823827](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823827)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823827&view=ms.vss-test-web.build-test-results-tab&runId=21400698&resultId=102047)|dotnet/machinelearning#7248|\r\n|[823750](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823750)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823750&view=ms.vss-test-web.build-test-results-tab&runId=21399800&resultId=102044)||\r\n|[823744](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823744)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=823744&view=ms.vss-test-web.build-test-results-tab&runId=21399794&resultId=102044)||\r\n|[822902](https://dev.azure.com/dnceng-public/public/_build/results?buildId=822902)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=822902&view=ms.vss-test-web.build-test-results-tab&runId=21373774&resultId=102047)|dotnet/machinelearning#7248|\r\n|[821016](https://dev.azure.com/dnceng-public/public/_build/results?buildId=821016)|dotnet/machinelearning|[Microsoft.ML.TorchSharp.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=821016&view=ms.vss-test-web.build-test-results-tab&runId=21310680&resultId=102047)|dotnet/machinelearning#7248|\r\n#### Summary\r\n|24-Hour Hit Count|7-Day Hit Count|1-Month Count|\r\n|---|---|---|\r\n|0|5|10|\r\n<!--Known issue error report end -->","Url":"https://github.com/dotnet/machinelearning/issues/7251","RelatedDescription":"Open issue \"Microsoft.ML.TorchSharp.Tests.QATests.TestSimpleQA timeout failure\" (#7251)"},{"Id":"2557133640","IsPullRequest":false,"CreatedAt":"2024-09-30T17:00:36","Actor":"tarekgh","Number":"7250","RawContent":null,"Title":"Microsoft.ML.TorchSharp.Tests takes long time to execute on Ubuntu and fail the CI run","State":"closed","Body":"## Build Information\r\nBuild: https://dev.azure.com/dnceng-public/cbb18261-c48f-4abb-8651-8cdcb5474649/_build/results?buildId=821016\r\nBuild error leg or test failing: Ubuntu_x64_Net60 / Ubuntu_x64_Net60 Debug_Build / Run Helix Tests\r\nPull request: https://github.com/dotnet/machinelearning/pull/7248\r\n<!-- Error message template  -->\r\n## Error Message\r\n\r\nFill the error message using [step by step known issues guidance](https://github.com/dotnet/arcade/blob/main/Documentation/Projects/Build%20Analysis/KnownIssueJsonStepByStep.md).\r\n\r\n<!-- Use ErrorMessage for String.Contains matches. Use ErrorPattern for regex matches (single line/no backtracking). Set BuildRetry to `true` to retry builds with this error. Set ExcludeConsoleLog to `true` to skip helix logs analysis. -->\r\n\r\n```json\r\n{\r\n  \"ErrorMessage\": \"Starting test: Microsoft.ML.TorchSharp.Tests.QATests.TestSimpleQA\",\r\n  \"BuildRetry\": false,\r\n  \"ExcludeConsoleLog\": false\r\n}\r\n```\r\n\r\n\r\n<!-- Known issue validation start -->\r\n ### Known issue validation\r\n**Build: :mag_right:** \r\n**Result validation:** :warning: Validation could not be done without an Azure DevOps build URL on the issue. Please add it to the \"**Build:** :mag_right:\" line.\r\n**Validation performed at:** 9/30/2024 4:58:22 PM UTC\r\n<!-- Known issue validation end -->\r\n<!--Known issue error report start -->\r\n\r\n### Report\r\n#### Summary\r\n|24-Hour Hit Count|7-Day Hit Count|1-Month Count|\r\n|---|---|---|\r\n|0|0|0|\r\n<!--Known issue error report end -->","Url":"https://github.com/dotnet/machinelearning/issues/7250","RelatedDescription":"Closed issue \"Microsoft.ML.TorchSharp.Tests takes long time to execute on Ubuntu and fail the CI run\" (#7250)"},{"Id":"2553951619","IsPullRequest":false,"CreatedAt":"2024-09-28T02:02:59","Actor":"YoungYuFlex","Number":"7249","RawContent":null,"Title":"Error inferring columns with AutoML in Blazor WASM","State":"open","Body":"I am trying to use AutoML in Blazor WASM and I am receiving this error message no matter what data source file I am using:\r\n`Unable to split the file provided into multiple, consistent columns. Readable formats include delimited files such as CSV/TSV. Check for a consistent number of columns and proper escaping and quoting.`\r\n\r\nI tried different csv/tsv files and same error everytime. I also tried basically same code and same data file running in a console application and it worked fine.\r\nAnd I also tried downloading the file after uploading it, and examined it in vscode, nothing seemed to be wrong, no issue for linebreaking...\r\n\r\nThis is my code and the error is popping when trying to infercolumns...\r\n```\r\npublic async Task LoadFiles(InputFileChangeEventArgs e)\r\n{\r\n    var file = e.File;\r\n    var fileName = file.Name;\r\n    \r\n    // Saving file\r\n    await using FileStream fs = new(fileName, FileMode.Create);\r\n    await file.OpenReadStream(1024*1024*1024).CopyToAsync(fs);\r\n    \r\n    // Initialize MLContext\r\n    MLContext ctx = new MLContext();\r\n\r\n    // Define data path\r\n    var dataPath = Path.GetFullPath(fileName);\r\n\r\n    // Infer column information\r\n    ColumnInferenceResults columnInference = ctx.Auto().InferColumns(\r\n        dataPath,\r\n        labelColumnIndex: 0,\r\n        hasHeader: true,\r\n        // separatorChar: ',',\r\n        groupColumns: false,\r\n        allowQuoting: true,\r\n        trimWhitespace: true\r\n    );\r\n}\r\n```\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7249","RelatedDescription":"Open issue \"Error inferring columns with AutoML in Blazor WASM\" (#7249)"},{"Id":"2553275147","IsPullRequest":true,"CreatedAt":"2024-09-27T20:10:31","Actor":"LittleLittleCloud","Number":"7246","RawContent":null,"Title":"[GenAI] pack GenAI core package","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n#7169 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/7246","RelatedDescription":"Closed or merged PR \"[GenAI] pack GenAI core package\" (#7246)"},{"Id":"2551002648","IsPullRequest":false,"CreatedAt":"2024-09-26T16:03:45","Actor":"rposener","Number":"7244","RawContent":null,"Title":"Timeseries SrCNN blocking use on ARM64","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI am developing on a new Surface device (ARM64 chipset) and I'm currently blocked by the lack of support of SrCnn support to use this for anomaly detection in data.\r\n\r\n**Describe the solution you'd like**\r\nI'd love to see this included and added for ARM64 support in version 4.\r\n\r\n**Describe alternatives you've considered**\r\nIf there is a major impediment here, I'd love your recommendations.  I am looking at other statistical analysis as a work-around for my specific use-case.\r\n\r\n**Additional context**\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7244","RelatedDescription":"Open issue \"Timeseries SrCNN blocking use on ARM64\" (#7244)"},{"Id":"2544095428","IsPullRequest":false,"CreatedAt":"2024-09-24T01:56:31","Actor":"chuongmep","Number":"7243","RawContent":null,"Title":"How to Group By with multiple columns? ","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI want can use `GroupBy `with list input column for dataframe\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\nIt could be good like this and allow return with new dataframe \r\n```\r\nvar groupBy = df.GroupBy(new string[] { \"Area\", \"Level\" });\r\n```\r\nOr  : \r\n```\r\ndf.GroupBy(\"Level\", \"Building Name\").Select(\"Source File\", \"Area\", \"Level\", \"Building Name\");\r\n```\r\nThis is python : \r\n```\r\ndf_report_grouped = df_report.groupby(['Building Name', 'Level'])['Area'].sum().reset_index()\r\n```\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7243","RelatedDescription":"Open issue \"How to Group By with multiple columns? \" (#7243)"},{"Id":"2537154328","IsPullRequest":false,"CreatedAt":"2024-09-19T19:01:31","Actor":"luisquintanilla","Number":"7241","RawContent":null,"Title":"Update Microsoft.ML.Tokenizers - o1 models","State":"open","Body":"Add o1 as a tokenizer option in Microsoft.ML.Tokenizers","Url":"https://github.com/dotnet/machinelearning/issues/7241","RelatedDescription":"Open issue \"Update Microsoft.ML.Tokenizers - o1 models\" (#7241)"}],"ResultType":"GitHubIssue"}},"RunOn":"2024-10-14T03:30:21.7460918Z","RunDurationInMilliseconds":567}