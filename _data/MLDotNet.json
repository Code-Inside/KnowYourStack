{"Data":{"GitHub":{"Issues":[{"Id":"890300138","IsPullRequest":true,"CreatedAt":"2021-05-18T01:53:59","Actor":"mmitche","Number":"5794","RawContent":null,"Title":"Use dotnet certificate","State":"closed","Body":"https://github.com/dotnet/announcements/issues/184","Url":"https://github.com/dotnet/machinelearning/pull/5794","RelatedDescription":"Closed or merged PR \"Use dotnet certificate\" (#5794)"},{"Id":"893812017","IsPullRequest":true,"CreatedAt":"2021-05-18T00:11:39","Actor":"michaelgsharp","Number":"5800","RawContent":null,"Title":"Arm ci build","State":"open","Body":"Draft PR to make sure the yaml is correct.\r\n\r\nIs based off of the arm-build branch since that hasn't gone itno master yet. Will rebase on master when it is.","Url":"https://github.com/dotnet/machinelearning/pull/5800","RelatedDescription":"Open PR \"Arm ci build\" (#5800)"},{"Id":"893801555","IsPullRequest":false,"CreatedAt":"2021-05-17T23:45:17","Actor":"gabrielpintomoya","Number":"5799","RawContent":null,"Title":"Error: Model generated OK but when running the autogenerated project and trying to predict get error: Schema mismatch for input column '****': expected String or vector of String, got Single '","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 Enterprise\r\n- **.NET Version (eg., dotnet --info)**:\r\n- Microsoft Visual Studio Community 2019 (2)\r\nVersion 16.9.4\r\nVisualStudio.16.Release/16.9.4+31205.134\r\nMicrosoft .NET Framework\r\nVersion 4.8.03752\r\n\r\nInstalled Version: Community\r\n\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- I just created a simple model with ML.NET Model Builder (Value Prediction Scenario) and trained during an hour and the result was ok. Log below.\r\n- The data was on a table database when all the columns are float types and one of them (the table id) is integer\r\n- I added the autogenerated projects to my project to predict the results.\r\n\r\n- **What happened?\r\n- When executing the prediction code I got the error: \"Schema mismatch for input column 'media1NecFisiologica': expected String or vector of String, got Single (Parameter 'inputSchema') \r\nBut that column is a float type on the table and I send a float number to try to predict.\r\nI also tried to change teh data type to decimal just in case but I got the same error.\r\n- **What did you expect?**\r\n- A prediction Result as a float number\r\n\r\n### Source code / logs\r\n   Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\nSchema mismatch for input column 'media1NecFisiologica_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nNombre del parámetro: inputSchema\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8644          8.19       122.32    10.95      29.4          1      |\r\n|2    LightGbmRegression                    0.8366          9.04       154.20    12.23      20.7          2      |\r\n\r\n===============================================Experiment Results=================================================\r\n------------------------------------------------------------------------------------------------------------------\r\n|                                                     Summary                                                    |\r\n------------------------------------------------------------------------------------------------------------------\r\n|ML Task: regression                                                                                             |\r\n|Dataset: C:\\Users\\gpinto\\AppData\\Local\\Temp\\2e8ae3e9-3c87-412c-a3b0-71332ef45f9f.csv                            |\r\n|Label : CalidadPonderada                                                                                        |\r\n|Total experiment time : 50.0977468 Secs                                                                         |\r\n|Total number of models explored: 2                                                                              |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\n|                                              Top 2 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8644          8.19       122.32    10.95      29.4          1      |\r\n|2    LightGbmRegression                    0.8366          9.04       154.20    12.23      20.7          2      |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\nGenerate project\r\nGenerate project success\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8649          8.17       122.00    10.93      27.4          1      |\r\n|2    LightGbmRegression                    0.8366          9.04       154.20    12.23      20.3          2      |\r\n|3    FastTreeRegression                    0.8378          8.54       160.61    12.29      21.4          3      |\r\n|4    FastTreeTweedieRegression             0.8016          9.19       191.07    13.59      19.2          4      |\r\n|5    FastForestRegression                  0.8159          9.95       175.07    13.13      17.4          5      |\r\n|6    LbfgsPoissonRegression                0.3303         13.75       598.25    20.13      53.0          6      |\r\n|7    OnlineGradientDescentRegression       0.2492         16.29       612.15    23.24      22.0          7      |\r\nCannot hold covariance matrix in memory with 65733 features\r\n|8    SdcaRegression                        0.7367         13.05       248.91    15.65      22.7          8      |\r\n|9    LightGbmRegression                    0.8154         10.39       175.24    13.15      17.5          9      |\r\n|10   FastTreeRegression                    0.5838         16.61       375.80    19.28      51.2         10      |\r\n|11   SdcaRegression                        0.7968          9.96       183.06    13.33      22.1         11      |\r\n|12   LightGbmRegression                    0.8262         10.11       165.66    12.76      20.6         12      |\r\n|13   FastTreeRegression                    0.7938         11.63       192.44    13.82      15.7         13      |\r\n|14   SdcaRegression                        0.8496          8.59       135.00    11.47      21.1         14      |\r\n|15   LightGbmRegression                    0.8119         10.60       178.37    13.28      21.0         15      |\r\n|16   FastTreeRegression                    0.0219         25.61       850.75    29.03      16.4         16      |\r\n|17   SdcaRegression                        0.8482          8.72       135.13    11.56      21.1         17      |\r\n|18   LightGbmRegression                    0.7535         12.95       238.81    15.33      15.7         18      |\r\n|19   FastTreeRegression                   -3.6652         56.45      4047.48    63.38      15.6         19      |\r\n|20   SdcaRegression                        0.8055          9.66       171.63    12.98      22.6         20      |\r\n|21   LightGbmRegression                    0.8422          8.75       149.74    12.08      21.7         21      |\r\n|22   FastTreeRegression                    0.8462          8.13       152.09    11.90      33.9         22      |\r\n|23   SdcaRegression                        0.8592          8.47       127.37    11.20      26.9         23      |\r\n|24   LightGbmRegression                    0.8270          9.01       168.11    12.71      20.1         24      |\r\n|25   FastTreeRegression                    0.8506          8.35       148.39    11.73      28.2         25      |\r\n|26   SdcaRegression                        0.8310          9.45       154.09    12.25      21.2         26      |\r\n|27   LightGbmRegression                    0.8544          7.46       142.96    11.60      20.0         27      |\r\n|28   FastTreeRegression                   -1.7848         43.73      2415.22    48.94      15.4         28      |\r\n|29   SdcaRegression                        0.7438         13.04       243.60    15.41      21.6         29      |\r\n|30   LightGbmRegression                    0.8409          9.48       155.66    12.24      21.5         30      |\r\n|31   FastTreeRegression                    0.8446          8.22       153.39    11.97      36.1         31      |\r\n|32   SdcaRegression                        0.8195          9.71       161.68    12.61      21.4         32      |\r\n|33   LightGbmRegression                    0.7946         11.45       203.38    13.98      16.2         33      |\r\n|34   FastTreeRegression                    0.6575         16.04       305.92    17.44      14.6         34      |\r\n|35   SdcaRegression                        0.8412          9.20       143.37    11.89      20.7         35      |\r\n|36   LightGbmRegression                    0.8489          8.15       150.42    11.84      19.6         36      |\r\n|37   FastTreeRegression                   -4.1673         59.36      4483.62    66.70      15.4         37      |\r\n|38   SdcaRegression                        0.8599          8.34       126.30    11.13      24.4         38      |\r\n|39   LightGbmRegression                    0.7515         11.71       237.52    15.20      18.6         39      |\r\n|40   FastTreeRegression                    0.8180         10.14       177.66    13.04      17.8         40      |\r\n|41   SdcaRegression                        0.7195         13.71       270.08    16.14      21.7         41      |\r\n|42   LightGbmRegression                    0.8040          7.87       194.70    13.60      24.0         42      |\r\n|43   FastTreeRegression                   -0.0586         26.38       918.63    30.15      14.5         43      |\r\n|44   SdcaRegression                        0.8096         10.83       181.32    13.29      22.5         44      |\r\n|45   LightGbmRegression                    0.7863         11.91       208.06    14.25      21.1         45      |\r\n|46   FastTreeRegression                    0.8305          9.80       159.89    12.58      15.9         46      |\r\n|47   SdcaRegression                        0.8306          9.59       154.23    12.35      21.2         47      |\r\n|48   LightGbmRegression                    0.8057         10.65       184.69    13.51      21.9         48      |\r\n|49   FastTreeRegression                    0.8488          8.95       143.53    11.86      20.2         49      |\r\n|50   SdcaRegression                        0.8347          9.06       147.54    11.96      21.0         50      |\r\n|51   LightGbmRegression                    0.4163         20.35       577.32    23.71      21.0         51      |\r\n|52   FastTreeRegression                   -1.2516         38.80      1945.22    43.86      15.3         52      |\r\n|53   SdcaRegression                        0.8604          8.33       126.01    11.16      20.3         53      |\r\n|54   LightGbmRegression                    0.8188         10.26       171.36    13.02      20.6         54      |\r\n|55   FastTreeRegression                    0.7286          7.88       261.53    15.65      45.4         55      |\r\n|56   SdcaRegression                        0.7625         12.49       226.69    14.85      22.2         56      |\r\n|57   LightGbmRegression                    0.7910          9.93       194.88    13.83      19.1         57      |\r\n|58   FastTreeRegression                    0.8491          8.10       149.01    11.76      35.1         58      |\r\n|59   SdcaRegression                        0.7264         13.23       260.96    15.99      21.5         59      |\r\n|60   LightGbmRegression                    0.8215          9.93       171.02    12.94      17.0         60      |\r\n|61   FastTreeRegression                    0.8131         10.63       177.74    13.25      16.2         61      |\r\n|62   SdcaRegression                        0.8629          8.28       122.69    10.98      52.6         62      |\r\n|63   LightGbmRegression                    0.4212         19.47       561.64    23.50      16.1         63      |\r\n|64   FastTreeRegression                    0.8470          8.27       151.18    11.82      35.3         64      |\r\n|65   SdcaRegression                        0.6730         14.86       316.97    17.49      27.5         65      |\r\n|66   LightGbmRegression                    0.7195         14.07       271.88    16.28      17.0         66      |\r\n|67   FastTreeRegression                    0.8560          7.88       141.30    11.54      36.4         67      |\r\n|68   SdcaRegression                        0.8630          8.20       123.73    11.03      23.8         68      |\r\n|69   LightGbmRegression                    0.8298          9.86       163.01    12.62      25.0         69      |\r\n|70   FastTreeRegression                    0.8457          8.81       148.58    11.96      21.8         70      |\r\n|71   SdcaRegression                        0.8544          8.47       131.17    11.33      98.6         71      |\r\n|72   LightGbmRegression                    0.8233         10.21       168.45    12.87      24.9         72      |\r\n|73   FastTreeRegression                   -0.4108         31.03      1224.41    34.83      23.7         73      |\r\n|74   SdcaRegression                        0.7617         12.58       226.44    14.82     101.5         74      |\r\n|75   LightGbmRegression                    0.8394          8.33       158.66    12.12      23.4         75      |\r\n|76   FastTreeRegression                    0.8528          8.22       144.35    11.59      33.0         76      |\r\n|77   SdcaRegression                        0.8581          8.48       128.07    11.24      58.4         77      |\r\n|78   LightGbmRegression                    0.8222         10.24       169.35    12.91      23.5         78      |\r\n|79   FastTreeRegression                   -0.0267         26.43       890.02    29.67      20.5         79      |\r\n|80   SdcaRegression                        0.8384          8.93       146.73    11.98      23.9         80      |\r\n|81   LightGbmRegression                    0.8473          8.16       153.38    11.88      26.7         81      |\r\n|82   FastTreeRegression                    0.7375         13.90       236.99    15.36      21.0         82      |\r\n|83   SdcaRegression                        0.8397          9.17       145.19    11.97      23.9         83      |\r\n|84   LightGbmRegression                    0.8431          8.41       154.81    12.06      22.8         84      |\r\n|85   FastTreeRegression                    0.8429          8.40       154.52    12.03      35.4         85      |\r\n|86   SdcaRegression                        0.8624          8.22       124.33    11.04      33.6         86      |\r\n|87   LightGbmRegression                    0.8398          8.90       152.70    12.19      24.2         87      |\r\n|88   FastTreeRegression                    0.8567          8.13       140.06    11.49      34.2         88      |\r\n|89   SdcaRegression                        0.8448          8.71       138.68    11.63     112.1         89      |\r\n|90   LightGbmRegression                    0.8418          8.79       149.93    12.01      21.9         90      |\r\n|91   FastTreeRegression                    0.8049         11.31       181.68    13.34      23.2         91      |\r\n|92   SdcaRegression                        0.8623          8.22       124.47    11.05      33.8         92      |\r\n|93   LightGbmRegression                    0.8340          9.47       164.02    12.49      19.1         93      |\r\n|94   FastTreeRegression                    0.6797         14.68       287.86    16.85      25.8         94      |\r\n|95   SdcaRegression                        0.8434          8.65       139.24    11.66     101.3         95      |\r\n|96   LightGbmRegression                    0.8458          8.35       152.16    11.93      23.0         96      |\r\n|97   FastTreeRegression                    0.8060         10.84       182.93    13.46      23.0         97      |\r\n|98   SdcaRegression                        0.8582          8.34       127.60    11.22     109.6         98      |\r\n|99   LightGbmRegression                    0.8449          8.40       151.56    11.99      23.2         99      |\r\n|100  FastTreeRegression                    0.8077         10.69       184.33    13.48      24.0        100      |\r\n|101  SdcaRegression                        0.8554          8.55       130.77    11.33     117.3        101      |\r\n|102  LightGbmRegression                    0.8467          7.62       150.63    11.87      23.4        102      |\r\n|103  FastTreeRegression                    0.7937         11.69       192.58    13.83      24.3        103      |\r\n|104  SdcaRegression                        0.8659          8.20       121.59    10.92     111.4        104      |\r\n|105  LightGbmRegression                    0.8384          8.52       158.83    12.21      23.4        105      |\r\n|106  FastTreeRegression                    0.4617         18.82       472.77    21.63      24.2        106      |\r\n|107  SdcaRegression                        0.6918         14.24       298.76    16.97      25.7        107      |\r\n|108  LightGbmRegression                    0.8568          8.61       137.19    11.56      22.5        108      |\r\n|109  FastTreeRegression                   -1.9868         45.26      2588.66    50.67      23.2        109      |\r\n|110  SdcaRegression                        0.8622          8.23       124.59    11.09     122.0        110      |\r\n|111  LightGbmRegression                    0.8462          8.27       151.88    11.95      24.9        111      |\r\n|112  FastTreeRegression                    0.4989         18.19       442.34    20.95      31.6        112      |\r\n|113  SdcaRegression                        0.8611          8.31       126.04    11.13     127.2        113      |\r\n|114  LightGbmRegression                    0.8462          8.27       151.88    11.95      26.0        114      |\r\n|115  FastTreeRegression                    0.7928         11.63       193.49    13.86      27.5        115      |\r\n\r\n===============================================Experiment Results=================================================\r\n------------------------------------------------------------------------------------------------------------------\r\n|                                                     Summary                                                    |\r\n------------------------------------------------------------------------------------------------------------------\r\n|ML Task: regression                                                                                             |\r\n|Dataset: C:\\Users\\gpinto\\AppData\\Local\\Temp\\2e8ae3e9-3c87-412c-a3b0-71332ef45f9f.csv                            |\r\n|Label : CalidadPonderada                                                                                        |\r\n|Total experiment time : 3568.9233011 Secs                                                                       |\r\n|Total number of models explored: 116                                                                            |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\n|                                              Top 5 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8659          8.20       121.59    10.92     111.4          1      |\r\n|2    SdcaRegression                        0.8649          8.17       122.00    10.93      27.4          2      |\r\n|3    SdcaRegression                        0.8630          8.20       123.73    11.03      23.8          3      |\r\n|4    SdcaRegression                        0.8629          8.28       122.69    10.98      52.6          4      |\r\n|5    SdcaRegression                        0.8624          8.22       124.33    11.04      33.6          5      |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\nGenerate project\r\nGenerate project success\r\nPredicted value: CalidadPonderada:\r\nAdd MLPrediccionesML.Model\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8654          8.17       121.62    10.92      27.5          1      |\r\n|2    LightGbmRegression                    0.8424          8.80       152.70    12.10      20.8          2      |\r\n\r\n===============================================Experiment Results=================================================\r\n------------------------------------------------------------------------------------------------------------------\r\n|                                                     Summary                                                    |\r\n------------------------------------------------------------------------------------------------------------------\r\n|ML Task: regression                                                                                             |\r\n|Dataset: C:\\Users\\gpinto\\AppData\\Local\\Temp\\2e8ae3e9-3c87-412c-a3b0-71332ef45f9f.csv                            |\r\n|Label : CalidadPonderada                                                                                        |\r\n|Total experiment time : 48.3019823 Secs                                                                         |\r\n|Total number of models explored: 2                                                                              |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\n|                                              Top 2 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8654          8.17       121.62    10.92      27.5          1      |\r\n|2    LightGbmRegression                    0.8424          8.80       152.70    12.10      20.8          2      |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\nGenerate project\r\nGenerate project success\r\nPredicted value: CalidadPonderada:\r\nAdd MLPrediccionesML.Model\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    SdcaRegression                        0.8657          8.19       121.55    10.92      28.4          1      |\r\n|2    LightGbmRegression                    0.8424          8.80       152.70    12.10      20.5          2      |\r\n|3    FastTreeRegression                    0.8406          8.53       158.32    12.17      23.7          3      |\r\n|4    FastTreeTweedieRegression             0.7943          9.33       194.43    13.71      23.1          4      |\r\n|5    FastForestRegression                  0.8204          9.82       170.09    12.95      19.3          5      |\r\n|6    LbfgsPoissonRegression                0.3929         13.55       541.52    19.63      56.5          6      |\r\n|7    OnlineGradientDescentRegression       0.6245         14.53       366.25    18.59      20.9          7      |\r\nCannot hold covariance matrix in memory with 65728 features\r\n|8    SdcaRegression                        0.8130         10.41       175.87    13.15      21.6          8      |\r\n|9    LightGbmRegression                    0.3359         21.23       655.47    25.29      14.9          9      |\r\n|10   FastTreeRegression                    0.8598          8.35       135.75    11.37      21.1         10      |\r\n|11   SdcaRegression                        0.8645          8.18       122.38    10.96      24.7         11      |\r\n|12   LightGbmRegression                    0.8438          8.40       154.78    12.02      20.8         12      |\r\n|13   FastTreeRegression                    0.8238         10.40       166.86    12.81      14.5         13      |\r\n|14   SdcaRegression                        0.8374          8.91       146.05    11.99      23.0         14      |\r\n|15   LightGbmRegression                    0.8386          8.56       158.45    12.27      21.1         15      |\r\n|16   FastTreeRegression                    0.7276         14.33       246.36    15.66      14.0         16      |\r\n|17   SdcaRegression                        0.8326          9.32       151.02    12.17      22.1         17      |\r\n|18   LightGbmRegression                    0.8576          7.98       141.91    11.56      15.9         18      |\r\n|19   FastTreeRegression                   -1.0589         37.95      1793.42    42.20      62.3         19      |\r\n|20   SdcaRegression                        0.7278         13.29       259.13    15.96      21.5         20      |\r\n|21   LightGbmRegression                    0.6624         15.28       333.03    18.02      21.0         21      |\r\n|22   FastTreeRegression                    0.8049         10.96       183.21    13.47      15.5         22      |\r\n|23   SdcaRegression                        0.7572         12.56       230.25    15.01      21.3         23      |\r\n|24   LightGbmRegression                    0.8392          9.41       152.71    12.26      16.1         24      |\r\n|25   FastTreeRegression                    0.8496          8.66       141.60    11.71      16.3         25      |\r\n|26   SdcaRegression                        0.5985         16.56       393.07    19.46      21.8         26      |\r\n|27   LightGbmRegression                    0.8332          7.94       162.23    12.45      18.8         27      |\r\n|28   FastTreeRegression                    0.8201         10.40       168.06    12.92      15.2         28      |\r\n|29   SdcaRegression                        0.8191          9.76       162.81    12.66      22.5         29      |\r\n|30   LightGbmRegression                    0.4528         18.93       530.97    22.85      18.8         30      |\r\n|31   FastTreeRegression                   -3.5904         56.10      3984.62    62.89      22.3         31      |\r\n|32   SdcaRegression                        0.8536          8.79       132.83    11.46      27.2         32      |\r\n|33   LightGbmRegression                    0.8342          7.79       163.78    12.49      15.4         33      |\r\n|34   FastTreeRegression                    0.7708         12.66       216.31    14.65      14.5         34      |\r\n|35   SdcaRegression                        0.8560          8.45       129.82    11.26      85.5         35      |\r\n|36   LightGbmRegression                    0.8224         10.20       168.72    12.89      15.7         36      |\r\n|37   FastTreeRegression                    0.4014         20.18       523.34    22.76      16.2         37      |\r\n|38   SdcaRegression                        0.8014         10.04       181.29    13.34      21.4         38      |\r\n|39   LightGbmRegression                    0.7977         11.09       192.76    13.80      21.9         39      |\r\n|40   FastTreeRegression                    0.8512          8.16       146.85    11.70      31.3         40      |\r\n|41   SdcaRegression                        0.8529          8.73       132.37    11.38      20.8         41      |\r\n|42   LightGbmRegression                    0.8339          8.58       160.84    12.33      23.8         42      |\r\n|43   FastTreeRegression                   -0.3284         29.61      1149.46    33.71      15.5         43      |\r\n|44   SdcaRegression                        0.8653          8.20       122.05    10.94      91.9         44      |\r\n|45   LightGbmRegression                    0.8278          9.90       165.14    12.69      21.5         45      |\r\n|46   FastTreeRegression                   -0.5789         33.09      1365.82    36.77      16.0         46      |\r\n|47   SdcaRegression                        0.8509          8.62       133.01    11.44      21.4         47      |\r\n|48   LightGbmRegression                    0.8508          8.92       142.48    11.82      21.7         48      |\r\n|49   FastTreeRegression                    0.5245         17.57       430.75    20.64      72.5         49      |\r\n|50   SdcaRegression                        0.7459         12.86       240.54    15.41      21.4         50      |\r\n|51   LightGbmRegression                    0.8186          9.97       172.66    13.03      16.4         51      |\r\n|52   FastTreeRegression                    0.8420          8.52       154.16    12.00      19.4         52      |\r\n|53   SdcaRegression                        0.8518          8.59       135.56    11.52      93.2         53      |\r\n|54   LightGbmRegression                    0.8309          9.81       161.99    12.59      23.5         54      |\r\n|55   FastTreeRegression                    0.8659          8.41       129.43    11.21      23.3         55      |\r\n|56   SdcaRegression                        0.6953         13.98       292.84    16.93      22.1         56      |\r\n|57   LightGbmRegression                    0.8560          7.81       138.62    11.45      23.2         57      |\r\n|58   FastTreeRegression                    0.8306          9.83       163.37    12.51      32.4         58      |\r\n|59   SdcaRegression                        0.8547          8.48       130.94    11.36      21.7         59      |\r\n|60   LightGbmRegression                    0.8421          8.34       155.53    12.10      21.6         60      |\r\n|61   FastTreeRegression                    0.7990          9.35       194.04    13.52      39.1         61      |\r\n|62   SdcaRegression                        0.8508          8.96       136.62    11.56      25.5         62      |\r\n|63   LightGbmRegression                    0.8465          8.19       151.69    11.93      18.7         63      |\r\n|64   FastTreeRegression                    0.8056          8.70       189.36    13.19      44.8         64      |\r\n|65   SdcaRegression                        0.8003         11.08       191.60    13.63      24.9         65      |\r\n|66   LightGbmRegression                    0.7686         11.27       218.52    14.63      19.0         66      |\r\n|67   FastTreeRegression                    0.6368         16.47       322.67    17.90      20.3         67      |\r\n|68   SdcaRegression                        0.8648          8.16       122.19    10.94      28.7         68      |\r\n|69   LightGbmRegression                    0.7520         12.92       244.59    15.39      23.7         69      |\r\n|70   FastTreeRegression                    0.8460          8.45       150.92    11.91      25.7         70      |\r\n|71   SdcaRegression                        0.7625         12.71       226.12    14.84     108.8         71      |\r\n|72   LightGbmRegression                    0.8510          7.89       145.77    11.77      27.2         72      |\r\n|73   FastTreeRegression                    0.7851         12.15       199.38    14.08      23.1         73      |\r\n|74   SdcaRegression                        0.8539          8.57       131.62    11.32      80.4         74      |\r\n|75   LightGbmRegression                    0.8629          7.96       134.22    11.27      25.8         75      |\r\n|76   FastTreeRegression                    0.8616          7.97       135.40    11.20      34.0         76      |\r\n|77   SdcaRegression                        0.8627          8.24       123.28    11.00      51.4         77      |\r\n|78   LightGbmRegression                    0.8494          7.90       147.52    11.80      28.9         78      |\r\n|79   FastTreeRegression                    0.7255         13.74       247.15    15.61      22.4         79      |\r\n|80   SdcaRegression                        0.8646          8.18       122.33    10.95      32.6         80      |\r\n|81   LightGbmRegression                    0.4039         20.09       588.45    23.96      24.9         81      |\r\n|82   FastTreeRegression                    0.8590          8.45       136.41    11.45      25.2         82      |\r\n|83   SdcaRegression                        0.8500          8.49       132.32    11.38      26.9         83      |\r\n|84   LightGbmRegression                    0.8605          7.80       135.97    11.36      30.5         84      |\r\n|85   FastTreeRegression                    0.8541          9.00       140.38    11.68      24.5         85      |\r\n|86   SdcaRegression                        0.8584          8.46       127.47    11.21      53.1         86      |\r\n|87   LightGbmRegression                    0.8631          8.12       130.82    11.26      28.9         87      |\r\n|88   FastTreeRegression                    0.8506          8.19       148.28    11.72      48.3         88      |\r\n|89   SdcaRegression                        0.8596          8.34       125.62    11.09      52.2         89      |\r\n|90   LightGbmRegression                    0.7767         10.93       220.97    14.56      24.1         90      |\r\n|91   FastTreeRegression                    0.1890         23.36       703.88    26.38      24.3         91      |\r\n|92   SdcaRegression                        0.8594          8.39       127.46    11.20      86.8         92      |\r\n|93   LightGbmRegression                    0.8446          8.94       147.69    11.98      28.4         93      |\r\n|94   FastTreeRegression                    0.8496          8.21       149.27    11.74      48.7         94      |\r\n|95   SdcaRegression                        0.7845         11.62       210.47    14.22      26.9         95      |\r\n|96   LightGbmRegression                    0.8640          8.03       131.09    11.22      28.0         96      |\r\n|97   FastTreeRegression                    0.8552          8.77       136.86    11.62      27.3         97      |\r\n|98   SdcaRegression                        0.8603          8.37       126.63    11.16     119.4         98      |\r\n|99   LightGbmRegression                    0.8607          8.09       133.75    11.38      25.6         99      |\r\n|100  FastTreeRegression                    0.8426          9.33       148.04    12.06      27.3        100      |\r\n|101  SdcaRegression                        0.8255          8.94       152.83    12.14      27.1        101      |\r\n|102  LightGbmRegression                    0.8610          8.07       133.57    11.36      30.7        102      |\r\n|103  FastTreeRegression                    0.8663          8.34       128.64    11.19      34.3        103      |\r\n|104  SdcaRegression                        0.8544          8.52       131.17    11.38      29.9        104      |\r\n|105  LightGbmRegression                    0.8564          7.96       140.21    11.55      28.3        105      |\r\n|106  FastTreeRegression                    0.8591          8.48       137.49    11.46      35.3        106      |\r\n|107  SdcaRegression                        0.8579          8.57       128.42    11.23     126.6        107      |\r\n|108  LightGbmRegression                    0.8655          7.95       129.26    11.14      22.9        108      |\r\n|109  FastTreeRegression                    0.8506          8.02       148.10    11.72      51.6        109      |\r\n|110  SdcaRegression                        0.8600          8.37       126.93    11.17     126.8        110      |\r\n\r\n===============================================Experiment Results=================================================\r\n------------------------------------------------------------------------------------------------------------------\r\n|                                                     Summary                                                    |\r\n------------------------------------------------------------------------------------------------------------------\r\n|ML Task: regression                                                                                             |\r\n|Dataset: C:\\Users\\gpinto\\AppData\\Local\\Temp\\2e8ae3e9-3c87-412c-a3b0-71332ef45f9f.csv                            |\r\n|Label : CalidadPonderada                                                                                        |\r\n|Total experiment time : 3579.5917172 Secs                                                                       |\r\n|Total number of models explored: 111                                                                            |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\n|                                              Top 5 models explored                                             |\r\n------------------------------------------------------------------------------------------------------------------\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration #Iteration      |\r\n|1    FastTreeRegression                    0.8663          8.34       128.64    11.19      34.3          1      |\r\n|2    FastTreeRegression                    0.8659          8.41       129.43    11.21      23.3          2      |\r\n|3    SdcaRegression                        0.8657          8.19       121.55    10.92      28.4          3      |\r\n|4    LightGbmRegression                    0.8655          7.95       129.26    11.14      22.9          4      |\r\n|5    SdcaRegression                        0.8653          8.20       122.05    10.94      91.9          5      |\r\n------------------------------------------------------------------------------------------------------------------\r\n\r\nGenerate project\r\nGenerate project success\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5799","RelatedDescription":"Open issue \"Error: Model generated OK but when running the autogenerated project and trying to predict get error: Schema mismatch for input column '****': expected String or vector of String, got Single '\" (#5799)"},{"Id":"875769252","IsPullRequest":true,"CreatedAt":"2021-05-17T20:54:54","Actor":"michaelgsharp","Number":"5783","RawContent":null,"Title":"Updated arcade to the latest version","State":"closed","Body":"Since we don't have it set up to automatically update arcade yet, this PR manually updates arcade to the latest version.","Url":"https://github.com/dotnet/machinelearning/pull/5783","RelatedDescription":"Closed or merged PR \"Updated arcade to the latest version\" (#5783)"},{"Id":"893506244","IsPullRequest":false,"CreatedAt":"2021-05-17T16:31:31","Actor":"michaelgsharp","Number":"5798","RawContent":null,"Title":"Add substitutes for 4 IntelMKL methods so SymSgd can be added to non x86/x64 builds","State":"open","Body":"Currently we have to exclude SymSgd from non x86/x64 builds due to the use of 4 IntelMKL methods. We need to substitute these for other methods so that we can include SymSgd in the non x86/x64 builds.","Url":"https://github.com/dotnet/machinelearning/issues/5798","RelatedDescription":"Open issue \"Add substitutes for 4 IntelMKL methods so SymSgd can be added to non x86/x64 builds\" (#5798)"},{"Id":"893252888","IsPullRequest":true,"CreatedAt":"2021-05-17T11:52:52","Actor":"darth-vader-lg","Number":"5797","RawContent":null,"Title":"Bug fix: Saving problem with TF2 SavedModel fmt in TensorflowTransform class.","State":"open","Body":"The SaveModel function of the TensorflowTransform class didn't save the TensorFlow saved_model directory in the zip repo. It was just done for frozen graphs but missing for the SavedModel format.\r\n\r\nI followed the schema that you used for the DnnRetrainTransform class to fix it:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/43c49f6ce4370cf91dcd7bf302d82f30d798420c/src/Microsoft.ML.Vision/DnnRetrainTransform.cs#L68-L75\r\nand https://github.com/dotnet/machinelearning/blob/43c49f6ce4370cf91dcd7bf302d82f30d798420c/src/Microsoft.ML.Vision/DnnRetrainTransform.cs#L701-L726.\r\n\r\nThe same part was not present in the TensorflowTransform class. Just the frozen graph saving:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/43c49f6ce4370cf91dcd7bf302d82f30d798420c/src/Microsoft.ML.TensorFlow/TensorflowTransform.cs#L425-L467.\r\n\r\nIt leads to an incomplete zip repo that cannot be reloaded after.\r\n\r\nAfter this fix the zip repo can be saved and loaded for inference.\r\n![Inference2](https://user-images.githubusercontent.com/9255497/118483542-6b29d800-b716-11eb-8634-9331c2d12756.png)\r\n[saved_model.pb.zip](https://github.com/dotnet/machinelearning/files/6493522/saved_model.pb.zip)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5797","RelatedDescription":"Open PR \"Bug fix: Saving problem with TF2 SavedModel fmt in TensorflowTransform class.\" (#5797)"},{"Id":"893233022","IsPullRequest":true,"CreatedAt":"2021-05-17T11:26:44","Actor":"darth-vader-lg","Number":"5796","RawContent":null,"Title":"Raising of the recursions limit for onnx model loading. (Issue #5585)","State":"open","Body":"Raised the limit of recursions (from 10 to 100) in the creation of the CodedInputStream in the OnnxTransformer (as the default value in the Google.Protobuf). Otherwise some models cannot be loaded (ex. TF2 Efficientdet).\r\n\r\nFixes #5585 \r\n\r\nI have already tested it on all TF2 ModelZoo models converted to onnx and on my custom object detection models. It's all right now. \r\n![Inference1](https://user-images.githubusercontent.com/9255497/118480375-711dba00-b712-11eb-8a71-3335de0fce7e.png)\r\n[saved_model.onnx.zip](https://github.com/dotnet/machinelearning/files/6493389/saved_model.onnx.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5796","RelatedDescription":"Open PR \"Raising of the recursions limit for onnx model loading. (Issue #5585)\" (#5796)"},{"Id":"891804855","IsPullRequest":false,"CreatedAt":"2021-05-14T10:22:32","Actor":"minhnguyen484","Number":"5795","RawContent":null,"Title":"Cannot retrain the model that it used LbfgsMaximumEntropy algorithms","State":"open","Body":"Hi Najeeb\r\nFollow you guide in the last tip, I created the function to retrain the model. I used LbfgsMaximumEntropy algorithms:\r\n\r\n// STEP 1: Common data loading configuration\r\n            var data = mlContext.Data.LoadFromEnumerable(modelList);\r\n\r\n            // STEP 2: Common data process configuration with pipeline data transformations\r\n            var dataPrepEstimator = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"Label\", inputColumnName: nameof(PredictModel.EngineerId))\r\n                    .Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName: \"JobTypeIdFeaturized\", inputColumnName: nameof(PredictModel.JobTypeId)))\r\n                    .Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName: \"CustomerIdFeaturized\", inputColumnName: nameof(PredictModel.CustomerId)))\r\n                    .Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName: \"CustomerTypeIdFeaturized\", inputColumnName: nameof(PredictModel.CustomerTypeId)))\r\n                    .Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName: \"SiteIdFeaturized\", inputColumnName: nameof(PredictModel.SiteId)))\r\n                    .Append(mlContext.Transforms.Text.FeaturizeText(outputColumnName: \"TenantIdFeaturized\", inputColumnName: nameof(PredictModel.TenantId)))\r\n                    .Append(mlContext.Transforms.Concatenate(outputColumnName: \"Features\", \"JobTypeIdFeaturized\", \"CustomerIdFeaturized\",\r\n                                                                                           \"CustomerTypeIdFeaturized\", \"SiteIdFeaturized\", \"TenantIdFeaturized\"));\r\n\r\n            var lbfgsTrainingPipeLine = dataPrepEstimator.Append(mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(\"Label\", \"Features\"));\r\n            var keyToValuePipeLine = mlContext.Transforms.Conversion.MapValueToKey(\"PredictedLabel\");\r\n\r\n            ITransformer trainedModel = lbfgsTrainingPipeLine.Fit(data);\r\n            ITransformer keyToValueModel = keyToValuePipeLine.Fit(trainedModel.Transform(data));\r\n\r\n            mlContext.Model.Save(trainedModel, data.Schema, $\"{modelPath}\\\\data_predict.zip\");\r\n            mlContext.Model.Save(keyToValueModel, trainedModel.Transform(data).Schema, $\"{modelPath}\\\\data_prep_pipeline.zip\");\r\n\r\nMy question is:\r\n1. How can I use the trained model to predict?\r\n    var predictionEngine = mlContext.Model.CreatePredictionEngine<EngineerPredictModel, EngineerRegressionPredictionModel>(trainedModel); => this code got an error.\r\n\r\n2. How can I retrain the model with this way? This is my retrain function, and I got an error in step 4.\r\n    public static void RetrainModel(MLContext mlContext, IEnumerable<PredictModel> modelList, string modelPath)\r\n        {\r\n            Console.WriteLine(\"Re-training regression model ...\");\r\n\r\n            // 1. Load data preparation pipeline\r\n            ITransformer dataPrepPipeline = mlContext.Model.Load($\"{modelPath}\\\\data_prep_pipeline.zip\", out _);\r\n\r\n            // 2. Load trained model\r\n            ITransformer trainedModel = mlContext.Model.Load($\"{modelPath}\\\\data_predict.zip\", out _);\r\n\r\n            var predictor = (trainedModel as TransformerChain<ITransformer>).LastTransformer as MulticlassPredictionTransformer<MaximumEntropyModelParameters>;\r\n            MaximumEntropyModelParameters originalModelParameters = predictor.Model;\r\n\r\n            // 3. Load new data\r\n            var newData = mlContext.Data.LoadFromEnumerable(modelList);\r\n\r\n            // 4. Process new data\r\n            IDataView transformedNewData = dataPrepPipeline.Transform(newData);\r\n\r\n            // 5. Retrain model            \r\n            var retrainedModel = mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(\"Label\", \"Features\").Fit(transformedNewData, originalModelParameters);\r\n\r\n            ///mlContext.Model.Save(dataPrepPipeline, newData.Schema, $\"{modelPath}\\\\data_prep_pipeline.zip\");\r\n            mlContext.Model.Save(retrainedModel, transformedNewData.Schema, $\"{modelPath}\\\\data_predict.zip\");\r\n        }\r\n   \r\nPlease answer when you can.\r\nThanks and best regards.","Url":"https://github.com/dotnet/machinelearning/issues/5795","RelatedDescription":"Open issue \"Cannot retrain the model that it used LbfgsMaximumEntropy algorithms\" (#5795)"},{"Id":"890036899","IsPullRequest":false,"CreatedAt":"2021-05-12T12:33:04","Actor":"ndgroth","Number":"5793","RawContent":null,"Title":"IDataView for experiments with AutoML","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am adapting the AutoML sample to fit my purpose. Everything works fine if I place my data in a CSV file, but in case, the data is already in memory as a List<DataPoint> because I am calculating Features. So instead of saving that to a CSV file and loading it back in again, I replaced this line:\r\n**TrainDataView = textLoader.Load(TrainDataPath);**\r\nwith:\r\n**TrainDataView = mlContext.Data.LoadFromEnumerable<DataPoint>(Data);**\r\n\r\nBoth are IDataViews, so I am guessing it should work. For the time being, I kept the ColumnInference working from the CSV file. But the regression fails.\r\n\r\nIs there a way to avoid saving/loading data?\r\n\r\n- **What happened?**\r\n=============== Running AutoML experiment ===============\r\n#########################################################\r\nRunning AutoML regression experiment...\r\nPress any key to stop the experiment run...\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration                 |\r\n|1    SdcaRegression                           NaN          0.00         0.00     0.00      15.8                 |\r\n1 models were returned after 15.92 seconds\r\n\r\n- **What did you expect?**\r\n=============== Running AutoML experiment ===============\r\n#########################################################\r\nRunning AutoML regression experiment...\r\nPress any key to stop the experiment run...\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration                 |\r\n|1    SdcaRegression                      -554.7830        460.07    368733.51   588.39       3.0                |\r\n|2    LightGbmRegression                  -151.0080        436.38    625374.63   702.75       1.3                |\r\n|3    FastTreeRegression                  -54.9780        267.71    287578.01   484.74       2.7                 |\r\n|4    FastTreeTweedieRegression            -1.6479        215.75    278471.13   450.67       1.2                 |\r\n|5    FastForestRegression                -32.4529        343.83    540098.80   627.91       1.8                 |\r\n|6    LbfgsPoissonRegression              -20.8898       1102.84  50035704.04  3150.17       0.9\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5793","RelatedDescription":"Open issue \"IDataView for experiments with AutoML\" (#5793)"},{"Id":"889600384","IsPullRequest":false,"CreatedAt":"2021-05-12T04:25:00","Actor":"hexate","Number":"5792","RawContent":null,"Title":"System.AccessViolationException' occurred in TensorFlow.NET.dll when calling predictionEngine.Predict()","State":"open","Body":"\r\n### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n.NET SDK (reflecting any global.json):\r\n Version:   5.0.103\r\n Commit:    72dec52dbd\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19042\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\5.0.103\\\r\n\r\nHost (useful for support):\r\n  Version: 5.0.3\r\n  Commit:  c636bbdc8a\r\n\r\n.NET SDKs installed:\r\n  5.0.101 [C:\\Program Files\\dotnet\\sdk]\r\n  5.0.103 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.25 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.25 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 5.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 5.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.25 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 5.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 5.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 5.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 5.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrying to create a prediction engine and then calling Predict() after loading a tensorflow model. The error is thrown when trying to call Predict().\r\n\r\nLatest nugets are referenced:\r\nMicrosoft.ML - 1.5.5\r\nMicrosoft.ML.TensorFlow - 1.5.5\r\nTensorFlow.NET - 0.40.1\r\n\r\n- **What happened?**\r\n\r\nEncounter this error:\r\n\r\nAn unhandled exception of type 'System.AccessViolationException' occurred in TensorFlow.NET.dll\r\nAttempted to read or write protected memory. This is often an indication that other memory is corrupt.\r\n\r\n- **What did you expect?**\r\nNo error. Ability to call Predict()\r\n\r\n### Source code / logs\r\n\r\nx64 is selected for building.\r\n\r\n`\r\nTensorFlowModel tensorFlowModel = mlContext.Model.LoadTensorFlowModel(modelLocation);\r\n\r\nIEstimator<ITransformer> pipeline = tensorFlowModel.ScoreTensorFlowModel(\"sequential_1/dense_1/BiasAdd\", \"inputs\", false)\r\n    .Append(mlContext.Transforms.CopyColumns(\"Prediction\", \"sequential_1/dense_1/BiasAdd\"));\r\n\r\nvar engine = mlContext.Model.CreatePredictionEngine<TensorData, PricePrediction>(model);\r\nvar prediction = engine.Predict(data); // error thrown on this line\r\n`","Url":"https://github.com/dotnet/machinelearning/issues/5792","RelatedDescription":"Open issue \"System.AccessViolationException' occurred in TensorFlow.NET.dll when calling predictionEngine.Predict()\" (#5792)"},{"Id":"887832811","IsPullRequest":true,"CreatedAt":"2021-05-11T16:38:58","Actor":"derekdiamond","Number":"5791","RawContent":null,"Title":"Give message with line and column of CSV file if data conversion fails","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5791","RelatedDescription":"Open PR \"Give message with line and column of CSV file if data conversion fails\" (#5791)"},{"Id":"887830311","IsPullRequest":false,"CreatedAt":"2021-05-11T16:38:01","Actor":"derekdiamond","Number":"5790","RawContent":null,"Title":"Incomplete error message when loading data from a CSV file","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- Loaded a CSV with #N/A in a numeric column\r\n- **What happened?**\r\n- Got exception that Invalid format for number, but no data on where in the CSV\r\n- **What did you expect?**\r\n- To get data on where in the CSV the data had invalid format\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5790","RelatedDescription":"Open issue \"Incomplete error message when loading data from a CSV file\" (#5790)"},{"Id":"885055552","IsPullRequest":true,"CreatedAt":"2021-05-10T20:34:48","Actor":"michaelgsharp","Number":"5789","RawContent":null,"Title":"Arm build changes","State":"open","Body":"Changes that allow building for arm/arm64/apple silicon, as well as cross targeting to those same architectures.\r\n\r\nTests don't pass on those architectures yet, this is just enabling building. Anything that doesn't depend on x86/64 SIMD or IntelMKL works correctly.","Url":"https://github.com/dotnet/machinelearning/pull/5789","RelatedDescription":"Open PR \"Arm build changes\" (#5789)"},{"Id":"884651907","IsPullRequest":false,"CreatedAt":"2021-05-10T17:01:38","Actor":"Bytezart","Number":"5788","RawContent":null,"Title":"Microsoft.ML.TimeSeries: Unable to load shared library 'MklImports' or one of its dependencies.","State":"open","Body":"### System information\r\n**OS:** MacOS Big Sur \r\n**OS Version:** 11.3.1\r\n**.Net Version:** 5.0.202\r\n**.Net Framework:** .Net Core 3.1\r\n**Packages/Versions:**\r\nMicrosoft.ML 1.5.5\r\nMicrosoft.ML.TimeSeries 1.5.5\r\nMicrosoft.ML.Mkl.Redist 1.5.5\r\n\r\n### Issue\r\nExecuting the following method throws an exception as denoted below.\r\nSsaForecastingTransformer.Fit(IDataView input) throws exception Microsoft.ML.TimeSeries: Unable to load shared library 'MklImports' or one of its dependencies.\r\n\r\n### Source Code\r\nI can produce this error using the example code as found in the method documentation at [microsoft.ml.timeseriescatalog.forecastbyssa](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.timeseriescatalog.forecastbyssa?view=ml-dotnet) or in even simpler configurations.\r\n\r\n### Self Help Troubleshooting \r\n\r\n1. **Installed Extra ML.ET Dependencies as instructed @ [Install extra ML.NET dependencies - ML.NET | Microsoft Docs](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/install-extra-dependencies)**\r\n\r\n\tThe following fails on this version of MacOS. However, upon further inspection of the HomeBrew script the bottle SHA signatures were failing to validate. Correcting these seems to have allowed the script to install.\r\n\r\n\t`wget https://raw.githubusercontent.com/Homebrew/homebrew-core/fb8323f2b170bd4ae97e1bac9bf3e2983af3fdb0/Formula/libomp.rb && brew install ./libomp.rb && brew link libomp --force`\r\n\r\n2. **Enabled  DYLD_PRINT_LIBRARIES** \r\nAfter enabling this environment variable it appears that dotnet --version command will list all the linked libraries as exampled below. However,  the libomp library cannot be found in this list.\r\n\r\n\tExample Output of dotnet --version where libomp isn't found.\r\n\tdyld: loaded: <23377312-A7DE-3C6C-BCCD-CC68DA1B1898> /usr/local/share/dotnet/dotnet\r\n\tdyld: loaded: <B027735F-B398-381C-84A7-606D7BBE4997> /usr/lib/libc++.1.dylib\r\n\tdyld: loaded: <EADFB1D1-E113-35B4-BD2D-C1E4C38010D4> /usr/lib/libSystem.B.dylib\r\n\tdyld: loaded: <22AFC7FC-2DB6-3EF0-9CC0-EFFB9B65D5E2> /usr/lib/libc++abi.dylib\r\n\t...\r\n\t...\r\n\t...\r\n\r\n### Related Issue\r\n[Unable to load shared library 'MklImports' or one of its dependencies. · Issue #3903 · dotnet/machinelearning · GitHub](https://github.com/dotnet/machinelearning/issues/3903)","Url":"https://github.com/dotnet/machinelearning/issues/5788","RelatedDescription":"Open issue \"Microsoft.ML.TimeSeries: Unable to load shared library 'MklImports' or one of its dependencies.\" (#5788)"},{"Id":"871512396","IsPullRequest":true,"CreatedAt":"2021-05-10T16:55:23","Actor":"pgovind","Number":"5776","RawContent":null,"Title":"Improvements to the sort routine","State":"closed","Body":"Currently our sort routine doesn't handle `null` values in columns correctly. It assumes that all columns have the same `NullCount`. This PR removes this limitation.\r\n\r\n\r\nFixes recent reports from @asmirnov82. Also fixes https://github.com/dotnet/machinelearning/issues/5655\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5776","RelatedDescription":"Closed or merged PR \"Improvements to the sort routine\" (#5776)"},{"Id":"884309749","IsPullRequest":false,"CreatedAt":"2021-05-10T14:09:23","Actor":"nhirschey","Number":"5787","RawContent":null,"Title":"Add options for different covariance matrix estimators for OlsModelParameters","State":"open","Body":"### Issue\r\n\r\nML.NET does not have an option for alternate covariance matrix estimators for use with OlsModelParameters. I would like to be able to select different covariance matrix estimators for estimating coefficient standard errors and p-values. These different covariance matrix estimators are standard in economics and other social sciences. See for example the covariance matrix estimators and software architecture here: https://cran.r-project.org/web/packages/sandwich/index.html\r\n\r\nI understand the business case for why statistical inference is not a high priority for the ML.NET team. But look at it this way. Do you want students to use ML.NET in statistics classes in Universities? That would seem like a good gateway to onboarding people onto ML.NET. If so, then you need to add different covariance matrix estimators.\r\n\r\nThis is a real use case where I want to use ML.NET for statistics in a university course that I am teaching.","Url":"https://github.com/dotnet/machinelearning/issues/5787","RelatedDescription":"Open issue \"Add options for different covariance matrix estimators for OlsModelParameters\" (#5787)"},{"Id":"883631805","IsPullRequest":false,"CreatedAt":"2021-05-10T07:51:49","Actor":"Glenn-jpg","Number":"5786","RawContent":null,"Title":"What are the differences between the FastTree and LightGBM algorithm used by ML.Net?","State":"open","Body":"I was referred to ask this question here by @justinormont and I was also wondering if @guolinke could assist in answering. \r\n\r\nFor my master thesis, I am using the ML.Net library with the model builder to build machine learning models for regression / to predict values. My field of study is in constructional mechanics, so I'm rather new to machine learning.\r\n\r\nFor most of my models, tree-based regression algorithms seem to be the best performing, and of these LightGBM and FastTree are the best performing algorithms.\r\n\r\nI've tried to read up on LightGBM here: https://www.microsoft.com/en-us/research/publication/lightgbm-a-highly-efficient-gradient-boosting-decision-tree/ And FastTree here: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.fasttree.fasttreeregressiontrainer?view=ml-dotnet\r\n\r\nHowever, I struggle to distinguish what the difference between these algorithms is. Could someone explain what the difference between LightGBM and FastTree is?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5786","RelatedDescription":"Open issue \"What are the differences between the FastTree and LightGBM algorithm used by ML.Net?\" (#5786)"},{"Id":"882995426","IsPullRequest":false,"CreatedAt":"2021-05-09T23:53:53","Actor":"iluveu28","Number":"5785","RawContent":null,"Title":"AutoML : Getting Empty Prediction Results","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Linux\r\n- **.NET Version (eg., dotnet --info)**: 3.1\r\n\r\nThis is a follow up to the issue that no one responded - https://github.com/dotnet/machinelearning/issues/5738\r\n\r\nFirst of all, why does it group the columns in the first place ? It doesn't group the numerical columns for my other project which has only 5 columns in total. How does it determine when to group them?\r\n\r\nSo the missing Features column error is gone now after setting the flag to false, thank you. However, the results are empty. The predictions variable is returning a list of 0 values. What am I doing wrong below? Again, the same code works fine for my other project with 5 columns.\r\n\r\n\tvar options = new TextLoader.Options\r\n\t{\r\n\t\tSeparators = new[] { ',' },\r\n\t\tHasHeader = true,\r\n\t\tColumns = columns,\r\n\t\tAllowQuoting = true,\r\n\t\tAllowSparse = true\r\n\t};\r\n\r\n\tvar loader = _mlContext.Data.CreateTextLoader(columns,\r\n\t\t\thasHeader: true,\r\n\t\t\tseparatorChar: ',');\r\n\r\n            File.WriteAllText(testDataPath, content);\r\n\r\n            var testData = loader.Load(testDataPath);\r\n\r\n            ITransformer mlModel = _mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n\r\n            var output = mlModel.Transform(testData);\r\n\r\n            var predictions = output.GetColumn<UInt32>(labelColumnName);\r\n\r\n            var predictedLabel = output.GetColumn<ReadOnlyMemory<char>>(\"PredictedLabel\");\r\n\r\n            int count = predictedLabel.Count();\r\n\r\n            string jsonResults = \"\";\r\n\r\n            foreach (ReadOnlyMemory<char> result in predictedLabel)\r\n\t{\r\n              jsonResults += \"{ output: \" + result.ToString() + \"}\";\r\n\r\n\t}\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5785","RelatedDescription":"Open issue \"AutoML : Getting Empty Prediction Results\" (#5785)"},{"Id":"873467532","IsPullRequest":true,"CreatedAt":"2021-05-06T22:57:49","Actor":"pgovind","Number":"5778","RawContent":null,"Title":"Improvements to the Merge routine","State":"closed","Body":"Currently, we don't differentiate between `null` values and `default` values in columns. As a result, these values are considered equivalent in the `Merge` routine. This PR fixes that by handling them separately. Also added unit tests so we don't regress in the future.\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/5765 and contributes to https://github.com/dotnet/machinelearning/issues/5691\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5778","RelatedDescription":"Closed or merged PR \"Improvements to the Merge routine\" (#5778)"},{"Id":"876927644","IsPullRequest":false,"CreatedAt":"2021-05-05T23:08:06","Actor":"briacht","Number":"5784","RawContent":null,"Title":"Customer reported: Image Classification API Fit() error","State":"open","Body":"From: https://twitter.com/kasozi39567299/status/1390069853214679042?s=20\r\n\r\n![image](https://user-images.githubusercontent.com/10437687/117220420-0a1c0f00-adbc-11eb-9c43-f792688eace1.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5784","RelatedDescription":"Open issue \"Customer reported: Image Classification API Fit() error\" (#5784)"},{"Id":"874420247","IsPullRequest":false,"CreatedAt":"2021-05-04T05:17:20","Actor":"Hpero4","Number":"5781","RawContent":null,"Title":"Shape Transpose?","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: .NET Core 5.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n    Assuming that the image preprocessing has been completed, the following operations only convert the image to a vector.\r\n    ```\r\n    var pipeline \r\n        = mlContext.Transforms.ExtractPixels(\r\n                inputColumnName: nameof(ModelInputData.img),\r\n                outputColumnName: ModelSettings.ModelInput,\r\n                scaleImage:1f/255f,\r\n                colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Blue,\r\n                interleavePixelColors: true,\r\n                outputAsFloatArray: true\r\n            )\r\n            .Append(mlContext.Transforms.ApplyOnnxModel(\r\n                modelFile: SwModelLocation, \r\n                outputColumnName: ModelSettings.ModelOutput, \r\n                inputColumnName: ModelSettings.ModelInput\r\n                ));\r\n    ```\r\n- **What happened?**\r\n    I want to use the H5 model of keras on ml.net through onnx.\r\n    But I can’t process the shape of the input data.\r\n    The input Shape of the model is [None, 240, 16, 1];\r\n    I don’t know how to do such an operation in ML.Net:\r\n    ```\r\n    # Python Code\r\n    np.NDArray.T[None, :, :, None]\r\n    # It turns Shape=(16, 240)  into Shape=(1, 240, 16, 1)\r\n    # When the original shape[0] is greater than 16, a new shape[0] will be obtained from the original shape[0]/16, as follows:\r\n    # original .shape = (144, 240)\r\n    # new_arr = original .T[None, :, :, None]\r\n    # new_arr.shape = (9, 240, 16, 1)\r\n    ```\r\n    <br/>\r\n    In C# I try have tried to rotate the bitmap 270° clockwise during preprocessing and swap the input width and height, but can't predict accurately:\r\n    \r\n    ```\r\n    // C# Code\r\n    Bitmap.RotateFlip(RotateFlipType.Rotate270FlipNone);\r\n    \r\n    // Make the following modifications to ModelInputData\r\n    private class ModelInputData\r\n    {\r\n        [ImageType(InputSetting.ImageWidth, InputSetting.ImageHeight)]\r\n        public Bitmap img { get; set; }\r\n    }\r\n    \r\n    /*var pipeline ...*/\r\n    ```\r\n    \r\n    And if the T[None, :, :, None] operation is not performed in python, the output of the model will be the same as the output of the model before modification in C#, So I think this problem is caused by the input data Shape.\r\n- **What did you expect?**\r\n    Thank you for your great work.\r\n    I would like to know does ML.Net or C# provide relevant methods for this operation?\r\n\r\n### Source code / logs\r\n```\r\n# This is the smallest example showing the difference between the two in Python.\r\n\r\nimport numpy as np\r\n\r\nif __name__ == '__main__':\r\n    # After obtaining the image and preprocessing, both C# and Python get such data.\r\n    # Bitmap in C#, and Numpy.NDArray in Python,\r\n    # but this is not important, because their data is the same, only the class is different.\r\n    initial_data = np.arange(3840).reshape((16, 240))\r\n\r\n    # Through \"DebuggerExtensions.Preview\" i found that the model input data in C# is the same as the execution result of this line of code\r\n    cs_input_data = initial_data.reshape((1, 240, 16, 1))\r\n\r\n    # But I need such data\r\n    py_input_data = initial_data.T[None, :, :, None]\r\n\r\n    # print difference\r\n    for i in range(cs_input_data.shape[0]):\r\n        for j in range(cs_input_data.shape[1]):\r\n            for k in range(cs_input_data.shape[2]):\r\n                cs_index = np.where(cs_input_data == cs_input_data[i][j][k])\r\n                py_index = np.where(py_input_data == cs_input_data[i][j][k])\r\n\r\n                print(\"[{}, {}] -> [{}, {}]\".format(cs_index[1][0], cs_index[2][0], py_index[1][0], py_index[2][0]))\r\n\r\n    # debug breakpoint\r\n    print(\"finished.\")\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5781","RelatedDescription":"Closed issue \"Shape Transpose?\" (#5781)"},{"Id":"874177978","IsPullRequest":true,"CreatedAt":"2021-05-04T01:16:32","Actor":"metr0jw","Number":"5780","RawContent":null,"Title":"Add Korean translation","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5780","RelatedDescription":"Closed or merged PR \"Add Korean translation\" (#5780)"},{"Id":"874738722","IsPullRequest":true,"CreatedAt":"2021-05-03T16:54:29","Actor":"michaelgsharp","Number":"5782","RawContent":null,"Title":"Onnx load model","State":"open","Body":"Fixes #5766 and #5764 by letting the user specify a temp path location, which defaults to the current location to keep existing behavior, and by make sure the temp onnx model file gets cleaned up by opening it with a delete on close flag.","Url":"https://github.com/dotnet/machinelearning/pull/5782","RelatedDescription":"Open PR \"Onnx load model\" (#5782)"},{"Id":"874003427","IsPullRequest":false,"CreatedAt":"2021-05-02T17:54:01","Actor":"masgh021","Number":"5779","RawContent":null,"Title":"object detection output   float32[None,None2,13,13]","State":"open","Body":"my model is exported from custom.vision ,\r\ni have small image in input  for object detection model ,\r\nafter when i check the out put it gives me this type \r\ntype: float32[None,None2,13,13]\r\n(Netron  )\r\nmy predict are wrong .\r\n[error Image](https://pasteboard.co/K03QI2g.png) ","Url":"https://github.com/dotnet/machinelearning/issues/5779","RelatedDescription":"Open issue \"object detection output   float32[None,None2,13,13]\" (#5779)"},{"Id":"872572858","IsPullRequest":false,"CreatedAt":"2021-04-30T14:05:27","Actor":"Josef23","Number":"5777","RawContent":null,"Title":"Autoencoders in ML.Net","State":"open","Body":"I cannot find anything more relevant about autoencoders in ML.Net than this closed issue: [https://github.com/dotnet/machinelearning](4254).\r\n\r\nIs it possible now to use autoencoders in ML.Net?","Url":"https://github.com/dotnet/machinelearning/issues/5777","RelatedDescription":"Open issue \"Autoencoders in ML.Net\" (#5777)"},{"Id":"870940552","IsPullRequest":false,"CreatedAt":"2021-04-29T12:02:18","Actor":"ddobric","Number":"5775","RawContent":null,"Title":"Error when downloading the file 'inception_v3.meta'","State":"open","Body":"Hi all,\r\n\r\nwe are using ML.NET in production for image classification. In our application, we also use TensorFlow inception model that is implicitly downloaded.\r\n\r\nThe problem happened last few days as the application in the production stopped working because the download URLhas changed:\r\n\r\n> 2021-04-29T07:22:32\r\n> System.InvalidOperationException: Error downloading a resource from 'https://aka.ms/mlnet-resources/inception_v3.meta': No such host is known. No such host is known.,\r\n\r\n\r\nI guess there must be some smarter way to prevent this error in the future.\r\n\r\nAnd, we still had posted a similar issue related to the inception file. See https://github.com/dotnet/machinelearning/issues/5083\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5775","RelatedDescription":"Open issue \"Error when downloading the file 'inception_v3.meta'\" (#5775)"},{"Id":"870472093","IsPullRequest":false,"CreatedAt":"2021-04-28T23:09:09","Actor":"evo11x","Number":"5774","RawContent":null,"Title":"AutoML trainer parameters","State":"open","Body":"Is there a way to get the AutoML trainer parameters?\r\nBecause I need to train over 100 different datasets/models and I cannot run AutoML on each one of them, it takes too long.","Url":"https://github.com/dotnet/machinelearning/issues/5774","RelatedDescription":"Open issue \"AutoML trainer parameters\" (#5774)"},{"Id":"869423193","IsPullRequest":true,"CreatedAt":"2021-04-28T16:55:42","Actor":"michaelgsharp","Number":"5771","RawContent":null,"Title":"OS X libomp CI fix.","State":"closed","Body":"Fixed the CI issue with libomp.\r\n\r\nThe issue is that version 7 of libomp doesn't have a bottle for Big Sur. The build machines must have just upgraded to it. If I tell it to build from source it is able to successfully build version 7, and when the tests run they are able to find the intel mkl library as well as pass all the tests. Version 7 of libomp seems to be linked with intel mkl somehow and thats why we need to keep using version 7.0.0 for now.","Url":"https://github.com/dotnet/machinelearning/pull/5771","RelatedDescription":"Closed or merged PR \"OS X libomp CI fix.\" (#5771)"},{"Id":"870014005","IsPullRequest":false,"CreatedAt":"2021-04-28T14:30:37","Actor":"thoron","Number":"5773","RawContent":null,"Title":"Feature Vector<Type, NN> does not work as AutoML validation data","State":"open","Body":"### System information\r\n\r\n- Windows 10.0.21364.0\r\n- .NET SDK Version:   5.0.202\r\n\r\n### Issue\r\n- **What did you do?**\r\nI want to use AutoML and having the feature column as a `Vector<Type, NN>` and add validation data to the experiment as in the exposed method: \r\n\r\n`public ExperimentResult<TMetrics> Execute(IDataView trainData, IDataView validationData, string labelColumnName = \"Label\", IEstimator<ITransformer> preFeaturizer = null, IProgress<RunDetail<TMetrics>> progressHandler = null)`\r\n\r\nExample code:\r\n```csharp\r\n_mlContext.Auto()\r\n    .CreateRegressionExperiment(experimentSettings)\r\n    .Execute(_trainDataView, _testDataView, progressHandler: experimentProgress, labelColumnName: \"LabelFeaturized\");\r\n```\r\n\r\n\r\n- **What happened?**\r\nThe experiment fails with to following exception:\r\n```\r\nSystem.ArgumentException: Training data and validation data schemas do not match. Column 'Features' is of type Vector<Single, 5> in train data, and type Vector<Single, 5> in validation data. (Parameter 'validationData')\r\n    at Microsoft.ML.AutoML.UserInputValidationUtil.ValidateValidationData(IDataView trainData, IDataView validationData)\r\nat Microsoft.ML.AutoML.UserInputValidationUtil.ValidateExperimentExecuteArgs(IDataView trainData, ColumnInformation columnInformation, IDataView validationData, TaskKind task)\r\nat Microsoft.ML.AutoML.ExperimentBase`2.ExecuteTrainValidate(IDataView trainData, ColumnInformation columnInfo, IDataView validationData, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\nat Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, IDataView validationData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\nat Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, IDataView validationData, String labelColumnName, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n```\r\n\r\n- **What did you expect?**\r\nThe validation data to be used in the experiment and the `Vector` typed Feature column to be an acceptable datatype. \r\n\r\nPerhaps this line needs to account for `Vector<Type,NN>` ? \r\nhttps://github.com/dotnet/machinelearning/blob/04dda55ab0902982b16309c8e151f13a53e9366d/src/Microsoft.ML.AutoML/Utils/UserInputValidationUtil.cs#L220","Url":"https://github.com/dotnet/machinelearning/issues/5773","RelatedDescription":"Open issue \"Feature Vector<Type, NN> does not work as AutoML validation data\" (#5773)"},{"Id":"869558693","IsPullRequest":false,"CreatedAt":"2021-04-28T06:46:31","Actor":"arafattehsin","Number":"5772","RawContent":null,"Title":"Object Detection Bounding Box gone wrong","State":"open","Body":"### System information\r\n\r\n- **Windows 10**:\r\n- **.NET Core 3.1**: \r\n\r\n### Issue\r\n\r\n- **I created an object detection model with fantastic accuracy**\r\n- **All works good. However, when I try to map the bounding box coordinates, I see that the coordinates returned are not correct by the model (or may be I am totally wrong and I should know how to make it work)**\r\n- **The bounding box should have been drawn correctly around the detected items.**\r\n\r\n### Source code / logs\r\n\r\nThis is the Preview I get (before training)\r\n\r\n![image](https://user-images.githubusercontent.com/16351038/116357509-ded77400-a83f-11eb-9005-a45b5c842e7e.png)\r\n\r\nThis is what I get after training.\r\n\r\n![image](https://user-images.githubusercontent.com/16351038/116359271-f6176100-a841-11eb-8c0e-8e23c5d5ed58.png)\r\n\r\nThis is what I get for a different image (after training).\r\n\r\n![image](https://user-images.githubusercontent.com/16351038/116359399-1a733d80-a842-11eb-8b52-ded9c563f7c1.png)\r\n\r\n> Note: I know they are delicious. 🍩\r\n\r\nHowever, after passing the same image to model, I get the coordinates which are mapped like this;\r\n\r\n![trifle-5](https://user-images.githubusercontent.com/16351038/116357930-6cb35f00-a840-11eb-91a6-1e12464fbfaa.jpeg)\r\n\r\nNothing fancy in terms of code;\r\n\r\n```\r\n var boundingBoxes = predictionResult.BoundingBoxes;\r\n\r\n    foreach (BoundingBox box in boundingBoxes)\r\n    {\r\n      // read image file\r\n      Image oldImg = Image.FromFile(destinationPath);\r\n    \r\n      using (Graphics g = Graphics.FromImage(oldImg))\r\n      {\r\n          // Create pen.\r\n          Pen redPen = new Pen(Color.Red, 3);\r\n    \r\n          // Draw Rectangle\r\n          Rectangle rectangle = Rectangle.FromLTRB(Convert.ToInt32(box.Left), Convert.ToInt32(box.Top), Convert.ToInt32(box.Right), Convert.ToInt32(box.Bottom));\r\n    \r\n          g.DrawRectangle(redPen, rectangle);\r\n      }\r\n    .\r\n    .\r\n    .\r\n    .\r\n    \r\n    }\r\n```\r\n\r\nPlease tell me that I am absolutely wrong by correcting me or posting a correct solution. Thanks! 🙏\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5772","RelatedDescription":"Open issue \"Object Detection Bounding Box gone wrong\" (#5772)"}],"ResultType":"GitHubIssue"}},"RunOn":"2021-05-18T05:30:30.5679997Z","RunDurationInMilliseconds":578}