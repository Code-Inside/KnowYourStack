{"Data":{"GitHub":{"Issues":[{"Id":"3299593152","IsPullRequest":false,"CreatedAt":"2025-10-04T01:26:01","Actor":"williamlzw","Number":"7492","RawContent":null,"Title":".NET BUG: Ġ' was wrongly split","State":"closed","Body":"C# is incorrectly split, while python does not.\n```\nfrom transformers import AutoTokenizer\n\n#tokenizer_dir = 'D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX'\ntokenizer_dir = 'Qwen/Qwen3-Reranker-0.6B'\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_dir, padding_side=\"left\")\nprefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be '<|im_end|>\\n<|im_start|>user\\n\"\nsuffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\nprefix_tokens = tokenizer.encode(prefix, add_special_tokens=False)\nfor token in prefix_tokens:\n    print(token, tokenizer.decode(token))\n```\n\noutput:\n151644 <|im_start|>\n8948 system\n198\n\n60256 Judge\n3425  whether\n279  the\n11789  Document\n20027  meets\n279  the\n8502  requirements\n3118  based\n389  on\n279  the\n11361  Query\n323  and\n279  the\n758  In\n1235 struct\n3897  provided\n13 .\n7036  Note\n429  that\n279  the\n4226  answer\n646  can\n1172  only\n387  be\n364  '\n151645 <|im_end|>\n198\n\n151644 <|im_start|>\n872 user\n198\n\n=========================\n```\nusing Microsoft.ML.Tokenizers;\nusing System.Text.Json;\n\nclass program\n{\n    const string IMStart = \"<|im_start|>\";\n    const string IMEnd = \"<|im_end|>\";\n\n    public static void Main()\n    {\n        string text = $\"{IMEnd}\\n{IMStart}assistant\\n<think>\\n\\n</think>\\n\\n\";\n        string text1 = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be '<|im_end|>\\n<|im_start|>user\\n\";\n        text1 = text1.Replace(\" \", \"\\u0120\").Replace(\"\\n\", \"\\u010A\");\n        using Stream vocabStream = File.OpenRead(\"D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX\\\\vocab.json\");\n        using Stream mergesStream = File.OpenRead(\"D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX\\\\merges.txt\");\n        string configPath = \"D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX\\\\tokenizer_config.json\";\n        var specialTokens = LoadSpecialTokens(configPath);\n\n        var bpe = BpeTokenizer.Create(vocabStream, mergesStream, PreTokenizer.CreateWordOrNonWord(specialTokens), specialTokens:specialTokens);\n        var encoding = bpe.EncodeToTokens(text1, out _);\n        Console.WriteLine(\"\\nEncoded IDs:\");\n        foreach (var id in encoding)\n        {\n            Console.WriteLine($\"{id.Id} -> {id.Value.Replace(\"\\u010A\", \"\\n\").Replace(\"\\u0120\", \" \")}\");\n        }\n    }\n\n    private static Dictionary<string, int> LoadSpecialTokens(string configPath)\n    {\n        if (!File.Exists(configPath))\n        {\n            throw new FileNotFoundException($\"Config file not found: {configPath}\");\n        }\n\n        var json = File.ReadAllText(configPath);\n        using JsonDocument doc = JsonDocument.Parse(json);\n        JsonElement root = doc.RootElement;\n\n        // 创建特殊标记字典\n        var specialTokens = new Dictionary<string, int>();\n\n        // 1. 首先添加 additional_special_tokens\n        if (root.TryGetProperty(\"additional_special_tokens\", out JsonElement additionalTokens))\n        {\n            foreach (JsonElement token in additionalTokens.EnumerateArray())\n            {\n                string content = token.GetString();\n                if (!string.IsNullOrEmpty(content))\n                {\n                    // 查找在 added_tokens_decoder 中对应的 ID\n                    int? tokenId = FindTokenIdInDecoder(root, content);\n\n                    if (tokenId.HasValue)\n                    {\n                        // 使用 added_tokens_decoder 中的 ID\n                        specialTokens[content] = tokenId.Value;\n                    }\n                    else\n                    {\n                        // 分配新 ID（在原有最大ID基础上增加）\n                        int newId = specialTokens.Count > 0\n                            ? specialTokens.Values.Max() + 1\n                            : 1000000;\n                        specialTokens[content] = newId;\n                    }\n                }\n            }\n        }\n\n        // 2. 添加 added_tokens_decoder 中的其他标记（不在 additional_special_tokens 中的）\n        if (root.TryGetProperty(\"added_tokens_decoder\", out JsonElement addedTokens))\n        {\n            foreach (JsonProperty prop in addedTokens.EnumerateObject())\n            {\n                if (int.TryParse(prop.Name, out int tokenId))\n                {\n                    string content = prop.Value.GetProperty(\"content\").GetString();\n                    if (!string.IsNullOrEmpty(content)\n                        && !specialTokens.ContainsKey(content))\n                    {\n                        specialTokens[content] = tokenId;\n                    }\n                }\n            }\n        }\n\n        // 3. 确保关键标记存在\n        EnsureSpecialToken(specialTokens, \"<|endoftext|>\", 151643);\n        EnsureSpecialToken(specialTokens, \"<|im_start|>\", 151644);\n        EnsureSpecialToken(specialTokens, \"<|im_end|>\", 151645);\n\n        //Console.WriteLine(\"Loaded special tokens:\");\n        //foreach (var kvp in specialTokens)\n        //{\n        //    Console.WriteLine($\"{kvp.Value}: {kvp.Key}\");\n        //}\n\n        return specialTokens;\n    }\n\n    private static int? FindTokenIdInDecoder(JsonElement root, string tokenContent)\n    {\n        if (root.TryGetProperty(\"added_tokens_decoder\", out JsonElement addedTokens))\n        {\n            foreach (JsonProperty prop in addedTokens.EnumerateObject())\n            {\n                if (int.TryParse(prop.Name, out int tokenId))\n                {\n                    string content = prop.Value.GetProperty(\"content\").GetString();\n                    if (content == tokenContent)\n                    {\n                        return tokenId;\n                    }\n                }\n            }\n        }\n        return null;\n    }\n\n    private static void EnsureSpecialToken(Dictionary<string, int> specialTokens, string token, int defaultId)\n    {\n        if (!specialTokens.ContainsKey(token))\n        {\n            specialTokens[token] = defaultId;\n        }\n    }\n}\n```\noutput:\n151644 -> <|im_start|>\n8948 -> system\n198 ->\n\n60256 -> Judge\n3425 ->  whether\n279 ->  the\n11789 ->  Document\n20027 ->  meets\n279 ->  the\n8502 ->  requirements\n3118 ->  based\n389 ->  on\n279 ->  the\n11361 ->  Query\n323 ->  and\n279 ->  the\n758 ->  In\n1235 -> struct\n3897 ->  provided\n13 -> .\n7036 ->  Note\n429 ->  that\n279 ->  the\n4226 ->  answer\n646 ->  can\n1172 ->  only\n387 ->  be\n220 ->\n6 -> '\n151645 -> <|im_end|>\n198 ->\n\n151644 -> <|im_start|>\n872 -> user\n198 ->\n","Url":"https://github.com/dotnet/machinelearning/issues/7492","RelatedDescription":"Closed issue \".NET BUG: Ġ' was wrongly split\" (#7492)"},{"Id":"3479576251","IsPullRequest":true,"CreatedAt":"2025-10-03T19:58:29","Actor":"ericstj","Number":"7516","RawContent":null,"Title":"Improve native build and mark our official build as CFS Clean","State":"closed","Body":"The CFS Clean marking will prevent our build from accessing public packaging endpoints (like NuGet.org, myget.org, etc).\r\nSee https://eng.ms/docs/cloud-ai-platform/devdiv/one-engineering-system-1es/1es-build/cloudbuild/resolving-cfs-s360-items\r\n\r\nThe other settings are just various native toolchain improvements like deterministic build, source linking, etc.  I also enabled the repo to build with Dev18 while I was at it.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7516","RelatedDescription":"Closed or merged PR \"Improve native build and mark our official build as CFS Clean\" (#7516)"},{"Id":"3481890706","IsPullRequest":true,"CreatedAt":"2025-10-03T17:20:49","Actor":"ericstj","Number":"7520","RawContent":null,"Title":"Improve unique directory generation for temp files","State":"open","Body":"Refactor unique directory creation logic to use random file names.\r\n\r\nFixes https://github.com/dotnet/machinelearning/issues/7485\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7520","RelatedDescription":"Open PR \"Improve unique directory generation for temp files\" (#7520)"},{"Id":"3481545966","IsPullRequest":true,"CreatedAt":"2025-10-03T17:02:36","Actor":"dotnet-maestro[bot]","Number":"7519","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\n\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\n## From https://github.com/dotnet/arcade\n- **Subscription**: [c692823c-b896-437f-4f57-08dc434cc8f6](https://maestro.dot.net/subscriptions?search=c692823c-b896-437f-4f57-08dc434cc8f6)\n- **Build**: [20251002.2](https://dev.azure.com/dnceng/internal/_build/results?buildId=2807056) ([285551](https://maestro.dot.net/channel/2/github:dotnet:arcade/build/285551))\n- **Date Produced**: October 2, 2025 7:59:28 PM UTC\n- **Commit**: [bac4c2c4add004bbce35ff5d17bc295dd4ebcd57](https://github.com/dotnet/arcade/commit/bac4c2c4add004bbce35ff5d17bc295dd4ebcd57)\n- **Branch**: [main](https://github.com/dotnet/arcade/tree/main)\n\n[DependencyUpdate]: <> (Begin)\n\n- **Updates**:\n  - From [11.0.0-beta.25477.2 to 11.0.0-beta.25502.2][1]\n     - Microsoft.DotNet.Arcade.Sdk\n     - Microsoft.DotNet.Build.Tasks.Feed\n     - Microsoft.DotNet.Helix.Sdk\n     - Microsoft.DotNet.SignTool\n     - Microsoft.DotNet.SwaggerGenerator.MSBuild\n     - Microsoft.DotNet.XliffTasks\n     - Microsoft.DotNet.XUnitExtensions\n\n[1]: https://github.com/dotnet/arcade/compare/e19df00378...bac4c2c4ad\n\n[DependencyUpdate]: <> (End)\n\n\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\n\n","Url":"https://github.com/dotnet/machinelearning/pull/7519","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#7519)"},{"Id":"3420510489","IsPullRequest":false,"CreatedAt":"2025-10-03T16:24:13","Actor":"williamlzw","Number":"7508","RawContent":null,"Title":"Hope to simplify torchsharp's Tokenizer to facilitate expansion","State":"closed","Body":"https://github.com/dotnet/machinelearning/issues/7507","Url":"https://github.com/dotnet/machinelearning/issues/7508","RelatedDescription":"Closed issue \"Hope to simplify torchsharp's Tokenizer to facilitate expansion\" (#7508)"},{"Id":"3480645030","IsPullRequest":true,"CreatedAt":"2025-10-03T10:42:06","Actor":"krwq","Number":"7518","RawContent":null,"Title":"Modify expiration dates in .gdnbaselines","State":"open","Body":"Updated expiration dates for baseline results - those should still be suppressed in order for BinSkim to not complain. We do not have control over external components.","Url":"https://github.com/dotnet/machinelearning/pull/7518","RelatedDescription":"Open PR \"Modify expiration dates in .gdnbaselines\" (#7518)"},{"Id":"3479824904","IsPullRequest":false,"CreatedAt":"2025-10-03T05:16:45","Actor":"ntoan69","Number":"7517","RawContent":null,"Title":"Support 16 KB page sizes","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\n\n16 KB Google Play compatibility requirement\nStarting November 1st, 2025, all new apps and updates to existing apps submitted to Google Play and targeting Android 15+ devices must support 16 KB page sizes on 64-bit devices.\n\n**Describe the solution you'd like**\n\nCompile 16 KB-aligned shared libraries\n\n**Describe alternatives you've considered**\n\n\n**Additional context**\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7517","RelatedDescription":"Open issue \"Support 16 KB page sizes\" (#7517)"},{"Id":"3479076528","IsPullRequest":true,"CreatedAt":"2025-10-03T01:22:49","Actor":"tarekgh","Number":"7514","RawContent":null,"Title":"BpeTokenizer Cleanup","State":"closed","Body":"This change is a simple clean-up for the BPE tokenizer:\r\n\r\n* Adds support for `BeginningOfSentenceToken` and `EndOfSentenceToken` when these tokens are not present in the vocabulary but are instead provided as special tokens by the tokenizer.\r\n* Simplifies the implementation of the `Decode` method.","Url":"https://github.com/dotnet/machinelearning/pull/7514","RelatedDescription":"Closed or merged PR \"BpeTokenizer Cleanup\" (#7514)"},{"Id":"3479297049","IsPullRequest":true,"CreatedAt":"2025-10-03T00:42:55","Actor":"ericstj","Number":"7515","RawContent":null,"Title":"Update Windows image, fix mac build","State":"closed","Body":"Public CI doesn't test this.  Will kick off official build\r\n\r\nhttps://dev.azure.com/dnceng/internal/_build/results?buildId=2807210&view=results","Url":"https://github.com/dotnet/machinelearning/pull/7515","RelatedDescription":"Closed or merged PR \"Update Windows image, fix mac build\" (#7515)"},{"Id":"3396447200","IsPullRequest":true,"CreatedAt":"2025-10-01T22:36:03","Actor":"JoshuaSloan","Number":"7499","RawContent":null,"Title":"Added NumberOfLeaves to FastForestRegression and FastForestOva options","State":"closed","Body":"`Fixes #7498`\r\n\r\nThe NumberOfLeaves hyperparameter was not updating in FastForest AutoML experiments for regression and multiclass classification tasks (see regression example in the associated [issue](https://github.com/dotnet/machinelearning/issues/7498), which was trained on the California Housing [dataset](https://www.kaggle.com/datasets/camnugent/california-housing-prices) and optimizing for root mean squared error).\r\n\r\nConsequently, the trial parameters reported via an experiment monitor's final ReportBestTrial() method were not aligning with the actual model produced by the experiment. Additionally, model performance was hurt due to the static hyperparameter constraint.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7499","RelatedDescription":"Closed or merged PR \"Added NumberOfLeaves to FastForestRegression and FastForestOva options\" (#7499)"},{"Id":"3413997722","IsPullRequest":false,"CreatedAt":"2025-10-01T22:35:03","Actor":"artl93","Number":"7503","RawContent":null,"Title":"Initialize es-metadata.yml for inventory","State":"closed","Body":"Please add a file named `es-metadata.yml` to the root of this repository with the following contents:\n\n```\nschemaVersion: 0.0.1\nisProduction: false\naccountableOwners:\n  service: 7a9b52f6-7805-416c-9390-343168c0cdb3\nrouting:\n  defaultAreaPath:\n    org: devdiv\n    path: DevDiv\\NET Libraries\n```\n\nThis file will help initialize inventory metadata for the repository.","Url":"https://github.com/dotnet/machinelearning/issues/7503","RelatedDescription":"Closed issue \"Initialize es-metadata.yml for inventory\" (#7503)"},{"Id":"3414003004","IsPullRequest":true,"CreatedAt":"2025-10-01T22:35:02","Actor":"Copilot","Number":"7504","RawContent":null,"Title":"Initialize es-metadata.yml for inventory","State":"closed","Body":"This PR adds the required `es-metadata.yml` file to the root of the repository to initialize inventory metadata. The file contains the necessary configuration for service ownership and routing information as specified in the issue.\n\nThe file includes:\n- Schema version 0.0.1\n- Production flag set to false\n- Accountable owners service GUID for proper service ownership tracking\n- Default routing configuration for the DevDiv\\.NET Libraries area path\n\nThis metadata file will enable proper inventory tracking and management for the repository.\n\nFixes #7503.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\n✨ Let Copilot coding agent [set things up for you](https://github.com/dotnet/machinelearning/issues/new?title=✨+Set+up+Copilot+instructions&body=Configure%20instructions%20for%20this%20repository%20as%20documented%20in%20%5BBest%20practices%20for%20Copilot%20coding%20agent%20in%20your%20repository%5D%28https://gh.io/copilot-coding-agent-tips%29%2E%0A%0A%3COnboard%20this%20repo%3E&assignees=copilot) — coding agent works faster and does higher quality work when set up for your repo.\n","Url":"https://github.com/dotnet/machinelearning/pull/7504","RelatedDescription":"Closed or merged PR \"Initialize es-metadata.yml for inventory\" (#7504)"},{"Id":"3465721926","IsPullRequest":false,"CreatedAt":"2025-10-01T22:34:41","Actor":"tarekgh","Number":"7512","RawContent":null,"Title":"Added Tokenizer's APIs for v2","State":"closed","Body":"This issue tracks the APIs added to the tokenizer library.\n\n## Proposal\n\n### BpeTokenizer \n\nWe’ve already established a pattern for creating tokenizers using `Tokenizer.Create(...)`. When multiple parameters are required, we wrap them in an `Options` object. For example, `BertTokenizer.Create` accepts a `BertOptions` parameter.\n\nFollowing this pattern, we’re adding a new `Create` method to `BpeTokenizer` and introducing the `BpeOptions` class to encapsulate the parameters passed to `Create`. Currently, `BpeTokenizer` has a `Create` method that takes flat parameters:\n\n```C#\n        public static BpeTokenizer Create(\n                                string vocabFile,\n                                string? mergesFile,\n                                PreTokenizer? preTokenizer = null,\n                                Normalizer? normalizer = null,\n                                IReadOnlyDictionary<string, int>? specialTokens = null,\n                                string? unknownToken = null,\n                                string? continuingSubwordPrefix = null,\n                                string? endOfWordSuffix = null,\n                                bool fuseUnknownTokens = false)\n```\n\nThe proposal here is wrapping all parameters into `BpeOptions` object. \n\n```diff\n\n  namespace Microsoft.ML.Tokenizers\n  {\n      public sealed class BpeTokenizer : Tokenizer\n      {\n+         public static BpeTokenizer Create(BpeOptions options);\n         \n+          public bool? ByteLevel { get; }\n+           public string? BeginningOfSentenceToken { get; }\n\n      }\n\n+     public sealed class BpeOptions\n+     {\n+         public BpeOptions(System.Collections.Generic.IEnumerable<(string, int)> vocabulary);\n+\n+         public string? BeginningOfSentenceToken { get; set; }\n+         public string? ContinuingSubwordPrefix { get; set; }\n+         public string? EndOfSentenceToken { get; set; }\n+         public string? EndOfWordSuffix { get; set; }\n+         public bool? FuseUnknownTokens { get; set; }\n+         public IEnumerable<string>? Merges { get; set; }\n+         public Normalizer? Normalizer { get; set; }\n+         public PreTokenizer? PreTokenizer { get; set; }\n+         public IReadOnlyDictionary<string, int> SpecialTokens { get; set; }\n+         public string? UnknownToken { get; set; }\n+         public IEnumerable<(string, int)> Vocabulary { get; }\n+         public bool? ByteLevel { get; set; }\n+     }\n```\n\n**Notes**\n\n* Added a new `ByteLevel` property to enable BPE tokenizer support for [`ByteLevel`](https://github.com/huggingface/tokenizers/blob/916df542684d5f2333c0ba1140deda64efa5cf91/bindings/python/py_src/tokenizers/implementations/byte_level_bpe.py#L10). This handles vocabularies stored as bytes (typically UTF-8 encoded) and ensures text is pre-tokenized accordingly.\n* Introduced `BeginningOfSentenceToken`, an optional token that can be inserted at the start when encoding text.\n* `Vocab` and `Merges` are now passed as `IEnumerable` to provide flexibility, since these data sources may come from different origins.\n\n### SentencePieceTokenizer \n\nWe already have `LlamaTokenizer.Create`, with `LlamaTokenizer` subclassing `SentencePieceTokenizer`. Since `SentencePieceTokenizer` now supports multiple internal models (`Bpe` and `Unigram`), we should expose the `Create` method directly from `SentencePieceTokenizer` rather than exposing separate classes for each model. The model type is already embedded in the tokenizer file passed to `Create`.\n\n```C#\n        public static new LlamaTokenizer.Create(Stream modelStream, bool addBeginOfSentence = true, bool addEndOfSentence = false, IReadOnlyDictionary<string, int>? specialTokens = null)\n```\n\nThe proposal is to have the following Create method:\n\n```diff\n  namespace Microsoft.ML.Tokenizers\n  {\n\n      public class SentencePieceTokenizer : Microsoft.ML.Tokenizers.Tokenizer\n      {\n+         public static SentencePieceTokenizer Create(Stream modelStream, bool addBeginOfSentence = true, bool addEndOfSentence = false, IReadOnlyDictionary<string, int> specialTokens = null);\n      }\n   }\n```\n\n### CompositePreTokenizer\n\nA pre-tokenizer is used to split input text into smaller chunks before tokenization and encoding. In some scenarios, such as DeepSeek, multiple pre-tokenizers are required to run in sequence. To support this, the proposal is to introduce a `CompositePreTokenizer`, which implements the `PreTokenizer` abstraction.\n\n```diff\n  namespace Microsoft.ML.Tokenizers\n  {\n+     public class CompositePreTokenizer : PreTokenizer\n+     {\n+         public CompositePreTokenizer(IReadOnlyList<Tokenizers.PreTokenizer> preTokenizers, IReadOnlyDictionary<string, int> specialTokens = null);\n+         public IReadOnlyList<PreTokenizer> PreTokenizers { get; }\n\n           public override IEnumerable<(int, int)> PreTokenize(System.ReadOnlySpan<char> text);\n           public override IEnumerable<(int, int)> PreTokenize(string text);\n+     }\n   }\n```","Url":"https://github.com/dotnet/machinelearning/issues/7512","RelatedDescription":"Closed issue \"Added Tokenizer's APIs for v2\" (#7512)"},{"Id":"3474798955","IsPullRequest":true,"CreatedAt":"2025-10-01T22:34:40","Actor":"tarekgh","Number":"7513","RawContent":null,"Title":"Address the design review feedback","State":"closed","Body":"Fixes https://github.com/dotnet/machinelearning/issues/7512","Url":"https://github.com/dotnet/machinelearning/pull/7513","RelatedDescription":"Closed or merged PR \"Address the design review feedback\" (#7513)"},{"Id":"3328117397","IsPullRequest":true,"CreatedAt":"2025-10-01T17:40:27","Actor":"KM5075","Number":"7496","RawContent":null,"Title":"Fix minor typo in BinFinder.cs","State":"closed","Body":"Fix a minor typo in a comment within BinFinder.cs. No functional changes.","Url":"https://github.com/dotnet/machinelearning/pull/7496","RelatedDescription":"Closed or merged PR \"Fix minor typo in BinFinder.cs\" (#7496)"},{"Id":"3428821552","IsPullRequest":false,"CreatedAt":"2025-10-01T17:32:09","Actor":"asp2286","Number":"7509","RawContent":null,"Title":"MacOS_x64 Debug/Release build jobs fail in MachineLearning-CI: “Bash exited with code '1' – Install MacOS build dependencies”","State":"closed","Body":" - OS & Version: macOS hosted agents (Azure Pipelines), osx.13 (macOS 13.x), x64 only\n - ML.NET Version: current main (MachineLearning-CI)\n - .NET Version: per repo global.json (targets .NET 8)\n\nIn the MachineLearning-CI pipeline, only the macOS x64 jobs fail at the Install MacOS build dependencies step with:\nBash exited with code '1'\n\nSteps to reproduce the behavior:\n1. Azure DevOps → Pipelines → MachineLearning-CI.\n2. Queue on main with defaults.\n3. Observe MacOS_x64 Debug_Build and MacOS_x64 Release_Build.\n4. See error\n\nExpected behavior\nmacOS x64 Debug/Release should install dependencies and proceed to build/tests like other jobs.\n\nScreenshots\n<img width=\"1709\" height=\"1029\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bc1c9f24-56b5-4f0b-a79b-3d64ce81e38b\" />\n\nAdditional context\nLikely macOS dependency bootstrap issue, possibly due to:\nHomebrew formula drift (OpenMP): libomp standalone formula may be missing/renamed on current images","Url":"https://github.com/dotnet/machinelearning/issues/7509","RelatedDescription":"Closed issue \"MacOS_x64 Debug/Release build jobs fail in MachineLearning-CI: “Bash exited with code '1' – Install MacOS build dependencies”\" (#7509)"},{"Id":"3429005106","IsPullRequest":true,"CreatedAt":"2025-10-01T17:32:08","Actor":"asp2286","Number":"7510","RawContent":null,"Title":"macOS x64 CI: fix dependency install and OpenMP runtime copy (use Homebrew libomp, adjust Helix payload)","State":"closed","Body":"# PR: macOS x64 CI: fix dependency install and OpenMP runtime copy\r\n\r\n### Summary\r\nThis PR fixes **MachineLearning-CI** failures on **macOS x64** where jobs stop at *Install MacOS build dependencies* with:\r\n\r\n```\r\nBash exited with code '1'\r\n```\r\n\r\nThe breakage comes from two areas:\r\n1. **Dependency install**: The pipeline relied on a custom `libomp.rb` path that no longer works on hosted macOS images.\r\n2. **Helix payload**: The script attempted to copy both `libomp.dylib` and `libiomp5.dylib`, but `libiomp5.dylib` is not available when installing `libomp` from Homebrew core.\r\n\r\n**Fixes #7509**\r\n\r\n---\r\n\r\n### Changes\r\n#### `build/ci/job-template.yml`\r\n- Replace custom `brew install …/build/libomp.rb` with standard Homebrew:\r\n  ```bash\r\n  brew update\r\n  brew install -f --overwrite python@3.13\r\n  brew install libomp\r\n  brew link libomp --force\r\n  ```\r\n- Note added: Homebrew ≥4.6 rejects installing formulae from raw paths.\r\n\r\n#### `eng/helix.proj`\r\n- macOS **x64 only**:\r\n  - Set `DYLD_LIBRARY_PATH` so Helix can find `libomp.dylib`.\r\n  - Copy only `/usr/local/opt/libomp/lib/libomp.dylib` into the publish folder.\r\n  - Remove copying of `libiomp5.dylib` (not present with `libomp` from Homebrew).\r\n  - Add install-name fix so binaries reference `@loader_path/libomp.dylib`.\r\n\r\n---\r\n\r\n### Why\r\n- Hosted macOS runners changed: raw formula paths are blocked, and only `libomp` is available via core.\r\n- Ensures reliable dependency install and payload runtime linking.\r\n- Other platforms (Linux, Windows, macOS arm64) are unaffected.\r\n\r\n---\r\n\r\n### Testing\r\n- Reproduced failure on `osx.13.amd64.open` queue.\r\n- With these changes:\r\n  - Dependency install step completes successfully.\r\n  - `libomp.dylib` is present in publish folder.\r\n  - Helix payload runs with `DYLD_LIBRARY_PATH` set correctly.\r\n- Validated in a test run: both macOS x64 Debug/Release proceed past dependency install and build succeeds.\r\n\r\n---\r\n\r\n### Risk / Impact\r\n- **Low**: scoped only to macOS x64 build dependencies and Helix payload.\r\n- No product code changes, only CI infra adjustments.\r\n\r\n---\r\n\r\n### Additional Notes\r\n- Linux and Windows jobs were already green.\r\n- If maintainers prefer `llvm` over `libomp` as the OpenMP provider, happy to adjust.\r\n\r\n---\r\n\r\n### PR Checklist\r\n- [x] **CLA signed**\r\n- [x] **Tests**: N/A (CI infra only)\r\n- [x] **Docs**: N/A (no public-facing change)\r\n- [x] **Breaking change**: No\r\n- [x] **Linked issue**: #7509\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7510","RelatedDescription":"Closed or merged PR \"macOS x64 CI: fix dependency install and OpenMP runtime copy (use Homebrew libomp, adjust Helix payload)\" (#7510)"},{"Id":"3455354145","IsPullRequest":true,"CreatedAt":"2025-09-26T01:24:01","Actor":"tarekgh","Number":"7511","RawContent":null,"Title":"Mark internal classes as internal","State":"closed","Body":"We unintentionally marked two internal classes as public. The change is to mark them back as internal. ","Url":"https://github.com/dotnet/machinelearning/pull/7511","RelatedDescription":"Closed or merged PR \"Mark internal classes as internal\" (#7511)"},{"Id":"3403171990","IsPullRequest":true,"CreatedAt":"2025-09-18T07:21:00","Actor":"asp2286","Number":"7501","RawContent":null,"Title":"CI(macOS x64): install libomp from Homebrew Core (drop local libomp.rb)","State":"closed","Body":"# Fix macOS x64 CI: install `libomp` via Homebrew tap (no local formula)\r\n\r\n**Branch:** `fix-macos-libomp`  \r\n**Scope:** CI only – changes limited to `build/ci/job-template.yml` (macOS x64 job)\r\n\r\n---\r\n\r\n## What & Why\r\n\r\nOn **macOS x64** jobs, our pipeline tries to install OpenMP via a *local* Homebrew formula:\r\n\r\n```bash\r\nbrew install $(Build.SourcesDirectory)/build/libomp.rb --build-from-source --formula\r\n```\r\n\r\nRecent Homebrew (4.6+) rejects local, untapped formulae and fails with:\r\n\r\n```\r\nHomebrew requires formulae to be in a tap, rejecting:\r\n  /Users/runner/work/1/s/build/libomp.rb\r\nTo create a tap, run e.g. brew tap-new <user|org>/<repository>\r\n```\r\n\r\nThis does **not** affect `macOS_cross_arm64` jobs because they already use the official `homebrew/core` formula (`brew install libomp`).\r\n\r\n### The fix\r\n\r\nFor **macOS x64** only, switch to the official tap-hosted formula and force a link so the headers and libs are discoverable by our native builds:\r\n\r\n```yaml\r\n# Before (failing; local .rb file)\r\nexport HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=TRUE && brew install $(Build.SourcesDirectory)/build/libomp.rb --build-from-source --formula\r\n\r\n# After (working; official tap)\r\nbrew update && brew install libomp && brew link libomp --force\r\n```\r\n\r\nNo product/code changes; **CI infra-only**.\r\n\r\n---\r\n\r\n## Validation\r\n\r\n- ✅ Verified the failing step is isolated to `macOS_x64` with the error above.\r\n- ✅ `macOS_cross_arm64` continues to use the official tap and succeeds.\r\n- ✅ Local repro on a GitHub-hosted macOS runner using the new commands installs `libomp` and exposes headers (`/usr/local/opt/libomp/include`) and libs (`/usr/local/opt/libomp/lib`).\r\n\r\n> Note: Homebrew marks `libomp` as *keg-only*. The `brew link ... --force` step ensures the toolchain sees it without extra flags. If we ever want to avoid `--force`, we can export:\r\n>\r\n> ```bash\r\n> export CPPFLAGS=\"-I/usr/local/opt/libomp/include\"\r\n> export LDFLAGS=\"-L/usr/local/opt/libomp/lib\"\r\n> ```\r\n\r\n---\r\n\r\n## Risk & Impact\r\n\r\n- **Risk:** Low. The change only affects the CI macOS x64 dependency-install step.\r\n- **Impact:** Unblocks native builds on macOS x64 by ensuring OpenMP is available.\r\n- **No Changes** to shipping packages, versioning, public APIs, or runtime behavior.\r\n\r\n---\r\n\r\n## Alternative considered\r\n\r\n- Creating and maintaining a custom Homebrew tap for `libomp.rb`. Rejected to avoid long‑term maintenance overhead when the official formula suffices.\r\n\r\n---\r\n\r\n## Change summary\r\n\r\n- Update `build/ci/job-template.yml` macOS x64 path:\r\n  - Replace local formula install with `brew update && brew install libomp && brew link libomp --force`.\r\n  - **No changes** to the ARM cross path (already uses official tap).\r\n\r\n---\r\n\r\n## How to verify in CI\r\n\r\n1. Queue the pipeline for `macOS_x64 Debug_Build`.\r\n2. Confirm the step **Install MacOS build dependencies** succeeds, showing:\r\n   - *“Pouring libomp…”, “Linking … 6 symlinks created”*\r\n3. Validate native build succeeds (CpuMathNative, FastTreeNative, etc.).\r\n4. Ensure no downstream targets rely on `OneDalNative` on macOS unless explicitly provided (unrelated to this PR).\r\n\r\n---\r\n\r\n## Notes for maintainers\r\n\r\n- This PR **does not** modify any source under `src/` or packaging. It is safe to service‑merge.\r\n- If future runners transition to Apple Silicon-only, this step remains valid (Homebrew tap still provides `libomp`).\r\n\r\n---\r\n\r\n## Checklist (author)\r\n\r\n- [x] CI-only change; no product code.\r\n- [x] macOS x64 path updated; ARM path unchanged.\r\n- [x] Verified the new commands succeed on a runner.\r\n- [x] Added rationale & reproduction details in this PR description.\r\n\r\n<!--\r\nMaintainer checklist (adapted from Reviewer_Checklist.md). Keep collapsed in the PR body.\r\n\r\n- [ ] CI is green on all required legs.\r\n- [ ] Affected area scoped to CI; no shipping assets changed.\r\n- [ ] No public API changes; no breaking changes.\r\n- [ ] Build/install steps use supported, tap-hosted Homebrew formulae (no local .rb files).\r\n- [ ] Windows/Linux pipelines unaffected.\r\n- [ ] No additional credentials, secrets, or taps required.\r\n- [ ] If later backported, the YAML path exists in the target branch.\r\n- [ ] PR title and labels reflect “infra/CI” nature.\r\n-->\r\n\r\n---\r\n\r\n### Screenshots / logs (for context)\r\n\r\n**Failure (before):**\r\n```\r\nError: Homebrew requires formulae to be in a tap, rejecting:\r\n  /Users/runner/work/1/s/build/libomp.rb\r\n```\r\n\r\n**Success (after):**\r\n```\r\n==> Fetching downloads for: libomp\r\n==> Pouring libomp--<version>.ventura.bottle.tar.gz\r\nLinking /usr/local/Cellar/libomp/<version>... 6 symlinks created.\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7501","RelatedDescription":"Closed or merged PR \"CI(macOS x64): install libomp from Homebrew Core (drop local libomp.rb)\" (#7501)"},{"Id":"3401672315","IsPullRequest":true,"CreatedAt":"2025-09-18T07:20:27","Actor":"asp2286","Number":"7500","RawContent":null,"Title":"macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)","State":"closed","Body":"# macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)\r\n\r\n**Problem**\r\nOn macOS x64, building `src/Native` fails with:\r\n```\r\nfatal error: 'daal.h' file not found\r\n```\r\nThe oneDAL “devel” (headers) package is not available via NuGet for `osx-x64`, so locally `ONEDAL_DEVEL_PATH` is not present and `OneDalNative` cannot compile. Today the native CMake unconditionally includes `OneDalNative` on x64, which makes a default macOS developer build fail.\r\n\r\n**What this PR changes**\r\n- Gate `add_subdirectory(OneDalNative)` behind explicit configuration:\r\n  - Only include `OneDalNative` when both `ONEDAL_DEVEL_PATH` and `ONEDAL_REDIST_PATH` are defined **and** `${ONEDAL_DEVEL_PATH}/include/daal.h` exists.\r\n  - Otherwise, print an informative `message(STATUS ...)` and skip `OneDalNative`.\r\n\r\n**Why this is safe**\r\n- Windows/Linux CI builds that pass `ONEDAL_*` continue to build `OneDalNative` unchanged.\r\n- macOS builds (where oneDAL headers aren’t available via NuGet by default) no longer fail—they build the rest of the native components and skip `OneDalNative`.\r\n- No changes to `build.sh` are required. The script already sets `-DONEDAL_*` only when callers pass the corresponding command-line switches.\r\n\r\n**Repro (before)**\r\n```\r\n# macOS x64 without oneDAL headers\r\ncmake ... && make\r\n# -> OneDalNative/OneDalAlgorithms.cpp: fatal error: 'daal.h' file not found\r\n```\r\n\r\n**Behavior (after)**\r\n- If `ONEDAL_*` not provided: CMake prints `Skipping OneDalNative: ONEDAL_DEVEL_PATH/ONEDAL_REDIST_PATH not set` and the rest builds fine.\r\n- If `ONEDAL_*` provided and `${ONEDAL_DEVEL_PATH}/include/daal.h` exists: `OneDalNative` builds as before.\r\n\r\n**Test matrix**\r\n- ✅ macOS x64 (Intel): builds successfully; `OneDalNative` skipped by default; other native targets build.\r\n- ✅ macOS arm64 (Apple Silicon): previously didn’t include `OneDalNative` (arch guard); behavior unchanged.\r\n- ✅ Linux/Windows (CI): when `ONEDAL_*` are set (as in existing pipelines), behavior unchanged and `OneDalNative` builds.\r\n\r\n**Notes**\r\n- This PR intentionally doesn’t alter OpenMP handling or `SymSgdNative`. On macOS x64, developers who need `SymSgdNative` can use Homebrew LLVM (`brew install llvm libomp`) or provide appropriate OpenMP flags; that is orthogonal to oneDAL headers availability.\r\n- We can later add an explicit `-DMLNET_BUILD_ONEDAL=ON/OFF` flag for stricter control if maintainers prefer.","Url":"https://github.com/dotnet/machinelearning/pull/7500","RelatedDescription":"Closed or merged PR \"macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)\" (#7500)"},{"Id":"3384268007","IsPullRequest":true,"CreatedAt":"2025-09-18T07:20:04","Actor":"asp2286","Number":"7497","RawContent":null,"Title":"Add experimental IsolationForest trainer for ML.NET","State":"closed","Body":"## Related issues\r\nFixes #3043\r\n\r\n# Add Isolation Forest Anomaly Detection Trainer (Experimental)\r\n\r\nThis PR adds an **Isolation Forest** anomaly detection trainer for ML.NET.  \r\nIsolation Forest (Liu, Ting, Zhou, 2008) is a tree-ensemble algorithm for unsupervised anomaly detection that isolates outliers via random partitioning. It complements existing ML.NET anomaly detectors (e.g., SR-CNN, IID) with a density-agnostic approach.\r\n\r\n---\r\n\r\n## Motivation\r\n- Provide a widely-used, general-purpose anomaly detection method.  \r\n- Works without strong distribution assumptions.  \r\n- Produces both a continuous anomaly score and a binary label.  \r\n- Achieves parity with popular libraries like scikit-learn.\r\n\r\n---\r\n\r\n## Design (v1, Experimental)\r\n- **Core engine**: `IsolationForestModel` (pure C#) implements random partitioning trees, scoring, and SHAP-like path contributions.  \r\n- **Pipeline integration**: `IsolationForestTrainer : IEstimator<ITransformer>` appends:\r\n  - `Score` (float, scaled 0–100; higher = more anomalous),\r\n  - `PredictedLabel` (bool), thresholded by `Contamination` or explicit override.  \r\n- **Options**:\r\n  - `Trees`\r\n  - `SampleSize (psi)`\r\n  - `Seed`\r\n  - `Contamination`\r\n  - `ParallelBuild`\r\n  - `ThresholdOverride`\r\n\r\n> ⚠️ **Experimental note**: v1 uses `CustomMapping` internally. Models trained with this trainer cannot currently be persisted with `mlContext.Model.Save()`. A follow-up will introduce a proper `IsolationForestTransformer` with save/load and efficient row-mapping.\r\n\r\n---\r\n\r\n## Usage\r\n```csharp\r\nvar pipeline = ml.Transforms.Concatenate(\"Features\", \"X1\", \"X2\")\r\n    .Append(new IsolationForestTrainer(new IsolationForestTrainer.Options\r\n    {\r\n        Trees = 200,\r\n        SampleSize = 256,\r\n        Contamination = 0.02\r\n    }));\r\n\r\nvar model = pipeline.Fit(data);\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7497","RelatedDescription":"Closed or merged PR \"Add experimental IsolationForest trainer for ML.NET\" (#7497)"},{"Id":"3420501783","IsPullRequest":false,"CreatedAt":"2025-09-16T05:38:37","Actor":"williamlzw","Number":"7507","RawContent":null,"Title":"vocab.json of qwen3 model cannot be loaded into Tokenizer","State":"open","Body":"The vocab.json of the qwen3 model does not contain \"added_tokens\" and cannot be loaded into the Tokenizer.\n\n<img width=\"420\" height=\"647\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/938bce80-4d52-46dd-bd90-39ab82a59095\" />","Url":"https://github.com/dotnet/machinelearning/issues/7507","RelatedDescription":"Open issue \"vocab.json of qwen3 model cannot be loaded into Tokenizer\" (#7507)"},{"Id":"3420170018","IsPullRequest":false,"CreatedAt":"2025-09-16T03:18:53","Actor":"williamlzw","Number":"7506","RawContent":null,"Title":"It's recommended that base classes use fewer internal methods.","State":"open","Body":"It's recommended that base classes use fewer internal methods. I need to write a Qwen3Tokenizer class based on the CodeGenTokenizer class. I've noticed that many methods are internal. I'm forced to define a CodeGenTokenizerA class to write the Qwen3Tokenizer class.","Url":"https://github.com/dotnet/machinelearning/issues/7506","RelatedDescription":"Open issue \"It's recommended that base classes use fewer internal methods.\" (#7506)"},{"Id":"3420060036","IsPullRequest":false,"CreatedAt":"2025-09-16T02:09:14","Actor":"williamlzw","Number":"7505","RawContent":null,"Title":"The ph3 model decodes Chinese characters and displays garbled characters.","State":"open","Body":"<img width=\"434\" height=\"112\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2baa0814-0334-42a4-99f0-8b96fe53da14\" />\n\n```\nusing Microsoft.ML.Tokenizers;\nusing Microsoft.ML.GenAI.Phi;\nusing Microsoft.ML.GenAI.Core;\nusing Microsoft.Extensions.AI;\n\n\npublic class Program\n{\n    public async static void TestPhi3()\n    {\n        string device = \"cuda\";\n        var weightFolder = @\"G:\\model\\Phi-3-mini-128k-instruct\";\n        var model = Phi3ForCausalLM.FromPretrained(weightFolder, \"config.json\", layersOnTargetDevice: -1, quantizeToInt4: true, targetDevice: device);\n        var modelPath = Path.Join(weightFolder, \"tokenizer.model\");\n        var tokenizer = Phi3TokenizerHelper.FromPretrained(modelPath);\n        var pipeline = new CausalLMPipeline<Tokenizer, Phi3ForCausalLM>(tokenizer, model, device);\n        var client = new Phi3CausalLMChatClient(pipeline);\n        var task = \"\"\"\n            你能讲一个有趣的笑话吗?\n            \"\"\";\n        List<ChatMessage> _chatHistory = new();\n        _chatHistory.Add(new ChatMessage(ChatRole.System, \"你是一个助手,用中文回答用户的问题\"));\n        _chatHistory.Add(new ChatMessage(ChatRole.User, task));\n        var options = new ChatOptions\n        {\n            StopSequences = [\"<|end_of_text|>\"],//phi3\n            AdditionalProperties = new() { { \"max_length\", 2048 } },\n        };\n        await foreach (var response in client.GetStreamingResponseAsync(_chatHistory, options))\n        {\n            Console.Write(response.Text);\n        }\n\n        Console.WriteLine();\n        Console.WriteLine(\"End!\");\n    }\n\n    public static void Main()\n    {\n        TestPhi3();\n    }\n}\n```\n\n<img width=\"477\" height=\"125\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f53c2e65-8c32-4e91-8010-f567baa66bef\" />","Url":"https://github.com/dotnet/machinelearning/issues/7505","RelatedDescription":"Open issue \"The ph3 model decodes Chinese characters and displays garbled characters.\" (#7505)"},{"Id":"3413291798","IsPullRequest":false,"CreatedAt":"2025-09-13T11:55:48","Actor":"asp2286","Number":"7502","RawContent":null,"Title":"Proposal: Pluggable RNG in MLContext (enable deterministic, portable RNGs like MT19937)","State":"open","Body":"## Summary\n\nI propose adding a minimal extension point to let users inject a custom RNG into `MLContext`, without changing defaults or breaking back-compat. This enables deterministic, portable randomness across platforms and languages (e.g., align with C++ `std::mt19937`), and allows advanced users to choose an RNG that matches their reproducibility requirements.\n\n## Motivation\n\n- **Reproducibility across ecosystems**: Many data science stacks standardize on MT19937 (e.g., C++ `std::mt19937`, NumPy’s legacy PCG/MT usage), making it easier to compare experiments when the same PRNG is available in ML.NET.\n- **Zero impact by default**: Default behavior remains unchanged and backwards compatible.\n- **Testability**: Easier to write bitwise-stable tests that don’t depend on underlying `System.Random` variations.\n\n## Design\n\nAdd a small interface and an optional parameter to `MLContext`:\n\n```csharp\npublic interface IRandomSource\n{\n    int Next();\n    int Next(int maxValue);\n    int Next(int minValue, int maxValue);\n    long NextInt64();\n    long NextInt64(long maxValue);\n    long NextInt64(long minValue, long maxValue);\n    double NextDouble();\n    float NextSingle();\n    void NextBytes(Span<byte> buffer);\n}\n\n// Existing constructor remains\npublic sealed class MLContext\n{\n    public MLContext(int? seed = null) : this(seed, rng: null) { }\n\n    public MLContext(int? seed, IRandomSource? rng)\n    {\n        _rng = rng ?? new RandomSourceAdapter(seed is null ? Random.Shared : new Random(seed.Value));\n        // ... existing initialization\n    }\n\n    internal IRandomSource RandomSource => _rng;\n    private readonly IRandomSource _rng;\n}\n\ninternal sealed class RandomSourceAdapter : IRandomSource\n{\n    private readonly Random _rand;\n    public RandomSourceAdapter(Random rand) => _rand = rand;\n    public int Next() => _rand.Next();\n    public int Next(int maxValue) => _rand.Next(maxValue);\n    public int Next(int minValue, int maxValue) => _rand.Next(minValue, maxValue);\n    public long NextInt64() => _rand.NextInt64();\n    public long NextInt64(long maxValue) => _rand.NextInt64(maxValue);\n    public long NextInt64(long minValue, long maxValue) => _rand.NextInt64(minValue, maxValue);\n    public double NextDouble() => _rand.NextDouble();\n    public float NextSingle() => _rand.NextSingle();\n    public void NextBytes(Span<byte> buffer) => _rand.NextBytes(buffer);\n}\n","Url":"https://github.com/dotnet/machinelearning/issues/7502","RelatedDescription":"Open issue \"Proposal: Pluggable RNG in MLContext (enable deterministic, portable RNGs like MT19937)\" (#7502)"},{"Id":"3396378196","IsPullRequest":false,"CreatedAt":"2025-09-09T03:07:34","Actor":"JoshuaSloan","Number":"7498","RawContent":null,"Title":"FastForest NumberOfLeaves hyperparameter not updating in Regression/MulticlassClassification SweepablePipeline","State":"open","Body":"**System Information (please complete the following information):**\n - OS & Version: Windows 11\n - ML.NET Version: ML.NET v4.0.2\n - .NET Version: .NET 9.0\n\n**Describe the bug**\nFastForestRegression and FastForestOva (unlike FastForestBinary) do not modify the NumberOfLeaves hyperparameter despite being defined in the associated [search space](https://github.com/dotnet/machinelearning/blob/fb39755f143b1a2969f20b0597e58083dc306e5a/src/Microsoft.ML.AutoML/CodeGen/fast_forest_search_space.json?plain=1#L16). Consequently, while performance for BinaryClassification is on par with comparable AutoML frameworks (e.g. [FLAML](https://github.com/microsoft/FLAML) using exclusively RandomForest), it falls behind for the other task types.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Train an AutoML experiment using a SweepablePipeline for either Regression or MulticlassClassification\n2. Set all non-FastForest trainers to false (such that only FastForest remains)\n3. Append an experiment monitor and log the TrialResult.TrialSettings.Parameters\n4. Compare the best model to the reported parameters\n\n**Expected behavior**\nI would expect the model hyperparameters logged from the experiment monitor's final ReportBestTrial() method to match the best model obtained from the experiment. However, while other model hyperparameters are in alignment, the NumberOfLeaves looks suspiciously like the [default](https://github.com/dotnet/machinelearning/blob/fb39755f143b1a2969f20b0597e58083dc306e5a/src/Microsoft.ML.FastTree/FastTreeArguments.cs?plain=1#L340) FastTree value. \n\n**Screenshots, Code, Sample Projects**\n*Trial 31 obtained new best model with (loss: 63689.36950302901, metric: 63689.36950302901)\n{\"_pipeline_\":{\"_SCHEMA_\":\"e0 * e2 * e3 * e4\",\"e0\":{\"OutputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"],\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]},\"e2\":{\"OutputColumnNames\":[\"ocean_proximity\"],\"InputColumnNames\":[\"ocean_proximity\"]},\"e3\":{\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"ocean_proximity\"],\"OutputColumnName\":\"Features\"},\"e4\":{<mark>\"NumberOfTrees\":15,\"NumberOfLeaves\":81</mark>,\"FeatureFraction\":0.8326445,\"LabelColumnName\":\"median_house_value\",\"FeatureColumnName\":\"Features\"}},\"_SCHEMA_\":\"e0 * e1 * e3 * e4\",\"e0\":{\"OutputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"],\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]},\"e1\":{\"OutputColumnNames\":[\"ocean_proximity\"],\"InputColumnNames\":[\"ocean_proximity\"]},\"e2\":{\"OutputColumnNames\":[\"ocean_proximity\"],\"InputColumnNames\":[\"ocean_proximity\"]},\"e3\":{\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"ocean_proximity\"],\"OutputColumnName\":\"Features\"},\"e4\":{\"NumberOfTrees\":100,\"NumberOfLeaves\":100,\"FeatureFraction\":1,\"LabelColumnName\":\"median_house_value\",\"FeatureColumnName\":\"Features\"}}*\n\n<img width=\"1696\" height=\"894\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2547b614-ddfd-47af-9481-c2c18fc13e52\" />\n","Url":"https://github.com/dotnet/machinelearning/issues/7498","RelatedDescription":"Open issue \"FastForest NumberOfLeaves hyperparameter not updating in Regression/MulticlassClassification SweepablePipeline\" (#7498)"},{"Id":"3320905110","IsPullRequest":false,"CreatedAt":"2025-08-14T07:58:05","Actor":"games","Number":"7495","RawContent":null,"Title":"Microsoft.ML.LightGbm not supported on Mac M1 – 'lib_lightgbm' (no such file)","State":"closed","Body":"**System Information (please complete the following information):**\n - OS & Version: macOS 15.6\n - ML.NET Version: ML.NET v4.0.2\n - .NET Version: .NET 9.0\n\n**Describe the bug**\nWhen attempting to use Microsoft.ML.LightGbm on an Apple Silicon Mac (M1), the package fails to load due to a missing native library dependency. The error message is:\n\nUnhandled exception. System.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. dotnet new console\n2. add packages \n4. copy the sample code from here (https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet-preview)\n5. dotnet run\n6. see error: unhandled exception. System.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable:\n\n**Expected behavior**\nLightGBM should run on Mac M1\n\n**Screenshots, Code, Sample Projects**\npackages version\n```xml\n    <PackageReference Include=\"Microsoft.ML\" Version=\"4.0.2\" />\n    <PackageReference Include=\"Microsoft.ML.LightGbm\" Version=\"4.0.2\" />\n```\n\n**Additional context**\n\nlib_lightgbm.dylib is missing in `osx-arm64`\n\n<img width=\"736\" height=\"742\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0c890d9d-256c-4b66-8451-25558d01e35e\" />\n","Url":"https://github.com/dotnet/machinelearning/issues/7495","RelatedDescription":"Closed issue \"Microsoft.ML.LightGbm not supported on Mac M1 – 'lib_lightgbm' (no such file)\" (#7495)"},{"Id":"3298376543","IsPullRequest":false,"CreatedAt":"2025-08-11T15:17:21","Actor":"stephentoub","Number":"7491","RawContent":null,"Title":"Incorporate new harmony tiktoken vocabulary","State":"closed","Body":"The recently released OSS openai models come with a new vocabulary. The TiktokenTokenizer should be updated accordingly.\n\nhttps://github.com/openai/tiktoken/commit/3591ff175d6a80efbe4fcc7f0e219ddd4b8c52f1\n\ncc: @tarekgh","Url":"https://github.com/dotnet/machinelearning/issues/7491","RelatedDescription":"Closed issue \"Incorporate new harmony tiktoken vocabulary\" (#7491)"},{"Id":"3307004234","IsPullRequest":true,"CreatedAt":"2025-08-11T15:17:20","Actor":"tarekgh","Number":"7494","RawContent":null,"Title":"Support OpenAI OSS Models with Tiktoken tokenizer","State":"closed","Body":"Fixes https://github.com/dotnet/machinelearning/issues/7491","Url":"https://github.com/dotnet/machinelearning/pull/7494","RelatedDescription":"Closed or merged PR \"Support OpenAI OSS Models with Tiktoken tokenizer\" (#7494)"},{"Id":"3301258241","IsPullRequest":true,"CreatedAt":"2025-08-07T17:02:50","Actor":"JoshuaSloan","Number":"7493","RawContent":null,"Title":"Fix PositiveRecall optimization in AutoMLExperiment","State":"open","Body":"BinaryClassificationMetric.PositiveRecall incorrectly returns PositivePrecision.\r\n\r\nI noticed this when testing an early stopping pipeline and found that the logged best trial metric did not align with the final model results. This is a self-evident fix (akin to a small typo), so I did not open a new issue for it.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.","Url":"https://github.com/dotnet/machinelearning/pull/7493","RelatedDescription":"Open PR \"Fix PositiveRecall optimization in AutoMLExperiment\" (#7493)"}],"ResultType":"GitHubIssue"}},"RunOn":"2025-10-04T03:30:22.1026177Z","RunDurationInMilliseconds":612}