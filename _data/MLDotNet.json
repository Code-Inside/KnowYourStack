{"Data":{"GitHub":{"Issues":[{"Id":"1693692062","IsPullRequest":false,"CreatedAt":"2023-05-05T00:46:48","Actor":"superichmann","Number":"6644","RawContent":null,"Title":"AutoML Regression Experiment Crash","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10 \r\n - ML.NET Version: ML.NET v2.0.1 automl 0.20.1\r\n - .NET Version: e.g. .NET 6.0\r\n\r\n**Describe the bug**\r\nAutoML Experiment crash\r\n\r\n**To Reproduce**\r\nI am doing autoML on data from database.. but attached is the csv of that data\r\n[automlbug.csv](https://github.com/dotnet/machinelearning/files/11381029/automlbug.csv)\r\nsplit train test fraction -> 0.01\r\n100 seconds experiment\r\ntarget column sales\r\npreFeaturizer->doubletosingle\r\nOptimization metric: RegressionMetric.MeanAbsoluteError\r\n\r\n**Expected behavior**\r\nexperiment should not crash\r\n\r\n**Screenshots, Code, Sample Projects**\r\n```\r\n    System.AggregateException: One or more errors occurred. (Index was outside the bounds of the array.) ---> System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n\r\n  Stack Trace:â€‰\r\n    PipelineProposer.ProposeSearchSpace()\r\n    EciCostFrugalTuner.Propose(TrialSettings settings)\r\n    AutoMLExperiment.RunAsync(CancellationToken ct)\r\n    --- End of inner exception stack trace ---\r\n    Task.ThrowIfExceptional(Boolean includeTaskCanceledExceptions)\r\n    Task`1.GetResultCore(Boolean waitCompletionNotification)\r\n    AutoMLExperiment.Run()\r\n    RegressionExperiment.Execute(IDataView trainData, IDataView validationData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6644","RelatedDescription":"Closed issue \"AutoML Regression Experiment Crash\" (#6644)"},{"Id":"1673902952","IsPullRequest":false,"CreatedAt":"2023-05-05T00:42:39","Actor":"LittleLittleCloud","Number":"6626","RawContent":null,"Title":"Can't load Datetime column when it contains null value","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: window 10\r\n - ML.NET Version: main branch\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nAs title\r\n\r\n#6621 \r\n\r\nWould need to add a null check here\r\nhttps://github.com/dotnet/machinelearning/blob/eb11e43c440f5a22d7b02058eae69422784841a5/src/Microsoft.ML.Data/DataLoadSave/Database/DatabaseLoaderCursor.cs#L307\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6626","RelatedDescription":"Closed issue \"Can't load Datetime column when it contains null value\" (#6626)"},{"Id":"1677498935","IsPullRequest":true,"CreatedAt":"2023-05-05T00:42:38","Actor":"LittleLittleCloud","Number":"6627","RawContent":null,"Title":"fix datetime null error","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nfix #6626 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/6627","RelatedDescription":"Closed or merged PR \"fix datetime null error\" (#6627)"},{"Id":"1693542999","IsPullRequest":false,"CreatedAt":"2023-05-04T22:06:44","Actor":"torronen","Number":"6643","RawContent":null,"Title":"AutoML 2.0: how to set sampling key","State":"closed","Body":"**Is your feature request related to a problem? Please describe.**\r\nI am trying to run crossvalidation with a sampling key.\r\n\r\nHowever,  .SetDataset(data, fold: 10); only accepts the number of folds. I can create cross-validation set with sampling key using `ctx.Data.CrossValidationSplit`, but the .SetDataset does not have overload to accept a set of `TrainTestData`.\r\n\r\nHow can I set my own  `IReadOnlyList<TrainTestData> cvdata `  using the new AutoML API ?\r\n\r\nExamples:\r\n```\r\nAutoMLExperiment experiment = ctx.Auto().CreateExperiment();\r\n\r\nIReadOnlyList<TrainTestData> cvdata = ctx.Data.CrossValidationSplit(data, numberOfFolds: 10, samplingKeyColumnName: SamplingKeyColumn); // how to use this in the experiment?\r\n\r\n            // Configure experiment\r\nexperiment\r\n                .SetPipeline(pipeline)\r\n                .SetBinaryClassificationMetric(BinaryClassificationMetric.Accuracy, labelColumn: columnInference.ColumnInformation.LabelColumnName)\r\n                .SetTrainingTimeInSeconds(60)\r\n                .SetDataset(data, fold: 10); //  how to set sampling key?\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6643","RelatedDescription":"Closed issue \"AutoML 2.0: how to set sampling key\" (#6643)"},{"Id":"1694890062","IsPullRequest":true,"CreatedAt":"2023-05-04T22:06:43","Actor":"torronen","Number":"6649","RawContent":null,"Title":"Add SamplingKeyColumnName to AutoMLExperiment API","State":"closed","Body":"Fixes #6643\r\n\r\nAdd sampling key column name to SetDataset method in new AutoML API to easily set sampling key.\r\n\r\nUsage:\r\n```\r\n   experiment\r\n                .SetPipeline(pipeline)\r\n                .SetBinaryClassificationMetric(BinaryClassificationMetric.Accuracy, labelColumn: columnInference.ColumnInformation.LabelColumnName)\r\n                .SetTrainingTimeInSeconds(trainingTimeSeconds)\r\n                .SetDataset(data, fold: NumFolds, samplingKeyColumnName: SamplingKeyColumn);\r\n```\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6649","RelatedDescription":"Closed or merged PR \"Add SamplingKeyColumnName to AutoMLExperiment API\" (#6649)"},{"Id":"1694956335","IsPullRequest":false,"CreatedAt":"2023-05-04T19:59:37","Actor":"LittleLittleCloud","Number":"6650","RawContent":null,"Title":"Should use a different source name for object detection trainer","State":"closed","Body":"![image](https://user-images.githubusercontent.com/16876986/236064448-bc35de01-f066-448a-b9e9-9286c6274608.png)\r\n\r\nShould be `ObjectDetectionTrainer` or something","Url":"https://github.com/dotnet/machinelearning/issues/6650","RelatedDescription":"Closed issue \"Should use a different source name for object detection trainer\" (#6650)"},{"Id":"1694471114","IsPullRequest":true,"CreatedAt":"2023-05-04T19:59:18","Actor":"michaelgsharp","Number":"6646","RawContent":null,"Title":"Added more logging to OBJ-DET","State":"closed","Body":"Added more logging to object detection.","Url":"https://github.com/dotnet/machinelearning/pull/6646","RelatedDescription":"Closed or merged PR \"Added more logging to OBJ-DET\" (#6646)"},{"Id":"1694491089","IsPullRequest":true,"CreatedAt":"2023-05-04T16:27:55","Actor":"michaelgsharp","Number":"6647","RawContent":null,"Title":"Change code coverage build pool to correct pool","State":"closed","Body":"Changed code coverage build pool to the correct pool. These machines are more powerful so hopefully code coverage runs faster and is less flaky.","Url":"https://github.com/dotnet/machinelearning/pull/6647","RelatedDescription":"Closed or merged PR \"Change code coverage build pool to correct pool\" (#6647)"},{"Id":"1696235201","IsPullRequest":false,"CreatedAt":"2023-05-04T15:22:06","Actor":"torronen","Number":"6655","RawContent":null,"Title":"Compiling on Ubuntu 22.04 ( CXX compiler: /usr/bin/clang++ - broken)","State":"open","Body":"Ubuntu 22.04 / Latest main\r\n\r\nI am following the Developer page instructions (https://github.com/dotnet/machinelearning/blob/main/docs/building/unix-instructions.md). However, I get some errors on compiling with c++. As you may guess I mostly work on Windows so it could be just some obvious thing missing.\r\n\r\nCould be clang version, but even if I remove it, then\r\nsudo apt-get install clang-3.9\r\n\r\nclang --version gives:\r\nUbuntu clang version 14.0.0-1ubuntu1\r\nTarget: x86_64-pc-linux-gnu\r\nThread model: posix\r\n\r\n\r\n```\r\n  -- Check for working CXX compiler: /usr/bin/clang++\r\n  -- Check for working CXX compiler: /usr/bin/clang++ - broken\r\n  -- Configuring incomplete, errors occurred!\r\n  CMake Error at /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.26/Modules/CMakeTestCXXCompiler.cmake:60 (message):\r\n    The C++ compiler\r\n\r\n      \"/usr/bin/clang++\"\r\n\r\n    is not able to compile a simple test program.\r\n```\r\n\r\n\r\n\r\n**Full**\r\n```\r\nroot@Ubuntu-2204-jammy-amd64-base ~/torronen/Kwork.Microsoft.ML2023 # ./build.sh\r\n  Determining projects to restore...\r\n  All projects are up-to-date for restore.\r\nAttempting to install dotnet from public_location.\r\ndotnet-install: Note that the intended use of this script is for Continuous Integration (CI) scenarios, where:\r\ndotnet-install: - The SDK needs to be installed without user interaction and without admin rights.\r\ndotnet-install: - The SDK installation doesn't need to persist across multiple CI runs.\r\ndotnet-install: To set up a development environment or to run apps, use installers rather than this script. Visit https://dotnet.microsoft.com/download to get the installer.\r\ndotnet-install: .NET Core Runtime with version '6.0.9' is already installed.\r\n  Determining projects to restore...\r\n  All projects are up-to-date for restore.\r\n  Determining projects to restore...\r\n  All projects are up-to-date for restore.\r\n  /root/torronen/Kwork.Microsoft.ML2023/src/Native/build.sh --configuration Debug --arch x64  --mkllibpath /root/.nuget/packages/mlnetmkldeps/0.0.0.12/runtimes/linux-x64/native --onedalredistpath /root/.nuget/packages/inteldal.redist.linux-x64/2023.0.0.23046/build/native/daal/latest --onedaldevelpath /root/.nuget/packages/inteldal.devel.win-x64/2023.0.0.23189/build/native/daal/latest --onetbbredistpath /root/.nuget/packages/inteltbb.devel.linux/2021.7.1.15005/runtimes/linux-x64/native\r\n  Building Machine Learning native components from /root/torronen/Kwork.Microsoft.ML2023/src/Native to /root/torronen/Kwork.Microsoft.ML2023/artifacts/obj/Native/x64.Debug\r\n  + cmake /root/torronen/Kwork.Microsoft.ML2023/src/Native -G 'Unix Makefiles' -DCMAKE_BUILD_TYPE=Debug -DMKL_LIB_PATH=/root/.nuget/packages/mlnetmkldeps/0.0.0.12/runtimes/linux-x64/native -DONEDAL_REDIST_PATH=/root/.nuget/packages/inteldal.redist.linux-x64/2023.0.0.23046/build/native/daal/latest -DONEDAL_DEVEL_PATH=/root/.nuget/packages/inteldal.devel.win-x64/2023.0.0.23189/build/native/daal/latest -DONETBB_REDIST_PATH=/root/.nuget/packages/inteltbb.devel.linux/2021.7.1.15005/runtimes/linux-x64/native -DVERSION_FILE_PATH:STRING=/root/torronen/Kwork.Microsoft.ML2023/src/Native/../../artifacts/obj/version.c -DARCHITECTURE=x64\r\n  -- The CXX compiler identification is Clang 14.0.0\r\n  -- Detecting CXX compiler ABI info\r\n  -- Detecting CXX compiler ABI info - failed\r\n  -- Check for working CXX compiler: /usr/bin/clang++\r\n  -- Check for working CXX compiler: /usr/bin/clang++ - broken\r\n  -- Configuring incomplete, errors occurred!\r\n  CMake Error at /usr/local/lib/python3.10/dist-packages/cmake/data/share/cmake-3.26/Modules/CMakeTestCXXCompiler.cmake:60 (message):\r\n    The C++ compiler\r\n\r\n      \"/usr/bin/clang++\"\r\n\r\n    is not able to compile a simple test program.\r\n\r\n    It fails with the following output:\r\n\r\n      Change Dir: /root/torronen/Kwork.Microsoft.ML2023/artifacts/obj/Native/x64.Debug/CMakeFiles/CMakeScratch/TryCompile-PaojQZ\r\n\r\n      Run Build Command(s):/usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E env VERBOSE=1 /usr/bin/gmake -f Makefile cmTC_819f1/fast && /usr/bin/gmake  -f CMakeFiles/cmTC_819f1.dir/build.make CMakeFiles/cmTC_819f1.dir/build\r\n      gmake[1]: Entering directory '/root/torronen/Kwork.Microsoft.ML2023/artifacts/obj/Native/x64.Debug/CMakeFiles/CMakeScratch/TryCompile-PaojQZ'\r\n      Building CXX object CMakeFiles/cmTC_819f1.dir/testCXXCompiler.cxx.o\r\n      /usr/bin/clang++    -MD -MT CMakeFiles/cmTC_819f1.dir/testCXXCompiler.cxx.o -MF CMakeFiles/cmTC_819f1.dir/testCXXCompiler.cxx.o.d -o CMakeFiles/cmTC_819f1.dir/testCXXCompiler.cxx.o -c /root/torronen/Kwork.Microsoft.ML2023/artifacts/obj/Native/x64.Debug/CMakeFiles/CMakeScratch/TryCompile-PaojQZ/testCXXCompiler.cxx\r\n      Linking CXX executable cmTC_819f1\r\n      /usr/local/lib/python3.10/dist-packages/cmake/data/bin/cmake -E cmake_link_script CMakeFiles/cmTC_819f1.dir/link.txt --verbose=1\r\n      /usr/bin/clang++ -rdynamic CMakeFiles/cmTC_819f1.dir/testCXXCompiler.cxx.o -o cmTC_819f1\r\n      /usr/bin/ld: cannot find -lstdc++: No such file or directory\r\nclang : error : linker command failed with exit code 1 (use -v to see invocation) [/root/torronen/Kwork.Microsoft.ML2023/src/Native/Native.proj]\r\n      gmake[1]: *** [CMakeFiles/cmTC_819f1.dir/build.make:100: cmTC_819f1] Error 1\r\n      gmake[1]: Leaving directory '/root/torronen/Kwork.Microsoft.ML2023/artifacts/obj/Native/x64.Debug/CMakeFiles/CMakeScratch/TryCompile-PaojQZ'\r\n      gmake: *** [Makefile:127: cmTC_819f1/fast] Error 2\r\n\r\n\r\n\r\n\r\n\r\n    CMake will not be able to correctly generate this project.\r\n  Call Stack (most recent call first):\r\n    CMakeLists.txt:3 (project)\r\n\r\n\r\n/root/torronen/Kwork.Microsoft.ML2023/src/Native/Native.proj(117,5): error MSB3073: The command \"\"/root/torronen/Kwork.Microsoft.ML2023/src/Native/build.sh\" --configuration Debug --arch x64  --mkllibpath /root/.nuget/packages/mlnetmkldeps/0.0.0.12/runtimes/linux-x64/native --onedalredistpath /root/.nuget/packages/inteldal.redist.linux-x64/2023.0.0.23046/build/native/daal/latest --onedaldevelpath /root/.nuget/packages/inteldal.devel.win-x64/2023.0.0.23189/build/native/daal/latest --onetbbredistpath /root/.nuget/packages/inteltbb.devel.linux/2021.7.1.15005/runtimes/linux-x64/native\" exited with code 1.\r\n  Microsoft.ML.InternalCodeAnalyzer -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.InternalCodeAnalyzer/Debug/netstandard2.0/Microsoft.ML.InternalCodeAnalyzer.dll\r\n  Microsoft.ML.AutoML.SourceGenerator -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.AutoML.SourceGenerator/Debug/netstandard2.0/Microsoft.ML.AutoML.SourceGenerator.dll\r\n  Microsoft.ML.SearchSpace -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.SearchSpace/Debug/netstandard2.0/Microsoft.ML.SearchSpace.dll\r\n  RemoteExecutorConsoleApp -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/RemoteExecutorConsoleApp/Debug/net6.0/RemoteExecutorConsoleApp.dll\r\n  Microsoft.ML.Mkl.Redist -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Mkl.Redist/Debug/netstandard2.0/Microsoft.ML.Mkl.Redist.dll\r\n  Microsoft.ML.CpuMath -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.CpuMath/Debug/netcoreapp3.1/Microsoft.ML.CpuMath.dll\r\n  Microsoft.ML.CpuMath -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.CpuMath/Debug/netstandard2.0/Microsoft.ML.CpuMath.dll\r\n  Microsoft.ML.Tokenizers -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Tokenizers/Debug/netstandard2.0/Microsoft.ML.Tokenizers.dll\r\n  Microsoft.ML.DataView -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.DataView/Debug/netstandard2.0/Microsoft.ML.DataView.dll\r\n  Microsoft.ML.CpuMath.PerformanceTests -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.CpuMath.PerformanceTests/Debug/net6.0/Microsoft.ML.CpuMath.PerformanceTests.dll\r\n/root/torronen/Kwork.Microsoft.ML2023/Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"/root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Native/x64.Debug/libCpuMathNative.so\" because it was not found. [/root/torronen/Kwork.Microsoft.ML2023/test/Microsoft.ML.CpuMath.PerformanceTests/Microsoft.ML.CpuMath.PerformanceTests.csproj::TargetFramework=net6.0]\r\n  Microsoft.ML.Tokenizers.Tests -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Tokenizers.Tests/Debug/net6.0/Microsoft.ML.Tokenizers.Tests.dll\r\n  Microsoft.ML.NugetPackageVersionUpdater -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.NugetPackageVersionUpdater/Debug/net6.0/Microsoft.ML.NugetPackageVersionUpdater.dll\r\n  Microsoft.ML.Core -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Core/Debug/netstandard2.0/Microsoft.ML.Core.dll\r\n  Microsoft.ML.Maml -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Maml/Debug/netstandard2.0/Microsoft.ML.Maml.dll\r\n  Microsoft.Data.Analysis -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.Data.Analysis/Debug/netstandard2.0/Microsoft.Data.Analysis.dll\r\n  Microsoft.ML.Data -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Data/Debug/netstandard2.0/Microsoft.ML.Data.dll\r\n  Microsoft.Data.Analysis.Interactive -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.Data.Analysis.Interactive/Debug/netcoreapp3.1/Microsoft.Data.Analysis.Interactive.dll\r\n  Microsoft.ML.Transforms -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.Transforms/Debug/netstandard2.0/Microsoft.ML.Transforms.dll\r\n  Microsoft.ML.ResultProcessor -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.ResultProcessor/Debug/netstandard2.0/Microsoft.ML.ResultProcessor.dll\r\n  Microsoft.ML.PCA -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.PCA/Debug/netstandard2.0/Microsoft.ML.PCA.dll\r\n  Microsoft.ML.TestFrameworkCommon -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.TestFrameworkCommon/Debug/net6.0/Microsoft.ML.TestFrameworkCommon.dll\r\n  Microsoft.Data.Analysis.Interactive.Tests -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.Data.Analysis.Interactive.Tests/Debug/net6.0/Microsoft.Data.Analysis.Interactive.Tests.dll\r\n  Microsoft.ML.StandardTrainers -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.StandardTrainers/Debug/netstandard2.0/Microsoft.ML.StandardTrainers.dll\r\n  Microsoft.ML.KMeansClustering -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML.KMeansClustering/Debug/netstandard2.0/Microsoft.ML.KMeansClustering.dll\r\n  Microsoft.ML -> /root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Microsoft.ML/Debug/netstandard2.0/Microsoft.ML.dll\r\n/root/torronen/Kwork.Microsoft.ML2023/Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"/root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Native/x64.Debug/libLdaNative.so\" because it was not found. [/root/torronen/Kwork.Microsoft.ML2023/src/Microsoft.ML/Microsoft.ML.csproj]\r\n\r\nBuild FAILED.\r\n\r\nclang : error : linker command failed with exit code 1 (use -v to see invocation) [/root/torronen/Kwork.Microsoft.ML2023/src/Native/Native.proj]\r\n/root/torronen/Kwork.Microsoft.ML2023/src/Native/Native.proj(117,5): error MSB3073: The command \"\"/root/torronen/Kwork.Microsoft.ML2023/src/Native/build.sh\" --configuration Debug --arch x64  --mkllibpath /root/.nuget/packages/mlnetmkldeps/0.0.0.12/runtimes/linux-x64/native --onedalredistpath /root/.nuget/packages/inteldal.redist.linux-x64/2023.0.0.23046/build/native/daal/latest --onedaldevelpath /root/.nuget/packages/inteldal.devel.win-x64/2023.0.0.23189/build/native/daal/latest --onetbbredistpath /root/.nuget/packages/inteltbb.devel.linux/2021.7.1.15005/runtimes/linux-x64/native\" exited with code 1.\r\n/root/torronen/Kwork.Microsoft.ML2023/Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"/root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Native/x64.Debug/libCpuMathNative.so\" because it was not found. [/root/torronen/Kwork.Microsoft.ML2023/test/Microsoft.ML.CpuMath.PerformanceTests/Microsoft.ML.CpuMath.PerformanceTests.csproj::TargetFramework=net6.0]\r\n/root/torronen/Kwork.Microsoft.ML2023/Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"/root/torronen/Kwork.Microsoft.ML2023/artifacts/bin/Native/x64.Debug/libLdaNative.so\" because it was not found. [/root/torronen/Kwork.Microsoft.ML2023/src/Microsoft.ML/Microsoft.ML.csproj]\r\n    0 Warning(s)\r\n    4 Error(s)\r\n\r\nTime Elapsed 00:00:05.14\r\nBuild failed with exit code 1. Check errors above.\r\nroot@Ubuntu-2204-jammy-amd64-base ~/torronen/Kwork.Microsoft.ML2023 #\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6655","RelatedDescription":"Open issue \"Compiling on Ubuntu 22.04 ( CXX compiler: /usr/bin/clang++ - broken)\" (#6655)"},{"Id":"1696189456","IsPullRequest":false,"CreatedAt":"2023-05-04T14:55:14","Actor":"superichmann","Number":"6654","RawContent":null,"Title":"AutoML Regression Experiment Ends Unsuccessfully","State":"open","Body":"**System Information:**\r\n - OS & Version: Windows 10\r\n**microsoft.ml**\\3.0.0-preview.23229.2\r\n**microsoft.ml.automl**\\0.21.0-preview.23229.2\r\n**microsoft.ml.onedal**\\0.21.0-preview.23229.2\r\nupdated from https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet-libraries/nuget/v3/index.json\r\n - .NET Version: e.g. .NET 6.0\r\n\r\n**Describe the bug**\r\nAfter updating to latest build through dotnet-libraries nuget in order to apply the fix for #6565 the same AutoML regression experiments that were completed in a 10 seconds are now incomplete, I have increased to 800 seconds and still receive the error :\\\r\n`RegressionMetric.MeanAbsoluteError`\r\ntrain: 1667 rows\r\ntest: 16 rows\r\n **Message**:â€‰\r\n```\r\n    System.AggregateException: One or more errors occurred. (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) (One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity)) ---> System.AggregateException: One or more errors occurred. (Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity) ---> System.TimeoutException: Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity\r\n\r\n  Stack Trace:â€‰\r\n    AutoMLExperiment.RunAsync(CancellationToken ct)\r\n    --- End of inner exception stack trace ---\r\n    Task.ThrowIfExceptional(Boolean includeTaskCanceledExceptions)\r\n    Task`1.GetResultCore(Boolean waitCompletionNotification)\r\n    AutoMLExperiment.Run()\r\n    RegressionExperiment.Execute(IDataView trainData, IDataView validationData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n```\r\nIf there are best practices for the new version please tell me what they are. maybe I am doing something wrong\r\n**Expected behavior**\r\nAt least one model should be found?\r\n\r\n**Additional context**\r\nThe long exception message is due to the fact that the trials are sent from Parallel.ForEach\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6654","RelatedDescription":"Open issue \"AutoML Regression Experiment Ends Unsuccessfully\" (#6654)"},{"Id":"1695553242","IsPullRequest":false,"CreatedAt":"2023-05-04T08:47:23","Actor":"torronen","Number":"6653","RawContent":null,"Title":"AutoML 2.0: Get columnInformation from binary IDV file","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version:Windows 11\r\n - ML.NET Version: latest from main\r\n - .NET Version: .NET 7.0\r\n\r\nThis is also just to point out a \"pain point\". I have a temporary solution. There probably exists a better way, but I could not find it.\r\n\r\nColumnInformation is needed by ctx.Auto().Featurizer(data, columnInformation: columnInference.ColumnInformation)\r\n\r\nSamples use ctx.Auto().InferColumns but this method only accepts CSV files.\r\n\r\nHow to get ColumnInformation if user reads the data from IDV binary file, or perhaps SQL Server, or uses custom data objects?\r\nfor example, \r\n```\r\nvar data = ctx.Data.LoadFromBinary(source);\r\n....\r\n SweepablePipeline pipeline = ctx.Transforms.SelectColumns(columnsToKeep) \r\n                .Append(ctx.Auto().Featurizer(data, columnInformation: columnInference.ColumnInformation)) **<<--- How to get ColumnInformation from data ?**\r\n                .Append(ctx.Auto().BinaryClassification(labelColumnName: columnInference.ColumnInformation.LabelColumnName\r\n```\r\n\r\nTemporary workaround:\r\nI will save column inference results as json from orginal CSV together with IDV file, then deserialize to get the matchin column information for said CSV file. \r\n\r\nThoughts:\r\nIDataView has a Schema, just not inside a correct class. Is there a method to convert?\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6653","RelatedDescription":"Open issue \"AutoML 2.0: Get columnInformation from binary IDV file\" (#6653)"},{"Id":"1695337488","IsPullRequest":false,"CreatedAt":"2023-05-04T06:27:05","Actor":"torronen","Number":"6652","RawContent":null,"Title":"AutoML 2.0: Trying to serializing params from TrialResult fails","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: latest from [main]\r\n - .NET Version: .NET 7.0\r\n\r\n**Describe the bug**\r\nAt end of AutoML experiment I want to log the parameters used. \r\nThis fails:      \r\n```\r\n             var json = JsonConvert.SerializeObject(result.TrialSettings.Parameter);\r\n            System.IO.File.WriteAllText(saveTo + \".param\", json);\r\n```\r\n            \r\nI can still get them with help of .ToString() method and that will be enough for me.\r\nSerializing just would be a easier way.\r\n\r\nAny possible code updates should probably also address #6651\r\n\r\n\r\n(this line also fails due to null from paramData[data]?.Keys == null, just a possible hint:\r\n        foreach (var paramKey in result.TrialSettings.Parameter.Keys)\r\n            {\r\n                if (paramData.Keys.Count() < 50)\r\n                {\r\n                    foreach (var data in paramData.Keys)\r\n                    {\r\nif (paramData[data] != null && (paramData[data]?.Keys == null || paramData[data].Keys.Count() < 50))\r\n\r\n            ","Url":"https://github.com/dotnet/machinelearning/issues/6652","RelatedDescription":"Open issue \"AutoML 2.0: Trying to serializing params from TrialResult fails\" (#6652)"},{"Id":"1695296351","IsPullRequest":false,"CreatedAt":"2023-05-04T05:41:32","Actor":"torronen","Number":"6651","RawContent":null,"Title":"AutoML 2.0: How to get trainer used for best model","State":"open","Body":"I am using latest version from [main] per today. At end of the trial, I want to log parameters and trainer used. I also want to get global feature index. My code* for global feature index relies on knowing which trainer is used. \r\n\r\nFor now, I intend to \"hack\" it this way. I believe this will be adequate for my need (not yet tested):\r\nvar pipelineString = pipeline.ToString(experimentResults.TrialSettings.Parameter);\r\nif(pipelineString.Contains(\"FastTree\")\r\n\r\nHowever, it would be good to have documentation or implementation, if needed, to read the parameters in a structured format. I have not looked at the source, so maybe it just needs a sample or documentation.\r\n\r\n\r\n\r\n*my code for GFI uses this code, and I have different lines for each tree trainer. If there are better ways it would make my life easier...\r\n```\r\nMicrosoft.ML.Data.TransformerChain<Microsoft.ML.IPredictionTransformer<object>> transformerchain = (model as Microsoft.ML.Data.TransformerChain<Microsoft.ML.IPredictionTransformer<object>>);\r\n                    Microsoft.ML.Data.BinaryPredictionTransformer<**Microsoft.ML.Calibrators.CalibratedModelParametersBase<Microsoft.ML.Trainers.FastTree.FastTreeBinaryModelParameters, Microsoft.ML.Calibrators.PlattCalibrator>**>\r\nlastTransformer = (BinaryPredictionTransformer<CalibratedModelParametersBase<FastTreeBinaryModelParameters, PlattCalibrator>>)transformerchain.LastTransformer;\r\n\r\nlastTransformer.Model.SubModel.GetFeatureWeights(ref weights);\r\nfloat[] weightsValues = weights.DenseValues().ToArray();\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6651","RelatedDescription":"Open issue \"AutoML 2.0: How to get trainer used for best model\" (#6651)"},{"Id":"1694593223","IsPullRequest":false,"CreatedAt":"2023-05-03T18:36:00","Actor":"torronen","Number":"6648","RawContent":null,"Title":"AutoML 2.0: Distributes learning / potential \"hack\" using checkpoints CSV on a network drive?","State":"open","Body":"I could not find docs or plans about distributed learning. If that is correct, any ideas for how it could be implemented or links to common approaches? \r\n\r\nAutoML 2.0 seems to have a nice checkpoint CSV file. \r\nWould it be possible to make a \"hack\" using the checkpoint file? Would there a tuner that would allow me to use it for distributed tuning? Or, perhaps setting different MLContext seed on each machine would do it?\r\n\r\nI am thinking something like this might work with minimal source editing:\r\n1. Checkpoint file to a network drive\r\n2. Make each experiment run only 1 trial, then restart (so the current status gets read) - or edit source to re-read the checkpoint file\r\n3. Multiple clients would run simultaneously\r\n\r\nPotential problems I could expect:\r\n 1. Some type of randomity is probably needed from tuner, otherwise all clients might run the trial on same parameters\r\n 2. Probably needs to add locks for saving to CSV\r\n \r\n","Url":"https://github.com/dotnet/machinelearning/issues/6648","RelatedDescription":"Open issue \"AutoML 2.0: Distributes learning / potential \"hack\" using checkpoints CSV on a network drive?\" (#6648)"},{"Id":"1694056461","IsPullRequest":false,"CreatedAt":"2023-05-03T13:13:37","Actor":"szimmer-dap","Number":"6645","RawContent":null,"Title":"Replace <PackageLicenseFile> with <PackageLicenseExpression>","State":"open","Body":"Hi there!\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWe are currently adapting a package approval workflow, where packages are approved or blocked based on certain criteria. One very important criterion is the package's license. There is a list of approved licenses (like MIT, Apache, BSD, ...) and a list of licenses that can not be used (like GPL).\r\n\r\nAlthough the Microsoft.ML Nuget packages are under MIT license, it's hard to auto-approve them, because they use an embedded license file instead of an SPDX tag (https://spdx.github.io/spdx-spec/v2-draft/SPDX-license-list/). As a result, the license does not show up in the package's metadata (compare e.g. the \"About\" page of [https://www.nuget.org/packages/Microsoft.ML](https://www.nuget.org/packages/Microsoft.ML) with [https://www.nuget.org/packages/Microsoft.Data.SqlClient](https://www.nuget.org/packages/Microsoft.Data.SqlClient), where the latter clearly states the package's license, while Microsoft.ML does not).\r\n\r\n**Describe the solution you'd like**\r\nWould you consider using an SPDX license expression? Basically, all that is needed is replacing the line\r\n`<PackageLicenseFile>LICENSE.txt</PackageLicenseFile>`\r\nwith\r\n`<PackageLicenseExpression>MIT</PackageLicenseExpression>`\r\nin all *.csproj or *.props files (or whatever mechanism generates the corresponding *.nuspec file). The LICENSE file can still remain in the package, just the metadata would change. The corresponding .nuspec file should then change the line\r\n`<license type=\"file\">LICENSE.txt</license>`\r\nto\r\n`<license type=\"expression\">MIT</license>`\r\n\r\nThis would be a huge help for us, because with embedded license files we have to manually check and approve every single version of every package.\r\n\r\n**Describe alternatives you've considered**\r\nThe alternative would be for us to download every package, manually check the context of each embedded LICENSE file, make sure that it is in fact an approved license, and then manually allow the package. This would have to be done for every release of every package without an SPDX license tags.\r\n\r\n**Additional context**\r\nThe [dotnet / runtime](https://github.com/dotnet/runtime) repo seems to use already [use license expressions](https://github.com/dotnet/runtime/blob/0be256e71009beaa0e01591c4115d92d68b93a95/Directory.Build.props#L333) (and apparently use a an additional `<LicenseFile>`).\r\nThe [microsoft / MSBuildSdks](https://github.com/microsoft/MSBuildSdks/issues/312) repo switched to license expressions about two years ago, following the recommendations provided in Microsoft's [.nuspec reference](https://learn.microsoft.com/en-us/nuget/reference/nuspec#license).","Url":"https://github.com/dotnet/machinelearning/issues/6645","RelatedDescription":"Open issue \"Replace <PackageLicenseFile> with <PackageLicenseExpression>\" (#6645)"},{"Id":"1692240802","IsPullRequest":true,"CreatedAt":"2023-05-02T11:22:14","Actor":"janholo","Number":"6642","RawContent":null,"Title":"Fix Apply in PrimitiveColumnContainer so it does not change source column","State":"open","Body":"The Apply method calls SetValidityBit on the source container and not on the target container. That way the null check of the container values gets incorrect.\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6642","RelatedDescription":"Open PR \"Fix Apply in PrimitiveColumnContainer so it does not change source column\" (#6642)"},{"Id":"1691557801","IsPullRequest":true,"CreatedAt":"2023-05-01T23:35:52","Actor":"michaelgsharp","Number":"6641","RawContent":null,"Title":"Update ML.NET to work with .NET8","State":"open","Body":"Remove references to .NETCore3.1 since its out of support.\r\n\r\nRemove obsolete/deprecated code.","Url":"https://github.com/dotnet/machinelearning/pull/6641","RelatedDescription":"Open PR \"Update ML.NET to work with .NET8\" (#6641)"},{"Id":"1691292882","IsPullRequest":false,"CreatedAt":"2023-05-01T20:06:09","Actor":"LanceElCamino","Number":"6640","RawContent":null,"Title":"[LightGBM]  [Fatal] Unknown importance type error using Ml.Net API","State":"open","Body":"**System Information (please complete the following information):**\r\n -  Windows 11 22H2\r\n - ML.NET 2.0.1\r\n - Auto.Ml \r\n - .NET Framework 4.8\r\n\r\nKeep getting this error:\r\n![image](https://user-images.githubusercontent.com/122576256/235521011-0df3eb89-b484-4491-a579-aa44c125d477.png)\r\n\r\n`using Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.AutoML;\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\n\r\n\r\nnamespace PriceActionTestPFI\r\n{\r\n    internal class Program\r\n    {\r\n        //Model Input class\r\n        public class ModelInput\r\n        {\r\n            [LoadColumn(6)]\r\n            [ColumnName(@\"PAF:Range\")]\r\n            public float PAF_Range { get; set; }\r\n\r\n            [LoadColumn(7)]\r\n            [ColumnName(@\"PAF:atr\")]\r\n            public float PAF_atr { get; set; }\r\n\r\n            [LoadColumn(11)]\r\n            [ColumnName(@\"PAF:NormPrice\")]\r\n            public float PAF_NormPrice { get; set; }\r\n\r\n            [LoadColumn(12)]\r\n            [ColumnName(@\"MlLabels:Enter\")]\r\n            public float MlLabels_Enter { get; set; }\r\n\r\n            [LoadColumn(13)]\r\n            [ColumnName(@\"BarTimes:BarTime\")]\r\n            public float BarTimes_BarTime { get; set; }\r\n\r\n            [LoadColumn(15)]\r\n            [ColumnName(@\"BarTimes:TimeVsAvg\")]\r\n            public float BarTimes_TimeVsAvg { get; set; }\r\n\r\n            [LoadColumn(16)]\r\n            [ColumnName(@\"BarTimes:Fast\")]\r\n            public bool BarTimes_Fast { get; set; }\r\n\r\n            [LoadColumn(17)]\r\n            [ColumnName(@\"Lin. reg. slope:Lin. reg. slope3\")]\r\n            public float Lin__reg__slope_Lin__reg__slope3 { get; set; }\r\n\r\n            [LoadColumn(18)]\r\n            [ColumnName(@\"Lin. reg. slope:Lin. reg. slope5\")]\r\n            public float Lin__reg__slope_Lin__reg__slope5 { get; set; }\r\n\r\n            [LoadColumn(19)]\r\n            [ColumnName(@\"Lin. reg. slope:Lin. reg. slope10\")]\r\n            public float Lin__reg__slope_Lin__reg__slope10 { get; set; }\r\n\r\n            [LoadColumn(20)]\r\n            [ColumnName(@\"Lin. reg. slope:Lin. reg. slope20\")]\r\n            public float Lin__reg__slope_Lin__reg__slope20 { get; set; }\r\n\r\n            [LoadColumn(21)]\r\n            [ColumnName(@\"AvgUpDown:AverageGain\")]\r\n            public float AvgUpDown_AverageGain { get; set; }\r\n\r\n            [LoadColumn(22)]\r\n            [ColumnName(@\"AvgUpDown:AverageLoss\")]\r\n            public float AvgUpDown_AverageLoss { get; set; }\r\n\r\n            [LoadColumn(47)]\r\n            [ColumnName(@\"SwingLevels:MajBullBoS\")]\r\n            public bool SwingLevels_MajBullBoS { get; set; }\r\n\r\n            [LoadColumn(48)]\r\n            [ColumnName(@\"SwingLevels:MajBearBoS\")]\r\n            public bool SwingLevels_MajBearBoS { get; set; }\r\n\r\n            [LoadColumn(49)]\r\n            [ColumnName(@\"SwingLevels:MajBullCont\")]\r\n            public bool SwingLevels_MajBullCont { get; set; }\r\n\r\n            [LoadColumn(50)]\r\n            [ColumnName(@\"SwingLevels:MajBearCont\")]\r\n            public bool SwingLevels_MajBearCont { get; set; }\r\n\r\n            [LoadColumn(51)]\r\n            [ColumnName(@\"SwingLevels:MinBullBoS\")]\r\n            public bool SwingLevels_MinBullBoS { get; set; }\r\n\r\n            [LoadColumn(52)]\r\n            [ColumnName(@\"SwingLevels:MinBearBoS\")]\r\n            public bool SwingLevels_MinBearBoS { get; set; }\r\n\r\n            [LoadColumn(53)]\r\n            [ColumnName(@\"SwingLevels:MinBullCont\")]\r\n            public bool SwingLevels_MinBullCont { get; set; }\r\n\r\n            [LoadColumn(54)]\r\n            [ColumnName(@\"SwingLevels:MinBearCont\")]\r\n            public bool SwingLevels_MinBearCont { get; set; }\r\n\r\n            [LoadColumn(55)]\r\n            [ColumnName(@\"SwingLevels:ProxLastSH\")]\r\n            public float SwingLevels_ProxLastSH { get; set; }\r\n\r\n            [LoadColumn(56)]\r\n            [ColumnName(@\"SwingLevels:ProxLastSL\")]\r\n            public float SwingLevels_ProxLastSL { get; set; }\r\n\r\n            [LoadColumn(57)]\r\n            [ColumnName(@\"SwingLevels:ProxLastSH2\")]\r\n            public float SwingLevels_ProxLastSH2 { get; set; }\r\n\r\n            [LoadColumn(58)]\r\n            [ColumnName(@\"SwingLevels:ProxLastSL2\")]\r\n            public float SwingLevels_ProxLastSL2 { get; set; }\r\n\r\n        }\r\n\r\n        //Model Output class\r\n        public class ModelOutput\r\n        {\r\n            //[ColumnName(@\"Features\")]\r\n            //public float[] __Features__ { get; set; }\r\n\r\n            [ColumnName(@\"PredictedLabel\")]\r\n            public float PredictedLabel { get; set; }\r\n\r\n            [ColumnName(@\"Score\")]\r\n            public float[] Score { get; set; }\r\n\r\n        }\r\n\r\n        private static string ModelPath = \"PriceActionTestPFImulti.zip\";\r\n        static void Main(string[] args)\r\n        {\r\n            //Create new ML context\r\n            var mlContext = new MLContext();\r\n\r\n            //Load data from csv/text file\r\n            IDataView CSAData = mlContext.Data.LoadFromTextFile<ModelInput>(path:\"ES Friday 1625.csv\", hasHeader: true, separatorChar: ',');\r\n\r\n            //Split data into training and testing sets (70%/30%)\r\n            var split = mlContext.Data.TrainTestSplit(CSAData, testFraction: 0.3);\r\n            var trainData = split.TrainSet;\r\n            var testData = split.TestSet;\r\n\r\n            // Create, train, evaluate and save a model\r\n            TransformerChain<ITransformer> trainedModel = BuildTrainEvaluateAndSaveModel(mlContext, trainData, testData);\r\n\r\n            // Make a single test prediction loading the model from .ZIP file\r\n            TestSinglePrediction(mlContext);\r\n\r\n            // Calculate the Permuation Feature Importance (PFI)\r\n            CalculatePermutationFeatureImportance(mlContext, trainData, trainedModel);\r\n            //CalculatePFI(mlContext, trainData, trainedModel, labelColumnName: @\"MlLabels:Enter\");\r\n\r\n            Console.WriteLine(\"Press any key to exit..\");\r\n            Console.ReadLine();\r\n        }\r\n\r\n        private static TransformerChain<ITransformer> BuildTrainEvaluateAndSaveModel(MLContext mlContext, IDataView trainingDataView, IDataView testDataView)\r\n        {\r\n            // Run AutoML Multiclass Classification experiment\r\n            Console.WriteLine(\"=============== Training the model ===============\");\r\n            Console.WriteLine($\"Running AutoML experiment for 600 seconds...\");\r\n            ExperimentResult<MulticlassClassificationMetrics> experimentResult = mlContext.Auto()\r\n                .CreateMulticlassClassificationExperiment(600)\r\n                .Execute(trainingDataView, labelColumnName: @\"MlLabels:Enter\");\r\n\r\n            // Evaluate the model and print metrics\r\n            Console.WriteLine(\"===== Evaluating model's accuracy with test data =====\");\r\n            RunDetail<MulticlassClassificationMetrics> best = experimentResult.BestRun;\r\n            ITransformer trainedModel = best.Model;\r\n            TransformerChain<ITransformer> trainedModelChain = (TransformerChain<ITransformer>)best.Model;\r\n            IDataView predictions = trainedModel.Transform(testDataView);\r\n            var metrics = mlContext.MulticlassClassification.Evaluate(predictions, labelColumnName: @\"MlLabels:Enter\", scoreColumnName: \"Score\", predictedLabelColumnName: \"PredictedLabel\",\r\n                topKPredictionCount: 1);\r\n\r\n            // Print metrics from top model\r\n            Console.WriteLine($\"*************************************************\");\r\n            Console.WriteLine($\"*       Metrics for {best.TrainerName} Multiclass Classification model      \");\r\n            Console.WriteLine($\"*------------------------------------------------\");\r\n            Console.WriteLine($\"*       MicroAccuracy:      {metrics.MicroAccuracy:#.##}\");\r\n            Console.WriteLine($\"*       MacroAccuracy:      {metrics.MacroAccuracy:#.##}\");\r\n            Console.WriteLine($\"*       LogLoss:            {metrics.LogLoss:#.##}\");\r\n            Console.WriteLine(metrics.ConfusionMatrix.GetFormattedConfusionTable());\r\n            Console.WriteLine($\"*************************************************\");\r\n\r\n            // Save/persist the trained model to a .ZIP file\r\n            mlContext.Model.Save(trainedModel, trainingDataView.Schema, ModelPath);\r\n\r\n            Console.WriteLine(\"The model is saved to {0}\", ModelPath);\r\n\r\n            return trainedModelChain;\r\n\r\n        }\r\n        private static void TestSinglePrediction(MLContext mlContext)\r\n        {\r\n            Console.WriteLine(\"=============== Testing prediction engine ===============\");\r\n\r\n            var Sample = new ModelInput()\r\n            {\r\n                PAF_Range = 2.25F,\r\n                PAF_atr = 2.710295F,\r\n                PAF_NormPrice = 0.7777778F,\r\n                BarTimes_BarTime = 101.461F,\r\n                BarTimes_TimeVsAvg = 100.6064F,\r\n                Lin__reg__slope_Lin__reg__slope3 = -0.875F,\r\n                Lin__reg__slope_Lin__reg__slope5 = 0.275F,\r\n                Lin__reg__slope_Lin__reg__slope10 = 0.2893939F,\r\n                Lin__reg__slope_Lin__reg__slope20 = -0.08139098F,\r\n                AvgUpDown_AverageGain = 0.75F,\r\n                AvgUpDown_AverageLoss = 0.52F,\r\n                SwingLevels_ProxLastSH = 1.002004F,\r\n                SwingLevels_ProxLastSL = 1.006112F,\r\n                SwingLevels_ProxLastSH2 = 0.998963884F,\r\n                SwingLevels_ProxLastSL2 = 1.001261034F,\r\n\r\n            };\r\n\r\n            ITransformer trainedModel = mlContext.Model.Load(ModelPath, out var _);\r\n\r\n            // Create prediction engine related to the loaded trained model\r\n            var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(trainedModel);\r\n          \r\n            // Score\r\n            var predictedResult = predEngine.Predict(Sample);\r\n\r\n            Console.WriteLine($\"**********************************************************************\");\r\n            Console.WriteLine($\"Predicted Entrance: {predictedResult.PredictedLabel}, Actual: -1\");\r\n            Console.WriteLine($\"Probability: {predictedResult.Score.Max()}\");\r\n            Console.WriteLine($\"**********************************************************************\");\r\n        }\r\n\r\n        private static void CalculatePermutationFeatureImportance(MLContext mlContext, IDataView trainingDataView, TransformerChain<ITransformer> trainedModel)\r\n        {\r\n            // Transform data (make predictions)\r\n            IDataView transformedData = trainedModel.Transform(trainingDataView);\r\n\r\n            // Get labels for feature importance\r\n            VBuffer<ReadOnlyMemory<char>> nameBuffer = default;\r\n            transformedData.Schema[\"__Features__\"].Annotations.GetValue(\"SlotNames\", ref nameBuffer);\r\n            // NOTE: The column name \"__Features__\" needs to match the featureColumnName used in the trainer, the name \"SlotNames\" is always the same regardless of trainer. View variable in Debug to find name.\r\n\r\n            var featureColumnNames = nameBuffer.DenseValues().ToList();\r\n\r\n            // Calculate Feature Permutation\r\n            var permutationMetrics = mlContext.MulticlassClassification.PermutationFeatureImportance(model :trainedModel,\r\n                                                                                                    data: transformedData,\r\n                                                                                                    labelColumnName: @\"MlLabels:Enter\",\r\n                                                                                                    numberOfExamplesToUse: 10000, permutationCount: 30);\r\n\r\n            // Format feature importance output\r\n            Console.WriteLine(\"Feature\\tPFI\");\r\n\r\n            var featureImportanceMetrics =\r\n                permutationMetrics\r\n                .Select((kvp) => new { kvp.Key, kvp.Value.MicroAccuracy })\r\n                .OrderByDescending(myFeatures => Math.Abs(myFeatures.MicroAccuracy.Mean));\r\n\r\n            var featurePFI = new List<Tuple<string, double>>();\r\n            foreach (var feature in featureImportanceMetrics)\r\n            {\r\n                var pfiValue = Math.Abs(feature.MicroAccuracy.Mean);\r\n                featurePFI.Add(new Tuple<string, double>(feature.Key, pfiValue));\r\n            }\r\n            foreach (var tuple in featurePFI)\r\n            { Console.WriteLine($\"{tuple.Item1} - {tuple.Item2}\"); }\r\n\r\n        }\r\n    }\r\n}`\r\nIt still completes the experiment but prefer LightGBM to be included.","Url":"https://github.com/dotnet/machinelearning/issues/6640","RelatedDescription":"Open issue \"[LightGBM]  [Fatal] Unknown importance type error using Ml.Net API\" (#6640)"},{"Id":"1690463965","IsPullRequest":false,"CreatedAt":"2023-05-01T06:50:05","Actor":"Mihaiii","Number":"6639","RawContent":null,"Title":"Does ML.NET support KNN? (part 2)","State":"open","Body":"This is a continuation of #1712 .\r\nWe are in 2023 now and we have ML.NET 2.\r\n\r\nDoes ML.NET 2 support KNN?","Url":"https://github.com/dotnet/machinelearning/issues/6639","RelatedDescription":"Open issue \"Does ML.NET support KNN? (part 2)\" (#6639)"},{"Id":"1683842533","IsPullRequest":false,"CreatedAt":"2023-05-01T02:13:00","Actor":"LanceElCamino","Number":"6630","RawContent":null,"Title":"Multiclass Classification AutoML and PFI won't complete","State":"closed","Body":"ML (2.0.1)\r\nML.AutoML (0.20.1) \r\n\r\n**Describe the bug**\r\nThe AutoMl experiment never finishes, just keeps running. No error output. Works fine when running as Binary Classification but now need Multiclass Classification. Have attached a small csv file to reproduce.\r\n\r\n**To Reproduce**\r\nCopy and paste code into new console app (Net 6.0). \r\nSave csv in Solution>Project>bin>Debug>net6.0 folder.\r\nRun.\r\n\r\n**Expected behavior**\r\nShould output to console the experiment results and PFI metrics.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n![image](https://user-images.githubusercontent.com/122576256/234399319-31d362a8-d60a-4bae-bbc0-5c10a38b99e8.png)\r\n\r\nJust shows this and never stops running.\r\n\r\nWhat did I do wrong?\r\n`using System.Collections.Immutable;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.AutoML;\r\nusing System.Data;\r\n\r\nnamespace PriceActionTestPFI\r\n{\r\n    internal class Program\r\n    {\r\n        //Model Input class\r\n        public class ModelInput\r\n        {\r\n            [ColumnName(@\"High\"), LoadColumn(0)]\r\n            public float High { get; set; }\r\n\r\n            [ColumnName(@\"Low\"), LoadColumn(1)]\r\n            public float Low { get; set; }\r\n\r\n            [ColumnName(@\"Close\"), LoadColumn(2)]\r\n            public float Close { get; set; }\r\n\r\n            [ColumnName(@\"MlLabels:Enter\"), LoadColumn(3)]\r\n            public float Enter { get; set; }\r\n\r\n            [ColumnName(@\"BarTimes:BarTime\"), LoadColumn(4)]\r\n            public float BarTime { get; set; }\r\n\r\n            [ColumnName(@\"BarTimes:BarTimeAvg\"), LoadColumn(5)]\r\n            public float BarTimeAvg { get; set; }\r\n\r\n            [ColumnName(@\"SlopeSimple:SlopeLine1\"), LoadColumn(6)]\r\n            public float Slope1 { get; set; }\r\n\r\n            [ColumnName(@\"LeavittConvolutionAcceleration:Acc\"), LoadColumn(7)]\r\n            public float Acc { get; set; }\r\n\r\n            [ColumnName(@\"SlopeSimple:SlopeLine2\"), LoadColumn(8)]\r\n            public float Slope2 { get; set; }\r\n\r\n            [ColumnName(@\"LeavittConvolution:Conv\"), LoadColumn(9)]\r\n            public float Conv { get; set; }\r\n\r\n            [ColumnName(@\"LeavittProjection:LProjection\"), LoadColumn(10)]\r\n            public float Projection { get; set; }\r\n\r\n            [ColumnName(@\"LeavittConvolutionSlope:SlopeValue\"), LoadColumn(11)]\r\n            public float Lslope { get; set; }\r\n        }\r\n\r\n        //Model Output class\r\n        public class ModelOutput\r\n        {\r\n            // [ColumnName(@\"Features\")]\r\n            // public float[] Features { get; set; }\r\n\r\n            [ColumnName(@\"PredictedLabel\")]\r\n            public float PredictedLabel { get; set; }\r\n\r\n            [ColumnName(@\"Score\")]\r\n            public float Score { get; set; }\r\n\r\n        }\r\n\r\n        private static string ModelPath = \"PATest3PFI.zip\";\r\n        static void Main(string[] args)\r\n        {\r\n            //Create new ML context\r\n            var mlContext = new MLContext();\r\n\r\n            //Load data from csv/text file\r\n            IDataView CSAData = mlContext.Data.LoadFromTextFile<ModelInput>(path: \"ES Tuesday 922.csv\", hasHeader: true, separatorChar: ',');\r\n\r\n            //Split data into training and testing sets (80%/20%)\r\n            var split = mlContext.Data.TrainTestSplit(CSAData, testFraction: 0.2);\r\n            var trainData = split.TrainSet;\r\n            var testData = split.TestSet;\r\n\r\n            // Create, train, evaluate and save a model\r\n            TransformerChain<ITransformer> trainedModel = BuildTrainEvaluateAndSaveModel(mlContext, trainData, testData);\r\n\r\n            // Make a single test prediction loading the model from .ZIP file\r\n            TestSinglePrediction(mlContext);\r\n\r\n            // Calculate the Permuation Feature Importance (PFI)\r\n            CalculatePermutationFeatureImportance(mlContext, trainData, trainedModel);\r\n\r\n            Console.WriteLine(\"Press any key to exit..\");\r\n            Console.ReadLine();\r\n        }\r\n        private static TransformerChain<ITransformer> BuildTrainEvaluateAndSaveModel(MLContext mlContext, IDataView trainingDataView, IDataView testDataView)\r\n        {\r\n            // Run AutoML Multiclass Classification experiment\r\n            Console.WriteLine(\"=============== Training the model ===============\");\r\n            Console.WriteLine($\"Running AutoML experiment for 20 seconds...\");\r\n            ExperimentResult<MulticlassClassificationMetrics> experimentResult = mlContext.Auto()\r\n                .CreateMulticlassClassificationExperiment(20)\r\n                .Execute(trainingDataView, labelColumnName: @\"MlLabels:Enter\");\r\n\r\n            // Evaluate the model and print metrics\r\n            Console.WriteLine(\"===== Evaluating model's accuracy with test data =====\");\r\n            RunDetail<MulticlassClassificationMetrics> best = experimentResult.BestRun;\r\n            ITransformer trainedModel = best.Model;\r\n            TransformerChain<ITransformer> trainedModelChain = (TransformerChain<ITransformer>)best.Model;\r\n            IDataView predictions = trainedModel.Transform(testDataView);\r\n            var metrics = mlContext.MulticlassClassification.Evaluate(predictions, labelColumnName: @\"MlLabels:Enter\", scoreColumnName: \"Score\", predictedLabelColumnName: \"PredictedLabel\",\r\n                topKPredictionCount: 1);\r\n\r\n            // Print metrics from top model\r\n            Console.WriteLine($\"*************************************************\");\r\n            Console.WriteLine($\"*       Metrics for {best.TrainerName} Multiclass Classification model      \");\r\n            Console.WriteLine($\"*------------------------------------------------\");\r\n            Console.WriteLine($\"*       MicroAccuracy:      {metrics.MicroAccuracy:#.##}\");\r\n            Console.WriteLine($\"*       MacroAccuracy:      {metrics.MacroAccuracy:#.##}\");\r\n            Console.WriteLine($\"*       LogLoss:            {metrics.LogLoss:#.##}\");\r\n            Console.WriteLine($\"*       PerClassLogLoss:    {metrics.PerClassLogLoss:#.##}\");\r\n            Console.WriteLine($\"*       TopKAccuracy:       {metrics.TopKAccuracy:#.##}\");\r\n            Console.WriteLine(metrics.ConfusionMatrix.GetFormattedConfusionTable());\r\n            Console.WriteLine($\"*************************************************\");\r\n\r\n            // Save/persist the trained model to a .ZIP file\r\n            mlContext.Model.Save(trainedModel, trainingDataView.Schema, ModelPath);\r\n\r\n            Console.WriteLine(\"The model is saved to {0}\", ModelPath);\r\n\r\n            return trainedModelChain;\r\n        }\r\n\r\n        private static void TestSinglePrediction(MLContext mlContext)\r\n        {\r\n            Console.WriteLine(\"=============== Testing prediction engine ===============\");\r\n\r\n            var Sample = new ModelInput()\r\n            {\r\n                High = 4323.25F,\r\n                Low = 4317.25F,\r\n                Close = 4321.75F,\r\n                BarTime = 1962.559F,\r\n                BarTimeAvg = 1065.821F,\r\n                Slope1 = -0.593749667F,\r\n                Acc = 0.434773016F,\r\n                Slope2 = 0.5404195F,\r\n                Conv = 4312.420398F,\r\n                Projection = 4313.347917F,\r\n                Lslope = -0.393904748F,\r\n            };\r\n\r\n            ITransformer trainedModel = mlContext.Model.Load(ModelPath, out var _);\r\n\r\n            // Create prediction engine related to the loaded trained model\r\n            var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(trainedModel);\r\n\r\n            // Score\r\n            var predictedResult = predEngine.Predict(Sample);\r\n\r\n            Console.WriteLine($\"**********************************************************************\");\r\n            Console.WriteLine($\"Predicted Entrance: {predictedResult.PredictedLabel}, actual: -1\");\r\n            Console.WriteLine($\"Probability: {predictedResult.Score}\");\r\n            Console.WriteLine($\"**********************************************************************\");\r\n        }\r\n\r\n        private static void CalculatePermutationFeatureImportance(MLContext mlContext, IDataView trainingDataView, TransformerChain<ITransformer> trainedModel)\r\n        {\r\n            // Extract the trainer (last transformer in the model)\r\n            var linearPredictor = (ISingleFeaturePredictionTransformer<object>)trainedModel.LastTransformer;\r\n\r\n            // Transform data (make predictions)\r\n            IDataView transformedData = trainedModel.Transform(trainingDataView);\r\n\r\n            // Get labels for feature importance\r\n            VBuffer<ReadOnlyMemory<char>> nameBuffer = default;\r\n            transformedData.Schema[\"__Features__\"].Annotations.GetValue(\"SlotNames\", ref nameBuffer);\r\n            // NOTE: The column name \"__Features__\" needs to match the featureColumnName used in the trainer, the name \"SlotNames\" is always the same regardless of trainer. View variable in Debug to find name.\r\n\r\n            var featureColumnNames = nameBuffer.DenseValues().ToList();\r\n\r\n            // Calculate Feature Permutation\r\n            ImmutableArray<BinaryClassificationMetricsStatistics> permutationMetrics =\r\n                                            mlContext.BinaryClassification.PermutationFeatureImportance(predictionTransformer: linearPredictor,\r\n                                                                                         data: transformedData,\r\n                                                                                         labelColumnName: @\"MlLabels:Enter\",\r\n                                                                                         numberOfExamplesToUse: 100, permutationCount: 30);\r\n\r\n            // Format feature importance output\r\n            Console.WriteLine(\"Feature\\tPFI\");\r\n\r\n            var featureImportanceMetrics =\r\n                permutationMetrics\r\n                .Select((metric, index) => new { index, metric.Accuracy })\r\n                .OrderByDescending(myFeatures => Math.Abs(myFeatures.Accuracy.Mean));\r\n\r\n\r\n            var featureNames = new List<string>();\r\n            var featurePFI = new List<double>();\r\n            foreach (var feature in featureImportanceMetrics)\r\n            {\r\n                featureNames.Add($\"{featureColumnNames[feature.index],-20}\");\r\n                featurePFI.Add(feature.Accuracy.Mean);\r\n                Console.WriteLine($\"{featureColumnNames[feature.index],-20}|\\t{feature.Accuracy.Mean}\");\r\n            }\r\n\r\n        }\r\n    }\r\n}`\r\n[ES Tuesday 922.csv](https://github.com/dotnet/machinelearning/files/11326721/ES.Tuesday.922.csv)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6630","RelatedDescription":"Closed issue \"Multiclass Classification AutoML and PFI won't complete\" (#6630)"},{"Id":"1689170777","IsPullRequest":false,"CreatedAt":"2023-04-30T01:22:03","Actor":"michaelgsharp","Number":"6637","RawContent":null,"Title":"AutoML Test timeout failure","State":"closed","Body":"These tests are flaky and timeout causing CI issues when they fail. @LittleLittleCloud I bet increasing the timeout for the trial will be enough to fix it, but the CI machines, especially for code coverage, aren't as powerful as our local ones.\r\n\r\nMicrosoft.ML.AutoML.Test.AutoMLExperimentTests.AutoMLExperiment_Iris_Train_Test_Split_Test\r\nSystem.TimeoutException : Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity\r\n\r\nMicrosoft.ML.AutoML.Test.AutoMLExperimentTests.AutoMLExperiment_Iris_CV_5_Test\r\nSystem.TimeoutException : Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity\r\n\r\nMicrosoft.ML.AutoML.Test.AutoMLExperimentTests.AutoMLExperiment_UCI_Adult_CV_5_Test\r\nSystem.TimeoutException : Training time finished without completing a successful trial. Either no trial completed or the metric for all completed trials are NaN or Infinity","Url":"https://github.com/dotnet/machinelearning/issues/6637","RelatedDescription":"Closed issue \"AutoML Test timeout failure\" (#6637)"},{"Id":"1689254880","IsPullRequest":true,"CreatedAt":"2023-04-30T01:22:02","Actor":"LittleLittleCloud","Number":"6638","RawContent":null,"Title":"Update AutoMLExperimentTests.cs to fix timeout error","State":"closed","Body":"We are excited to review your PR.\r\n\r\nfix #6637 \r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6638","RelatedDescription":"Closed or merged PR \"Update AutoMLExperimentTests.cs to fix timeout error\" (#6638)"},{"Id":"1687551259","IsPullRequest":true,"CreatedAt":"2023-04-29T09:25:58","Actor":"michaelgsharp","Number":"6636","RawContent":null,"Title":"Update TorchSharp to latest version","State":"closed","Body":"Updates TorchSharp to the latest version and fixes any of the breaking changes. ","Url":"https://github.com/dotnet/machinelearning/pull/6636","RelatedDescription":"Closed or merged PR \"Update TorchSharp to latest version\" (#6636)"},{"Id":"1685384925","IsPullRequest":true,"CreatedAt":"2023-04-28T17:27:08","Actor":"LittleLittleCloud","Number":"6633","RawContent":null,"Title":"add obj-detection automl sweeper","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6633","RelatedDescription":"Closed or merged PR \"add obj-detection automl sweeper\" (#6633)"},{"Id":"1685804384","IsPullRequest":false,"CreatedAt":"2023-04-26T23:19:04","Actor":"LittleLittleCloud","Number":"6635","RawContent":null,"Title":"Propose: Let's expose Bert sentence embedding to public","State":"closed","Body":"**Is your feature request related to a problem? Please describe.**\r\nUsing TextEmbedding API from OpenAI is great, but it's not free.\r\n\r\nBert embedding is available in ML.Net (or might be available with minor change), but it's not public available.\r\n\r\nWe all love free and good stuff, so let's expose bert embedding transformer to public. That would be a useful feature in retrieving relevant corpus when creating prompts\r\n\r\n**Describe the solution you'd like**\r\na transformer that transforms a text to an embedding vector\r\n- input: \"text\"\r\n- output column: float[768]\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6635","RelatedDescription":"Closed issue \"Propose: Let's expose Bert sentence embedding to public\" (#6635)"},{"Id":"1685426419","IsPullRequest":false,"CreatedAt":"2023-04-26T17:18:39","Actor":"luisquintanilla","Number":"6634","RawContent":null,"Title":"Add support for .tiktoken file format to Microsoft.ML.Tokenizers","State":"open","Body":"OpenAI library [tiktoken](https://github.com/openai/tiktoken) provides tokenization support for. Older GPT models were compatible with common [BPE tokenizer vocab format (vocab.json / merges.txt)](https://huggingface.co/gpt2/tree/main). More recent models support [other formats](https://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken). \r\n\r\nUpdate Microsoft.ML.Tokenizers to provide support for clk100_base vocabulary format","Url":"https://github.com/dotnet/machinelearning/issues/6634","RelatedDescription":"Open issue \"Add support for .tiktoken file format to Microsoft.ML.Tokenizers\" (#6634)"},{"Id":"1685341698","IsPullRequest":true,"CreatedAt":"2023-04-26T16:47:41","Actor":"LittleLittleCloud","Number":"6632","RawContent":null,"Title":"add obj sweeper in AutoML","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6632","RelatedDescription":"Closed or merged PR \"add obj sweeper in AutoML\" (#6632)"},{"Id":"1684234590","IsPullRequest":false,"CreatedAt":"2023-04-26T04:11:53","Actor":"alvstw","Number":"6631","RawContent":null,"Title":"FieldAwareFactorizationMachine is not working in arm64 macOS","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: macOS 13.3.1 arm64\r\n - ML.NET Version: 2.0\r\n - .NET Version: .NET 7.0\r\n\r\n**Describe the bug**\r\nRunning FieldAwareFactorizationMachine model produce the following error:\r\nSystem.DllNotFoundException: Unable to load shared library 'CpuMathNative' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: ","Url":"https://github.com/dotnet/machinelearning/issues/6631","RelatedDescription":"Open issue \"FieldAwareFactorizationMachine is not working in arm64 macOS\" (#6631)"},{"Id":"1681785812","IsPullRequest":false,"CreatedAt":"2023-04-24T18:10:15","Actor":"JakeRadMSFT","Number":"6629","RawContent":null,"Title":"Resizing Images and Boxes for Vision Scenarios","State":"open","Body":"Repro:\r\n\r\n- Train OD Model with large images ( 4000 x 3000 )\r\n\r\nResult:\r\n\r\n- Stalls at Epoch 0 and uses 100% of CPU\r\n\r\nExpected Result:\r\n\r\n- It works :)\r\n\r\nWorkaround:\r\n\r\n- Resize Images\r\n  - https://github.com/JakeRadMSFT/Scratch/blob/main/ObjectDetective/ObjectDetective/ObjectDetectionVOTT.training.cs#L183\r\n- Resize Boxes\r\n  - https://github.com/JakeRadMSFT/Scratch/blob/6981d4701de25f002fe87bf9ed95083e3a2ebc44/ObjectDetective/ObjectDetective/ObjectDetectionVOTT.training.cs#L94","Url":"https://github.com/dotnet/machinelearning/issues/6629","RelatedDescription":"Open issue \"Resizing Images and Boxes for Vision Scenarios\" (#6629)"},{"Id":"1677637638","IsPullRequest":true,"CreatedAt":"2023-04-21T16:49:15","Actor":"JakeRadMSFT","Number":"6628","RawContent":null,"Title":"Add support for string vectors to DataFrame","State":"closed","Body":"This PR adds support for string vector/\"ReadOnlyMemory<char>\" vectors.\r\n\r\nRelevant issue: https://github.com/dotnet/machinelearning/issues/5872\r\n\r\nBuilding on: https://github.com/dotnet/machinelearning/pull/6409\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6628","RelatedDescription":"Closed or merged PR \"Add support for string vectors to DataFrame\" (#6628)"}],"ResultType":"GitHubIssue"}},"RunOn":"2023-05-05T03:30:21.4121197Z","RunDurationInMilliseconds":501}