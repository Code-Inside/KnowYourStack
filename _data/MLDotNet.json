{"Data":{"GitHub":{"Issues":[{"Id":"1895004059","IsPullRequest":false,"CreatedAt":"2023-09-13T18:00:29","Actor":"andrei-faber","Number":"6823","RawContent":null,"Title":"The project won't build","State":"open","Body":"**System Information (please complete the following information):**\r\nWindows 11 x64\r\n.NET 7.0.111, latest source code\r\n\r\n**Describe the bug**\r\nBuild error:\r\n```\r\nD:\\Projects.Ext\\machinelearning\\src\\Native\\Native.proj(133,5): error MSB3073: The command \"\"D:\\Projects.Ext\\machinelearning\\src\\Native\\build.cmd\" Debug x64 --mkllibpath C:\\Users\\andreifaber\\.nuget\\packages\\mlnetmkldeps\\0. 0.0.12\\runtimes\\win-x64\\native --onedaldevelpath C:\\Users\\andreifaber\\.nuget\\packages\\inteldal.devel.win-x64\\2023.0.0.23189\\build\\native\\daal\\latest --onetbbdevelpath C:\\Users\\andreifaber\\.nuget\\packages\\inteltbb.devel.wi n\\2021.7.1.15305\\lib\\native\\win-x64\" exited with code 1.\r\nD:\\Projects.Ext\\machinelearning\\Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"D:\\Projects.Ext\\machinelearning\\artifacts\\bin\\Native\\x64.Debug\\CpuMathNative.dll\" because it was not found. [D:\\Projec ts.Ext\\machinelearning\\test\\Microsoft.ML.CpuMath.PerformanceTests\\Microsoft.ML.CpuMath.PerformanceTests.csproj::TargetFramework=net6.0]\r\nD:\\Projects.Ext\\machinelearning\\Directory.Build.targets(54,3): error MSB3030: Could not copy the file \"D:\\Projects.Ext\\machinelearning\\artifacts\\bin\\Native\\x64.Debug\\LdaNative.dll\" because it was not found. [D:\\Projects.E xt\\machinelearning\\src\\Microsoft.ML\\Microsoft.ML.csproj]\r\n    0 Warning(s)\r\n    3 Error(s)\r\n```\r\n\r\n**To Reproduce**\r\nbuild.cmd -configuration Debug /p:TargetArchitecture=x64\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6823","RelatedDescription":"Open issue \"The project won't build\" (#6823)"},{"Id":"1894936714","IsPullRequest":true,"CreatedAt":"2023-09-13T17:12:30","Actor":"asmirnov82","Number":"6822","RawContent":null,"Title":"PrimitiveDataFrameColumn.Clone method crashes when is used with IEnumerable mapIndices argument","State":"open","Body":"In frame of this PR:\r\n\r\n1) Cover PrimitiveDataFrameColumn.Clone method with additional unit tests\r\n2) Use Span.Fill method to init null validity buffer instead of setting individual bits  in a cycle\r\n\r\n`lastNullBitMapBuffer.RawSpan.Slice(lastNullBitMapBuffer.Length - nullBufferAllocatable, nullBufferAllocatable).Fill(value.HasValue ? (byte)0xFF : (byte)0x0);`\r\n\r\n3) Fixes #6821 \r\n\r\nRoot cause: \r\nusing of _ret[curRow] = value;_ for empty column. \r\nchanged to _ret.Append(value);_\r\n\r\nAdditionaly fix creation of incorrect column type for the inheritors of PrimitiveDataFrame<T> \r\n\r\n4) Refactoring: Fixing 3 and 2 allowed to get rid of _internal bool _modifyNullCountWhileIndexing_ field.","Url":"https://github.com/dotnet/machinelearning/pull/6822","RelatedDescription":"Open PR \"PrimitiveDataFrameColumn.Clone method crashes when is used with IEnumerable mapIndices argument\" (#6822)"},{"Id":"1894905497","IsPullRequest":false,"CreatedAt":"2023-09-13T16:49:38","Actor":"asmirnov82","Number":"6821","RawContent":null,"Title":"Primitive DataFrame Column Clone method crashes with IEnumerable argument","State":"open","Body":"public PrimitiveDataFrameColumn<T> Clone(IEnumerable<long> mapIndices) - crashes with _**System.ArgumentOutOfRangeException: 'rowIndex Parameter name: Index cannot be greater than the Column's Length'**_ exception\r\n\r\nSimple unti test:\r\n\r\n```\r\n[Fact]\r\npublic void TestNotNullableColumnCloneWithIndicesMapAsEnumerable()\r\n{\r\n    //Arrange\r\n    var column = new Int32DataFrameColumn(\"Int column\", values: new[] { 0, 5, 2, 4, 1, 3 });\r\n    var indicesMap = new long[] { 0, 1, 2, 5, 3, 4 };\r\n\r\n    //Act\r\n    var clonedColumn = column.Clone(indicesMap);\r\n\r\n    //Assert\r\n    Assert.NotSame(column, clonedColumn);\r\n    Assert.Equal(column.Name, clonedColumn.Name);\r\n    Assert.Equal(column.DataType, clonedColumn.DataType);\r\n    Assert.Equal(column.NullCount, clonedColumn.NullCount);\r\n    Assert.Equal(indicesMap.Length, clonedColumn.Length);\r\n\r\n    for (int i = 0; i < indicesMap.Length; i++)\r\n        Assert.Equal(column[indicesMap[i]], clonedColumn[i]);\r\n}\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6821","RelatedDescription":"Open issue \"Primitive DataFrame Column Clone method crashes with IEnumerable argument\" (#6821)"},{"Id":"1894429353","IsPullRequest":false,"CreatedAt":"2023-09-13T12:31:52","Actor":"asmirnov82","Number":"6820","RawContent":null,"Title":"All DataFrame Elementwise methods uncorrectly work with NULL values","State":"open","Body":"**Describe the bug**\r\nPrimitiveColumn ElementwiseEquals, ElementwizeNotEquals and other Elementwise method ignore validity information\r\n\r\nFor example. this unit test fails as it ElementWizeEquals return true for the first item ( as 0 == null):\r\n\r\n```\r\n[Fact]\r\npublic void TestElementWiseEquals()\r\n{\r\n    PrimitiveDataFrameColumn<int> intColumn1 = new PrimitiveDataFrameColumn<int>(\"Int1\", new int?[] { 0, 2, 3 });\r\n    PrimitiveDataFrameColumn<int> intColumn2 = new PrimitiveDataFrameColumn<int>(\"Int2\", new int?[] { null, 2, 3 });\r\n\r\n    var results = intColumn1.ElementwiseEquals(intColumn2);\r\n\r\n    Assert.False(results[0]);\r\n}\r\n```\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6820","RelatedDescription":"Open issue \"All DataFrame Elementwise methods uncorrectly work with NULL values\" (#6820)"},{"Id":"1892257616","IsPullRequest":false,"CreatedAt":"2023-09-12T10:54:55","Actor":"superichmann","Number":"6819","RawContent":null,"Title":"estimator save not working","State":"open","Body":"when trying to save `EstimatorChain<NormalizingTransformer>` with the save function I get: \r\n`BinaryFormatter serialization and deserialization are disabled within this application`\r\nCan you please fix the code in such a way that it will actually work?","Url":"https://github.com/dotnet/machinelearning/issues/6819","RelatedDescription":"Open issue \"estimator save not working\" (#6819)"},{"Id":"1891370080","IsPullRequest":false,"CreatedAt":"2023-09-11T22:32:26","Actor":"kayhustle","Number":"6818","RawContent":null,"Title":"Does ML .net support Z Score Normalization?","State":"open","Body":"I'm trying to calculate the z score normalized transform using ML.net TransformsCatalog. In Python this is achieved using the StandardScaler transform. I don't see this mentioned in the list of transforms. Is this type of transformation supported via one of the supported transformations?\r\nThanks","Url":"https://github.com/dotnet/machinelearning/issues/6818","RelatedDescription":"Open issue \"Does ML .net support Z Score Normalization?\" (#6818)"},{"Id":"1889071285","IsPullRequest":false,"CreatedAt":"2023-09-10T09:29:09","Actor":"Ceeeeed","Number":"6817","RawContent":null,"Title":"LightGMB bad allocation crash","State":"open","Body":" - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET v2.0.1 & AutoML v0.20.1\r\n - .NET Version: .NET 7.0\r\n - 16gb ram\r\n - 4 cores\r\n \r\nHello, \r\nduring an AutoML regression training session, after more than three hours of training and successful training of 5 models `[LightGBM] [Warning] bad allocation` warnings shows in the console, and after a while the program crashes.\r\n\r\n### About my dataset:\r\n111 275 columns and 872 rows (including label column). Contains only floats from -1 to 1.\r\n\r\n### Code responsible for training the model:\r\n```cs\r\npublic async Task<IEnumerable<TrialResult>> TrainModel(DataOperationsCatalog.TrainTestData trainValidationData)\r\n{\r\n    Logger.Log($\"Running the experiment...\");\r\n\r\n    AutoMLExperiment experiment = MLContext.Auto().CreateExperiment();\r\n\r\n    experiment\r\n        .SetPipeline(pipeline)\r\n        .SetRegressionMetric(RegressionMetric.MeanAbsoluteError)\r\n        .SetTrainingTimeInSeconds(maxTrainingTime)\r\n        .SetDataset(trainValidationData);\r\n\r\n    CancellationTokenSource cts = new();\r\n\r\n    AutoMLMonitor monitor = new(pipeline, maxTrainingTime, maxTrainingIterations, cts);\r\n    experiment.SetMonitor(monitor);\r\n\r\n    await experiment.RunAsync(cts.Token);\r\n    return monitor.GetCompletedTrials();\r\n}\r\n```\r\n\r\n### My pipeline is simple:\r\n```cs\r\npipeline = MLContext.Auto().Regression(useFastForest: false, useFastTree: false, useLbfgs: false, useLgbm: true, useSdca: false);\r\n```\r\n\r\n### Logs: \r\n(In the timestamp, the first number is the application running time (hh:mm) and the second number is the local time (hh:mm:ss))\r\n```\r\n[0:00 - 06:59:59] Loading data set...\r\n[0:01 - 07:01:09] Creating data view...\r\n[0:01 - 07:01:11] Running the experiment...\r\n[0:01 - 07:01:11] Model 1 started training using LightGbmRegression algorithm\r\n[0:01 - 07:01:20] 10s/80000s (0.01 %) - Model finished training in 9.44s using LightGbmRegression algorithm (CPU: 95.51 %, RAM: 1828.41) - result: 15.08 %\r\n[0:01 - 07:01:20] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (15.08 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[0:01 - 07:01:20] Model 2 started training using LightGbmRegression algorithm\r\n[0:03 - 07:02:42] 91s/80000s (0.11 %) - Model finished training in 81.75s using LightGbmRegression algorithm (CPU: 102.15 %, RAM: 1971.35) - result: 8.46 %\r\n[0:03 - 07:02:42] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (8.46 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[0:03 - 07:02:42] Model 3 started training using LightGbmRegression algorithm\r\n[0:10 - 07:09:56] 526s/80000s (0.66 %) - Model finished training in 434.11s using LightGbmRegression algorithm (CPU: 101.56 %, RAM: 2008.12) - result: 6.49 %\r\n[0:10 - 07:09:56] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (6.49 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[0:10 - 07:09:56] Model 4 started training using LightGbmRegression algorithm\r\n[3:09 - 10:08:58] 11267s/80000s (14.08 %) - Model finished training in 10741.15s using LightGbmRegression algorithm (CPU: 104.30 %, RAM: 5345.96) - result: 5.58 %\r\n[3:09 - 10:08:58] ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲ New best result! (5.58 %) ▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲▲\r\n[3:09 - 10:08:58] Model 5 started training using LightGbmRegression algorithm\r\n[3:21 - 10:20:58] 11987s/80000s (14.98 %) - Model finished training in 720.38s using LightGbmRegression algorithm (CPU: 102.34 %, RAM: 2526.46) - result: 8.69 %\r\n[3:21 - 10:20:58] Model 6 started training using LightGbmRegression algorithm\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] [LightGBM] [Warning] bad allocation\r\nbad allocation\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] bad allocation\r\n[LightGBM] [Warning] bad allocation\r\n(...) more of those\r\n```\r\n[full log.txt](https://github.com/dotnet/machinelearning/files/12567896/full.log.txt)","Url":"https://github.com/dotnet/machinelearning/issues/6817","RelatedDescription":"Open issue \"LightGMB bad allocation crash\" (#6817)"},{"Id":"1888932369","IsPullRequest":true,"CreatedAt":"2023-09-10T02:00:23","Actor":"feiyun0112","Number":"6816","RawContent":null,"Title":"use HingeLoss as default loss function","State":"open","Body":"#6815 \r\n\r\n[StandardTrainersCatalog.AveragedPerceptron](https://github.com/dotnet/machinelearning/blob/09b80f8a08340dc7d79ac75e13c722313f0845eb/src/Microsoft.ML.StandardTrainers/StandardTrainersCatalog.cs#L429C13-L429C196) factory method uses LogLoss as its default loss function, which contradicts method documentation and defaults.AveragedPerceptronTrainer.Options","Url":"https://github.com/dotnet/machinelearning/pull/6816","RelatedDescription":"Open PR \"use HingeLoss as default loss function\" (#6816)"},{"Id":"1888804877","IsPullRequest":false,"CreatedAt":"2023-09-09T16:26:14","Actor":"KirillShlenskiy","Number":"6815","RawContent":null,"Title":"AveragedPerceptron factory method uses wrong default loss function","State":"open","Body":"**System Information:**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 3.0.0-preview.23266.6\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\n[StandardTrainersCatalog.AveragedPerceptron](https://github.com/dotnet/machinelearning/blob/09b80f8a08340dc7d79ac75e13c722313f0845eb/src/Microsoft.ML.StandardTrainers/StandardTrainersCatalog.cs#L429C13-L429C196) factory method uses LogLoss as its default loss function, which contradicts method documentation and `AveragedPerceptronTrainer.Options` defaults.\r\n\r\n`AveragedPerceptron` method summary states:\r\n> `<param name=\"lossFunction\">`The <a href=\"https://en.wikipedia.org/wiki/Loss_function\">loss</a> function minimized in the training process. If null, HingeLoss would be used and lead to a max-margin averaged perceptron trainer.`</param>`\r\n\r\nThis results in the following inconsistency in behaviour:\r\n```CSharp\r\n// Uses LogLoss:\r\nMLContext.BinaryClassification.Trainers.AveragedPerceptron(\"Label\");\r\n\r\n// Uses HingeLoss:\r\nMLContext.BinaryClassification.Trainers.AveragedPerceptron(new AveragedPerceptronTrainer.Options { LabelColumnName = \"Label\" });\r\n```\r\n\r\n**Expected behavior**\r\n2 options:\r\n- Make the non-options `AveragedPerceptron` factory method overload use `HingeLoss` as its default loss function (breaking change).\r\n- Amend the method documentation.","Url":"https://github.com/dotnet/machinelearning/issues/6815","RelatedDescription":"Open issue \"AveragedPerceptron factory method uses wrong default loss function\" (#6815)"},{"Id":"1888195901","IsPullRequest":true,"CreatedAt":"2023-09-08T19:16:42","Actor":"asmirnov82","Number":"6814","RawContent":null,"Title":"Improve performance of column cloning inside DataFrame arithmetics","State":"open","Body":"The goal of this PR is to perform Arithmetics operation on columns with the same underlying data type approximately 3 times faster.\r\n\r\nDetail of changes:\r\n\r\n1) Fix PrimitiveColumnContainer Clone() method to use memory block coping for internal buffer instead of appending values one by one (with memory reallocation on each buffer resizing cycle). Do similar changes for CloneNullBitMapBuffers() method\r\n\r\n2)  Improve BinaryOperation.Implementation methods for all Arithmetic operations that happen not in place (default behavior). \r\nBefore the change autogenerated code looked like this:\r\n\r\n```\r\npublic partial class SingleDataFrameColumn\r\n{\r\n    internal SingleDataFrameColumn AddImplementation(SingleDataFrameColumn column, bool inPlace = false)\r\n    {\r\n        if (column.Length != Length)\r\n        {\r\n            throw new ArgumentException(Strings.MismatchedColumnLengths, nameof(column));\r\n        }\r\n        SingleDataFrameColumn newColumn = inPlace ? this : CloneAsSingleColumn();\r\n        newColumn.ColumnContainer.Add(column.ColumnContainer);\r\n        return newColumn;\r\n    }\r\n}\r\n```\r\n\r\nAfter PR https://github.com/dotnet/machinelearning/pull/6677 CloneAsSingleColumn can be changed to just this.Clone(). This allow to avoid unnecessary type conversion, that happens inside CloneAs... method and use fast Clone() method with bulk memory copy for internal buffers. For example. for Single:\r\n\r\n```\r\ninternal PrimitiveColumnContainer<float> CloneAsFloatContainer()\r\n{\r\n ...\r\n    for (int i = 0; i < span.Length; i++)\r\n   {\r\n          newBuffer.Append(SingleConverter<T>.Instance.GetSingle(span[i]);\r\n   }\r\n}\r\n```\r\n\r\n3) Fix DataFrameBuffer constructor. \r\nDataFrameBuffer overrides parent ReadOnlyDataFrameBuffer ReadOnlyBuffer to return own new field _memory instead of parent _readOnlyBuffer (after this parent _readonlybuffer is ignored and never used). However in constructor _memory is not created, instead base constructor is called to allocate _readonlybuffer (which is ignored). So after creating Capacity of such buffer is always 0 (ignoring the actual parameter passed to the constructor) and additional memory is allocated\r\n\r\n4) After 3 is fixed, changed code to use DataFrameBuffer constructor with capacity instead of creating empty dataframe buffer and than reallocating memory by calling EnsureCapacity \r\n\r\n___________________________\r\n\r\nResult:\r\n\r\nSimple tests for 1 million of rows:\r\n\r\n```\r\n[GlobalSetup]\r\npublic void SetUp()\r\n{\r\n    var values = Enumerable.Range(0, ItemsCount);\r\n    _column1 = new Int32DataFrameColumn(\"Column1\", values);\r\n    _column2 = new Int32DataFrameColumn(\"Column2\", values);\r\n}\r\n\r\n[Benchmark]\r\npublic void Sum()\r\n{\r\n    var column = _column1 + _column2;\r\n}\r\n```\r\n\r\n```\r\nBefore PR:\r\n| Method |    Mean |     Error |   StdDev |\r\n|    Sum | 18.02 ms | 0.090 ms | 0.080 ms |\r\n\r\nAfter PR:\r\n| Method |     Mean |     Error |    StdDev |\r\n|    Sum | 6.896 ms | 0.1363 ms | 0.1673 ms |\r\n```","Url":"https://github.com/dotnet/machinelearning/pull/6814","RelatedDescription":"Open PR \"Improve performance of column cloning inside DataFrame arithmetics\" (#6814)"},{"Id":"1884483922","IsPullRequest":true,"CreatedAt":"2023-09-08T19:13:01","Actor":"michaelgsharp","Number":"6811","RawContent":null,"Title":"removed codecov token","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6811","RelatedDescription":"Closed or merged PR \"removed codecov token\" (#6811)"},{"Id":"1888170048","IsPullRequest":true,"CreatedAt":"2023-09-08T18:53:48","Actor":"michaelgsharp","Number":"6813","RawContent":null,"Title":"added in win-arm64","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6813","RelatedDescription":"Open PR \"added in win-arm64\" (#6813)"},{"Id":"1884875445","IsPullRequest":false,"CreatedAt":"2023-09-06T23:17:17","Actor":"andrewtek","Number":"6812","RawContent":null,"Title":"Need a supported way to get Eigenvectors from PrincipalComponentAnalysisTransformer","State":"open","Body":"I am wanting to evaluate the Eigenvectors when performing Principal Component Analysis. Unfortunately, these appear to locked away inside a private field of PrincipalComponentAnalysisTransformer. \r\n\r\nUsing reflection, I can get the private _transformInfos field from my fitted instance of PrincipalComponentAnalysisTransformer. This provides me with an array of the private internal class TransformInfo. From here, I can use reflection to get the first array entry's Eigenvectors field which will return my float[][] array.\r\n\r\nWould it be possible to add a \"GetEigenvectors\" method to PrincipalComponentAnalysisTransformer that returns this float[][] data? ","Url":"https://github.com/dotnet/machinelearning/issues/6812","RelatedDescription":"Open issue \"Need a supported way to get Eigenvectors from PrincipalComponentAnalysisTransformer\" (#6812)"},{"Id":"1881808819","IsPullRequest":false,"CreatedAt":"2023-09-05T11:45:19","Actor":"ogoun","Number":"6810","RawContent":null,"Title":"Fault convert to ONNX object detection model","State":"open","Body":"**System Information:**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET v3.0.0-preview.23266.6\r\n - .NET Version: .NET 7.0\r\n\r\n**Describe the bug**\r\nFault conversion to ONNX\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Train object detection model by tutorial (https://devblogs.microsoft.com/dotnet/object-detection-ml-dotnet-model-builder/)\r\n2. Try convert model\r\n```charp\r\npublic class ModelInput\r\n        {\r\n            [LoadColumn(0)]\r\n            [ColumnName(@\"Labels\")]\r\n            public string[] Labels { get; set; }\r\n\r\n            [LoadColumn(1)]\r\n            [ColumnName(@\"Image\")]\r\n            [Microsoft.ML.Transforms.Image.ImageType(640, 640)]\r\n            public MLImage Image { get; set; }\r\n\r\n            [LoadColumn(2)]\r\n            [ColumnName(@\"Box\")]\r\n            public float[] Box { get; set; }\r\n\r\n        }\r\n\r\npublic static void Export()\r\n        {\r\n            var onnxPath = \"test.onnx\";\r\n            var mlContext = new MLContext();\r\n            ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var _);\r\n\r\n            var input = new ModelInput[30];\r\n            for (int i = 0; i < input.Length; i++)\r\n            {\r\n                input[i] = new ModelInput\r\n                {\r\n                    Image = MLImage.CreateFromFile(@\"demo.jpg\")\r\n                };\r\n            }\r\n            IDataView trainingData = mlContext.Data.LoadFromEnumerable(input);\r\n            using (var onnx = File.Open(onnxPath, FileMode.OpenOrCreate))\r\n            {\r\n                mlContext.Model.ConvertToOnnx(mlModel, trainingData, onnx);\r\n            }\r\n        }\r\n```\r\n3. Got error\r\nSystem.InvalidOperationException: 'Unsupported type: Microsoft.ML.Data.MLImage'\r\n\r\n**Expected behavior**\r\nGot onnx model\r\n\r\n**Additional context**\r\nIf I try to represent the input as an array [B,3,W,H], it says that it expects an image, when I pass the image, it says that it does not support it.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6810","RelatedDescription":"Open issue \"Fault convert to ONNX object detection model\" (#6810)"},{"Id":"1878973631","IsPullRequest":false,"CreatedAt":"2023-09-03T07:24:30","Actor":"Chiragjasuja","Number":"6809","RawContent":null,"Title":"Add support for Apache.Arrow.Types.TimestampType","State":"open","Body":"**System Information (please complete the following information):**\r\n - Win 10\r\n - Microsoft.Data.Analysis v0.20.1\r\n - .NET Version: .NET 6\r\n\r\n**Describe the bug**\r\nI am getting below exception \r\n\r\nUnhandled exception. System.NotImplementedException: timestamp\r\n   at Microsoft.Data.Analysis.DataFrame.AppendDataFrameColumnFromArrowArray(Field field, IArrowArray arrowArray, DataFrame ret, String fieldNamePrefix)\r\n   at Microsoft.Data.Analysis.DataFrame.FromArrowRecordBatch(RecordBatch recordBatch)\r\n   at Program.<Main>$(String[] args) in C:\\Users\\mrchi\\source\\repos\\ApacheArrowExample\\ApacheArrowExample\\Program.cs:line 17\r\n   at Program.<Main>(String[] args)\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Take a .arrow file with one column of type Apache.Arrow.Types.TimestampType\r\n2. var dataframe = DataFrame.FromArrowRecordBatch(recordBatch);\r\n3. It will throw above exception\r\n\r\n**Expected behavior**\r\nThe record batch should transform to Dataframe with appropriate tye to handle timestamp (Datetime maybe)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6809","RelatedDescription":"Open issue \"Add support for Apache.Arrow.Types.TimestampType\" (#6809)"},{"Id":"1865835159","IsPullRequest":false,"CreatedAt":"2023-09-02T04:06:56","Actor":"pi-curst","Number":"6806","RawContent":null,"Title":"Append Datafarmes","State":"closed","Body":"**System Information (please complete the following information):**\r\n - .NET Version: [e.g. .NET 6.0.301]\r\n\r\n**Describe the bug**\r\n\r\nHi, Appending Dataframes (DataFrame.Append Method) doesn't seem to append based on column names, but appends based on the position. Is this normal?\r\n\r\n**To Reproduce**\r\n\r\n`var data = new DataFrame(); \r\n\r\nvar col1 = new StringDataFrameColumn(\"ColumnA\", new string[] { \"a\", \"b\", \"c\", \"d\", \"e\" });\r\nvar col2 = new Int32DataFrameColumn(\"ColumnB\", new int[] { 1, 2, 3, 4, 5 });\r\nvar col3 = new Int32DataFrameColumn(\"ColumnC\", new int[] { 10, 20, 30, 40, 50 });\r\nvar col4 = new StringDataFrameColumn(\"ColumnA\", new string[] { \"f\", \"g\", \"c\", \"d\", \"e\" });\r\nvar col5 = new Int32DataFrameColumn(\"ColumnB\", new int[] { 6, 7, 3, 4, 5 });\r\nvar col6 = new Int32DataFrameColumn(\"ColumnC\", new int[] { 100, 200, 300, 400, 500 });\r\n\r\nvar dataFrame1 = new DataFrame(col1, col2, col3);\r\nvar dataFrame2 = new DataFrame(col4, col6, col5);\r\n\r\nvar dataFrames = new List<DataFrame> { dataFrame1, dataFrame2 };\r\nvar resultDataFrame = dataFrame1.Append(dataFrame2.Rows);`\r\n\r\n\r\n**Exhibited behavior**\r\n\r\nindex | ColumnA | ColumnB | ColumnC\r\n-- | -- | -- | --\r\n0 | a | 1 | 10\r\n1 | b | 2 | 20\r\n2 | c | 3 | 30\r\n3 | d | 4 | 40\r\n4 | e | 5 | 50\r\n5 | f | 100 | 6\r\n6 | g | 200 | 7\r\n7 | c | 300 | 3\r\n8 | d | 400 | 4\r\n9 | e | 500 | 5\r\n\r\n\r\n**Expected behavior**\r\n\r\nindex | ColumnA | ColumnB | ColumnC\r\n-- | -- | -- | --\r\n0 | a | 1 | 10\r\n1 | b | 2 | 20\r\n2 | c | 3 | 30\r\n3 | d | 4 | 40\r\n4 | e | 5 | 50\r\n5 | f | 6 | 100\r\n6 | g | 7 | 200\r\n7 | c | 3 | 300\r\n8 | d | 4 | 400\r\n9 | e | 5 | 500\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6806","RelatedDescription":"Closed issue \"Append Datafarmes\" (#6806)"},{"Id":"1877864231","IsPullRequest":true,"CreatedAt":"2023-09-02T04:06:55","Actor":"asmirnov82","Number":"6808","RawContent":null,"Title":"Append dataframe rows based on column names","State":"closed","Body":"Fixes #6806 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6808","RelatedDescription":"Closed or merged PR \"Append dataframe rows based on column names\" (#6808)"},{"Id":"1875097039","IsPullRequest":false,"CreatedAt":"2023-08-31T09:02:58","Actor":"CodedBeard","Number":"6807","RawContent":null,"Title":"GC pause caused by Tuple<int, int> on model load","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nMy app is quite sensitive to GC pauses, so I've been doing allocation profiling. I noticed that a lot of GC pauses are being caused by the usage of `Tuple<int, int>` within the `Attention` class when the model is loaded.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/aaf226c7e7c359edf27e663362e928e02c8b9d0f/src/Microsoft.ML.TorchSharp/AutoFormerV2/Attention.cs#L72-L79\r\n\r\n**Describe the solution you'd like**\r\nIn my own fork, I've switched to using `ValueTuple`, which has removed the allocations and thus GC pauses\r\n\r\n**Describe alternatives you've considered**\r\nI don't think there's an easier/cleaner fix for this.\r\n\r\n**Additional context**\r\nUsing `Microsoft.ML.TorchSharp` version `0.21.0-preview.23266.6`, I observed 240k allocations of `Tuple<int, int>` during model loading, coming in just after `Tensor`.\r\n\r\n<img width=\"364\" alt=\"ml-allocations\" src=\"https://github.com/dotnet/machinelearning/assets/4446559/532508f8-9bdb-48dc-82da-9ff0be517fb2\">\r\n\r\nAfter switching to `ValueTuple` on my own fork, these allocations were removed, resulting in a significant reduction in CG pauses during model loading.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6807","RelatedDescription":"Open issue \"GC pause caused by Tuple<int, int> on model load\" (#6807)"},{"Id":"1864410786","IsPullRequest":false,"CreatedAt":"2023-08-27T22:18:38","Actor":"l3aalteshuva","Number":"6804","RawContent":null,"Title":"ITransform","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/6804","RelatedDescription":"Closed issue \"ITransform\" (#6804)"},{"Id":"1865657667","IsPullRequest":true,"CreatedAt":"2023-08-24T19:56:15","Actor":"michaelgsharp","Number":"6805","RawContent":null,"Title":"removed deprecated yosemite brew","State":"closed","Body":"Removed the deprecated reference to yosemite in the mac os brew file.","Url":"https://github.com/dotnet/machinelearning/pull/6805","RelatedDescription":"Closed or merged PR \"removed deprecated yosemite brew\" (#6805)"},{"Id":"1864090498","IsPullRequest":false,"CreatedAt":"2023-08-23T22:17:19","Actor":"saibaldas","Number":"6803","RawContent":null,"Title":"Using Roberta-base fine-tuned for boolq exported to ONNX in ML.NET ","State":"open","Body":"Roberta-base fine-tuned for the boolq dataset uses the tokenizer encode_plus to encode both the question and context. When exported to ONNX , the inputs are \r\n\r\nname: input_ids\r\ntensor: int64[batch_size,sequence_length]\r\n\r\nname: attention_mask\r\ntensor: int64[batch_size,sequence_length]\r\n\r\nPlease suggest the steps to run the ONNX for inference in ML.NET . The BertTokenizer can't be used as the tokenizer is BPE\r\nTried to use the https://gist.github.com/luisquintanilla/bc91de8668cfa7c3755b20329fadd027 without much success \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6803","RelatedDescription":"Open issue \"Using Roberta-base fine-tuned for boolq exported to ONNX in ML.NET \" (#6803)"},{"Id":"1863686875","IsPullRequest":false,"CreatedAt":"2023-08-23T16:49:02","Actor":"torronen","Number":"6802","RawContent":null,"Title":"AutoML: consider adding precision in checkpoint file","State":"open","Body":"Nightly, VS 2022, .NET 7.0\r\n\r\nThe checkpoint file has columns with 3-digit precision. In some cases I see loss being exactly the same on every run in the checkpoint file. I would like to confirm it it is exactly (or almost) same prediction. Therefore I would like to see 5-digit values in this file. \r\n\r\nI think, in difficult problems it may also help the tuner to go to correct direction. \r\n\r\nI know it is a minor issue to go 0.01% level but I also think there is no downside to adding precision to this file.\r\n\r\n**Example**\r\nCost-frugal tuner. Are these results not improving because of the type of the data, or because the changes to params are too small? \r\n![image](https://github.com/dotnet/machinelearning/assets/26261427/aefb41af-5ca0-4171-ae65-57b8fdd8b1bd)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6802","RelatedDescription":"Open issue \"AutoML: consider adding precision in checkpoint file\" (#6802)"},{"Id":"1862684347","IsPullRequest":false,"CreatedAt":"2023-08-23T06:52:19","Actor":"superichmann","Number":"6801","RawContent":null,"Title":"Predicted values are not at original scale after applying preFeaturizer","State":"open","Body":"When applying a preFeaturizer on the target column\r\n`var logTransformer = mlContext.Transforms.NormalizeMinMax(\"Label\",fixZero:true);`\r\nwithin a regression experiment, the predicted values\r\n`IDataView preds = result.Model.Transform(predictMe);`\r\nare in the wrong scale.\r\n\r\nOriginal values:\r\n10\r\n22\r\n33\r\n12\r\n6\r\n6\r\n5\r\n\r\nPredictions **without** preFeaturizer:\r\n8.593365\r\n19.133606\r\n19.094164\r\n11.576735\r\n11.040246\r\n10.156776\r\n9.546574\r\n\r\nPredictions **with** preFeaturizer:\r\n0.06661523\r\n0.14832252\r\n0.14801677\r\n0.08974213\r\n0.08558331\r\n0.0787347\r\n0.07400444\r\n\r\nas you can see, the predictions with the preFeaturizer applied are in a totally different scale.\r\n\r\nHow can I actually get the predicted values in the scale of the original target column and not in the scale of the applied transformer? ","Url":"https://github.com/dotnet/machinelearning/issues/6801","RelatedDescription":"Open issue \"Predicted values are not at original scale after applying preFeaturizer\" (#6801)"},{"Id":"1860312887","IsPullRequest":false,"CreatedAt":"2023-08-21T23:28:06","Actor":"MaxGrekhov","Number":"6800","RawContent":null,"Title":"BPE Tokenizer doesn't allow reading carriage return symbol","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: windows 11\r\n - ML.NET Version: [0.20.1](https://www.nuget.org/packages/Microsoft.ML.Tokenizers/0.20.1)\r\n - .NET Version: .NET 7\r\n\r\n**Describe the bug**\r\nBPE Tokenizer doesn't allow reading carriage return symbol.\r\nhttps://github.com/dotnet/machinelearning/blob/077a6b81966dc2c514572568917f36cb94e08ac4/src/Microsoft.ML.Tokenizers/Model/BPE.cs#L297\r\nReading text with ReadLines causes inability to read the carriage return symbol in merges.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n```csharp\r\nusing System.Text.Json;\r\nusing Microsoft.ML.Tokenizers;\r\n\r\nvar vocabFilePath = @\"vocab.json\";\r\nvar mergeFilePath = @\"merges.txt\";\r\ntry\r\n{\r\n    var tokenizer = new Tokenizer(new Bpe(vocabFilePath, mergeFilePath, \"<unk>\"));\r\n\r\n    var input = \" Test String \";\r\n\r\n    var tokenizerEncodedResult = tokenizer.Encode(input);\r\n    Console.WriteLine(JsonSerializer.Serialize(tokenizerEncodedResult.Ids));\r\n    var tokenizerDecodedResult = tokenizer.Decode(tokenizerEncodedResult.Ids);\r\n    Console.WriteLine(tokenizerDecodedResult);\r\n}\r\ncatch (Exception e)\r\n{\r\n    Console.WriteLine(e);\r\n}\r\n```\r\n\r\n```\r\nSystem.InvalidOperationException: Invalid merger file format at line: 3869\r\n   at Microsoft.ML.Tokenizers.Bpe.ConvertMergesToHashmap(String mergesFile)\r\n   at Microsoft.ML.Tokenizers.Bpe.ReadFile(String vocab, String merges)\r\n   at Microsoft.ML.Tokenizers.Bpe..ctor(String vocabFile, String mergesFile, String unknownToken, String continuingSubwordPrefix, String endOfWordSuffix)\r\n   at Program.<Main>$(String[] args) in D:\\dev\\personal\\ai\\Program.cs:line 8\r\n```\r\n\r\n**Expected behavior**\r\nBPE should process merges without exception\r\n\r\n**Simple solution**\r\nRead a json instead\r\n```csharp\r\n\r\ninternal static Vec<(string, string)> ConvertMergesToHashmap(string? mergesFile)\r\n{\r\n    if (mergesFile is null)\r\n    {\r\n        return new Vec<(string, string)>();\r\n    }\r\n\r\n    Vec<(string, string)> merges = new(1000);\r\n\r\n    int lineNumber = 0;\r\n    List<string> mergesList;\r\n    using (Stream stream = File.OpenRead(mergesFile))\r\n    {\r\n        mergesList = JsonSerializer.Deserialize<List<string>>(stream);\r\n    }\r\n    foreach (string line in mergesList)\r\n    {\r\n        lineNumber++;\r\n        if (line.StartsWith(\"#version\", StringComparison.Ordinal) || line.Length == 0)\r\n        {\r\n            continue;\r\n        }\r\n        int index = line.IndexOf(' ');\r\n        if (index < 0 || index == line.Length - 1 || line.IndexOf(' ', index + 1) >= 0)\r\n        {\r\n            throw new InvalidOperationException($\"Invalid merger file format at line: {lineNumber}\");\r\n        }\r\n        merges.Push((line.Substring(0, index), line.Substring(index + 1)));\r\n    }\r\n\r\n    return merges;\r\n}\r\n```\r\n\r\n**Additional context**\r\nI was able to fix the exception. However, BPE algorithm generates different results in comparison to google's sentencepiece that is widely used in ML.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6800","RelatedDescription":"Open issue \"BPE Tokenizer doesn't allow reading carriage return symbol\" (#6800)"},{"Id":"1857824134","IsPullRequest":false,"CreatedAt":"2023-08-19T18:04:58","Actor":"gsgou","Number":"6799","RawContent":null,"Title":"implement conv1d cross platform without a dependency on TorchSharp","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI need to pre-process data before invoking a ONNX model in xamarin and .net maui.\r\nVery often this requires conv1d but TorchSharp isn't available on mobile.\r\nDo you plan to add some basic operations as conv1d in the lib soon?\r\n\r\n[conv1d](https://pytorch.org/docs/stable/generated/torch.nn.functional.conv1d.html)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6799","RelatedDescription":"Open issue \"implement conv1d cross platform without a dependency on TorchSharp\" (#6799)"},{"Id":"1852898171","IsPullRequest":false,"CreatedAt":"2023-08-16T09:54:04","Actor":"eperegrine","Number":"6798","RawContent":null,"Title":"Clarification on the privacy of data","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\nIn the documentation it is stated that the training and use of models is done locally, however there is not explicit statement about the secuirty of that data - is there any analystics or usage of local training data. Would it be safe to train on commercially sensitive data (assuming responsible use of the model)?\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\nAn answer to my question and ideally an update to documentation addressing this concern\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6798","RelatedDescription":"Open issue \"Clarification on the privacy of data\" (#6798)"},{"Id":"1849918359","IsPullRequest":false,"CreatedAt":"2023-08-14T14:37:05","Actor":"superichmann","Number":"6797","RawContent":null,"Title":"Setting CategoricalColumnNames is not Actually Doing Anything","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: Microsoft.ML, 2.0.1\r\nMicrosoft.ML.AutoML, 0.20.1\r\nBUT ALSO ON LATEST PreRelease from dotnet-libraries\r\n - .NET Version: 7.0\r\n\r\n**Describe the bug**\r\nColumnInformation CategoricalColumnNames suppose to instruct automl to consider specific columns as categories which in turn should increase precision on the training.\r\n\r\nIn the  past (couple of months ago) I did a test with setting columns to CategoricalColumnNames, it was some prerelease version from  dotnet-libraries and the training result actually was better and training time was much longer.\r\n\r\nToday, I have re-tested this and training time and score is exactly the same as not setting CategoricalColumnNames.\r\n\r\n**To Reproduce**\r\ndownload code (change extansion to ipynb) [ColumnInformationDoesNotWork.txt](https://github.com/dotnet/machinelearning/files/12335917/ColumnInformationDoesNotWork.txt)\r\nopen with vscode\r\ndownload train.csv from [here](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data?select=train.csv)\r\nrun ipynb\r\nsee scores are similiar for both with CI and without.\r\n\r\n**Expected behavior**\r\nWhen adding CI the training should handle the data differently and as well produce a better score with longer training time.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n[ColumnInformationDoesNotWork.txt](https://github.com/dotnet/machinelearning/files/12335917/ColumnInformationDoesNotWork.txt)\r\n\r\n**Additional context**\r\nI might be missing something in parameter initialization of the process, if so please instruct me on what exactly to set.\r\n\r\n**Code Snippets**\r\n```\r\nvar set = new RegressionExperimentSettings();\r\nset.MaxExperimentTimeInSeconds = 1; // Maxmodels bypass\r\nset.Trainers.Clear();\r\nset.Trainers.Add(RegressionTrainer.FastForest);\r\nRegressionExperiment experiment = mlContext.Auto().CreateRegressionExperiment(set);\r\nColumnInformation CI = new ColumnInformation();\r\nCI.CategoricalColumnNames.Add(\"family\");\r\nCI.CategoricalColumnNames.Add(\"store_nbr\");\r\nvar x1 = experiment.Execute(train,CI);\r\nvar score1 = x1.BestRun.ValidationMetrics.RSquared;\r\nConsole.WriteLine(\"Result with categoricals definitions: \" + score1);\r\n```\r\n\r\n```\r\nvar no = new RegressionExperimentSettings();\r\nno.MaxExperimentTimeInSeconds = 1; // Maxmodels bypass\r\nno.Trainers.Clear();\r\nno.Trainers.Add(RegressionTrainer.FastForest);\r\nCI.CategoricalColumnNames.Clear();\r\nRegressionExperiment experiment2 = mlContext.Auto().CreateRegressionExperiment(no);\r\nvar x2 = experiment2.Execute(train,CI);\r\nvar score2 = x2.BestRun.ValidationMetrics.RSquared;\r\nConsole.WriteLine(\"Result without categoricals definitions: \" + score2);\r\n```\r\n\r\nThanks!\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6797","RelatedDescription":"Open issue \"Setting CategoricalColumnNames is not Actually Doing Anything\" (#6797)"},{"Id":"1848551968","IsPullRequest":false,"CreatedAt":"2023-08-13T11:28:58","Actor":"torronen","Number":"6796","RawContent":null,"Title":"Add baseline metrics to trainer results","State":"open","Body":"Datasets are almost never perfectly balanced. That means that an impressive metric, let's say 80% binary classification accuracy, could be worse than selecting always the most common category.  Therefore, I would like to automatically calculate the baseline metrics, for example:\r\n - null accuracy\r\n - distribution of items according to categories\r\n - baseline metric for ranking of a random order\r\n\r\nI think ideally, I would be able to read the baseline metrics as easily as the training data metrics. I think it should be also promoted as during the currenty AI summer I see many developers quickly build AI-enabled apps without any or much  validation, i.e. whatever GPT models says is enough without validation or even real prompt engineering with comparison to ground truth; whatever Model builder says is the final validation and so on. \r\n\r\nI think this would be in line with promoting fairness values. Equally incorrect results for everyone is not fair. Model Builder could probably even show graphically how much better model performs on test dataset than random or null accuracy.\r\n\r\nFirst I think it would be important to record what is the ideal way to evaluate metrics. For example, comparison to null accuracy would probably be good for binary classification but not others. For ranking, there seems to be a few options. Implementation is probably not terribly difficult.\r\n\r\n1. Decide baseline metrics for each ML task\r\n2. Decide programming interface and where to calculate the metrics\r\n3. Implementation","Url":"https://github.com/dotnet/machinelearning/issues/6796","RelatedDescription":"Open issue \"Add baseline metrics to trainer results\" (#6796)"},{"Id":"1848310341","IsPullRequest":false,"CreatedAt":"2023-08-13T00:10:16","Actor":"ooples","Number":"6795","RawContent":null,"Title":"Schema mismatch for label column 'Label': expected Single, got Vector<Single> (Parameter 'labelCol')","State":"open","Body":"I'm trying out this nuget package and experimenting with the different normalization options for regression and prediction trainers. My code is working perfectly when I use Single values (float) but I saw that there were bunch of normalization options that only seemed to work using a vector of Single values so I get the error when I change all of my float values to a float array. Am I just missing something obvious?\r\n\r\nFYI I'm using ML.NET 3.0.0-preview.23266.6 for this example\r\n\r\n```cs\r\nvar trainingCount = 50;\r\nvar modelInputList = new List<ModelInput>();\r\nvar estCount = valuesList.Any() ? valuesList.First().ValueList.Count : 0;\r\n\r\nfor (int j = 0; j < estCount; j++)\r\n{\r\n    var modelInput = new ModelInput();\r\n\r\n    var actual = j < estCount - 1 ? actualList[j] : 0;\r\n    modelInput.Actual = new float[] { Convert.ToSingle(actual) };\r\n\r\n    for (int k = 0; k < valueCount; k++)\r\n    {\r\n        var rvItem = Convert.ToSingle(valuesList[k].ValueList[j]);\r\n\r\n        switch (k)\r\n        {\r\n            case 0:\r\n                modelInput.Input1 = new float[] { rvItem };\r\n                break;\r\n            case 1:\r\n                modelInput.Input2 = new float[] { rvItem };\r\n                break;\r\n            case 2:\r\n                modelInput.Input3 = new float[] { rvItem };\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n    }\r\n\r\n    modelInputList.Add(modelInput);\r\n}\r\n\r\nvar firstHalf = mlContext.Data.LoadFromEnumerable(modelInputList.Take(trainingCount));\r\nvar secondHalf = mlContext.Data.LoadFromEnumerable(modelInputList.Skip(trainingCount));\r\nvar dataProcessPipeline = mlContext.Transforms\r\n                    .CopyColumns(\"Label\", nameof(ModelInput.Actual))\r\n                    .Append(mlContext.Transforms.NormalizeBinning(outputColumnName: nameof(ModelInput.Input1)))\r\n                    .Append(mlContext.Transforms.NormalizeBinning(outputColumnName: nameof(ModelInput.Input2)))\r\n                    .Append(mlContext.Transforms.NormalizeBinning(outputColumnName: nameof(ModelInput.Input3)))\r\n                    .Append(mlContext.Transforms.Concatenate(\"Features\", nameof(ModelInput.Input1),\r\n                        nameof(ModelInput.Input2), nameof(ModelInput.Input3)));\r\nvar trainer = mlContext.Regression.Trainers.OnlineGradientDescent();\r\nvar trainingPipeline = dataProcessPipeline.Append(trainer);\r\nvar trainedModel = trainingPipeline.Fit(firstHalf); // getting the exception here\r\nvar trainingData = trainedModel.Transform(firstHalf);\r\nvar predictions = trainedModel.Transform(secondHalf);\r\n\r\npublic class ModelInput\r\n{\r\n    [LoadColumn(0)]\r\n    [VectorType(1)]\r\n    public float[] Actual { get; set; }\r\n\r\n    [LoadColumn(1)]\r\n    [VectorType(1)]\r\n    public float[] Input1 { get; set; }\r\n\r\n    [LoadColumn(2)]\r\n    [VectorType(1)]\r\n    public float[] Input2 { get; set; }\r\n\r\n    [LoadColumn(3)]\r\n    [VectorType(1)]\r\n    public float[] Input3 { get; set; }\r\n}","Url":"https://github.com/dotnet/machinelearning/issues/6795","RelatedDescription":"Open issue \"Schema mismatch for label column 'Label': expected Single, got Vector<Single> (Parameter 'labelCol')\" (#6795)"},{"Id":"1845883949","IsPullRequest":true,"CreatedAt":"2023-08-10T20:51:07","Actor":"Lehonti","Number":"6794","RawContent":null,"Title":"File-scoped namespaces in files directly under `Microsoft.ML.Core`","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6794","RelatedDescription":"Open PR \"File-scoped namespaces in files directly under `Microsoft.ML.Core`\" (#6794)"}],"ResultType":"GitHubIssue"}},"RunOn":"2023-09-14T03:30:19.4437337Z","RunDurationInMilliseconds":553}