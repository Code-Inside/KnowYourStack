{"Data":{"GitHub":{"Issues":[{"Id":"721011426","IsPullRequest":true,"CreatedAt":"2020-10-13T23:59:31","Actor":"Lynx1820","Number":"5435","RawContent":null,"Title":"ProduceWordBags Onnx Export Fix ","State":"open","Body":"`ProduceWordBags` Onnx export assumes that the input will be a string of untokenized text. However, in ML.NET the user can choose to tokenize the text before passing it. Even though this is an unnecessary step, since a `WordTokenizer` is added before the `NgramExtraction` transformer, there is no error in ML.NET but there is an error in OnnxRuntime because a double tokenization resulted in more dimensions in Onnx. I have changed the Squeeze transformer to Reshape, so the dimension can remain consistent in this edge case. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5435","RelatedDescription":"Open PR \"ProduceWordBags Onnx Export Fix \" (#5435)"},{"Id":"720807403","IsPullRequest":false,"CreatedAt":"2020-10-13T20:40:30","Actor":"dcostea","Number":"5434","RawContent":null,"Title":"Models build with SDCA trainers and seeded ML context are getting different values for accuracy  ","State":"open","Body":"### System information\r\n\r\n- **Windows 10**:\r\n- **.NET 5 RC1 & RC2**: \r\n\r\n### Issue\r\n\r\n- **I build a model using a MLContext with seed parameter set and I use SDCAMaximumEntropy or SDCANonCalibrated**\r\n- **The accuracy fluctuates with every build**\r\n- **I expect the accuracy to be the same. If I'm using other trainers like LighGbm, the accuracy is consistent, the same with every build.**\r\n\r\n### Source code / logs\r\nYou can find the notebook here: https://github.com/dcostea/SmartFireAlarm/blob/master/SmartFireAlarm/Jupyter/sample.ipynb\r\nI have extracted here the code:\r\n```\r\n#r \"nuget:Microsoft.ML,1.5.2\"\r\n#r \"nuget:Microsoft.ML.LightGBM,1.5.2\"\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Trainers.LightGbm;\r\nusing Microsoft.ML.Data;\r\n\r\nMLContext mlContext = new MLContext(seed: 123);\r\n\r\nconst string TRAIN_DATASET_PATH = \"./sensors_data_train.csv\";\r\nIDataView trainingData = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n    path: TRAIN_DATASET_PATH,\r\n    hasHeader: true,\r\n    separatorChar: ',');\r\n\r\nconst string TEST_DATASET_PATH = \"./sensors_data_test.csv\";\r\nIDataView testingData = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n    path: TEST_DATASET_PATH,\r\n    hasHeader: true,\r\n    separatorChar: ',');\r\n\r\nvar featureColumns = new string[] { \"Temperature\", \"Luminosity\", \"Infrared\", \"Distance\" };\r\n\r\nvar trainingPipeline = mlContext.Transforms.Conversion.MapValueToKey(\"Label\")\r\n    .Append(mlContext.Transforms.Concatenate(\"Features\", featureColumns))\r\n    .Append(mlContext.MulticlassClassification.Trainers.SDCAMaximumEntropy(\"Label\", \"Features\"))\r\n    .Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n\r\nvar model = trainingPipeline.Fit(trainingData);\r\n\r\nvar predictions = model.Transform(testingData);\r\nvar metrics = mlContext.MulticlassClassification.Evaluate(predictions, \"Label\", \"Score\", \"PredictedLabel\");\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5434","RelatedDescription":"Open issue \"Models build with SDCA trainers and seeded ML context are getting different values for accuracy  \" (#5434)"},{"Id":"720536960","IsPullRequest":true,"CreatedAt":"2020-10-13T16:52:49","Actor":"michaelgsharp","Number":"5433","RawContent":null,"Title":"added in DcgTruncationLevel to AutoML api","State":"open","Body":"Fixes issue #5425. Adds in DcgTruncation level to the AutoML api to match the normal ML.Net API.","Url":"https://github.com/dotnet/machinelearning/pull/5433","RelatedDescription":"Open PR \"added in DcgTruncationLevel to AutoML api\" (#5433)"},{"Id":"719613909","IsPullRequest":false,"CreatedAt":"2020-10-13T16:28:28","Actor":"nnoradie","Number":"5430","RawContent":null,"Title":"The expected value calculation does not have knowledge of the data range of the series","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**:  ML.Net 1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDetected anomalies on dataset with only non-negative values and saw a negative expected value range.\r\n\r\n- **What happened?**\r\n![image](https://user-images.githubusercontent.com/69877427/95783099-f7a68080-0c85-11eb-97a7-414329c36faf.png)\r\n\r\n- **What did you expect?**\r\nThe expected value range to be non-negative.\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nCsv and email correspondence \r\n[covid19_deaths.zip](https://github.com/dotnet/machinelearning/files/5367173/covid19_deaths.zip)\r\n\r\n\r\nThe options set for anomaly detection:\r\nvar options = new SrCnnEntireAnomalyDetectorOptions()\r\n            {\r\n                Threshold = 0.05,\r\n                BatchSize = -1, // not set, so we are using the default, is that -1?\r\n                Sensitivity = 75.0,\r\n                DetectMode = SrCnnDetectMode.AnomalyAndMargin,\r\n                Period = -1,\r\n                DeseasonalityMode = SrCnnDeseasonalityMode.Median // the period is -1, so I assume deseasonalize is not applied?\r\n            };\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5430","RelatedDescription":"Closed issue \"The expected value calculation does not have knowledge of the data range of the series\" (#5430)"},{"Id":"720200029","IsPullRequest":false,"CreatedAt":"2020-10-13T12:38:58","Actor":"ddobric","Number":"5432","RawContent":null,"Title":"Webhosting of models and high memory consumption","State":"open","Body":"We have a web application that hosts a trained model to enable users for prediction scenarios.\r\nThe solution is based on the *ImageClassificationModelTraining.Solution*  in the *machinelearning-samples* repo. \r\nThe training was done by following code (just a snippet for a case that it is important):\r\n\r\n```csharp\r\n            var pipeline = mlContext.MulticlassClassification.Trainers.ImageClassification(options: hyperParams)\r\n            .Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: \"PredictedLabel\",\r\n                                                                      inputColumnName: \"PredictedLabel\"));\r\n\r\n            // Apply 5-fold cross validation\r\n            var cvResults = mlContext.MulticlassClassification.CrossValidate(cvDataView, pipeline, numberOfFolds: numOfFolds, labelColumnName: \"LabelAsKey\", seed: 8881);\r\n\r\n            // Get best Model which is on the first place\r\n            var topModel = cvResults[0].Model;\r\n\r\n            //Show the performance metrics for the multi-class classification            \r\n            var metrics = mlContext.MulticlassClassification.Evaluate(cvResults[0].ScoredHoldOutSet, labelColumnName: \"LabelAsKey\", predictedLabelColumnName: \"PredictedLabel\");\r\n ``` \r\n\r\nTo make this working, we have loaded a pool of Prediction Engine instances, which will be assigned to incoming requests. Following code shows how instances are created on startup.\r\n\r\n```csharp\r\n       private List<PredictionEngine<TSrc, TDest>> LoadPool(string modelFullPathName)\r\n        {\r\n            List<PredictionEngine<TSrc, TDest>> engines = new List<PredictionEngine<TSrc, TDest>>();\r\n\r\n            for (int i = 0; i < config.PoolSize; i++)\r\n            {\r\n                var mlnetModel = mlContext.Model.Load(modelFullPathName, out _);//ModelInfo.ServerFilePath\r\n                var predictionEngine = mlContext.Model.CreatePredictionEngine<TSrc, TDest>(mlnetModel);\r\n                engines.Add(predictionEngine);\r\n            }\r\n\r\n            return engines;\r\n        }\r\n```\r\nThis part works fine. As next, we have measured how much RAM the application will need when deployed to the *AppService* (or anything else). We figured out that the memory consumption of trained model is extremely high.\r\nFollowing diagram shows the behaviour of the prediction engine. First, we load a set of prediction engines (in this example 6 instances) by using the code shown above.\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/95859723-53910800-0d5f-11eb-8758-917ba4499a15.png)\r\n\r\nAfter loading some space in RAM is consumed. However on the first *Predict* invoke of the particular instance of the prediction engine, there is a peak of 1.5-2.0 GB. After the peak, the memory consumption gets stable again.\r\n\r\nThe issue with the peak is that, when it happens, it causes the AppService health feature sometimes to restart the service. Ok, it is not nice, but it can be fixed by using higher AppService offering. However, it would be good to know where does the peak comes from for the case that it can get higher than 2GB.\r\n\r\nAnother negative observation is the high memory consumption of the single instance of the prediction engine. Following diagram shows the consumption in dependence on the number of instances of the prediction engine.\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/95860311-2bee6f80-0d60-11eb-9c23-3fe86514b31a.png)\r\n\r\nThe blue line shows the consumption after the load of the predication engine and the green one shows consumption of the prediction engine instances after the ```Predict``` method has been invoked on each of them.\r\n\r\nThe dotted line is the memory consumption as calculated by the formel shown in the diagram. The issue with behaviour is that the consumption of the single prediction engine instance is approx. **600MB**, which is too much. We could easily calculate here how much would cost the App Service with just 100 concurrent users. It is too much for this scenario.\r\n\r\nWe can understand and agree that training is a heavy scenario and might require a lot of memory and CPU resources. However trained models must be more lightweight.\r\n\r\n### System information\r\n\r\n- **Windows 10**:\r\n- **  DotNet 3.1.402**: \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5432","RelatedDescription":"Open issue \"Webhosting of models and high memory consumption\" (#5432)"},{"Id":"719875778","IsPullRequest":false,"CreatedAt":"2020-10-13T05:27:03","Actor":"gharibkhani","Number":"5431","RawContent":null,"Title":"System.InvalidOperationException: 'LightGBM Error, code is -1","State":"open","Body":"- Tested on Windows 10 and Server 2019:\r\n- .NET 4.7: \r\n\r\n**Issue**\r\nIt crashes in this line \r\n\r\n- var model = pipeline.Fit(trainData);\r\n\r\n- I get this error: System.InvalidOperationException: 'LightGBM Error, code is -1, error message is 'Unknown importance type: only support split=0 and gain=1'.'\r\n\r\nThis error can be reproduced by an example. I just used the example in docs.microsoft.com and able to reproduce it.\r\n\r\nhttps://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet\r\n\r\nI created a console app and you can access it from the link below:\r\n\r\nhttps://drive.google.com/drive/folders/1-wc04CM75-IGoxjRAniDuhqI-zrHTWwM?usp=sharing\r\n\r\nI talked to the LightGBM team and they mentioned this issue exists in .Net code and not theirs.","Url":"https://github.com/dotnet/machinelearning/issues/5431","RelatedDescription":"Open issue \"System.InvalidOperationException: 'LightGBM Error, code is -1\" (#5431)"},{"Id":"719613873","IsPullRequest":false,"CreatedAt":"2020-10-12T19:36:30","Actor":"nnoradie","Number":"5429","RawContent":null,"Title":"Cannot detect anomalies on percent of grand total ","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:.Net 4.8\r\n- **.NET Version (eg., dotnet --info)**:  ML.Net 1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDetect anomalies on the percent of grand total of a value that returned multiple anomalies.\r\n\r\n- **What happened?**\r\nNo anomalies were returned\r\n![image](https://user-images.githubusercontent.com/69877427/95783665-2ffa8e80-0c87-11eb-9e77-b910cc88e095.png)\r\n![image](https://user-images.githubusercontent.com/69877427/95783686-3983f680-0c87-11eb-91d3-2514fc1fbe25.png)\r\n\r\n\r\n- **What did you expect?**\r\nTo see anomalies at the same points in time as in the original value,\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nCsvs, gif, and email correspondence\r\n[percent of grand total.zip](https://github.com/dotnet/machinelearning/files/5367178/percent.of.grand.total.zip)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5429","RelatedDescription":"Open issue \"Cannot detect anomalies on percent of grand total \" (#5429)"},{"Id":"708562742","IsPullRequest":false,"CreatedAt":"2020-10-12T17:56:49","Actor":"lisahua","Number":"5410","RawContent":null,"Title":"SrCnnEntireAnomalyDetectorOptions should support Non-seasonal cases","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: .Net 4.8\r\n- **.NET Version (eg., dotnet --info)**: Ml.Net 1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?** Try to apply detect anomaly\r\n- **What happened?** We expect to use the SrCnnEntireAnomalyDetectorOptions for non-seasonal data, yet it gives an assertion that period cannot be negative. Shouldn't we gracefully ignore deseasonalize if period < 0?\r\n\r\n- **What did you expect?**  SrCnnEntireAnomalyDetectorOptions should support Non-seasonal cases\r\n\r\n### Source code / logs\r\n\r\nWe expect to use the SrCnnEntireAnomalyDetectorOptions for non-seasonal data, yet it gives an assertion that period cannot be negative. **Shouldn't we gracefully ignore deseasonalize if period < 0?** \r\n\r\n```\r\n       seasonalPeriod = mlContext.AnomalyDetection.DetectSeasonality(..)\r\n            var anomalyDetectorOptions = new SrCnnEntireAnomalyDetectorOptions()\r\n            {\r\n                DetectMode = detectMode,\r\n                Threshold = adjustThreshold,\r\n                Sensitivity = this.inputMetadata.Sensitivity,\r\n                Period =seasonalPeriod < 0  ? 0 : seasonalPeriod,\r\n            };\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5410","RelatedDescription":"Closed issue \"SrCnnEntireAnomalyDetectorOptions should support Non-seasonal cases\" (#5410)"},{"Id":"719359145","IsPullRequest":false,"CreatedAt":"2020-10-12T12:57:16","Actor":"patricia-ikosoft","Number":"5428","RawContent":null,"Title":"\"Input string was not in a correct format.\" exception when executing experiment with ML.AutoML","State":"open","Body":"### System information\r\n\r\n- Microsoft Windows 7 Professional, Version\t6.1.7601 Service Pack 1 Build 7601\r\n- .Net Core 3.1\r\n- Microsoft.ML.AutoML 0.17.2\r\n\r\n### Issue\r\n\r\n- I am executing an experiment with ML.AutoML, using the data from test2.csv\r\n-  I constantly have a parsing exception on experiment.Execute(data, labelProperty.Name),\r\nno matter what label I'm choosing, or if I'm loading the data directly from the file or I'm reading and parsing it myself.\r\n\r\n\r\n\r\n at System.Number.ThrowOverflowOrFormatException(ParsingStatus status, TypeCode type)\r\n   at Microsoft.ML.AutoML.SweeperProbabilityUtils.ParameterSetAsFloatArray(IValueGenerator[] sweepParams, ParameterSet ps, Boolean expandCategoricals)\r\n   at Microsoft.ML.AutoML.SmacSweeper.FitModel(IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.SmacSweeper.ProposeSweeps(Int32 maxSweeps, IEnumerable`1 previousRuns)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.SampleHyperparameters(MLContext context, SuggestedTrainer trainer, IEnumerable`1 history, Boolean isMaximizingMetric)\r\n   at Microsoft.ML.AutoML.PipelineSuggester.GetNextInferredPipeline(MLContext context, IEnumerable`1 history, DatasetColumnInfo[] columns, TaskKind task, Boolean isMaximizingMetric, CacheBeforeTrainer cacheBeforeTrainer, IEnumerable`1 trainerAllowList)\r\n   at Microsoft.ML.AutoML.Experiment`2.Execute()\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(ColumnInformation columnInfo, DatasetColumnInfo[] columns, IEstimator`1 preFeaturizer, IProgress`1 progressHandler, IRunner`1 runner)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.ExecuteCrossValSummary(IDataView[] trainDatasets, ColumnInformation columnInfo, IDataView[] validationDatasets, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, ColumnInformation columnInformation, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at Microsoft.ML.AutoML.ExperimentBase`2.Execute(IDataView trainData, String labelColumnName, String samplingKeyColumn, IEstimator`1 preFeaturizer, IProgress`1 progressHandler)\r\n   at MLPoc.Services.LoadDataService.TrainDataAndCreateModel(List`1 properties, DynamicTypeProperty labelProperty, List`1 lineValues) in C:\\DevITPAzurePatricia\\Ikosoft\\MLPoc\\Services\\LoadDataService.cs:line 81\r\n\r\n\r\n### Source code / logs\r\n[code.zip](https://github.com/dotnet/machinelearning/files/5365217/code.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5428","RelatedDescription":"Open issue \"\"Input string was not in a correct format.\" exception when executing experiment with ML.AutoML\" (#5428)"},{"Id":"719249606","IsPullRequest":false,"CreatedAt":"2020-10-12T10:05:43","Actor":"zjdandy99ge","Number":"5427","RawContent":null,"Title":"object detection on local ML","State":"open","Body":"there is object detect ml on Azure， I want to do that on local, anyone can give me some advice or demo?\r\n\r\nthanks a  lot.","Url":"https://github.com/dotnet/machinelearning/issues/5427","RelatedDescription":"Open issue \"object detection on local ML\" (#5427)"},{"Id":"716552710","IsPullRequest":false,"CreatedAt":"2020-10-10T17:20:07","Actor":"Anachostic","Number":"5421","RawContent":null,"Title":"Options for running ML.NET in Hyper-V","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 64-bit in Hyper-V\r\n- **.NET Version (eg., dotnet --info)**: 4.8/Standard 2.0\r\n\r\n### Issue\r\n\r\nI have an application utilizing ML.NET image classification that works excellent on Windows 10 desktop, but does not load when run in a Hyper-V virtual machine.\r\n\r\nThe execution stops during initialization and 4 inner-exceptions-deep is the error:\r\n\r\nException has been thrown by the target of an invocation.\r\nException has been thrown by the target of an invocation.\r\nException has been thrown by the target of an invocation.\r\nException has been thrown by the target of an invocation.\r\nUnable to load DLL 'tensorflow': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n\r\nI have read other postings online that this might have to do with the lack of GPU capabilities in the default Hyper-V video driver.  Does anyone have any workarounds or solutions for this?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5421","RelatedDescription":"Closed issue \"Options for running ML.NET in Hyper-V\" (#5421)"},{"Id":"718428900","IsPullRequest":false,"CreatedAt":"2020-10-09T21:20:05","Actor":"ppampati","Number":"5426","RawContent":null,"Title":"Exception while inferencing ML.NET ONNX model that uses TextFeatures","State":"open","Body":"[###](url) System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?\r\n     Trained a Fast tree model on text data.\r\n     Saved the trained model to ONNX format\r\n     Load the ONNX model and run Prediction\r\n- **What happened?\r\n      Prediction code threw an exception and application crashed.\r\n- **What did you expect?**\r\n      Prediction code to return score and predict label.\r\nSample code is attached\r\n[MLNetONNXSample.zip](https://github.com/dotnet/machinelearning/files/5357598/MLNetONNXSample.zip)\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5426","RelatedDescription":"Open issue \"Exception while inferencing ML.NET ONNX model that uses TextFeatures\" (#5426)"},{"Id":"717765883","IsPullRequest":false,"CreatedAt":"2020-10-09T00:48:23","Actor":"jwood803","Number":"5425","RawContent":null,"Title":"Add DcgTruncationLevel to Ranking AutoML API","State":"open","Body":"When performing Ranking in AutoML, it will always return back a length of 3 in the DCG and nDCG metrics. However, when using the Evaluate method for Ranking, it has a property in the `RankingEvaluatorOptions` to specify the DcgTruncationLevel.\r\n\r\n```csharp\r\nvar rankingEvaluatorOptions = new RankingEvaluatorOptions { DcgTruncationLevel = 10 };\r\n```\r\n\r\nThis was noticed when adding the Ranking AutoML sample in [this comment](https://github.com/dotnet/machinelearning-samples/pull/852#discussion_r498425201)","Url":"https://github.com/dotnet/machinelearning/issues/5425","RelatedDescription":"Open issue \"Add DcgTruncationLevel to Ranking AutoML API\" (#5425)"},{"Id":"716997196","IsPullRequest":true,"CreatedAt":"2020-10-08T20:29:22","Actor":"frank-dong-ms","Number":"5423","RawContent":null,"Title":"arcade linux build","State":"closed","Body":"make arcade linux build pass\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5423","RelatedDescription":"Closed or merged PR \"arcade linux build\" (#5423)"},{"Id":"717003033","IsPullRequest":true,"CreatedAt":"2020-10-08T17:18:04","Actor":"frank-dong-ms","Number":"5424","RawContent":null,"Title":"merge master to arcade branch","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5424","RelatedDescription":"Closed or merged PR \"merge master to arcade branch\" (#5424)"},{"Id":"716374400","IsPullRequest":false,"CreatedAt":"2020-10-08T12:32:18","Actor":"ThomasArdal","Number":"5420","RawContent":null,"Title":"System.ArgumentOutOfRangeException: 'Features column 'Feature' not found (Parameter 'schema')'","State":"closed","Body":"### System information\r\n\r\n- Windows 10\r\n- .NET Core 3.1\r\n- ML.NET 1.5.2\r\n\r\n### Issue\r\n\r\nI'm having a problem when training a model. I have a range of HTTP requests and I want to be able to identify is the request is coming from a bot or not. To train this I have a range of these:\r\n\r\n```csharp\r\npublic class Request\r\n{\r\n    public string Url { get; set; }\r\n    public string UserAgent { get; set; }\r\n    public bool IsBot { get; set; }\r\n}\r\n```\r\n\r\nAnd a prediction class like this:\r\n\r\n```csharp\r\npublic class IsBotPrediction\r\n{\r\n    [ColumnName(\"PredictedLabel\")]\r\n    public bool Prediction { get; set; }\r\n    public float Score { get; set; }\r\n}\r\n```\r\n\r\nJust for this example, I have created a list of hardcoded data:\r\n\r\n```csharp\r\nvar trainingData = new List<Request>\r\n{\r\n    new Request { Url = \"/wp-admin\", UserAgent = \"a bot\", IsBot = true },\r\n    new Request { Url = \"/backoffice\", UserAgent = \"a bot\", IsBot = true },\r\n    new Request { Url = \"/hack\", UserAgent = \"a bot\", IsBot = true },\r\n    new Request { Url = \"/login\", UserAgent = \"a bot\", IsBot = false },\r\n    new Request { Url = \"/dashboard\", UserAgent = \"a bot\", IsBot = false },\r\n    new Request { Url = \"/humans.txt\", UserAgent = \"a bot\", IsBot = false },\r\n    new Request { Url = \"/admin\", UserAgent = \"a bot\", IsBot = true },\r\n};\r\n```\r\n\r\nTo train a model I'm using the following code:\r\n\r\n```csharp\r\nIDataView mlData = mlContext.Data.LoadFromEnumerable(trainingData);\r\n\r\nvar dataPrepPipeline = mlContext\r\n    .Transforms\r\n    .Text\r\n    .FeaturizeText(\"UrlF\", \"Url\")\r\n    .Append(mlContext.Transforms.Text.FeaturizeText(\"UserAgentF\", \"UserAgent\"))\r\n    .Append(mlContext.Transforms.Concatenate(\"Features\", \"UrlF\", \"UserAgentF\"))\r\n    .Append(mlContext.Transforms.NormalizeMinMax(\"Features\", \"Features\"))\r\n    .AppendCacheCheckpoint(mlContext);\r\nvar prepPipeline = dataPrepPipeline.Fit(mlData);\r\n\r\nvar trainer = mlContext\r\n    .BinaryClassification\r\n    .Trainers\r\n    .AveragedPerceptron(labelColumnName: \"IsBot\", numberOfIterations: 10, featureColumnName: \"Features\");\r\n\r\nvar preprocessedData = prepPipeline.Transform(mlData);\r\n\r\nITransformer trainedModel = trainer.Fit(preprocessedData);\r\n```\r\n\r\nThe trained model seems to be a success. But when I try to create a prediction engine:\r\n\r\n```csharp\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<Request, IsBotPrediction>(trainedModel);\r\n```\r\n\r\nI get the following exception:\r\n\r\n> System.ArgumentOutOfRangeException: 'Features column 'Feature' not found (Parameter 'schema')'\r\n\r\nCan you please help me figure out what this means?","Url":"https://github.com/dotnet/machinelearning/issues/5420","RelatedDescription":"Closed issue \"System.ArgumentOutOfRangeException: 'Features column 'Feature' not found (Parameter 'schema')'\" (#5420)"},{"Id":"716936459","IsPullRequest":true,"CreatedAt":"2020-10-08T02:23:47","Actor":"frank-dong-ms","Number":"5422","RawContent":null,"Title":"Arcade linux","State":"closed","Body":"1. sync to master to take latest code\r\n2. make arcade build on linux\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5422","RelatedDescription":"Closed or merged PR \"Arcade linux\" (#5422)"},{"Id":"716138735","IsPullRequest":false,"CreatedAt":"2020-10-07T02:07:22","Actor":"frogcrush","Number":"5419","RawContent":null,"Title":"Local GPU training fails with Image Classification scenario using Model Builder","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10 2004\r\n- **.NET Version (eg., dotnet --info)**: 5.0.100-rc.1.20452.10\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTried using ML.NET Model Builder with my GTX 1070 to run an image classification scenario.\r\n\r\n- **What happened?**\r\nVRAM spikes to 99% usage, then exceptions are printed in the logs and the training fails.\r\n\r\n- **What did you expect?**\r\nTraining to succeed.\r\n\r\n### Source code / logs\r\n[log.txt](https://github.com/dotnet/machinelearning/files/5337885/log.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5419","RelatedDescription":"Open issue \"Local GPU training fails with Image Classification scenario using Model Builder\" (#5419)"},{"Id":"715893719","IsPullRequest":false,"CreatedAt":"2020-10-06T17:51:40","Actor":"robertlampe","Number":"5418","RawContent":null,"Title":"if all iterations are completed, I don't want to wait until the train-time reaches 0","State":"open","Body":"### System information\r\n\r\n- **Windows 10.0.19041**:\r\n- **.NET Core 3.1.402**: \r\n\r\n### Issue\r\n- **What did you do?**\r\nWith each command I need to specificy the train time. e.g.\r\n`mlnet regression --dataset \"Step2.csv\" --label-col \"Position\" --has-header true --train-time 3600 --cache on`\r\n- **What happened?**\r\nI noticed that there are max 70 iterations. If all the iterations are completed before the train-time ends, I have to wait untill it counts till 0 before it outputs the best iteration & generates the example code.\r\n- **What did you expect?**\r\nIf the max amount of iterations have been completed, the training should stop. There is no need to wait until the countdown goes to 0 while being idle.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5418","RelatedDescription":"Open issue \"if all iterations are completed, I don't want to wait until the train-time reaches 0\" (#5418)"},{"Id":"715031754","IsPullRequest":true,"CreatedAt":"2020-10-06T05:26:37","Actor":"eerhardt","Number":"5417","RawContent":null,"Title":"Fix perf regression in ShuffleRows","State":"closed","Body":"RowShufflingTransformer is using ChannelReader incorrectly. It needs to block waiting for items to read and was Thread.Sleeping in order to wait, but not spin the current core. This caused a major perf regression.\r\n\r\nThe fix is to block synchronously correctly - by calling AsTask() on the ValueTask that is returned from the ChannelReader and block on the Task.\r\n\r\nFix #5416\r\n\r\nResults of the added benchmark:\r\n\r\n||      Method |    Mean |    Error |   StdDev | Extra Metric |\r\n|------------|------------:|--------:|---------:|---------:|-------------:|\r\n|master | ShuffleRows | 2.911 s | 0.0379 s | 0.0354 s |            - |\r\n|PR | ShuffleRows | 2.736 ms | 0.0530 ms | 0.0470 ms |            - |\r\n\r\n\r\ncc @jwood803 @ogo-adp @stephentoub ","Url":"https://github.com/dotnet/machinelearning/pull/5417","RelatedDescription":"Closed or merged PR \"Fix perf regression in ShuffleRows\" (#5417)"},{"Id":"713511415","IsPullRequest":false,"CreatedAt":"2020-10-06T05:26:37","Actor":"ogo-adp","Number":"5416","RawContent":null,"Title":"ShuffleRows is broken (again) in 1.5.2","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows Server 2016\r\n- **.NET Version (eg., dotnet --info)**: .NET 4.8\r\n\r\n### Issue\r\n\r\nMy training tasks times exploded when going from 1.4 to 1.5.2 (from seconds to tens of hours). The culprit is ShuffleRows which is now extremely slow.\r\n\r\nShuffleRows was already broken in previous release (see issue #5312). The fix for that issue (#5313) is broken too in my opinion. It contains a line with a Thread.Sleep(1) to wait for async completion. This is a no go ... First the Sleep should not be there. And second, sleeping 1ms is dependent on timer resolution which is in general 15ms, so a wait will be in most cases 15ms. As my learning tasks read millions of datarows, this can not work and learning time explode to the point of being unusable. \r\n\r\nTo confirm that Thread.Sleep(1) is the culprit, I changed the timer resolution to 1ms on my server and learning time improved greatly but are still very far from the times I got with version 1.4. The fix for #5312 needs to be redone properly (sorry for being a bit harsh).\r\n\r\nSo ShuffleRows needs a fix, as I suspect this bug will impact many users. I'm not an async specialist so I can't fix the code myself.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5416","RelatedDescription":"Closed issue \"ShuffleRows is broken (again) in 1.5.2\" (#5416)"},{"Id":"711030632","IsPullRequest":false,"CreatedAt":"2020-10-05T20:19:02","Actor":"netilovefm1","Number":"5413","RawContent":null,"Title":"retinanet-bbox/regression_submodel/pyramid_regression_1/Relu:0_nchwc' Status Message: Input channels C is not equal to kernel channels * group. C: 40 kernel channels: 256 group: 1","State":"closed","Body":"### System information\r\n\r\n- windows8\r\n- .net core3.1\r\n\r\n### Issue\r\n\r\nI got a this issue \r\n\r\nbut I don't understand what it means ....\r\n\r\nhow can I change my code ? \r\n\r\nrelu is set by keras so I don't understand \r\n### Source code / logs\r\n\r\nretinanet-bbox/regression_submodel/pyramid_regression_1/Relu:0_nchwc' Status Message: Input channels C is not equal to kernel channels * group. C: 40 kernel channels: 256 group: 1\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5413","RelatedDescription":"Closed issue \"retinanet-bbox/regression_submodel/pyramid_regression_1/Relu:0_nchwc' Status Message: Input channels C is not equal to kernel channels * group. C: 40 kernel channels: 256 group: 1\" (#5413)"},{"Id":"706801803","IsPullRequest":false,"CreatedAt":"2020-09-30T20:40:19","Actor":"wenrongwu","Number":"5409","RawContent":null,"Title":"It's happened at EstimatorChain.fit at asp.net web site with .net 4.7 and 4.8. The code works fine at Visual Studio 2019 with IIS express.","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n- **What happened?**\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5409","RelatedDescription":"Closed issue \"It's happened at EstimatorChain.fit at asp.net web site with .net 4.7 and 4.8. The code works fine at Visual Studio 2019 with IIS express.\" (#5409)"},{"Id":"710396750","IsPullRequest":false,"CreatedAt":"2020-09-30T20:39:14","Actor":"eventxplore","Number":"5412","RawContent":null,"Title":"Issue with Graph.def invalid for a tensorflow model","State":"closed","Body":"Windows 10 latest\r\n.NET Core 3.1\r\n\r\nOpening savedmodel tensorflow pb file gives invalid Graph.def message.\r\n\r\nThe pb file is possible to open and view with this site:\r\nhttps://lutzroeder.github.io/netron/\r\n\r\nIt warns about huge model and it is huge with a complex network.\r\n\r\nWhen opening the file in ML.NET:\r\nLoadTensorFlowModel(<path>)  I get the message.\r\n\r\nI have opened another pb file ok so my environment is setup ok by this.\r\n\r\nI would like to get more info about what is wrong with the model file, to verify it before it is opened.\r\n\r\nIs there a verification tool or specification that could be matched to check the pb file, Thanks?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5412","RelatedDescription":"Closed issue \"Issue with Graph.def invalid for a tensorflow model\" (#5412)"},{"Id":"711737646","IsPullRequest":true,"CreatedAt":"2020-09-30T20:08:00","Actor":"antoniovs1029","Number":"5415","RawContent":null,"Title":"Change the _maxCalibrationExamples default on CalibratorUtils","State":"closed","Body":"As reported offline, ML.NET yielded different results than TLC when training a PlattCalibrator with the same dataset.\r\n\r\nUpon further investigation, it turns out that it only happened on datasets over 1 million rows, and the reason was that when porting the CalibratorUtils class from TLC, a \"_maxCalibrationExamples = 1000000\" default parameter was added.\r\n\r\nUpon reading through the code (in particular [CalibratorTrainingBase's ProcessingTrainingExample](https://github.com/dotnet/machinelearning/blob/4960f9de83351b25874e58d1ca504c9a32aa1112/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1437-L1443)) it turns out that on TLC `TrainCalibrator` was called with `maxRows = 0`, and this made that when training the PlattCalibrator, all the dataset was seen, but only 1M rows where selected randomly to be [added to the DataStore](https://github.com/dotnet/machinelearning/blob/4960f9de83351b25874e58d1ca504c9a32aa1112/src/Microsoft.ML.Data/Prediction/Calibrator.cs#L1402-L1417). In contrast, on ML.NET that same method was called with `maxRows = 1M`, and this made that only the first 1M rows were added to the DataStore (instead of randomly selecting them from the complete dataset). This caused bias and undesired results.","Url":"https://github.com/dotnet/machinelearning/pull/5415","RelatedDescription":"Closed or merged PR \"Change the _maxCalibrationExamples default on CalibratorUtils\" (#5415)"},{"Id":"706647770","IsPullRequest":true,"CreatedAt":"2020-09-30T18:13:21","Actor":"antoniovs1029","Number":"5406","RawContent":null,"Title":"Update to Onnxruntime 1.5.1","State":"closed","Body":"Updated to use Onnxruntime 1.5.1, and also added some variables to the Onnx-related tests so it's easier to manually test the onnxruntime GPU prereleases whenever it's necessary.","Url":"https://github.com/dotnet/machinelearning/pull/5406","RelatedDescription":"Closed or merged PR \"Update to Onnxruntime 1.5.1\" (#5406)"},{"Id":"706692416","IsPullRequest":true,"CreatedAt":"2020-09-30T04:58:50","Actor":"antoniovs1029","Number":"5407","RawContent":null,"Title":"[Draft] Test Onnx 1.4.0","State":"closed","Body":"[Draft] Test Onnx 1.4.0\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5407","RelatedDescription":"Closed or merged PR \"[Draft] Test Onnx 1.4.0\" (#5407)"},{"Id":"709087481","IsPullRequest":false,"CreatedAt":"2020-09-25T18:40:50","Actor":"nnoradie","Number":"5411","RawContent":null,"Title":"DetectEntireAnomalyBySrCnn should not deseasonalize if given seasonal period = -1. Instead we see an error","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**:  1.5.2\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nPassed seasonality period -1 into DetectEntireAnomalyBySrCnn\r\n\r\n- **What happened?**\r\nAn error was thrown\r\n\r\n- **What did you expect?**\r\nNo error, just for deseasonalizing to be skipped\r\n\r\n### Source code / logs\r\n![image](https://user-images.githubusercontent.com/69877427/94292232-88a0fc00-ff11-11ea-8c12-51557613e5a7.png)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5411","RelatedDescription":"Closed issue \"DetectEntireAnomalyBySrCnn should not deseasonalize if given seasonal period = -1. Instead we see an error\" (#5411)"},{"Id":"706719927","IsPullRequest":false,"CreatedAt":"2020-09-22T22:00:18","Actor":"justinormont","Number":"5408","RawContent":null,"Title":"Ranking AutoML Sample","State":"open","Body":"The [ML․NET samples repo](https://github.com/dotnet/machinelearning-samples) could use a ranking AutoML sample.\r\n\r\nCurrently there are AutoML samples for:\r\n* [Binary Classification sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/BinaryClassification_AutoML)\r\n* [MultiClass Classification sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/MulticlassClassification_AutoML)\r\n* [Regression sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/Regression_AutoML)\r\n* [Advanced experiment sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/AdvancedExperiment_AutoML)\r\n\r\nThese existing demos are missing how to use ranking in AutoML․NET.\r\n\r\nI would recommend basing on the [existing ranking sample](https://github.com/dotnet/machinelearning-samples/blob/master/samples/csharp/getting-started/Ranking_Web) and converting it to an AutoML sample.","Url":"https://github.com/dotnet/machinelearning/issues/5408","RelatedDescription":"Open issue \"Ranking AutoML Sample\" (#5408)"},{"Id":"711463242","IsPullRequest":false,"CreatedAt":"2020-09-21T03:42:05","Actor":"bizbizzz","Number":"5414","RawContent":null,"Title":"Can predictions be bounded?","State":"open","Body":"**Describe Bug**\r\nPredicted values are outside of expected range. Is there a way to bound the predictions? Or set to a minimum value?\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nGenerate regression model using CLI and play with inputs\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5414","RelatedDescription":"Open issue \"Can predictions be bounded?\" (#5414)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-10-14T05:30:33.8224065Z","RunDurationInMilliseconds":651}