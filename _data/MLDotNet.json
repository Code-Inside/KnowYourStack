{"Data":{"GitHub":{"Issues":[{"Id":"2403636217","IsPullRequest":true,"CreatedAt":"2024-07-11T16:51:25","Actor":"dotnet-maestro[bot]","Number":"7192","RawContent":null,"Title":"[release/3.0] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:45c6fd49-3a4f-4675-f3da-08dc0c527e17)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 45c6fd49-3a4f-4675-f3da-08dc0c527e17\r\n- **Build**: 20240710.5\r\n- **Date Produced**: July 10, 2024 2:34:11 PM UTC\r\n- **Commit**: c9efa535175049eb9cba06cae1f8c3d5dbe768a9\r\n- **Branch**: refs/heads/release/8.0\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 8.0.0-beta.24266.3 to 8.0.0-beta.24360.5][1]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 8.0.0-beta.24266.3 to 8.0.0-beta.24360.5][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 8.0.0-beta.24266.3 to 8.0.0-beta.24360.5][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 8.0.0-beta.24266.3 to 8.0.0-beta.24360.5][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 8.0.0-beta.24266.3 to 8.0.0-beta.24360.5][1]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 8.0.0-beta.24266.3 to 8.0.0-beta.24360.5][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/e6f70c7dd5...c9efa53517\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:45c6fd49-3a4f-4675-f3da-08dc0c527e17)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7192","RelatedDescription":"Open PR \"[release/3.0] Update dependencies from dotnet/arcade\" (#7192)"},{"Id":"2403351722","IsPullRequest":false,"CreatedAt":"2024-07-11T14:37:08","Actor":"vpenades","Number":"7191","RawContent":null,"Title":"ModelFilePath within a .mbconfig file stores an absolute path, which prevents the project to work correctly if moved or cloned.","State":"open","Body":"**System Information (please complete the following information):**\r\n - Windows 10\r\n - ML.NET v3.0.1\r\n - NET 8.0\r\n\r\n**Describe the bug**\r\n\r\nAt the end of a training run using the ML wizard, a .mbconfig file is created.\r\n\r\nThat file contains an entry called \"ModelFilePath:\" which points to the .mlnet file, which happens to be in the same directory as the .mbconfig file.\r\n\r\nBut, I've noticed that \"ModelFilePath:\" holds the full, absolute file path to the model, instead of just the file name, or the relative path name.\r\n\r\nThis can cause trouble if the project is moved to another directory, or it is cloned in another machine.\r\n\r\n**To Reproduce**\r\n\r\nJust do some training using the wizard, and check the \"ModelFilePath:\" entry inside the .mbconfig and check whether it's an absolute or a relative path.\r\n\r\n**Expected behavior**\r\n\r\n\"ModelFilePath:\" should not be an absolute path.","Url":"https://github.com/dotnet/machinelearning/issues/7191","RelatedDescription":"Open issue \"ModelFilePath within a .mbconfig file stores an absolute path, which prevents the project to work correctly if moved or cloned.\" (#7191)"},{"Id":"2398971961","IsPullRequest":true,"CreatedAt":"2024-07-10T19:00:34","Actor":"directhex","Number":"7189","RawContent":null,"Title":"Publish source index directly from repo","State":"closed","Body":"Building in-repo allows us to improve reliability of source index generation, and increases the likelihood that build issues will be found and fixed by repo owners (who understand their repos better than we do)","Url":"https://github.com/dotnet/machinelearning/pull/7189","RelatedDescription":"Closed or merged PR \"Publish source index directly from repo\" (#7189)"},{"Id":"2399531030","IsPullRequest":true,"CreatedAt":"2024-07-10T01:32:13","Actor":"tarekgh","Number":"7190","RawContent":null,"Title":"Tokenizer APIs Update","State":"open","Body":"Fixes https://github.com/dotnet/machinelearning/issues/7158\r\nFixes https://github.com/dotnet/machinelearning/issues/7144\r\n\r\n- https://github.com/dotnet/machinelearning/issues/7158\r\n- https://github.com/dotnet/machinelearning/issues/7144\r\n\r\nThis change addresses all feedback we got in the design review. ","Url":"https://github.com/dotnet/machinelearning/pull/7190","RelatedDescription":"Open PR \"Tokenizer APIs Update\" (#7190)"},{"Id":"2396649073","IsPullRequest":true,"CreatedAt":"2024-07-08T21:58:52","Actor":"LittleLittleCloud","Number":"7188","RawContent":null,"Title":"update torchsharp and helix image","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\nfix #7182 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/7188","RelatedDescription":"Open PR \"update torchsharp and helix image\" (#7188)"},{"Id":"2388678412","IsPullRequest":false,"CreatedAt":"2024-07-03T13:42:30","Actor":"willysoft","Number":"7187","RawContent":null,"Title":"Error During Retraining with New Labels","State":"open","Body":"### Issue Description\r\n\r\nI encountered an issue while attempting to retrain a model using the ML.NET framework. The retraining works perfectly when the new data contains existing labels, but it fails with the following error when new labels (not present in the original training data) are introduced:\r\n\r\n```csharp\r\n// Retrain model\r\nvar retrainedModel = mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(\r\n    new LbfgsMaximumEntropyMulticlassTrainer.Options() { \r\n        L1Regularization = 0.1195667F, \r\n        L2Regularization = 0.03125F, \r\n        LabelColumnName = @\"col1\", \r\n        FeatureColumnName = @\"Features\" \r\n    }).Fit(transformedNewData, originalModelParameters);\r\n```\r\n\r\n### Error Message\r\n\r\n```vbnet\r\nSystem.InvalidOperationException: 'No valid training instances found, all instances have missing features.'\r\n```\r\n\r\n### Steps to Reproduce\r\n\r\n1. Train an initial model using a dataset with a specific set of labels.\r\n2. Attempt to retrain the model using a new dataset that includes labels not present in the original dataset.\r\n\r\n### Expected Behavior\r\n\r\nThe model should be able to retrain successfully even when new labels are introduced in the retraining dataset.\r\n\r\n### Actual Behavior\r\n\r\nThe retraining process fails with an InvalidOperationException, stating that there are no valid training instances because all instances have missing features.\r\n\r\n### Environment\r\n\r\n- ML.NET version: 3.0.1\r\n- .NET version: net8.0\r\n- Operating System: Windows 10\r\n\r\n### Code Sample\r\n\r\n```csharp\r\npublic static void ReTrain(string outputModelPath, IEnumerable<ModelInput> newDatas)\r\n{\r\n    var mlContext = new MLContext();\r\n\r\n    // Define DataViewSchema of data prep pipeline and trained model\r\n    DataViewSchema dataPrepPipelineSchema, modelSchema;\r\n\r\n    // Load data preparation pipeline and trained model\r\n    var dataPrepPipeline = mlContext.Model.Load(\"data_preparation_pipeline.zip\", out dataPrepPipelineSchema);\r\n    var trainedModel = mlContext.Model.Load(\"ogd_model.zip\", out modelSchema);\r\n\r\n    // Extract trained model parameters\r\n    var transformers = (IEnumerable<ITransformer>)trainedModel;\r\n    var originalModelParameters = ((MulticlassPredictionTransformer<MaximumEntropyModelParameters>?)transformers.FirstOrDefault(x => x is MulticlassPredictionTransformer<MaximumEntropyModelParameters>))?.Model;\r\n\r\n    // Load New Data\r\n    var newDataView = mlContext.Data.LoadFromEnumerable(newDatas);\r\n\r\n    // Preprocess Data\r\n    var transformedNewData = dataPrepPipeline.Transform(newDataView);\r\n\r\n    // Retrain model\r\n    var retrainedModel = mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(\r\n        new LbfgsMaximumEntropyMulticlassTrainer.Options() { \r\n            L1Regularization = 0.1195667F, \r\n            L2Regularization = 0.03125F, \r\n            LabelColumnName = @\"col1\", \r\n            FeatureColumnName = @\"Features\" \r\n        }).Fit(transformedNewData, originalModelParameters);\r\n}\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/7187","RelatedDescription":"Open issue \"Error During Retraining with New Labels\" (#7187)"},{"Id":"2388613188","IsPullRequest":false,"CreatedAt":"2024-07-03T13:19:49","Actor":"arthurvb","Number":"7186","RawContent":null,"Title":"Implement Sentencepiece Unigram tokenizer","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI want to use a multilingual model from Huggingface ( https://huggingface.co/intfloat/multilingual-e5-large ) and the tokenizer is a sentencepiece unigram tokenizer, so I am unable to port it to C#/ONNX\r\n\r\n**Describe the solution you'd like**\r\nSupport for the unigram sentencepiece tokenizer in the `Microsoft.ML.Tokenizers` package.\r\n\r\n**Describe alternatives you've considered**\r\nBlingfire, but seems not maintained anymore and unclear if it would return exactly the same token-id's.\r\n\r\nThank you for your time and effort (the library in general is great!)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7186","RelatedDescription":"Open issue \"Implement Sentencepiece Unigram tokenizer\" (#7186)"},{"Id":"2381735189","IsPullRequest":false,"CreatedAt":"2024-06-29T12:59:40","Actor":"acrigney","Number":"7185","RawContent":null,"Title":"Cannot cancel AutoML tasks when invoked via .Execute() Same as issue #6878","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n - Win 10\r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n - All versions including and forward preview versions from versions 0.21.0\r\n - .NET Version: [e.g. .NET 8.0]\r\n\r\n**Describe the bug**\r\nCancellation does not work even for async calls\r\n\r\n**To Reproduce**\r\nPlease confirm this works now in your tests?\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\nCancellation should work\r\n\r\n**Screenshots, Code, Sample Projects**\r\nI can provide in private\r\n\r\n**Additional context**\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7185","RelatedDescription":"Open issue \"Cannot cancel AutoML tasks when invoked via .Execute() Same as issue #6878\" (#7185)"},{"Id":"2381117294","IsPullRequest":true,"CreatedAt":"2024-06-28T20:16:15","Actor":"LittleLittleCloud","Number":"7184","RawContent":null,"Title":"Add Microsoft.ML.GenAI.Phi, test package and sample project.","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n#7169 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/7184","RelatedDescription":"Open PR \"Add Microsoft.ML.GenAI.Phi, test package and sample project.\" (#7184)"},{"Id":"2360285660","IsPullRequest":true,"CreatedAt":"2024-06-26T16:43:31","Actor":"LittleLittleCloud","Number":"7177","RawContent":null,"Title":"Add GenAI core package","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n#7169 Task 2","Url":"https://github.com/dotnet/machinelearning/pull/7177","RelatedDescription":"Closed or merged PR \"Add GenAI core package\" (#7177)"},{"Id":"2374056652","IsPullRequest":false,"CreatedAt":"2024-06-26T02:38:38","Actor":"luisquintanilla","Number":"7183","RawContent":null,"Title":"[Tokenizers] WhiteSpace pretokenizer not only splitting on whitepace","State":"open","Body":"Given the following code:\r\n\r\n```csharp\r\nusing Microsoft.ML.Tokenizers;\r\n\r\nReadOnlySpan<char> sentence = \"[CLS] I love AI [SEP]\";\r\n\r\nvar pretokenizer = new WhiteSpace();\r\n\r\nvar tokens = pretokenizer.PreTokenize(sentence);\r\n\r\n// Actual\r\nConsole.WriteLine(\"Actual\");\r\nforeach(var result in tokens)\r\n{\r\n    var substr = sentence.Slice(result.Offset, result.Length);\r\n    Console.WriteLine(substr.ToString());\r\n}\r\n\r\nConsole.WriteLine(\"----\");\r\n\r\n// Expected\r\nConsole.WriteLine(\"Expected\");\r\nforeach(var expected in sentence.ToString().Split(' '))\r\n{\r\n    Console.WriteLine(expected);\r\n}\r\n```\r\n\r\nThe WhiteSpace tokenizer is splitting based on non-alphanumeric and whitespace characters.\r\n\r\n**Output:**\r\n\r\n```text\r\nActual:\r\n[\r\nCLS\r\n]\r\nI\r\nlove\r\nAI\r\n[\r\nSEP\r\n]\r\n----\r\nExpected:\r\n[CLS]\r\nI\r\nlove\r\nAI\r\n[SEP]\r\n```\r\n\r\nI would expect it to only split on whitespace based on the name.  ","Url":"https://github.com/dotnet/machinelearning/issues/7183","RelatedDescription":"Open issue \"[Tokenizers] WhiteSpace pretokenizer not only splitting on whitepace\" (#7183)"},{"Id":"2370650837","IsPullRequest":false,"CreatedAt":"2024-06-24T16:28:30","Actor":"LittleLittleCloud","Number":"7182","RawContent":null,"Title":"Helix test fail on latest torchsharp (0.102.5) and its runtime","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n - .NET Version: [e.g. .NET 5.0]\r\n\r\n**Describe the bug**\r\n\r\nThe Microsoft.ML.Torchsharp.Tests fails in the following helix tests if I update torchsharp and its runtime to 0.102.5 and 2.2.1.1.\r\n- centos x64\r\n- ubuntu x64\r\n\r\nThe error message from helix tests indicates some dependencies of `liblibtorchsharp` is missing. After turning on `LD_Debug`, it seems that one of the missing dependencies is `GLIBC_2.34`. Note that the image for helix test is still `centos 8 streaming` which glib version is 2.28. This could be the why the torchsharp test failures.\r\n\r\n```bash\r\nfile=/temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libtorch_cpu.so\r\n       260:\r\n       260:     find library=libgomp-98b21ff3.so.1 [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/libgomp-98b21ff3.so.1\r\n       260:       trying file=/usr/local/lib64/libgomp-98b21ff3.so.1\r\n       260:      search path=/temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native            (RUNPATH from file /temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libtorch_cpu.so)\r\n       260:       trying file=/temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libgomp-98b21ff3.so.1\r\n       260:\r\n       260:     /lib64/libc.so.6: error: version lookup error: version `GLIBC_2.34' not found (required by /temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libLibTorchSharp.so) (fatal)\r\n       260:     find library=libLibTorchSharp.so [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/libLibTorchSharp.so\r\n       260:       trying file=/usr/local/lib64/libLibTorchSharp.so\r\n       260:      search cache=/etc/ld.so.cache\r\n       260:      search path=/lib64/tls:/lib64:/usr/lib64/tls:/usr/lib64                (system search path)\r\n       260:       trying file=/lib64/tls/libLibTorchSharp.so\r\n       260:       trying file=/lib64/libLibTorchSharp.so\r\n       260:       trying file=/usr/lib64/tls/libLibTorchSharp.so\r\n       260:       trying file=/usr/lib64/libLibTorchSharp.so\r\n       260:\r\n       260:     find library=LibTorchSharp [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/LibTorchSharp\r\n       260:       trying file=/usr/local/lib64/LibTorchSharp\r\n       260:      search cache=/etc/ld.so.cache\r\n       260:      search path=/lib64/tls:/lib64:/usr/lib64/tls:/usr/lib64                (system search path)\r\n       260:       trying file=/lib64/tls/LibTorchSharp\r\n       260:       trying file=/lib64/LibTorchSharp\r\n       260:       trying file=/usr/lib64/tls/LibTorchSharp\r\n       260:       trying file=/usr/lib64/LibTorchSharp\r\n       260:\r\n       260:     find library=libLibTorchSharp [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/libLibTorchSharp\r\n       260:       trying file=/usr/local/lib64/libLibTorchSharp\r\n       260:      search cache=/etc/ld.so.cache\r\n       260:      search path=/lib64/tls:/lib64:/usr/lib64/tls:/usr/lib64                (system search path)\r\n       260:       trying file=/lib64/tls/libLibTorchSharp\r\n       260:       trying file=/lib64/libLibTorchSharp\r\n       260:       trying file=/usr/lib64/tls/libLibTorchSharp\r\n       260:       trying file=/usr/lib64/libLibTorchSharp\r\n```\r\n\r\n## Solution\r\n- on mlnet side: update helix test image from centos-streaming8-mlnet-helix and ubuntu-18.04-mlnet-helix to centos-streaming9-mlnet-helix and ubuntu-22.04-mlnet-helix\r\n- on [dotnet-buildtools-prereqs-docker](https://github.com/dotnet/dotnet-buildtools-prereqs-docker) side: add centos-streaming9-mlnet-helix. PR:https://github.com/dotnet/dotnet-buildtools-prereqs-docker/pull/1130\r\n- on torchsharp side: downgrade the building image from ubuntu-22.04-mlnet to ubuntu-20.04 to resolve glibc incompatible issue. PR:https://github.com/dotnet/TorchSharp/pull/1338\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7182","RelatedDescription":"Open issue \"Helix test fail on latest torchsharp (0.102.5) and its runtime\" (#7182)"},{"Id":"2331509888","IsPullRequest":false,"CreatedAt":"2024-06-24T16:21:25","Actor":"jackpotcityco","Number":"7166","RawContent":null,"Title":"When training with AutoML, I encounter a Win32Exception: The wait operation timed out after 30 seconds.","State":"closed","Body":"CPU: i7-12800h (14 cores, Total Threads: 20)\r\nRAM: 32 GB\r\nSSD: Samsung 980 Pro, 2 TB\r\nWindows Server 2019 Datacenter Evaluation\r\nNET Framework: 4.8\r\nMicrosoft.ML: 3.0.1\r\nMicrosoft.ML.AutoML: 0.21.1\r\n\r\n**Issue:**\r\nWhen I start to train a model using AutoML, I get a timeout after exactly 30 seconds and the application breaks/stops with below error message: (CPU working at 15%. RAM has 50% avaliable memory at the exception)\r\n\r\n_System.AggregateException: 'One or more errors occurred.'\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\nSqlException: Execution Timeout Expired.  The timeout period elapsed prior to completion of the operation or the server is not responding.\r\n**Win32Exception: The wait operation timed out**_\r\n\r\nNormally, the training of the Model should continue but I don't understand why I get this timeout after 30 seconds. It seems to be a default value and this must be possible to increase and change but I have not found out where to change this default value or how to solve this problem?\r\n\r\n**Datasets looks like this:**\r\ntrainData: Rows: 384846, Columns: 64\r\nhold_out_data:  Rows: 33958, Columns: 64\r\n\r\n**Below is the code I use:** \r\n_(You might mention to use \"MaxModels\" but the root problem is about be able to change the timeout period, I beleive)_\r\n```\r\n        void trainer_function(IDataView trainData, IDataView hold_out_data)\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n            var experiment = mlContext.Auto().CreateBinaryClassificationExperiment(new BinaryExperimentSettings\r\n            {\r\n                MaxExperimentTimeInSeconds = 600,\r\n                CacheBeforeTrainer = CacheBeforeTrainer.On,\r\n                CacheDirectoryName = \"C:/Aintelligence/temp/cache\",\r\n                MaximumMemoryUsageInMegaByte = 8192,\r\n                OptimizingMetric = BinaryClassificationMetric.PositivePrecision,\r\n                CancellationToken = CancellationToken.None\r\n            });\r\n            var progressHandler = new Progress<RunDetail<BinaryClassificationMetrics>>(ph =>\r\n            {\r\n                if (ph.ValidationMetrics != null && !ph.TrainerName.Contains(\"FastForest\"))\r\n                {\r\n                    double positivePrecision = Math.Round(ph.ValidationMetrics.PositivePrecision, 3); //Do something with: \"positivePrecision\"\r\n                }\r\n            });\r\n            //Start the experiment/Training\r\n            var results = experiment.Execute(trainData, hold_out_data, labelColumnName: \"Label\", progressHandler: progressHandler);\r\n        }\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7166","RelatedDescription":"Closed issue \"When training with AutoML, I encounter a Win32Exception: The wait operation timed out after 30 seconds.\" (#7166)"},{"Id":"2364422816","IsPullRequest":false,"CreatedAt":"2024-06-20T13:14:29","Actor":"lopango","Number":"7181","RawContent":null,"Title":"Possible bug in DoubleParser.cs","State":"open","Body":"In Microsoft.ML.Core\\Utilities\\DoubleParser.cs near lines 143 and 195\r\n\r\n```csharp\r\n            int ichEnd;\r\n            if (!DoubleParser.TryParse(span.Slice(ich, span.Length - ich), out value, out ichEnd, flags))\r\n            {\r\n                value = default(Double);\r\n                return Result.Error;\r\n            }\r\n\r\n            // Make sure everything was consumed.\r\n            while (ichEnd < span.Length)\r\n            {\r\n                if (!char.IsWhiteSpace(span[ichEnd]))\r\n                    return Result.Extra;\r\n                ichEnd++;\r\n            }\r\n```\r\nthe ichEnd is indexed on the sliced span. \r\nIf ich is not 0 there will be an offset when for \"ichEnd < span.Length\" and \"span[ichEnd]\"\r\n\r\nExample : for an input like \"  1.234  \" the method will return Result.Extra\r\n\r\nPÃ¶ssible solutions:\r\n* ichEnd += ich;\r\n* modify the tryparse to accept an offset and use the original span","Url":"https://github.com/dotnet/machinelearning/issues/7181","RelatedDescription":"Open issue \"Possible bug in DoubleParser.cs\" (#7181)"},{"Id":"2363994834","IsPullRequest":false,"CreatedAt":"2024-06-20T09:39:48","Actor":"RossHNPC","Number":"7180","RawContent":null,"Title":"Cuda v11.8 support for image classification problems?","State":"open","Body":"Current implementations for Image classification, following [MS guidance](https://learn.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/install-gpu-model-builder) restricts us to using Cuda SDK v10.1. This in turn limits the available Nvidia cards that can be used. Going to a production install we need to use cards supported/supplied by IT vendors, DELL, etc. These tend to be newer cards that are beyond the Turing architecture: Ampere, Ada Lovelace, etc.\r\n\r\nWe would like for the Cuda SDK support to be raised to v11.8 to take advantage of a wider range of supported cards.\r\n\r\nAlternatives at present are code fixes to block inference from happening before the models are loaded and available, this can be anywhere from 1 - 20 mins for a basic image classification model. Older cards, my laptop has a lowly T500, are loading in 10's of seconds. As a real time implementation this is a lot of missed classifications.\r\n\r\nIf there is no intention to update Cuda support please do let us know as we can then look at alternatives.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7180","RelatedDescription":"Open issue \"Cuda v11.8 support for image classification problems?\" (#7180)"},{"Id":"2361667361","IsPullRequest":true,"CreatedAt":"2024-06-19T08:09:18","Actor":"asmirnov82","Number":"7179","RawContent":null,"Title":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations  (.net8)","State":"open","Body":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations (.net8)\r\n\r\nFixes #7178\r\n\r\nThe aim of this PR to use new library for DataFrame arithmetic operations instead of custom implemtation. At the same time provide backward compatibility for pre-.Net8.0 versions of the package. To achive this, all .,net version specific code is localised in nested private classes of `static class Arithmetic` that implements `IArithmetic<T>` interface and are not used directly by any other DataFrame classes","Url":"https://github.com/dotnet/machinelearning/pull/7179","RelatedDescription":"Open PR \"Use new System.Numerics.Tensors library for DataFrame arithmetic operations  (.net8)\" (#7179)"},{"Id":"2361642204","IsPullRequest":false,"CreatedAt":"2024-06-19T08:01:17","Actor":"asmirnov82","Number":"7178","RawContent":null,"Title":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations (.net8)","State":"open","Body":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations instead of custom implementation\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7178","RelatedDescription":"Open issue \"Use new System.Numerics.Tensors library for DataFrame arithmetic operations (.net8)\" (#7178)"},{"Id":"2355269973","IsPullRequest":false,"CreatedAt":"2024-06-15T21:10:30","Actor":"IntegerMan","Number":"7176","RawContent":null,"Title":"Make class labels on the ConfusionMatrix publicly readable for custom charting support","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI'm trying to build a library of data science charts for visualizing the results of ML.NET model training. One of those is a graphical confusion matrix pictured below (no offense to the wonderful built-in formatted table option present in ML.NET already).\r\n![image](https://github.com/dotnet/machinelearning/assets/5049957/c43f9a6d-c508-448d-a6c1-e2a2e08c5090)\r\n\r\nUnfortunately, there's no public way of getting the names of classes for the matrix as `ConfusionMatrix.PredictedClassesIndicators` is internal. This means that class labels in multi-class classification charts must:\r\n\r\n1. Use an arbitrary label like \"Class 1\"\r\n2. Require the caller to specify an array of class names\r\n3. Call the public `ConfusionMatrix.GetFormattedConfusionMatrix` and parse the output to get the class names from the generated output.\r\n\r\n**Describe the solution you'd like**\r\nEither make `PredictedClassesIndicators` publicly gettable or provide a `GetClassLabel(int classIndex): string` method for accessing this information.\r\n\r\n**Describe alternatives you've considered**\r\nRight now I am requiring callers to provide an array of class names for multi-class classification. However, if this feature goes some time before it is implemented, I may decide to write code to parse the results of `GetFormattedConfusionMatrix` which does include those internal labels.\r\n\r\n**Additional context**\r\nMy goal is for ML.NET to be as viable as SciKit-Learn in as many contexts as possible. Right now, I'm using ML.NET for my master's program and I'd much rather turn in a report with a graphical confusion matrix than a formatted text confusion matrix. Also, I'm running these charts in a Polyglot Notebook.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7176","RelatedDescription":"Open issue \"Make class labels on the ConfusionMatrix publicly readable for custom charting support\" (#7176)"},{"Id":"2355255440","IsPullRequest":false,"CreatedAt":"2024-06-15T20:59:28","Actor":"IntegerMan","Number":"7175","RawContent":null,"Title":"Support text/vnd.mermaid MIME Type in Formatters","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI'd like to be able to easily write formatters for built-in and custom types that use Mermaid markdown to render a custom diagram for an object. My specific case in wanting this at the moment is a `Microsoft.ML.ITransformer` object where I want to visualize the chain of transformers from a machine learning model.\r\n\r\nI can generate a valid mermaid string, but outputting it from a Formatter either results in the mermaid string appearing as text if plain text or HTML mime types are used, or with my formatter not being used at all if I specify \"text/markdown\" or \"text/vnd.mermaid\" (Mermaid's official MIME type).\r\n\r\nThere are ways of manually passing things off to the Mermaid kernel via extensions, but those are a lot more work than a simple Formatter, and it'd be ideal to avoid having to write a magic command just to process something.\r\n\r\n**Describe the solution you'd like**\r\nFormatters with a MIME type of `text/vnd.mermaid` should have their output piped to the Mermaid kernel and the result of that operation should be rendered below the cell when the formatter is in use.\r\n\r\nYou should be able to set up a formatter in a manner like this:\r\n\r\n```cs\r\nFormatter.Register<ITransformer>((transformer, writer) =>\r\n{\r\n    writer.Write(MattEland.ML.Interactive.TransformerExtensions.ToMermaid(transformer));\r\n}, \"text/vnd.mermaid\");\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nI've considered finding an external rendering library to transform mermaid to a supported MIME type, writing a custom magic command to connect things directly to the Mermaid kernel, and considered avoiding Mermaid entirely here and building something in SVG.\r\n\r\n**Additional context**\r\nThis is part of a larger effort I'm making to try to improve the data analysis and data science workflow in a Polyglot Notebook based on things I've observed in book / course creation and while using this toolset pursuing my master's degree.\r\n\r\nSee https://github.com/IntegerMan/MattEland.ML/blob/main/MattEland.ML/MattEland.ML.Interactive/TransformerExtensions.cs and neighboring files for details on my early transformer mermaid visualization attempt.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7175","RelatedDescription":"Open issue \"Support text/vnd.mermaid MIME Type in Formatters\" (#7175)"},{"Id":"2354970257","IsPullRequest":false,"CreatedAt":"2024-06-15T15:57:34","Actor":"superichmann","Number":"7174","RawContent":null,"Title":"Add AutoEncoder as a Feature Selection Method","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nNo.\r\nCurrently the only **practical** option for feature selection in ML.net is MI. maybe PFI (post fit post transform) and maybe PCA (dimensionality reduction).\r\n\r\n**Describe the solution you'd like**\r\nMy online research shows that autoencoders for feature selection can be highly accurate and add another layer to the feature selection catalog.\r\n\r\n**Describe alternatives you've considered**\r\nUsing already implemented feature importance methods.\r\n\r\n**Additional context**\r\nResearch:\r\nhttps://hex.tech/blog/autoencoders-for-feature-selection/\r\nhttps://deepai.org/publication/autoencoder-feature-selector\r\nRelates to issues:\r\n[4254](https://github.com/dotnet/machinelearning/issues/4254)\r\n[5777](https://github.com/dotnet/machinelearning/issues/5777)\r\n\r\nNote: Perhaps utilizing autoencoders is actually possible in ml.net with importing external models or something like that, if it does I would love a to see how :) Thanks for everything guys!\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7174","RelatedDescription":"Open issue \"Add AutoEncoder as a Feature Selection Method\" (#7174)"},{"Id":"2337878692","IsPullRequest":true,"CreatedAt":"2024-06-13T19:14:03","Actor":"asmirnov82","Number":"7168","RawContent":null,"Title":"Add targeting .Net 8.0 for DataFrame package","State":"closed","Body":"Fixes #7167 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7168","RelatedDescription":"Closed or merged PR \"Add targeting .Net 8.0 for DataFrame package\" (#7168)"},{"Id":"2337874552","IsPullRequest":false,"CreatedAt":"2024-06-13T19:14:03","Actor":"asmirnov82","Number":"7167","RawContent":null,"Title":"Add targeting .Net 8.0 for DataFrame package","State":"closed","Body":"1. Add targeting .Net 8.0 for DataFrame package\r\n2. Update dependency to Apache.Arrow to use newer version\r\n3.  Fix code that uses Apache.Arrow obsolete methods","Url":"https://github.com/dotnet/machinelearning/issues/7167","RelatedDescription":"Closed issue \"Add targeting .Net 8.0 for DataFrame package\" (#7167)"},{"Id":"2338979869","IsPullRequest":true,"CreatedAt":"2024-06-13T18:35:12","Actor":"LittleLittleCloud","Number":"7170","RawContent":null,"Title":"add document for GenAI","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n- [ ] \r\nAdd desgin document for #7169 ","Url":"https://github.com/dotnet/machinelearning/pull/7170","RelatedDescription":"Closed or merged PR \"add document for GenAI\" (#7170)"},{"Id":"2342372801","IsPullRequest":true,"CreatedAt":"2024-06-09T16:36:48","Actor":"ErikApption","Number":"7173","RawContent":null,"Title":"create unique temporary directories to prevent permission issues","State":"open","Body":"Fixes #7172\r\n\r\nThis is a tentative fix for #7172 where ml.net fails when multiple users are using same directory. This fix checks if there is already a ml_dotnet<number> if so, it will increase the number until the path is available.\r\n\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [X] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7173","RelatedDescription":"Open PR \"create unique temporary directories to prevent permission issues\" (#7173)"},{"Id":"2342371566","IsPullRequest":false,"CreatedAt":"2024-06-09T16:33:34","Actor":"ErikApption","Number":"7172","RawContent":null,"Title":"Directory permission exception with multiple concurrent users on linux","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Linux Ubuntu 22.04.4 LTS\r\n - ML.NET Version: ML.NET 3.0.1\r\n - .NET Version: .NET 8.0\r\n\r\n**Describe the bug**\r\n\r\nWhen multiple users are running ML.NET on the same server. each process seems to require a temporary directory - however its name is hardcoded and the second user running ml.net will fail because /tmp/ml_dotnet is not accessible.\r\n\r\n```\r\n2024-06-08 20:00:31.5387|FATAL|Datahunter.Core.Helpers.MLHelper|Error initializing ML Model System.UnauthorizedAccessException: Access to the path '/tmp/ml_dotnet/hetgfm5v.kvn' is denied.\r\n ---> System.IO.IOException: Permission denied\r\n   --- End of inner exception stack trace ---\r\n   at System.IO.FileSystem.CreateDirectory(String fullPath, UnixFileMode unixCreateMode)\r\n   at System.IO.Directory.CreateDirectory(String path)\r\n   at Microsoft.ML.Repository.GetShortTempDir(IExceptionContext ectx)\r\n   at Microsoft.ML.Repository..ctor(Boolean needDir, IExceptionContext ectx)\r\n   at Microsoft.ML.RepositoryReader..ctor(Stream stream, IExceptionContext ectx, Boolean useFileSystem)\r\n   at Microsoft.ML.RepositoryReader.Open(Stream stream, IExceptionContext ectx, Boolean useFileSystem)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Launch one process with user one\r\n2. Launch same process with user two\r\n3. User two will get an IOException\r\n\r\n**Expected behavior**\r\nTemporary directory should be unique for each user\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7172","RelatedDescription":"Open issue \"Directory permission exception with multiple concurrent users on linux\" (#7172)"},{"Id":"2340674188","IsPullRequest":true,"CreatedAt":"2024-06-07T15:07:08","Actor":"directhex","Number":"7171","RawContent":null,"Title":"Add a stub packageSourceMapping","State":"open","Body":"Without packageSourceMapping, you may receive NuGet warning NU1507. Building with WarnAsError will elevate this to a fatal error.\r\n\r\n```\r\nC:\\d\\source-indexer\\bin\\repo\\machinelearning\\test\\Microsoft.ML.CpuMath.UnitTests\\Microsoft.ML.CpuMath.UnitTests.csproj : error NU1507: Warning As Error: There are 9 package sources defined in your configuration. When using central package management, please map your package sources with package source mapping (https://aka.ms/nuget-package-source-mapping) or specify a single package source. The following sources are defined: dotnet-public, dotnet-tools, dotnet-libraries, dotnet-eng, vs-buildservices, dotnet5-roslyn, mlnet-daily, mlnet-assets, dotnet8 [C:\\d\\source-indexer\\bin\\repo\\machinelearning\\Microsoft.ML.sln]\r\n```\r\n\r\nUsing * as a pattern means any repo can supply any package, the pattern can be further refined later.","Url":"https://github.com/dotnet/machinelearning/pull/7171","RelatedDescription":"Open PR \"Add a stub packageSourceMapping\" (#7171)"},{"Id":"2338977326","IsPullRequest":false,"CreatedAt":"2024-06-06T19:06:12","Actor":"LittleLittleCloud","Number":"7169","RawContent":null,"Title":"Add GenAI packages","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\n**Describe the solution you'd like**\r\nThe `GenAI` packages will provide torchsharp implementation for a series of popular GenAI models. The goal is to load the same weight from the corresponding python regular model.\r\n\r\n- [x] Add design doc (#7170)\r\n- [x] Add `Microsoft.ML.GenAI.Core` (#7177)\r\n\r\nThe following models will be added in the first wave\r\n- [ ] Phi-3 (`Microsoft.ML.GenAI.Phi`) #7184 \r\n- [ ] LLaMA (`Microsoft.ML.GenAI.LLaMA`)\r\n- [ ] Stable Diffusion (`Microsoft.ML.GenAI.StableDiffusion`)\r\n\r\nAlong with the benchmark\r\n- [ ] Benchmark for Phi-3\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7169","RelatedDescription":"Open issue \"Add GenAI packages\" (#7169)"},{"Id":"2331161144","IsPullRequest":true,"CreatedAt":"2024-06-03T13:27:00","Actor":"dotnet-maestro[bot]","Number":"7165","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: c692823c-b896-437f-4f57-08dc434cc8f6\r\n- **Build**: 20240702.2\r\n- **Date Produced**: July 2, 2024 10:38:54 PM UTC\r\n- **Commit**: 4a7d983f833d6b86365ea1b2b4d6ee72fbdbf944\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n  - **Microsoft.DotNet.SignTool**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n  - **Microsoft.DotNet.XliffTasks**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24352.2][6]\r\n\r\n[6]: https://github.com/dotnet/arcade/compare/2001d73c8f...4a7d983f83\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7165","RelatedDescription":"Open PR \"[main] Update dependencies from dotnet/arcade\" (#7165)"},{"Id":"2323990537","IsPullRequest":false,"CreatedAt":"2024-05-30T06:02:55","Actor":"pjsgsy","Number":"7164","RawContent":null,"Title":"Model builder training appears to leak data somehow into the training set","State":"closed","Body":"Windwos 11\r\nML.Net 3.0.1\r\n.Net 4.8 \r\n\r\nWhen traingin a large csv my model would get consistently high results that I could not replicate in testing outside of model builder. I was letting model builder handle the trainign/validation split, though I tried all those options. Folds, 70/30, 80/20, etc. Always ended up >90% micro accuracy over training time if left, but never got even close when run in real time.  After many days - I today split the SAME data file into 2 different files, telling model builder the validation data is in that separate file, and hey presto, can;t train more than 45%...  This is better (for worse!). The 2 files are a 80/20 split - I just did it myself. Give model builder the whole file and tell it to do the 80/20 split, and it will train to >93% again.  Something in there is broken it seems! So little visibility for me into what is going on, I don't have much more to offer in terms of what. it would appear the validation data is somehow leaked into the training set.\r\n\r\nSeperate validation file\r\n![image](https://github.com/dotnet/machinelearning/assets/439341/2a681847-64b1-41c8-a7fa-e3c11dfc7835)\r\n\r\nCombined file letting model builder do the split will train to >0.93, same data and metrics.\r\n\r\nModel builder version is 17.18.2.2415501\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7164","RelatedDescription":"Closed issue \"Model builder training appears to leak data somehow into the training set\" (#7164)"},{"Id":"2322959164","IsPullRequest":false,"CreatedAt":"2024-05-29T10:26:22","Actor":"aforoughi1","Number":"7163","RawContent":null,"Title":"Loading a LSTM Model Created in Torchsharp in ML.Net","State":"open","Body":"I can create/train/evaluate/save/load a multilayer LSTM model using Torchsharp but cannot run in ML.NET.\r\n\r\nThe main requirement is to export/import a Torchsharp model to ONNX and run it in ML.NET. However, Torchsharp doesn't implement torch.onnx.export method.  I'm stuck at a point and had to convert everything to pytorch just to export to ONNX. \r\n\r\n I also tried a custom pipeline and  trial runner to train and evaluate the model but I'm struggling with how these models can be saved/Loaded in ML.NET.    \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7163","RelatedDescription":"Open issue \"Loading a LSTM Model Created in Torchsharp in ML.Net\" (#7163)"}],"ResultType":"GitHubIssue"}},"RunOn":"2024-07-15T03:30:17.1326132Z","RunDurationInMilliseconds":443}