{"Data":{"GitHub":{"Issues":[{"Id":"2160092346","IsPullRequest":false,"CreatedAt":"2024-02-29T00:10:26","Actor":"thomasd3","Number":"7038","RawContent":null,"Title":"What is the best way to represent N/A if a value is not available?","State":"open","Body":"I'm using a binary classifier.\r\n\r\nMy feature list has a list of columns representing various states in my model. The range of values is -1 to +1.\r\nBut, in some cases, some states are simply not present, in some rows.\r\n\r\nFor example:\r\n```\r\n0, 1, 1, 1, 0, 0, 1\r\n1, 0, 0, 1, 1, 0, 0\r\n1, X, 1, 1, 1, 0, 1\r\n1, 0, 0, 0, 0, 1, 1\r\n```\r\n\r\nNotice the X? which really means, in my model, that there is an absence of data there.\r\nThe model is supposed to classify a specific situation based on the states of various systems. And sometimes that data is not present, shouldn't be interpolated from neighbors either, it really means that this signal does not exist at that time.\r\n\r\nWhat is the best way to represent this?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7038","RelatedDescription":"Open issue \"What is the best way to represent N/A if a value is not available?\" (#7038)"},{"Id":"2159384547","IsPullRequest":true,"CreatedAt":"2024-02-28T20:55:27","Actor":"ericstj","Number":"7037","RawContent":null,"Title":"Remove SourceLink SDK references","State":"closed","Body":"@ViktorHofer let me know that we no longer need to have explicit SDK references to these source-link packages.\r\n\r\nI'm removing them and also testing the behavior of build to ensure we still have source-link info in our binaries per https://learn.microsoft.com/en-us/dotnet/standard/library-guidance/sourcelink.","Url":"https://github.com/dotnet/machinelearning/pull/7037","RelatedDescription":"Closed or merged PR \"Remove SourceLink SDK references\" (#7037)"},{"Id":"2143516236","IsPullRequest":true,"CreatedAt":"2024-02-28T18:55:01","Actor":"stephentoub","Number":"7018","RawContent":null,"Title":"Prototype using spans in Model","State":"closed","Body":"@tarekgh, this isn't for merging, but it shows appx what I had in mind for incorporating spans into Model (I know you're currently revising the surface area, so take this with a grain of salt). This eliminates a majority of the remaining allocation that occurs when using Tokenizer.CountTokens/EncodeToIds, as it avoids allocating strings for each token that's already in the cache.\r\n\r\nFeel free to crib liberally from the second commit and close this PR.  Ignore the first commit, which I submitted separately.","Url":"https://github.com/dotnet/machinelearning/pull/7018","RelatedDescription":"Closed or merged PR \"Prototype using spans in Model\" (#7018)"},{"Id":"2158910023","IsPullRequest":false,"CreatedAt":"2024-02-28T12:56:00","Actor":"chuongmep","Number":"7036","RawContent":null,"Title":"Best way to convert Datatable to Dataframe","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nHi, \r\nDo we have any way to fast convert from `System.Data.Datatable` to `Microsoft.Data.Analysis.DataFrame` ?\r\n\r\nI tried with my solution but it still too slow\r\n\r\n**Describe the solution you'd like**\r\n\r\n```csharp\r\npublic static Microsoft.Data.Analysis.DataFrame ToDataFrame(this DataTable dataTable)\r\n    {\r\n        Microsoft.Data.Analysis.DataFrame dataFrame = new Microsoft.Data.Analysis.DataFrame();\r\n\r\n        foreach (DataColumn column in dataTable.Columns)\r\n        {\r\n            // get values from column cast as string\r\n            string[] values = dataTable.AsEnumerable().Select(r => r.Field<object>(column.ColumnName)?.ToString()).ToArray();\r\n            DataFrameColumn dataFrameColumn = DataFrameColumn.Create(column.ColumnName, values);\r\n            dataFrame.Columns.Add(dataFrameColumn);\r\n        }\r\n        return dataFrame;\r\n    }\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\n- I want keep format column type and quick convert between them.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7036","RelatedDescription":"Open issue \"Best way to convert Datatable to Dataframe\" (#7036)"},{"Id":"2157950944","IsPullRequest":true,"CreatedAt":"2024-02-28T02:26:39","Actor":"tarekgh","Number":"7035","RawContent":null,"Title":"Add Span support in tokenizer's Model abstraction","State":"open","Body":"This change is adding Span support to the Tokenizer's Model abstraction. This will help in performance and not restrict us in the future to use spans without to worry about more memory allocations. ","Url":"https://github.com/dotnet/machinelearning/pull/7035","RelatedDescription":"Open PR \"Add Span support in tokenizer's Model abstraction\" (#7035)"},{"Id":"2157810214","IsPullRequest":true,"CreatedAt":"2024-02-27T23:49:40","Actor":"michaelgsharp","Number":"7034","RawContent":null,"Title":"Helix queue testing","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7034","RelatedDescription":"Open PR \"Helix queue testing\" (#7034)"},{"Id":"2157709761","IsPullRequest":true,"CreatedAt":"2024-02-27T22:19:11","Actor":"michaelgsharp","Number":"7033","RawContent":null,"Title":"M1 helix testing","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7033","RelatedDescription":"Open PR \"M1 helix testing\" (#7033)"},{"Id":"2155085067","IsPullRequest":true,"CreatedAt":"2024-02-27T22:13:03","Actor":"michaelgsharp","Number":"7029","RawContent":null,"Title":"Make MlImage tests not block file for reading","State":"closed","Body":"Makes ML-Image tests not block the image file for reading as this is causing some test failures.","Url":"https://github.com/dotnet/machinelearning/pull/7029","RelatedDescription":"Closed or merged PR \"Make MlImage tests not block file for reading\" (#7029)"},{"Id":"2157499570","IsPullRequest":false,"CreatedAt":"2024-02-27T19:58:17","Actor":"scott19896","Number":"7032","RawContent":null,"Title":"Calling predict from LightGBM model file load","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows\r\n- **.NET Version (eg., dotnet --info)**: 6\r\n\r\n### Issue\r\n\r\nFollowing on from https://github.com/dotnet/machinelearning/pull/6569\r\n\r\nAre there any examples of how to load the LGBM model file and call predict on an entry by entry basis?\r\n\r\nLooking at the Booster wrapper, the GetModel call is private and so the only interface I could see to access the model is through the trainer. This only provides that access when calling Fit however, which is not needed from what I can tell when loading a pre-trained model.\r\n\r\nWould you know if this is something that is supported?  In other words, load a pre-trained LGBM model text file and access the Booster to call predicts \r\n\r\nThanks!","Url":"https://github.com/dotnet/machinelearning/issues/7032","RelatedDescription":"Open issue \"Calling predict from LightGBM model file load\" (#7032)"},{"Id":"2157465678","IsPullRequest":false,"CreatedAt":"2024-02-27T19:38:20","Actor":"elvinsomon","Number":"7031","RawContent":null,"Title":"When we have all support without limitations for ARM devises for use all ML.NET models?","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/issues/7031","RelatedDescription":"Open issue \"When we have all support without limitations for ARM devises for use all ML.NET models?\" (#7031)"},{"Id":"2155826542","IsPullRequest":true,"CreatedAt":"2024-02-27T07:06:57","Actor":"michaelgsharp","Number":"7030","RawContent":null,"Title":"Fix global.json to work better on non x64 hardware","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7030","RelatedDescription":"Open PR \"Fix global.json to work better on non x64 hardware\" (#7030)"},{"Id":"2139505439","IsPullRequest":false,"CreatedAt":"2024-02-26T19:06:38","Actor":"stephentoub","Number":"7008","RawContent":null,"Title":"Tiktoken should support being created without synchronous I/O and with user supplied data","State":"closed","Body":"If a developer wants to create a Tiktoken from something other than CreateByModelNameAsync, they're forced to use the Tiktoken constructor, which does synchronous I/O. There should be a factory equivalent to its constructors that use async I/O. There should likely also be a constructor that accepts the data already in memory rather than needing to load it separately.","Url":"https://github.com/dotnet/machinelearning/issues/7008","RelatedDescription":"Closed issue \"Tiktoken should support being created without synchronous I/O and with user supplied data\" (#7008)"},{"Id":"2139539018","IsPullRequest":false,"CreatedAt":"2024-02-26T19:06:22","Actor":"stephentoub","Number":"7010","RawContent":null,"Title":"Tokenizer.Decode special-cases EnglishRoberta","State":"closed","Body":"This suggests there's something wrong with the Model abstraction, and it means that any other model of a similar ilk to EnglishRoberta could not be supported (or not supported efficiently, or whatever reason caused this to be special-cased here). The special-casing should be removed and the abstraction fixed to make the special-casing unnecessary.\r\nhttps://github.com/dotnet/machinelearning/blob/4635a862ddd21b3e7de0404f73a897fecb2011a1/src/Microsoft.ML.Tokenizers/Tokenizer.cs#L203-L216","Url":"https://github.com/dotnet/machinelearning/issues/7010","RelatedDescription":"Closed issue \"Tokenizer.Decode special-cases EnglishRoberta\" (#7010)"},{"Id":"2139730970","IsPullRequest":false,"CreatedAt":"2024-02-26T19:06:08","Actor":"stephentoub","Number":"7011","RawContent":null,"Title":"CreateByModelNameAsync should recognize text-embedding-3-small/large","State":"closed","Body":"https://openai.com/blog/new-embedding-models-and-api-updates\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7011","RelatedDescription":"Closed issue \"CreateByModelNameAsync should recognize text-embedding-3-small/large\" (#7011)"},{"Id":"2140259172","IsPullRequest":false,"CreatedAt":"2024-02-26T19:05:52","Actor":"stephentoub","Number":"7013","RawContent":null,"Title":"More API feedback on Tokenizer and friends","State":"closed","Body":"Tokenizer:\r\n- Tokenizer is mutable after creation? e.g. you can set its PreTokenizer, Normalizer, and Decoder after it's created. If the intent is for a Tokenizer to be created once for a process and shared, is that mutability warranted / wise? Should the constructor accept a Decoder (it doesn't today) and then the properties made get-only? Or at a minimum should the properties be made init instead of set?\r\n- There are a bunch of parameters named \"sequence\", with XML comments then describing them as \"text\". Would \"text\" be a more obvious name for the parameter?\r\n- I find the double-negative of \"bool skipSpecialTokens = false\" confusing: that being false means special tokens should be considered. Would it be better as \"bool considerSpecialTokens = true\" or something similar? I also don't know what it means to \"skip special tokens\"... they're not actually being skipped, right? They might still be returned as tokens, they're just not treated any differently from all other tokens. If we were actually \"skipping special tokens\", I'd expect that the implementation would always be looking for them and just not yielding / counting / etc. them when discovered, and I don't believe that's what's happening.\r\n- Tokenizer supports both Encode and Decode, but the result from Encode is a TokenizerResult type. Shouldn't that type be named something specific to encoding, since it's not relevant to other operations Tokenizer exposes?\r\n- What is the purpose of TrainFromFiles? It seems to produce an IReadOnlyList<AddedToken> that's then entirely ignored. Should this method be deleted entirely?\r\n\r\nToken:\r\n- Why is this mutable?\r\n- Typically in .NET APIs that deal with slices of things specify an offset and a length, typically as separate properties. These APIs are specifying starting and ending indices, as a tuple, named Index and End. That feels very inconsistent. I'd have expected an Offset/Index property and a Length property. Same feedback for Split and any other similar types.\r\n\r\nPreTokenizer:\r\n- The parameter to PreTokenizer is called \"sentence\". Why is it called \"sentence\" here, \"sequence\" in other places, \"text\" or \"input\" in various comments, etc. Must this actually be a \"sentence\"?\r\n\r\nNormalizedString:\r\n- It's not clear to me what the `int[]` mapping is. I see the description in the comment, but it's not clear enough. I'm guessing that mapping[i] for i being a position in original is the corresponding index into normalizedString?\r\n- The constructor parameters' names don't match the property names, e.g. ctor parameter is normalizedString but the property is Normalized, ctor parameter is mapping but property is NormalizedToOriginalMapping, etc.\r\n\r\nTrainer:\r\n- Does anyone use this Trainer stuff? Can it be deleted?\r\n- All the Progress stuff seems only relevant to that.  Can it be deleted, too?\r\n\r\nModel:\r\n- Methods should start with a verb. TokenToId and IdToToken don't follow the typical guidance.\r\n- Why is GetVocabSize needed? Can't someone just use GetVocab().Count? Seems like that's what all the implementations do.\r\n- Why is GetVocab a method rather than a Vocab (or Vocabulary) property?\r\n- Are Save and GetTrainer needed?\r\n\r\nTikToken:\r\n- tikTokenBpeFile parameter should be bpeFilePath or something like that. If it's just called file, folks might infer that to mean it's the contents of the file.\r\n- specialTokensEncoder is a strange name. It's just a dictionary and doesn't do any encoding. Should it just be specialTokens?\r\n- tikTokenBpeFileStream parameter suggests this must be a \"FileStream\"... it needn't be. This should just be bpeStream or something like that.\r\n\r\nI suggest we take the surface area of Microsoft.ML.Tokenizers through an API review to get more eyes on it.\r\ncc: @terrajobst, @tarekgh ","Url":"https://github.com/dotnet/machinelearning/issues/7013","RelatedDescription":"Closed issue \"More API feedback on Tokenizer and friends\" (#7013)"},{"Id":"2150148900","IsPullRequest":true,"CreatedAt":"2024-02-26T18:57:18","Actor":"tarekgh","Number":"7024","RawContent":null,"Title":"Address the feedback on the tokenizer's library","State":"closed","Body":"This fix address the feedback reported in the issues:\r\n\r\n- https://github.com/dotnet/machinelearning/issues/7004\r\n- https://github.com/dotnet/machinelearning/issues/7005\r\n- https://github.com/dotnet/machinelearning/issues/7006\r\n- https://github.com/dotnet/machinelearning/issues/7008\r\n- https://github.com/dotnet/machinelearning/issues/7010\r\n- https://github.com/dotnet/machinelearning/issues/7011\r\n- https://github.com/dotnet/machinelearning/issues/7013\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7024","RelatedDescription":"Closed or merged PR \"Address the feedback on the tokenizer's library\" (#7024)"},{"Id":"2152373689","IsPullRequest":false,"CreatedAt":"2024-02-24T15:53:49","Actor":"OldManUnderTheHill","Number":"7028","RawContent":null,"Title":"Object detection training using CUDA gives decent results, while using CPU always returns nothing or inferior results","State":"open","Body":"**System Information (please complete the following information):**\r\n\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 16.18.2\r\n - .NET Version: 8.0\r\n\r\n**Describe the bug**\r\nI have a self created training set where I want to detect small marked passages of text (with a text marker). If I use CUDA for object detection training I get like the following result (using these parameters: --epoch 10 --device gpu0 -b 1 -st 0.3 -it 0.5 --width 600 --height 800)\r\n\r\n-> ObjectDetectionMulti                0.6115    \r\n\r\nIf I switch to CPU training while keeping all other parameters the result is always 0.0%. Testing the CPU model with some test images will never return any boxes, while the model from GPU training generates nice hits.\r\nAs a workaround I temporarily use the GPU model with CPU code.\r\n\r\nI know what I try to do is a bit strange, but it seems to work out if the GPU is used for training. A similar thing happens when I use the stop sign tutorial data set. Results when using the CPU for 5 epochs gives approx. 0.53 as result, while using the GPU on the same set with the same parameters 0.63.\r\n\r\nI added my dataset for further analysis, all used documents are public available on the internet.\r\n\r\n[LetterMarkerAnnot.zip](https://github.com/dotnet/machinelearning/files/14393399/LetterMarkerAnnot.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7028","RelatedDescription":"Open issue \"Object detection training using CUDA gives decent results, while using CPU always returns nothing or inferior results\" (#7028)"},{"Id":"2151210047","IsPullRequest":false,"CreatedAt":"2024-02-23T14:30:11","Actor":"abbottdev","Number":"7026","RawContent":null,"Title":"Add support/examples for Google Gemma lightweight LLM models","State":"open","Body":"**Is your feature request related to a problem? **\r\nSupport complex LLM reasoning tasks with ML .NET. My specific use case here is structured data extraction into a known format.\r\n\r\nBeing able to take this models and fine tune them using the ML .NET training/pipeline APIs would be a huge benefit.\r\n\r\n**Describe the solution you'd like**\r\nGoogle have opened sourced their base model Gemma which is a lightlight deriviative of the Gemini LLM. There is a keras implementation of it, a TensorFlow implementation. There are other options available but they havent been instruction tuned so the model would need more work for say, pytorch?\r\n\r\n**Additional context**\r\nhttps://blog.google/technology/developers/gemma-open-models/\r\nhttps://www.kaggle.com/models/google/gemma\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7026","RelatedDescription":"Open issue \"Add support/examples for Google Gemma lightweight LLM models\" (#7026)"},{"Id":"2150573552","IsPullRequest":false,"CreatedAt":"2024-02-23T08:02:21","Actor":"bettwedder","Number":"7025","RawContent":null,"Title":"Unable to remove SdcaLogisticRegressionOva from AutoML Multiclassification Experiment","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version:  v3.0.1 & AutoML 0.21.1\r\n - .NET Version: 8.0\r\n\r\n**Describe the bug**\r\nWhen creating an AutoML Multiclassification Experiment, you are unable to remove the trainer \"SdcaLogisticRegressionOva\".  \r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.  Create a Multiclass experiment settings object\r\n2.  Iterate on settings.Trainers and remove all trainers that are not \"LightGbm\" or \"FastForest\"\r\n3.  Create a Multiclass Progress Reporter that will output the TrainerName used.  \r\n4.  Use this replace command to remove the currently bugged (3.0.1 and 0.21.1) TrainerName value:  \r\n`TrainerName.Replace(\"Multi\", \"\").Replace(\"ReplaceMissingValues\", \"\").Replace(\"Concatenate\", \"\").Replace(\"Unknown\", \"\").Replace(\"=>\", \"\"); `\r\n5.  Run experiment and monitor names.\r\n\r\n\r\n**Expected behavior**\r\nOne of the first three models will include the unremovable trainer.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\n```\r\n  \r\n               MulticlassExperimentSettings settings = new MulticlassExperimentSettings()\r\n                {\r\n                    OptimizingMetric = optimizeMetric,\r\n                    MaxExperimentTimeInSeconds = experimentTime,\r\n                    CacheDirectoryName = cacheDir,\r\n                    CancellationToken = cts.Token,\r\n                    CacheBeforeTrainer = CacheBeforeTrainer.On\r\n                    \r\n                };\r\n\r\n                bool keptLightGBM = false;\r\n                foreach (var trainer in settings.Trainers.ToList())\r\n                {\r\n\r\n                    if (!trainer.ToString().ToUpperInvariant().Contains(\"LIGHTGBM\") && !trainer.ToString().ToUpperInvariant().Contains(\"FASTFOREST\"))\r\n                    {\r\n                        settings.Trainers.Remove(trainer);\r\n                        Console.WriteLine(\"Removed Trainer: \" + trainer.ToString());\r\n                    }\r\n                    //else\r\n                    //{\r\n                    //    if (keptLightGBM)\r\n                    //    {\r\n                    //        settings.Trainers.Remove(trainer);\r\n                    //        Console.WriteLine(\"Removed Extra \"LightGbm\" Trainer: \" + trainer.ToString());\r\n                    //    }\r\n                    //    else\r\n                    //        keptLightGBM = true;\r\n                    //}\r\n                }\r\n\r\n                MulticlassClassificationExperiment experiment = context.Auto().CreateMulticlassClassificationExperiment(settings);\r\n                ExperimentResult<MulticlassClassificationMetrics> result;\r\n\r\n                result = experiment.Execute(trainData, splitTestData, columnInformation, null, new MulticlassProgressReporter() { labelColumnName = label, CacheDir = cacheDir, ExperimentTime = DateTime.Now });\r\n\r\n```\r\n\r\nThis code produces this output: \r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/40208910/00b0f1ab-a208-4ad2-845f-8e72627a74ea)\r\n\r\n\r\n\r\n**Additional context**\r\nIf you only leave one LightGbm as the only trainer, then AutoML uses the \"SdcaLogisticRegressionOva\" every other time.\r\n\r\nThe trainer \"SdcaLogisticRegressionOva\" does not appear in the list after creating a settings object which is supposed to populate the list with all values.  Also, if you iterate on list of auto populated trainers, two items appear with the name \"LightGbm\".  \r\n\r\nLast, when I peek the definition of Microsoft.ML.AutoML.MulticlassClassificationTrainer, I get this list which also doesn't have \"SdcaLogisticRegressionOva\" in the list. \r\n\r\n```\r\n// Decompiled with JetBrains decompiler\r\n// Type: Microsoft.ML.AutoML.MulticlassClassificationTrainer\r\n// Assembly: Microsoft.ML.AutoML, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51\r\n// MVID: 5D7A79B7-CF20-433B-A534-1ED92C335230\r\n// Assembly location: C:\\Users\\xxxx\\.nuget\\packages\\microsoft.ml.automl\\0.21.1\\lib\\netstandard2.0\\Microsoft.ML.AutoML.dll\r\n// XML documentation location: C:\\Users\\xxxx\\.nuget\\packages\\microsoft.ml.automl\\0.21.1\\lib\\netstandard2.0\\Microsoft.ML.AutoML.xml\r\n\r\n#nullable disable\r\nnamespace Microsoft.ML.AutoML\r\n{\r\n  /// <summary>\r\n  /// Enumeration of ML.NET multiclass classification trainers used by AutoML.\r\n  /// </summary>\r\n  public enum MulticlassClassificationTrainer\r\n  {\r\n    /// <summary>\r\n    /// <see cref=\"T:Microsoft.ML.Trainers.OneVersusAllTrainer\" /> using <see cref=\"T:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer\" />.\r\n    /// </summary>\r\n    FastForestOva,\r\n    /// <summary>\r\n    /// <see cref=\"T:Microsoft.ML.Trainers.OneVersusAllTrainer\" /> using <see cref=\"T:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer\" />.\r\n    /// </summary>\r\n    FastTreeOva,\r\n    /// <summary>\r\n    /// See <see cref=\"T:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer\" />.\r\n    /// </summary>\r\n    LightGbm,\r\n    /// <summary>\r\n    /// See <see cref=\"T:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer\" />.\r\n    /// </summary>\r\n    LbfgsMaximumEntropy,\r\n    /// <summary>\r\n    /// <see cref=\"T:Microsoft.ML.Trainers.OneVersusAllTrainer\" /> using <see cref=\"T:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer\" />.\r\n    /// </summary>\r\n    LbfgsLogisticRegressionOva,\r\n    /// <summary>\r\n    /// See <see cref=\"T:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer\" />.\r\n    /// </summary>\r\n    SdcaMaximumEntropy,\r\n  }\r\n}\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/7025","RelatedDescription":"Open issue \"Unable to remove SdcaLogisticRegressionOva from AutoML Multiclassification Experiment\" (#7025)"},{"Id":"2145442937","IsPullRequest":true,"CreatedAt":"2024-02-23T00:41:24","Actor":"stephentoub","Number":"7020","RawContent":null,"Title":"Optimize regexes used in tiktoken","State":"closed","Body":"This ports the tweaks in https://github.com/openai/tiktoken/pull/234. I noticed the differences as they also show up in the source for https://www.youtube.com/watch?v=zduSFxRajkE.\r\n\r\n@tarekgh, if this conflicts with any of your changes, feel free to close this and I can re-make them after your changes land.","Url":"https://github.com/dotnet/machinelearning/pull/7020","RelatedDescription":"Closed or merged PR \"Optimize regexes used in tiktoken\" (#7020)"},{"Id":"2147660741","IsPullRequest":true,"CreatedAt":"2024-02-22T21:49:28","Actor":"michaelgsharp","Number":"7023","RawContent":null,"Title":"Fix formatting that fails in VS","State":"closed","Body":"Fixes minor formatting that fails in VS but not with command line.","Url":"https://github.com/dotnet/machinelearning/pull/7023","RelatedDescription":"Closed or merged PR \"Fix formatting that fails in VS\" (#7023)"},{"Id":"2146099505","IsPullRequest":true,"CreatedAt":"2024-02-21T20:14:45","Actor":"michaelgsharp","Number":"7021","RawContent":null,"Title":"Temp fix for the race condition during the tests.","State":"closed","Body":"Temporarily fixes the race condition that seems to be happening during the tests by making the offending tests run sequentially.","Url":"https://github.com/dotnet/machinelearning/pull/7021","RelatedDescription":"Closed or merged PR \"Temp fix for the race condition during the tests.\" (#7021)"},{"Id":"2146116326","IsPullRequest":true,"CreatedAt":"2024-02-21T08:33:30","Actor":"michaelgsharp","Number":"7022","RawContent":null,"Title":"Working on memory issue during tests for TorchSharp","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7022","RelatedDescription":"Open PR \"Working on memory issue during tests for TorchSharp\" (#7022)"},{"Id":"2143381151","IsPullRequest":true,"CreatedAt":"2024-02-20T20:08:18","Actor":"stephentoub","Number":"7015","RawContent":null,"Title":"Tweak CreateByModelNameAsync","State":"closed","Body":"- Add a CancellationToken to CreateByModelNameAsync, allowing the download and parsing to be canceled.\r\n- Use ReadLineAsync(cancellationToken), which not only allows it to be canceled, but avoids ~100K task allocations\r\n- Fix Helpers.FromBase64String to support lines longer than 300 chars\r\n\r\ncc: @tarekgh ","Url":"https://github.com/dotnet/machinelearning/pull/7015","RelatedDescription":"Closed or merged PR \"Tweak CreateByModelNameAsync\" (#7015)"},{"Id":"2143488085","IsPullRequest":true,"CreatedAt":"2024-02-20T19:02:04","Actor":"stephentoub","Number":"7017","RawContent":null,"Title":"Tweak Tiktoken's BytePairEncode for improved perf","State":"closed","Body":"- Stackalloc the indices/ranks when feasible\r\n- Use a span to eliminate bounds checks and allow for directly updating ranks\r\n\r\n```C#\r\n[Benchmark]\r\npublic int CountTokens() => _tokenizer.CountTokens(Poem);\r\n```\r\nwith the same Poem as in https://github.com/dotnet/machinelearning/pull/7012, and setting the LruCache size to 0 in order to skip the cache and measure what's being changed here...\r\n\r\nBefore:\r\n\r\n| Method      | Mean     | Allocated |\r\n|------------ |---------:|----------:|\r\n| CountTokens | 61.11 us |  19.52 KB |\r\n\r\nAfter:\r\n\r\n| Method      | Mean     | Allocated\r\n|------------ |---------:|----------:\r\n| CountTokens | 58.82 us |  11.27 KB\r\n\r\ncc: @tarekgh ","Url":"https://github.com/dotnet/machinelearning/pull/7017","RelatedDescription":"Closed or merged PR \"Tweak Tiktoken's BytePairEncode for improved perf\" (#7017)"},{"Id":"2143402003","IsPullRequest":true,"CreatedAt":"2024-02-20T18:34:11","Actor":"stephentoub","Number":"7016","RawContent":null,"Title":"Avoid LruCache in Tiktoken when cacheSize specified is 0","State":"closed","Body":"cc: @tarekgh ","Url":"https://github.com/dotnet/machinelearning/pull/7016","RelatedDescription":"Closed or merged PR \"Avoid LruCache in Tiktoken when cacheSize specified is 0\" (#7016)"},{"Id":"2144814227","IsPullRequest":false,"CreatedAt":"2024-02-20T16:41:24","Actor":"stephentoub","Number":"7019","RawContent":null,"Title":"Ensure tiktoken implementation up-to-date with OpenAI reference implementation","State":"open","Body":"The implementation at https://github.com/openai/tiktoken/commits/main/src/lib.rs has seen several improvements in the last year (eg https://github.com/openai/tiktoken/pull/255), including a couple that claim perf wins around algorithmic complexity for long inputs. The comments in the source also cite ways of avoiding needing an LRU cache.  We should ensure the C# implementation has all the corresponding goodness.","Url":"https://github.com/dotnet/machinelearning/issues/7019","RelatedDescription":"Open issue \"Ensure tiktoken implementation up-to-date with OpenAI reference implementation\" (#7019)"},{"Id":"2139509642","IsPullRequest":false,"CreatedAt":"2024-02-18T22:25:57","Actor":"stephentoub","Number":"7009","RawContent":null,"Title":"Split struct should not be readonly","State":"closed","Body":"Doing so prohibits desirable optimizations, like making the TokenString property lazily initialized from the original string (otherwise, we end up allocating a new string for every split even if the string isn't used).","Url":"https://github.com/dotnet/machinelearning/issues/7009","RelatedDescription":"Closed issue \"Split struct should not be readonly\" (#7009)"},{"Id":"2139776942","IsPullRequest":true,"CreatedAt":"2024-02-18T20:28:17","Actor":"stephentoub","Number":"7012","RawContent":null,"Title":"First round of perf improvements for tiktoken","State":"closed","Body":"Before:\r\n| Method              | Mean    | Allocated |\r\n|-------------------- |--------:|----------:|\r\n| CountTokensCached   | 3.677 s |   4.82 GB |\r\n| CountTokensUncached | 2.309 s |   3.03 GB |\r\n\r\nAfter:\r\n| Method              | Mean    | Allocated |\r\n|-------------------- |--------:|----------:|\r\n| CountTokensCached   | 2.545 s | 637.63 MB |\r\n| CountTokensUncached | 1.627 s | 408.34 MB |\r\n\r\n```C#\r\nusing BenchmarkDotNet.Attributes;\r\nusing BenchmarkDotNet.Running;\r\nusing Microsoft.ML.Tokenizers;\r\n\r\nBenchmarkSwitcher.FromAssembly(typeof(Tests).Assembly).Run(args);\r\n\r\n[MemoryDiagnoser(false)]\r\n[HideColumns(\"Job\", \"Error\", \"StdDev\", \"Median\", \"RatioSD\")]\r\npublic class Tests\r\n{\r\n    private Tokenizer _tokenizer;\r\n    private string[] _tests;\r\n\r\n    [GlobalSetup]\r\n    public async Task Setup()\r\n    {\r\n        _tokenizer = await Tokenizer.CreateByModelNameAsync(\"gpt-3.5-turbo\");\r\n        using HttpClient client = new HttpClient();\r\n        string text = string.Concat(Enumerable.Repeat(Poem, 8));\r\n        _tests = new string[8192]; // LruCache size\r\n        for (int i = 0; i < _tests.Length; i++)\r\n        {\r\n            _tests[i] = text.Substring(0, text.Length - i);\r\n        }\r\n    }\r\n\r\n    [Benchmark]\r\n    public int CountTokensCached()\r\n    {\r\n        int sum = 0;\r\n        for (int i = 0; i < _tests.Length; i++)\r\n        {\r\n            sum += _tokenizer.CountTokens(_tests[0]); // reuse same input each time\r\n        }\r\n        return sum;\r\n    }\r\n\r\n    [Benchmark]\r\n    public int CountTokensUncached()\r\n    {\r\n        int sum = 0;\r\n        for (int i = 0; i < _tests.Length; i++)\r\n        {\r\n            sum += _tokenizer.CountTokens(_tests[i]); // change the input to defeat the cache\r\n        }\r\n        return sum;\r\n    }\r\n\r\n    private const string Poem = \"\"\"\r\n        **Paws of Joy**\r\n\r\n        In the morning's tender light,\r\n        When dew-kissed grass awaits the sun,\r\n        There stirs a creature, full of might,\r\n        A friend whose loyalty is never undone.\r\n\r\n        **The Dog**, with eyes like galaxies,\r\n        Wags its tail, a metronome of glee,\r\n        Its heart a map of boundless territories,\r\n        Guiding us through life's vast sea.\r\n\r\n        **Furry sentinels**, guardians of our hearth,\r\n        They chase their tails in playful mirth,\r\n        Their barks a symphony of love and merriment,\r\n        Echoing through the quiet moments we've spent.\r\n\r\n        **Nose to ground**, they follow scents,\r\n        Unraveling mysteries with fervent intent,\r\n        From squirrel trails to forgotten dreams,\r\n        They lead us to places we've never seen.\r\n\r\n        **Golden retrievers** with hearts of gold,\r\n        **Dachshunds** with determination untold,\r\n        **Greyhounds** racing against the wind,\r\n        Each breed a chapter in the story they've pinned.\r\n\r\n        **Labradors** dive into lakes with glee,\r\n        **Chihuahuas** strut like tiny royalty,\r\n        **Huskies** howl at the moon's silver glow,\r\n        And **puppies**, oh sweet puppies, steal the show.\r\n\r\n        Their eyes speak of trust, unwavering and true,\r\n        Their fur holds secrets whispered by the dew,\r\n        In their presence, worries seem to fade,\r\n        As they teach us the art of living unafraid.\r\n\r\n        So here's to the dogs, our steadfast friends,\r\n        Who mend our hearts and heal life's bends,\r\n        May their tails forever wag, their noses explore,\r\n        For in their love, we find solace evermore.\r\n        \"\"\";\r\n}\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7012","RelatedDescription":"Closed or merged PR \"First round of perf improvements for tiktoken\" (#7012)"},{"Id":"2141079387","IsPullRequest":false,"CreatedAt":"2024-02-18T16:38:11","Actor":"amitchaudhary","Number":"7014","RawContent":null,"Title":"Add metrices calculation for model performance review.  ","State":"open","Body":"Especially, the key metrices like -\r\n1) Mean Absolute Error (MAE)\r\n2) Mean Squared Error (MSE)\r\n3) Root Mean Squared Error (RMSE) etc. ","Url":"https://github.com/dotnet/machinelearning/issues/7014","RelatedDescription":"Open issue \"Add metrices calculation for model performance review.  \" (#7014)"}],"ResultType":"GitHubIssue"}},"RunOn":"2024-02-29T03:30:17.5767236Z","RunDurationInMilliseconds":404}