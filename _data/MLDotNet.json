{"Data":{"GitHub":{"Issues":[{"Id":"3455354145","IsPullRequest":true,"CreatedAt":"2025-09-26T01:24:01","Actor":"tarekgh","Number":"7511","RawContent":null,"Title":"Mark internal classes as internal","State":"closed","Body":"We unintentionally marked two internal classes as public. The change is to mark them back as internal. ","Url":"https://github.com/dotnet/machinelearning/pull/7511","RelatedDescription":"Closed or merged PR \"Mark internal classes as internal\" (#7511)"},{"Id":"3403171990","IsPullRequest":true,"CreatedAt":"2025-09-18T07:21:00","Actor":"asp2286","Number":"7501","RawContent":null,"Title":"CI(macOS x64): install libomp from Homebrew Core (drop local libomp.rb)","State":"closed","Body":"# Fix macOS x64 CI: install `libomp` via Homebrew tap (no local formula)\r\n\r\n**Branch:** `fix-macos-libomp`  \r\n**Scope:** CI only – changes limited to `build/ci/job-template.yml` (macOS x64 job)\r\n\r\n---\r\n\r\n## What & Why\r\n\r\nOn **macOS x64** jobs, our pipeline tries to install OpenMP via a *local* Homebrew formula:\r\n\r\n```bash\r\nbrew install $(Build.SourcesDirectory)/build/libomp.rb --build-from-source --formula\r\n```\r\n\r\nRecent Homebrew (4.6+) rejects local, untapped formulae and fails with:\r\n\r\n```\r\nHomebrew requires formulae to be in a tap, rejecting:\r\n  /Users/runner/work/1/s/build/libomp.rb\r\nTo create a tap, run e.g. brew tap-new <user|org>/<repository>\r\n```\r\n\r\nThis does **not** affect `macOS_cross_arm64` jobs because they already use the official `homebrew/core` formula (`brew install libomp`).\r\n\r\n### The fix\r\n\r\nFor **macOS x64** only, switch to the official tap-hosted formula and force a link so the headers and libs are discoverable by our native builds:\r\n\r\n```yaml\r\n# Before (failing; local .rb file)\r\nexport HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK=TRUE && brew install $(Build.SourcesDirectory)/build/libomp.rb --build-from-source --formula\r\n\r\n# After (working; official tap)\r\nbrew update && brew install libomp && brew link libomp --force\r\n```\r\n\r\nNo product/code changes; **CI infra-only**.\r\n\r\n---\r\n\r\n## Validation\r\n\r\n- ✅ Verified the failing step is isolated to `macOS_x64` with the error above.\r\n- ✅ `macOS_cross_arm64` continues to use the official tap and succeeds.\r\n- ✅ Local repro on a GitHub-hosted macOS runner using the new commands installs `libomp` and exposes headers (`/usr/local/opt/libomp/include`) and libs (`/usr/local/opt/libomp/lib`).\r\n\r\n> Note: Homebrew marks `libomp` as *keg-only*. The `brew link ... --force` step ensures the toolchain sees it without extra flags. If we ever want to avoid `--force`, we can export:\r\n>\r\n> ```bash\r\n> export CPPFLAGS=\"-I/usr/local/opt/libomp/include\"\r\n> export LDFLAGS=\"-L/usr/local/opt/libomp/lib\"\r\n> ```\r\n\r\n---\r\n\r\n## Risk & Impact\r\n\r\n- **Risk:** Low. The change only affects the CI macOS x64 dependency-install step.\r\n- **Impact:** Unblocks native builds on macOS x64 by ensuring OpenMP is available.\r\n- **No Changes** to shipping packages, versioning, public APIs, or runtime behavior.\r\n\r\n---\r\n\r\n## Alternative considered\r\n\r\n- Creating and maintaining a custom Homebrew tap for `libomp.rb`. Rejected to avoid long‑term maintenance overhead when the official formula suffices.\r\n\r\n---\r\n\r\n## Change summary\r\n\r\n- Update `build/ci/job-template.yml` macOS x64 path:\r\n  - Replace local formula install with `brew update && brew install libomp && brew link libomp --force`.\r\n  - **No changes** to the ARM cross path (already uses official tap).\r\n\r\n---\r\n\r\n## How to verify in CI\r\n\r\n1. Queue the pipeline for `macOS_x64 Debug_Build`.\r\n2. Confirm the step **Install MacOS build dependencies** succeeds, showing:\r\n   - *“Pouring libomp…”, “Linking … 6 symlinks created”*\r\n3. Validate native build succeeds (CpuMathNative, FastTreeNative, etc.).\r\n4. Ensure no downstream targets rely on `OneDalNative` on macOS unless explicitly provided (unrelated to this PR).\r\n\r\n---\r\n\r\n## Notes for maintainers\r\n\r\n- This PR **does not** modify any source under `src/` or packaging. It is safe to service‑merge.\r\n- If future runners transition to Apple Silicon-only, this step remains valid (Homebrew tap still provides `libomp`).\r\n\r\n---\r\n\r\n## Checklist (author)\r\n\r\n- [x] CI-only change; no product code.\r\n- [x] macOS x64 path updated; ARM path unchanged.\r\n- [x] Verified the new commands succeed on a runner.\r\n- [x] Added rationale & reproduction details in this PR description.\r\n\r\n<!--\r\nMaintainer checklist (adapted from Reviewer_Checklist.md). Keep collapsed in the PR body.\r\n\r\n- [ ] CI is green on all required legs.\r\n- [ ] Affected area scoped to CI; no shipping assets changed.\r\n- [ ] No public API changes; no breaking changes.\r\n- [ ] Build/install steps use supported, tap-hosted Homebrew formulae (no local .rb files).\r\n- [ ] Windows/Linux pipelines unaffected.\r\n- [ ] No additional credentials, secrets, or taps required.\r\n- [ ] If later backported, the YAML path exists in the target branch.\r\n- [ ] PR title and labels reflect “infra/CI” nature.\r\n-->\r\n\r\n---\r\n\r\n### Screenshots / logs (for context)\r\n\r\n**Failure (before):**\r\n```\r\nError: Homebrew requires formulae to be in a tap, rejecting:\r\n  /Users/runner/work/1/s/build/libomp.rb\r\n```\r\n\r\n**Success (after):**\r\n```\r\n==> Fetching downloads for: libomp\r\n==> Pouring libomp--<version>.ventura.bottle.tar.gz\r\nLinking /usr/local/Cellar/libomp/<version>... 6 symlinks created.\r\n```\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7501","RelatedDescription":"Closed or merged PR \"CI(macOS x64): install libomp from Homebrew Core (drop local libomp.rb)\" (#7501)"},{"Id":"3401672315","IsPullRequest":true,"CreatedAt":"2025-09-18T07:20:27","Actor":"asp2286","Number":"7500","RawContent":null,"Title":"macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)","State":"closed","Body":"# macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)\r\n\r\n**Problem**\r\nOn macOS x64, building `src/Native` fails with:\r\n```\r\nfatal error: 'daal.h' file not found\r\n```\r\nThe oneDAL “devel” (headers) package is not available via NuGet for `osx-x64`, so locally `ONEDAL_DEVEL_PATH` is not present and `OneDalNative` cannot compile. Today the native CMake unconditionally includes `OneDalNative` on x64, which makes a default macOS developer build fail.\r\n\r\n**What this PR changes**\r\n- Gate `add_subdirectory(OneDalNative)` behind explicit configuration:\r\n  - Only include `OneDalNative` when both `ONEDAL_DEVEL_PATH` and `ONEDAL_REDIST_PATH` are defined **and** `${ONEDAL_DEVEL_PATH}/include/daal.h` exists.\r\n  - Otherwise, print an informative `message(STATUS ...)` and skip `OneDalNative`.\r\n\r\n**Why this is safe**\r\n- Windows/Linux CI builds that pass `ONEDAL_*` continue to build `OneDalNative` unchanged.\r\n- macOS builds (where oneDAL headers aren’t available via NuGet by default) no longer fail—they build the rest of the native components and skip `OneDalNative`.\r\n- No changes to `build.sh` are required. The script already sets `-DONEDAL_*` only when callers pass the corresponding command-line switches.\r\n\r\n**Repro (before)**\r\n```\r\n# macOS x64 without oneDAL headers\r\ncmake ... && make\r\n# -> OneDalNative/OneDalAlgorithms.cpp: fatal error: 'daal.h' file not found\r\n```\r\n\r\n**Behavior (after)**\r\n- If `ONEDAL_*` not provided: CMake prints `Skipping OneDalNative: ONEDAL_DEVEL_PATH/ONEDAL_REDIST_PATH not set` and the rest builds fine.\r\n- If `ONEDAL_*` provided and `${ONEDAL_DEVEL_PATH}/include/daal.h` exists: `OneDalNative` builds as before.\r\n\r\n**Test matrix**\r\n- ✅ macOS x64 (Intel): builds successfully; `OneDalNative` skipped by default; other native targets build.\r\n- ✅ macOS arm64 (Apple Silicon): previously didn’t include `OneDalNative` (arch guard); behavior unchanged.\r\n- ✅ Linux/Windows (CI): when `ONEDAL_*` are set (as in existing pipelines), behavior unchanged and `OneDalNative` builds.\r\n\r\n**Notes**\r\n- This PR intentionally doesn’t alter OpenMP handling or `SymSgdNative`. On macOS x64, developers who need `SymSgdNative` can use Homebrew LLVM (`brew install llvm libomp`) or provide appropriate OpenMP flags; that is orthogonal to oneDAL headers availability.\r\n- We can later add an explicit `-DMLNET_BUILD_ONEDAL=ON/OFF` flag for stricter control if maintainers prefer.","Url":"https://github.com/dotnet/machinelearning/pull/7500","RelatedDescription":"Closed or merged PR \"macOS: Only build OneDalNative when oneDAL headers & libs are configured (fixes macOS x64 build)\" (#7500)"},{"Id":"3384268007","IsPullRequest":true,"CreatedAt":"2025-09-18T07:20:04","Actor":"asp2286","Number":"7497","RawContent":null,"Title":"Add experimental IsolationForest trainer for ML.NET","State":"closed","Body":"## Related issues\r\nFixes #3043\r\n\r\n# Add Isolation Forest Anomaly Detection Trainer (Experimental)\r\n\r\nThis PR adds an **Isolation Forest** anomaly detection trainer for ML.NET.  \r\nIsolation Forest (Liu, Ting, Zhou, 2008) is a tree-ensemble algorithm for unsupervised anomaly detection that isolates outliers via random partitioning. It complements existing ML.NET anomaly detectors (e.g., SR-CNN, IID) with a density-agnostic approach.\r\n\r\n---\r\n\r\n## Motivation\r\n- Provide a widely-used, general-purpose anomaly detection method.  \r\n- Works without strong distribution assumptions.  \r\n- Produces both a continuous anomaly score and a binary label.  \r\n- Achieves parity with popular libraries like scikit-learn.\r\n\r\n---\r\n\r\n## Design (v1, Experimental)\r\n- **Core engine**: `IsolationForestModel` (pure C#) implements random partitioning trees, scoring, and SHAP-like path contributions.  \r\n- **Pipeline integration**: `IsolationForestTrainer : IEstimator<ITransformer>` appends:\r\n  - `Score` (float, scaled 0–100; higher = more anomalous),\r\n  - `PredictedLabel` (bool), thresholded by `Contamination` or explicit override.  \r\n- **Options**:\r\n  - `Trees`\r\n  - `SampleSize (psi)`\r\n  - `Seed`\r\n  - `Contamination`\r\n  - `ParallelBuild`\r\n  - `ThresholdOverride`\r\n\r\n> ⚠️ **Experimental note**: v1 uses `CustomMapping` internally. Models trained with this trainer cannot currently be persisted with `mlContext.Model.Save()`. A follow-up will introduce a proper `IsolationForestTransformer` with save/load and efficient row-mapping.\r\n\r\n---\r\n\r\n## Usage\r\n```csharp\r\nvar pipeline = ml.Transforms.Concatenate(\"Features\", \"X1\", \"X2\")\r\n    .Append(new IsolationForestTrainer(new IsolationForestTrainer.Options\r\n    {\r\n        Trees = 200,\r\n        SampleSize = 256,\r\n        Contamination = 0.02\r\n    }));\r\n\r\nvar model = pipeline.Fit(data);\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7497","RelatedDescription":"Closed or merged PR \"Add experimental IsolationForest trainer for ML.NET\" (#7497)"},{"Id":"3429005106","IsPullRequest":true,"CreatedAt":"2025-09-18T07:17:08","Actor":"asp2286","Number":"7510","RawContent":null,"Title":"macOS x64 CI: fix dependency install and OpenMP runtime copy (use Homebrew libomp, adjust Helix payload)","State":"open","Body":"# PR: macOS x64 CI: fix dependency install and OpenMP runtime copy\r\n\r\n### Summary\r\nThis PR fixes **MachineLearning-CI** failures on **macOS x64** where jobs stop at *Install MacOS build dependencies* with:\r\n\r\n```\r\nBash exited with code '1'\r\n```\r\n\r\nThe breakage comes from two areas:\r\n1. **Dependency install**: The pipeline relied on a custom `libomp.rb` path that no longer works on hosted macOS images.\r\n2. **Helix payload**: The script attempted to copy both `libomp.dylib` and `libiomp5.dylib`, but `libiomp5.dylib` is not available when installing `libomp` from Homebrew core.\r\n\r\n**Fixes #7509**\r\n\r\n---\r\n\r\n### Changes\r\n#### `build/ci/job-template.yml`\r\n- Replace custom `brew install …/build/libomp.rb` with standard Homebrew:\r\n  ```bash\r\n  brew update\r\n  brew install -f --overwrite python@3.13\r\n  brew install libomp\r\n  brew link libomp --force\r\n  ```\r\n- Note added: Homebrew ≥4.6 rejects installing formulae from raw paths.\r\n\r\n#### `eng/helix.proj`\r\n- macOS **x64 only**:\r\n  - Set `DYLD_LIBRARY_PATH` so Helix can find `libomp.dylib`.\r\n  - Copy only `/usr/local/opt/libomp/lib/libomp.dylib` into the publish folder.\r\n  - Remove copying of `libiomp5.dylib` (not present with `libomp` from Homebrew).\r\n  - Add install-name fix so binaries reference `@loader_path/libomp.dylib`.\r\n\r\n---\r\n\r\n### Why\r\n- Hosted macOS runners changed: raw formula paths are blocked, and only `libomp` is available via core.\r\n- Ensures reliable dependency install and payload runtime linking.\r\n- Other platforms (Linux, Windows, macOS arm64) are unaffected.\r\n\r\n---\r\n\r\n### Testing\r\n- Reproduced failure on `osx.13.amd64.open` queue.\r\n- With these changes:\r\n  - Dependency install step completes successfully.\r\n  - `libomp.dylib` is present in publish folder.\r\n  - Helix payload runs with `DYLD_LIBRARY_PATH` set correctly.\r\n- Validated in a test run: both macOS x64 Debug/Release proceed past dependency install and build succeeds.\r\n\r\n---\r\n\r\n### Risk / Impact\r\n- **Low**: scoped only to macOS x64 build dependencies and Helix payload.\r\n- No product code changes, only CI infra adjustments.\r\n\r\n---\r\n\r\n### Additional Notes\r\n- Linux and Windows jobs were already green.\r\n- If maintainers prefer `llvm` over `libomp` as the OpenMP provider, happy to adjust.\r\n\r\n---\r\n\r\n### PR Checklist\r\n- [x] **CLA signed**\r\n- [x] **Tests**: N/A (CI infra only)\r\n- [x] **Docs**: N/A (no public-facing change)\r\n- [x] **Breaking change**: No\r\n- [x] **Linked issue**: #7509\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7510","RelatedDescription":"Open PR \"macOS x64 CI: fix dependency install and OpenMP runtime copy (use Homebrew libomp, adjust Helix payload)\" (#7510)"},{"Id":"3428821552","IsPullRequest":false,"CreatedAt":"2025-09-18T06:18:37","Actor":"asp2286","Number":"7509","RawContent":null,"Title":"MacOS_x64 Debug/Release build jobs fail in MachineLearning-CI: “Bash exited with code '1' – Install MacOS build dependencies”","State":"open","Body":" - OS & Version: macOS hosted agents (Azure Pipelines), osx.13 (macOS 13.x), x64 only\n - ML.NET Version: current main (MachineLearning-CI)\n - .NET Version: per repo global.json (targets .NET 8)\n\nIn the MachineLearning-CI pipeline, only the macOS x64 jobs fail at the Install MacOS build dependencies step with:\nBash exited with code '1'\n\nSteps to reproduce the behavior:\n1. Azure DevOps → Pipelines → MachineLearning-CI.\n2. Queue on main with defaults.\n3. Observe MacOS_x64 Debug_Build and MacOS_x64 Release_Build.\n4. See error\n\nExpected behavior\nmacOS x64 Debug/Release should install dependencies and proceed to build/tests like other jobs.\n\nScreenshots\n<img width=\"1709\" height=\"1029\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/bc1c9f24-56b5-4f0b-a79b-3d64ce81e38b\" />\n\nAdditional context\nLikely macOS dependency bootstrap issue, possibly due to:\nHomebrew formula drift (OpenMP): libomp standalone formula may be missing/renamed on current images","Url":"https://github.com/dotnet/machinelearning/issues/7509","RelatedDescription":"Open issue \"MacOS_x64 Debug/Release build jobs fail in MachineLearning-CI: “Bash exited with code '1' – Install MacOS build dependencies”\" (#7509)"},{"Id":"3420510489","IsPullRequest":false,"CreatedAt":"2025-09-16T05:41:10","Actor":"williamlzw","Number":"7508","RawContent":null,"Title":"Hope to simplify torchsharp's Tokenizer to facilitate expansion","State":"open","Body":"https://github.com/dotnet/machinelearning/issues/7507","Url":"https://github.com/dotnet/machinelearning/issues/7508","RelatedDescription":"Open issue \"Hope to simplify torchsharp's Tokenizer to facilitate expansion\" (#7508)"},{"Id":"3420501783","IsPullRequest":false,"CreatedAt":"2025-09-16T05:38:37","Actor":"williamlzw","Number":"7507","RawContent":null,"Title":"vocab.json of qwen3 model cannot be loaded into Tokenizer","State":"open","Body":"The vocab.json of the qwen3 model does not contain \"added_tokens\" and cannot be loaded into the Tokenizer.\n\n<img width=\"420\" height=\"647\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/938bce80-4d52-46dd-bd90-39ab82a59095\" />","Url":"https://github.com/dotnet/machinelearning/issues/7507","RelatedDescription":"Open issue \"vocab.json of qwen3 model cannot be loaded into Tokenizer\" (#7507)"},{"Id":"3420170018","IsPullRequest":false,"CreatedAt":"2025-09-16T03:18:53","Actor":"williamlzw","Number":"7506","RawContent":null,"Title":"It's recommended that base classes use fewer internal methods.","State":"open","Body":"It's recommended that base classes use fewer internal methods. I need to write a Qwen3Tokenizer class based on the CodeGenTokenizer class. I've noticed that many methods are internal. I'm forced to define a CodeGenTokenizerA class to write the Qwen3Tokenizer class.","Url":"https://github.com/dotnet/machinelearning/issues/7506","RelatedDescription":"Open issue \"It's recommended that base classes use fewer internal methods.\" (#7506)"},{"Id":"3420060036","IsPullRequest":false,"CreatedAt":"2025-09-16T02:09:14","Actor":"williamlzw","Number":"7505","RawContent":null,"Title":"The ph3 model decodes Chinese characters and displays garbled characters.","State":"open","Body":"<img width=\"434\" height=\"112\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2baa0814-0334-42a4-99f0-8b96fe53da14\" />\n\n```\nusing Microsoft.ML.Tokenizers;\nusing Microsoft.ML.GenAI.Phi;\nusing Microsoft.ML.GenAI.Core;\nusing Microsoft.Extensions.AI;\n\n\npublic class Program\n{\n    public async static void TestPhi3()\n    {\n        string device = \"cuda\";\n        var weightFolder = @\"G:\\model\\Phi-3-mini-128k-instruct\";\n        var model = Phi3ForCausalLM.FromPretrained(weightFolder, \"config.json\", layersOnTargetDevice: -1, quantizeToInt4: true, targetDevice: device);\n        var modelPath = Path.Join(weightFolder, \"tokenizer.model\");\n        var tokenizer = Phi3TokenizerHelper.FromPretrained(modelPath);\n        var pipeline = new CausalLMPipeline<Tokenizer, Phi3ForCausalLM>(tokenizer, model, device);\n        var client = new Phi3CausalLMChatClient(pipeline);\n        var task = \"\"\"\n            你能讲一个有趣的笑话吗?\n            \"\"\";\n        List<ChatMessage> _chatHistory = new();\n        _chatHistory.Add(new ChatMessage(ChatRole.System, \"你是一个助手,用中文回答用户的问题\"));\n        _chatHistory.Add(new ChatMessage(ChatRole.User, task));\n        var options = new ChatOptions\n        {\n            StopSequences = [\"<|end_of_text|>\"],//phi3\n            AdditionalProperties = new() { { \"max_length\", 2048 } },\n        };\n        await foreach (var response in client.GetStreamingResponseAsync(_chatHistory, options))\n        {\n            Console.Write(response.Text);\n        }\n\n        Console.WriteLine();\n        Console.WriteLine(\"End!\");\n    }\n\n    public static void Main()\n    {\n        TestPhi3();\n    }\n}\n```\n\n<img width=\"477\" height=\"125\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/f53c2e65-8c32-4e91-8010-f567baa66bef\" />","Url":"https://github.com/dotnet/machinelearning/issues/7505","RelatedDescription":"Open issue \"The ph3 model decodes Chinese characters and displays garbled characters.\" (#7505)"},{"Id":"3414003004","IsPullRequest":true,"CreatedAt":"2025-09-13T18:59:53","Actor":"Copilot","Number":"7504","RawContent":null,"Title":"Initialize es-metadata.yml for inventory","State":"open","Body":"This PR adds the required `es-metadata.yml` file to the root of the repository to initialize inventory metadata. The file contains the necessary configuration for service ownership and routing information as specified in the issue.\n\nThe file includes:\n- Schema version 0.0.1\n- Production flag set to false\n- Accountable owners service GUID for proper service ownership tracking\n- Default routing configuration for the DevDiv\\.NET Libraries area path\n\nThis metadata file will enable proper inventory tracking and management for the repository.\n\nFixes #7503.\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\n✨ Let Copilot coding agent [set things up for you](https://github.com/dotnet/machinelearning/issues/new?title=✨+Set+up+Copilot+instructions&body=Configure%20instructions%20for%20this%20repository%20as%20documented%20in%20%5BBest%20practices%20for%20Copilot%20coding%20agent%20in%20your%20repository%5D%28https://gh.io/copilot-coding-agent-tips%29%2E%0A%0A%3COnboard%20this%20repo%3E&assignees=copilot) — coding agent works faster and does higher quality work when set up for your repo.\n","Url":"https://github.com/dotnet/machinelearning/pull/7504","RelatedDescription":"Open PR \"Initialize es-metadata.yml for inventory\" (#7504)"},{"Id":"3413997722","IsPullRequest":false,"CreatedAt":"2025-09-13T18:54:19","Actor":"artl93","Number":"7503","RawContent":null,"Title":"Initialize es-metadata.yml for inventory","State":"open","Body":"Please add a file named `es-metadata.yml` to the root of this repository with the following contents:\n\n```\nschemaVersion: 0.0.1\nisProduction: false\naccountableOwners:\n  service: 7a9b52f6-7805-416c-9390-343168c0cdb3\nrouting:\n  defaultAreaPath:\n    org: devdiv\n    path: DevDiv\\NET Libraries\n```\n\nThis file will help initialize inventory metadata for the repository.","Url":"https://github.com/dotnet/machinelearning/issues/7503","RelatedDescription":"Open issue \"Initialize es-metadata.yml for inventory\" (#7503)"},{"Id":"3413291798","IsPullRequest":false,"CreatedAt":"2025-09-13T11:55:48","Actor":"asp2286","Number":"7502","RawContent":null,"Title":"Proposal: Pluggable RNG in MLContext (enable deterministic, portable RNGs like MT19937)","State":"open","Body":"## Summary\n\nI propose adding a minimal extension point to let users inject a custom RNG into `MLContext`, without changing defaults or breaking back-compat. This enables deterministic, portable randomness across platforms and languages (e.g., align with C++ `std::mt19937`), and allows advanced users to choose an RNG that matches their reproducibility requirements.\n\n## Motivation\n\n- **Reproducibility across ecosystems**: Many data science stacks standardize on MT19937 (e.g., C++ `std::mt19937`, NumPy’s legacy PCG/MT usage), making it easier to compare experiments when the same PRNG is available in ML.NET.\n- **Zero impact by default**: Default behavior remains unchanged and backwards compatible.\n- **Testability**: Easier to write bitwise-stable tests that don’t depend on underlying `System.Random` variations.\n\n## Design\n\nAdd a small interface and an optional parameter to `MLContext`:\n\n```csharp\npublic interface IRandomSource\n{\n    int Next();\n    int Next(int maxValue);\n    int Next(int minValue, int maxValue);\n    long NextInt64();\n    long NextInt64(long maxValue);\n    long NextInt64(long minValue, long maxValue);\n    double NextDouble();\n    float NextSingle();\n    void NextBytes(Span<byte> buffer);\n}\n\n// Existing constructor remains\npublic sealed class MLContext\n{\n    public MLContext(int? seed = null) : this(seed, rng: null) { }\n\n    public MLContext(int? seed, IRandomSource? rng)\n    {\n        _rng = rng ?? new RandomSourceAdapter(seed is null ? Random.Shared : new Random(seed.Value));\n        // ... existing initialization\n    }\n\n    internal IRandomSource RandomSource => _rng;\n    private readonly IRandomSource _rng;\n}\n\ninternal sealed class RandomSourceAdapter : IRandomSource\n{\n    private readonly Random _rand;\n    public RandomSourceAdapter(Random rand) => _rand = rand;\n    public int Next() => _rand.Next();\n    public int Next(int maxValue) => _rand.Next(maxValue);\n    public int Next(int minValue, int maxValue) => _rand.Next(minValue, maxValue);\n    public long NextInt64() => _rand.NextInt64();\n    public long NextInt64(long maxValue) => _rand.NextInt64(maxValue);\n    public long NextInt64(long minValue, long maxValue) => _rand.NextInt64(minValue, maxValue);\n    public double NextDouble() => _rand.NextDouble();\n    public float NextSingle() => _rand.NextSingle();\n    public void NextBytes(Span<byte> buffer) => _rand.NextBytes(buffer);\n}\n","Url":"https://github.com/dotnet/machinelearning/issues/7502","RelatedDescription":"Open issue \"Proposal: Pluggable RNG in MLContext (enable deterministic, portable RNGs like MT19937)\" (#7502)"},{"Id":"3396447200","IsPullRequest":true,"CreatedAt":"2025-09-09T03:41:34","Actor":"JoshuaSloan","Number":"7499","RawContent":null,"Title":"Added NumberOfLeaves to FastForestRegression and FastForestOva options","State":"open","Body":"`Fixes #7498`\r\n\r\nThe NumberOfLeaves hyperparameter was not updating in FastForest AutoML experiments for regression and multiclass classification tasks (see regression example in the associated [issue](https://github.com/dotnet/machinelearning/issues/7498), which was trained on the California Housing [dataset](https://www.kaggle.com/datasets/camnugent/california-housing-prices) and optimizing for root mean squared error).\r\n\r\nConsequently, the trial parameters reported via an experiment monitor's final ReportBestTrial() method were not aligning with the actual model produced by the experiment. Additionally, model performance was hurt due to the static hyperparameter constraint.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7499","RelatedDescription":"Open PR \"Added NumberOfLeaves to FastForestRegression and FastForestOva options\" (#7499)"},{"Id":"3396378196","IsPullRequest":false,"CreatedAt":"2025-09-09T03:07:34","Actor":"JoshuaSloan","Number":"7498","RawContent":null,"Title":"FastForest NumberOfLeaves hyperparameter not updating in Regression/MulticlassClassification SweepablePipeline","State":"open","Body":"**System Information (please complete the following information):**\n - OS & Version: Windows 11\n - ML.NET Version: ML.NET v4.0.2\n - .NET Version: .NET 9.0\n\n**Describe the bug**\nFastForestRegression and FastForestOva (unlike FastForestBinary) do not modify the NumberOfLeaves hyperparameter despite being defined in the associated [search space](https://github.com/dotnet/machinelearning/blob/fb39755f143b1a2969f20b0597e58083dc306e5a/src/Microsoft.ML.AutoML/CodeGen/fast_forest_search_space.json?plain=1#L16). Consequently, while performance for BinaryClassification is on par with comparable AutoML frameworks (e.g. [FLAML](https://github.com/microsoft/FLAML) using exclusively RandomForest), it falls behind for the other task types.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. Train an AutoML experiment using a SweepablePipeline for either Regression or MulticlassClassification\n2. Set all non-FastForest trainers to false (such that only FastForest remains)\n3. Append an experiment monitor and log the TrialResult.TrialSettings.Parameters\n4. Compare the best model to the reported parameters\n\n**Expected behavior**\nI would expect the model hyperparameters logged from the experiment monitor's final ReportBestTrial() method to match the best model obtained from the experiment. However, while other model hyperparameters are in alignment, the NumberOfLeaves looks suspiciously like the [default](https://github.com/dotnet/machinelearning/blob/fb39755f143b1a2969f20b0597e58083dc306e5a/src/Microsoft.ML.FastTree/FastTreeArguments.cs?plain=1#L340) FastTree value. \n\n**Screenshots, Code, Sample Projects**\n*Trial 31 obtained new best model with (loss: 63689.36950302901, metric: 63689.36950302901)\n{\"_pipeline_\":{\"_SCHEMA_\":\"e0 * e2 * e3 * e4\",\"e0\":{\"OutputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"],\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]},\"e2\":{\"OutputColumnNames\":[\"ocean_proximity\"],\"InputColumnNames\":[\"ocean_proximity\"]},\"e3\":{\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"ocean_proximity\"],\"OutputColumnName\":\"Features\"},\"e4\":{<mark>\"NumberOfTrees\":15,\"NumberOfLeaves\":81</mark>,\"FeatureFraction\":0.8326445,\"LabelColumnName\":\"median_house_value\",\"FeatureColumnName\":\"Features\"}},\"_SCHEMA_\":\"e0 * e1 * e3 * e4\",\"e0\":{\"OutputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"],\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\"]},\"e1\":{\"OutputColumnNames\":[\"ocean_proximity\"],\"InputColumnNames\":[\"ocean_proximity\"]},\"e2\":{\"OutputColumnNames\":[\"ocean_proximity\"],\"InputColumnNames\":[\"ocean_proximity\"]},\"e3\":{\"InputColumnNames\":[\"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"ocean_proximity\"],\"OutputColumnName\":\"Features\"},\"e4\":{\"NumberOfTrees\":100,\"NumberOfLeaves\":100,\"FeatureFraction\":1,\"LabelColumnName\":\"median_house_value\",\"FeatureColumnName\":\"Features\"}}*\n\n<img width=\"1696\" height=\"894\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2547b614-ddfd-47af-9481-c2c18fc13e52\" />\n","Url":"https://github.com/dotnet/machinelearning/issues/7498","RelatedDescription":"Open issue \"FastForest NumberOfLeaves hyperparameter not updating in Regression/MulticlassClassification SweepablePipeline\" (#7498)"},{"Id":"3328117397","IsPullRequest":true,"CreatedAt":"2025-08-17T08:31:30","Actor":"KM5075","Number":"7496","RawContent":null,"Title":"Fix minor typo in BinFinder.cs","State":"open","Body":"Fix a minor typo in a comment within BinFinder.cs. No functional changes.","Url":"https://github.com/dotnet/machinelearning/pull/7496","RelatedDescription":"Open PR \"Fix minor typo in BinFinder.cs\" (#7496)"},{"Id":"3320905110","IsPullRequest":false,"CreatedAt":"2025-08-14T07:58:05","Actor":"games","Number":"7495","RawContent":null,"Title":"Microsoft.ML.LightGbm not supported on Mac M1 – 'lib_lightgbm' (no such file)","State":"closed","Body":"**System Information (please complete the following information):**\n - OS & Version: macOS 15.6\n - ML.NET Version: ML.NET v4.0.2\n - .NET Version: .NET 9.0\n\n**Describe the bug**\nWhen attempting to use Microsoft.ML.LightGbm on an Apple Silicon Mac (M1), the package fails to load due to a missing native library dependency. The error message is:\n\nUnhandled exception. System.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. dotnet new console\n2. add packages \n4. copy the sample code from here (https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.lightgbmextensions.lightgbm?view=ml-dotnet-preview)\n5. dotnet run\n6. see error: unhandled exception. System.DllNotFoundException: Unable to load shared library 'lib_lightgbm' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable:\n\n**Expected behavior**\nLightGBM should run on Mac M1\n\n**Screenshots, Code, Sample Projects**\npackages version\n```xml\n    <PackageReference Include=\"Microsoft.ML\" Version=\"4.0.2\" />\n    <PackageReference Include=\"Microsoft.ML.LightGbm\" Version=\"4.0.2\" />\n```\n\n**Additional context**\n\nlib_lightgbm.dylib is missing in `osx-arm64`\n\n<img width=\"736\" height=\"742\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/0c890d9d-256c-4b66-8451-25558d01e35e\" />\n","Url":"https://github.com/dotnet/machinelearning/issues/7495","RelatedDescription":"Closed issue \"Microsoft.ML.LightGbm not supported on Mac M1 – 'lib_lightgbm' (no such file)\" (#7495)"},{"Id":"3298376543","IsPullRequest":false,"CreatedAt":"2025-08-11T15:17:21","Actor":"stephentoub","Number":"7491","RawContent":null,"Title":"Incorporate new harmony tiktoken vocabulary","State":"closed","Body":"The recently released OSS openai models come with a new vocabulary. The TiktokenTokenizer should be updated accordingly.\n\nhttps://github.com/openai/tiktoken/commit/3591ff175d6a80efbe4fcc7f0e219ddd4b8c52f1\n\ncc: @tarekgh","Url":"https://github.com/dotnet/machinelearning/issues/7491","RelatedDescription":"Closed issue \"Incorporate new harmony tiktoken vocabulary\" (#7491)"},{"Id":"3307004234","IsPullRequest":true,"CreatedAt":"2025-08-11T15:17:20","Actor":"tarekgh","Number":"7494","RawContent":null,"Title":"Support OpenAI OSS Models with Tiktoken tokenizer","State":"closed","Body":"Fixes https://github.com/dotnet/machinelearning/issues/7491","Url":"https://github.com/dotnet/machinelearning/pull/7494","RelatedDescription":"Closed or merged PR \"Support OpenAI OSS Models with Tiktoken tokenizer\" (#7494)"},{"Id":"3301258241","IsPullRequest":true,"CreatedAt":"2025-08-07T17:02:50","Actor":"JoshuaSloan","Number":"7493","RawContent":null,"Title":"Fix PositiveRecall optimization in AutoMLExperiment","State":"open","Body":"BinaryClassificationMetric.PositiveRecall incorrectly returns PositivePrecision.\r\n\r\nI noticed this when testing an early stopping pipeline and found that the logged best trial metric did not align with the final model results. This is a self-evident fix (akin to a small typo), so I did not open a new issue for it.\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.","Url":"https://github.com/dotnet/machinelearning/pull/7493","RelatedDescription":"Open PR \"Fix PositiveRecall optimization in AutoMLExperiment\" (#7493)"},{"Id":"3299593152","IsPullRequest":false,"CreatedAt":"2025-08-07T08:45:15","Actor":"williamlzw","Number":"7492","RawContent":null,"Title":".NET BUG: Ġ' was wrongly split","State":"open","Body":"C# is incorrectly split, while python does not.\n```\nfrom transformers import AutoTokenizer\n\n#tokenizer_dir = 'D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX'\ntokenizer_dir = 'Qwen/Qwen3-Reranker-0.6B'\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_dir, padding_side=\"left\")\nprefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be '<|im_end|>\\n<|im_start|>user\\n\"\nsuffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\nprefix_tokens = tokenizer.encode(prefix, add_special_tokens=False)\nfor token in prefix_tokens:\n    print(token, tokenizer.decode(token))\n```\n\noutput:\n151644 <|im_start|>\n8948 system\n198\n\n60256 Judge\n3425  whether\n279  the\n11789  Document\n20027  meets\n279  the\n8502  requirements\n3118  based\n389  on\n279  the\n11361  Query\n323  and\n279  the\n758  In\n1235 struct\n3897  provided\n13 .\n7036  Note\n429  that\n279  the\n4226  answer\n646  can\n1172  only\n387  be\n364  '\n151645 <|im_end|>\n198\n\n151644 <|im_start|>\n872 user\n198\n\n=========================\n```\nusing Microsoft.ML.Tokenizers;\nusing System.Text.Json;\n\nclass program\n{\n    const string IMStart = \"<|im_start|>\";\n    const string IMEnd = \"<|im_end|>\";\n\n    public static void Main()\n    {\n        string text = $\"{IMEnd}\\n{IMStart}assistant\\n<think>\\n\\n</think>\\n\\n\";\n        string text1 = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be '<|im_end|>\\n<|im_start|>user\\n\";\n        text1 = text1.Replace(\" \", \"\\u0120\").Replace(\"\\n\", \"\\u010A\");\n        using Stream vocabStream = File.OpenRead(\"D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX\\\\vocab.json\");\n        using Stream mergesStream = File.OpenRead(\"D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX\\\\merges.txt\");\n        string configPath = \"D:\\\\model\\\\Qwen3-Reranker-0.6B-ONNX\\\\tokenizer_config.json\";\n        var specialTokens = LoadSpecialTokens(configPath);\n\n        var bpe = BpeTokenizer.Create(vocabStream, mergesStream, PreTokenizer.CreateWordOrNonWord(specialTokens), specialTokens:specialTokens);\n        var encoding = bpe.EncodeToTokens(text1, out _);\n        Console.WriteLine(\"\\nEncoded IDs:\");\n        foreach (var id in encoding)\n        {\n            Console.WriteLine($\"{id.Id} -> {id.Value.Replace(\"\\u010A\", \"\\n\").Replace(\"\\u0120\", \" \")}\");\n        }\n    }\n\n    private static Dictionary<string, int> LoadSpecialTokens(string configPath)\n    {\n        if (!File.Exists(configPath))\n        {\n            throw new FileNotFoundException($\"Config file not found: {configPath}\");\n        }\n\n        var json = File.ReadAllText(configPath);\n        using JsonDocument doc = JsonDocument.Parse(json);\n        JsonElement root = doc.RootElement;\n\n        // 创建特殊标记字典\n        var specialTokens = new Dictionary<string, int>();\n\n        // 1. 首先添加 additional_special_tokens\n        if (root.TryGetProperty(\"additional_special_tokens\", out JsonElement additionalTokens))\n        {\n            foreach (JsonElement token in additionalTokens.EnumerateArray())\n            {\n                string content = token.GetString();\n                if (!string.IsNullOrEmpty(content))\n                {\n                    // 查找在 added_tokens_decoder 中对应的 ID\n                    int? tokenId = FindTokenIdInDecoder(root, content);\n\n                    if (tokenId.HasValue)\n                    {\n                        // 使用 added_tokens_decoder 中的 ID\n                        specialTokens[content] = tokenId.Value;\n                    }\n                    else\n                    {\n                        // 分配新 ID（在原有最大ID基础上增加）\n                        int newId = specialTokens.Count > 0\n                            ? specialTokens.Values.Max() + 1\n                            : 1000000;\n                        specialTokens[content] = newId;\n                    }\n                }\n            }\n        }\n\n        // 2. 添加 added_tokens_decoder 中的其他标记（不在 additional_special_tokens 中的）\n        if (root.TryGetProperty(\"added_tokens_decoder\", out JsonElement addedTokens))\n        {\n            foreach (JsonProperty prop in addedTokens.EnumerateObject())\n            {\n                if (int.TryParse(prop.Name, out int tokenId))\n                {\n                    string content = prop.Value.GetProperty(\"content\").GetString();\n                    if (!string.IsNullOrEmpty(content)\n                        && !specialTokens.ContainsKey(content))\n                    {\n                        specialTokens[content] = tokenId;\n                    }\n                }\n            }\n        }\n\n        // 3. 确保关键标记存在\n        EnsureSpecialToken(specialTokens, \"<|endoftext|>\", 151643);\n        EnsureSpecialToken(specialTokens, \"<|im_start|>\", 151644);\n        EnsureSpecialToken(specialTokens, \"<|im_end|>\", 151645);\n\n        //Console.WriteLine(\"Loaded special tokens:\");\n        //foreach (var kvp in specialTokens)\n        //{\n        //    Console.WriteLine($\"{kvp.Value}: {kvp.Key}\");\n        //}\n\n        return specialTokens;\n    }\n\n    private static int? FindTokenIdInDecoder(JsonElement root, string tokenContent)\n    {\n        if (root.TryGetProperty(\"added_tokens_decoder\", out JsonElement addedTokens))\n        {\n            foreach (JsonProperty prop in addedTokens.EnumerateObject())\n            {\n                if (int.TryParse(prop.Name, out int tokenId))\n                {\n                    string content = prop.Value.GetProperty(\"content\").GetString();\n                    if (content == tokenContent)\n                    {\n                        return tokenId;\n                    }\n                }\n            }\n        }\n        return null;\n    }\n\n    private static void EnsureSpecialToken(Dictionary<string, int> specialTokens, string token, int defaultId)\n    {\n        if (!specialTokens.ContainsKey(token))\n        {\n            specialTokens[token] = defaultId;\n        }\n    }\n}\n```\noutput:\n151644 -> <|im_start|>\n8948 -> system\n198 ->\n\n60256 -> Judge\n3425 ->  whether\n279 ->  the\n11789 ->  Document\n20027 ->  meets\n279 ->  the\n8502 ->  requirements\n3118 ->  based\n389 ->  on\n279 ->  the\n11361 ->  Query\n323 ->  and\n279 ->  the\n758 ->  In\n1235 -> struct\n3897 ->  provided\n13 -> .\n7036 ->  Note\n429 ->  that\n279 ->  the\n4226 ->  answer\n646 ->  can\n1172 ->  only\n387 ->  be\n220 ->\n6 -> '\n151645 -> <|im_end|>\n198 ->\n\n151644 -> <|im_start|>\n872 -> user\n198 ->\n","Url":"https://github.com/dotnet/machinelearning/issues/7492","RelatedDescription":"Open issue \".NET BUG: Ġ' was wrongly split\" (#7492)"},{"Id":"3289292470","IsPullRequest":false,"CreatedAt":"2025-08-04T12:43:00","Actor":"krwq","Number":"7490","RawContent":null,"Title":"dotnet/machine learning should allow localizing exception messages","State":"open","Body":"Currently `dotnet/machine-learning` is using hard-coded exception messages. It should adopt resx files used in other `dotnet/*` repos and allow for their localization","Url":"https://github.com/dotnet/machinelearning/issues/7490","RelatedDescription":"Open issue \"dotnet/machine learning should allow localizing exception messages\" (#7490)"},{"Id":"3268488733","IsPullRequest":false,"CreatedAt":"2025-07-28T07:20:10","Actor":"SingleKey","Number":"7489","RawContent":null,"Title":"How to export ML.NET models for use in other programming languages?","State":"open","Body":"Description\nI'm looking for guidance on how to export ML.NET models for use in other programming languages. While I understand that ONNX format is one option, I've encountered some ML.NET models that don't support ONNX export.\n\nQuestion\nBesides ONNX export, what are the alternative approaches to make ML.NET models available for use in other programming languages? Are there any other standardized formats or methods that ML.NET supports for cross-language model deployment?\n\nAdditional Context\nI'm particularly interested in solutions that would work for models that currently don't have ONNX export capability, and I'd appreciate any documentation or examples that demonstrate these alternative approaches.\n\nThank you for your time and assistance!","Url":"https://github.com/dotnet/machinelearning/issues/7489","RelatedDescription":"Open issue \"How to export ML.NET models for use in other programming languages?\" (#7489)"},{"Id":"3226465258","IsPullRequest":false,"CreatedAt":"2025-07-13T12:24:59","Actor":"RehanSaeed","Number":"7488","RawContent":null,"Title":"New Text Classification Model on ARM Fails to Train","State":"open","Body":"**System Information (please complete the following information):**\n - OS & Version: Windows 11 for ARM on a Surface Laptop 7 \n - ML.NET Version: ML.NET Model Builder 2022 v17.19.2.2511501\n - .NET Version: v9\n\n**Describe the bug**\nWhen creating a new ML.NET Text Classification Model in Visual Studio. The wizard errors when trying to train the model.\n\n**To Reproduce**\nSteps to reproduce the behavior:\n1. File -> New Model on a blank .NET 9 project.\n2. Select Text Classification\n3. Enter a CSV file.\n4. Click on train\n\n**Expected behavior**\nI should be able to train the model. ARM is supposed to work.\n\n**Screenshots, Code, Sample Projects**\n\n<img width=\"2493\" height=\"1592\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/455235d7-10f8-42f0-9cff-739ca9ff9926\" />\n\n**Additional context**\n\nFull logs below:\n[MLModel1-67B6PD.txt](https://github.com/user-attachments/files/21204354/MLModel1-67B6PD.txt)","Url":"https://github.com/dotnet/machinelearning/issues/7488","RelatedDescription":"Open issue \"New Text Classification Model on ARM Fails to Train\" (#7488)"},{"Id":"3224085207","IsPullRequest":false,"CreatedAt":"2025-07-11T20:06:26","Actor":"fritzjoostenz","Number":"7487","RawContent":null,"Title":"Quo vadis for ml.net?","State":"open","Body":"My apologies in advance for logging my message here as an issue but I know of no other way to get in touch with the  Microsoft team dealing with ML.NET. I have picked ML.NET as a machine learning technology in my application but given that the last new releases and updates on important features and issues (such as #5895) seems to have stalled around two years ago (last blog post was in Nov 2023), I am wondering if this initiative has stalled and may be abandoned down the line? \nWould you please consider posting an update on the blog with an honest appraisal of the situation and whether new features will be forthcoming or not? There are many ML techniques such as KNN that can still be added. For me, the fact that you have to use predefined classes to make predictions is almost a show stopper.\nLooking forward to seeing an update on this excellent framework.","Url":"https://github.com/dotnet/machinelearning/issues/7487","RelatedDescription":"Open issue \"Quo vadis for ml.net?\" (#7487)"},{"Id":"3155822626","IsPullRequest":false,"CreatedAt":"2025-07-09T20:36:44","Actor":"williamlzw","Number":"7483","RawContent":null,"Title":"Naming error: c# Phi3ForCasualLM  ,   python Phi3ForCausalLM","State":"closed","Body":"Naming error: c# Phi3ForCasualLM  ,   python Phi3ForCausalLM\n\n`from transformers import  Phi3ForCausalLM`","Url":"https://github.com/dotnet/machinelearning/issues/7483","RelatedDescription":"Closed issue \"Naming error: c# Phi3ForCasualLM  ,   python Phi3ForCausalLM\" (#7483)"},{"Id":"3166845805","IsPullRequest":true,"CreatedAt":"2025-07-09T20:36:43","Actor":"feiyun0112","Number":"7484","RawContent":null,"Title":"Rename Casual to Causal","State":"closed","Body":"fix #7483 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/7484","RelatedDescription":"Closed or merged PR \"Rename Casual to Causal\" (#7484)"},{"Id":"3209863641","IsPullRequest":true,"CreatedAt":"2025-07-09T19:14:48","Actor":"ericstj","Number":"7486","RawContent":null,"Title":"Enable dependabot.","State":"closed","Body":"Configure dependabot for public dependency updates.  This will help this repo stay up to date with public dependencies.\r\n\r\nWe'll still need to review dependency PRs, and mirror packages to our feeds, but this will help ensure we stay up to date.","Url":"https://github.com/dotnet/machinelearning/pull/7486","RelatedDescription":"Closed or merged PR \"Enable dependabot.\" (#7486)"},{"Id":"3138102792","IsPullRequest":true,"CreatedAt":"2025-07-07T18:04:07","Actor":"Copilot","Number":"7482","RawContent":null,"Title":"Convert repository to NuGet Central Package Management","State":"closed","Body":"This PR converts the entire repository to use NuGet Central Package Management as requested in issue #7479. This centralizes all package version management in a single `Directory.Packages.props` file while ensuring the same packages and versions are restored.\n\n## Changes Made\n\n### Core Implementation\n- **Created `Directory.Packages.props`** with 89 PackageVersion items organized by category:\n  - Product dependencies (Apache.Arrow, Newtonsoft.Json, System.* packages, etc.)\n  - Test-only dependencies (MSTest, XUnit, coverlet, etc.) \n  - Build/infrastructure dependencies (MicroBuild, Arcade tools, etc.)\n- **Enabled `ManagePackageVersionsCentrally=true`** property to activate central package management\n- **Removed Version attributes** from all PackageReference items across:\n  - 64 .csproj files\n  - 4 .props/.targets files (test/Directory.Build.props, Directory.Build.targets, etc.)\n\n### Version Management\n- All package versions use existing properties from `eng/Versions.props` (e.g., `$(NewtonsoftJsonVersion)`, `$(SystemCollectionsImmutableVersion)`)\n- Maintains consistency with current version management approach\n- No changes to actual package versions - only centralized the management\n\n### Package Resolution Validation\n- ✅ Core projects restore successfully (Microsoft.ML.Core, Microsoft.ML.Data, Microsoft.ML.DataView)\n- ✅ Test projects restore successfully (Microsoft.ML.Tests, Microsoft.ML.Core.Tests)  \n- ✅ Sample projects restore successfully (Microsoft.ML.Samples, Microsoft.ML.Samples.OneDal)\n- ✅ Production projects restore successfully (Microsoft.ML.AutoML, Microsoft.ML.ImageAnalytics)\n- ✅ Package versions resolve correctly (verified via project.assets.json files)\n\n## Benefits\n\n1. **Centralized Management**: All package versions now managed in single location\n2. **Consistency**: Eliminates version conflicts across projects\n3. **Maintainability**: Easier to update package versions repository-wide\n4. **Transitive Pinning**: Enables better control over transitive dependencies\n\n## Validation\n\nThe conversion was validated by:\n- Individual project restore testing across core, test, and sample projects\n- Verification that resolved package versions match expected versions from Versions.props\n- Confirmation that no PackageReference Version attributes remain in project files\n\n**Note**: Some GenAI projects have temporary restore failures due to network issues with `JsonSchema.Net.Generation` package from Azure DevOps feeds, but this is unrelated to the central package management conversion and will resolve when the feed is accessible.\n\nFixes #7479.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `dnceng.pkgs.visualstudio.com`\n>   - Triggering command: `dotnet restore Microsoft.ML.sln ` (dns block)\n>   - Triggering command: `dotnet restore src/Microsoft.ML.GenAI.LLaMA/Microsoft.ML.GenAI.LLaMA.csproj ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\n💬 Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.","Url":"https://github.com/dotnet/machinelearning/pull/7482","RelatedDescription":"Closed or merged PR \"Convert repository to NuGet Central Package Management\" (#7482)"},{"Id":"3196495034","IsPullRequest":false,"CreatedAt":"2025-07-02T16:32:28","Actor":"ogo-adp","Number":"7485","RawContent":null,"Title":"Slow model loading performance after version 3.0.1","State":"open","Body":"**System Information**\n - OS & Version: Windows 10, Windows 2016\n - ML.NET Version: ML.NET > 3.01 (including 5.0 preview)\n - .NET Version: .NET 8.0\n\n**Describe the bug**\nWe use ML.NET on a large application with approx 20 models using only ML.NET FastTree regression.\nFor all ML.NET versions after 3.0.1 the time to load a model from a MLContext has increased dramatically\n\n**To Reproduce**\nCreate a regression model using FastTree\nLoad the model from a MLContext with version 3.0.1. Note the loading time\nLoad the same model with version 4.0.2. The loading time should be much higher\nWe observed between 7 and 50 times increased in loading times\n\n**Expected behavior**\nThe loading time should not be different\n\n**Screenshots, Code, Sample Projects**\nvar mlContext = new MLContext(seed: 0);\nvar loadedModel = mlContext.Model.Load(\"path_of_model.zip\", out _); \n-> loading time 111ms with 3.0.1, 1100ms with 4.0.2\n\n**Additional context**A\nLoading a model produced with version 4.0.2 using ML.NET 3.0.1 is fast\nLoading a model produced with version 4.0.2 using ML.NET 4.0.2 is slow\nOur model zip file range from 1000ko to 3000ko\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7485","RelatedDescription":"Open issue \"Slow model loading performance after version 3.0.1\" (#7485)"}],"ResultType":"GitHubIssue"}},"RunOn":"2025-09-28T03:30:20.0152796Z","RunDurationInMilliseconds":586}