{"Data":{"GitHub":{"Issues":[{"Id":"844272847","IsPullRequest":false,"CreatedAt":"2021-03-30T09:20:46","Actor":"ToshiyaIsomoto","Number":"5733","RawContent":null,"Title":"[Question] Why comparing (threshold and score), not (threshold and probability)","State":"open","Body":"https://github.com/dotnet/machinelearning/blob/2c8afeb64ed92f838e804fc6f4995163a7c92e3f/src/Microsoft.ML.Data/Scorers/BinaryClassifierScorer.cs#L275\r\n\r\nI want to output a high confident \"predicted label\", that the label with a \"probability\" higher than e.g., 0.8. I know the \"score\" and \"probability\" has the almost same meaning and changing \"threshold\" will output the high confidence \"predicted label\" (with such a code below).\r\n> BinaryClassification.ChangeModelThreshold(model, 0.8f);\r\n\r\nHowever, in the current code, a comparison is done between \"threshold\" and \"score\", and the \"score\" has not constant range like [0, 1] (ones for \"probability\"), right? How should I determine the \"threshold\" value? Why comparison is not done between \"threshold\" and \"probability\". \r\n ","Url":"https://github.com/dotnet/machinelearning/issues/5733","RelatedDescription":"Open issue \"[Question] Why comparing (threshold and score), not (threshold and probability)\" (#5733)"},{"Id":"842463583","IsPullRequest":false,"CreatedAt":"2021-03-30T05:12:34","Actor":"R0Wi","Number":"5731","RawContent":null,"Title":"Markdown format issue for LogLoss and LogLossReduction","State":"closed","Body":"Looking at the `MulticlassClassificationMetrics.LogLoss`, `CalibratedBinaryClassificationMetrics.LogLossReduction` and `MulticlassClassificationMetrics.LogLossReduction` it seems that the math formulas inside the remarks are not formatted correctly.\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: db0c3c11-e826-253d-983d-bc64f22bb609\r\n* Version Independent ID: db553462-9f1c-789d-caf2-408edc18d7d1\r\n* Content: [MulticlassClassificationMetrics.LogLoss Property (Microsoft.ML.Data)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.multiclassclassificationmetrics.logloss?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Data/MulticlassClassificationMetrics.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/5731","RelatedDescription":"Closed issue \"Markdown format issue for LogLoss and LogLossReduction\" (#5731)"},{"Id":"842463889","IsPullRequest":true,"CreatedAt":"2021-03-30T02:32:42","Actor":"R0Wi","Number":"5732","RawContent":null,"Title":"Fix doc markdown Fixes #5731","State":"closed","Body":"Fixed documentation markdown remarks for\r\n* MulticlassClassificationMetrics.LogLoss\r\n* MulticlassClassificationMetrics.LogLossReduction\r\n* CalibratedBinaryClassificationMetrics.LogLossReduction\r\n\r\nSigned-off-by: Robin Windey <ro.windey@gmail.com>","Url":"https://github.com/dotnet/machinelearning/pull/5732","RelatedDescription":"Closed or merged PR \"Fix doc markdown Fixes #5731\" (#5732)"},{"Id":"842175591","IsPullRequest":false,"CreatedAt":"2021-03-26T17:40:42","Actor":"voges316","Number":"5730","RawContent":null,"Title":"AutoML binary experiment continues using poorly performing model","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: CentOS 7-9.2009\r\n- **.NET Version (eg., dotnet --info)**:  3.1.112, Microsoft.ML v1.5.5, Microsoft.ML.AutoML v0.17.5\r\n\r\n### Issue\r\n\r\nWas using automl for sentiment analysis on the imdb dataset https://ai.stanford.edu/~amaas/data/sentiment/ . Created a binary classification experiment that would use all trainers (9 by default), optimize Accuracy (also default), and run for 2 hours. I also added a progress handler that would print metrics of the results as the experiment progressed.\r\nAfter running for some time, the progress handler showed the experiment was switching between AveragedPerceptronBinary, LbfgsLogisticRegressionBinary, and SgdCalibratedBinary. The second two made some sense since the Accuracy results were higher (approx 0.90) and occasionally would increase, but the first one \"AveragedPerceptronBinary\" confused me, since it consistently had  low results (approx 0.5, 0.7, etc). \r\n\r\nI'm wondering if this is a bug in the Experiment Logic or not. I would expect the experiment to discard a poorly performing Model instead of continuing to come back to it again, which appears to be what it does for all the other models except for AveragedPerceptronBinary. For example, FastTreeBinary is only tried once and then ignored, but AveragedPerceptronBinary is tried all the way until the end.\r\n\r\n\r\n### Source code / logs\r\n\r\n```\r\nShow data in DataView: Showing 1 rows with the columns\r\n######################################################\r\nRow--> | Review:I honestly don't understand how tripe like this gets made. The worst junior-high talent show skit you've ever seen is more entertaining than this film. Will Ferrell's wrestling fetish provides the only (briefly) humorous moments. Utterly horrible.| Label:False\r\n\r\nAutoML RunExperiment (s): 7200\r\nAutoML keeping Models in memory\r\nAutoML Optizing Metric: Accuracy\r\nAutoML Trainers being used:\r\n        AveragedPerceptron\r\n        FastForest\r\n        FastTree\r\n        LightGbm\r\n        LinearSvm\r\n        LbfgsLogisticRegression\r\n        SdcaLogisticRegression\r\n        SgdCalibrated\r\n        SymbolicSgdLogisticRegression\r\n     Trainer                               Accuracy    AUC       AUPRC   F1-score  Duration\r\n   1 AveragedPerceptronBinary               0.8984    0.9591    0.9550    0.9003   33.5595 *\r\n   2 SdcaLogisticRegressionBinary           0.8845    0.9539    0.9488    0.8870   42.0153\r\n   3 LinearSvmBinary                        0.8806    0.9555    0.9504    0.8764   31.1247\r\n   4 FastTreeBinary                         0.8706    0.9444    0.9424    0.8730  182.7707\r\n   5 LbfgsLogisticRegressionBinary          0.8938    0.9579    0.9527    0.8960   63.6329\r\n   6 FastForestBinary                       0.7451    0.8190    0.8076    0.7597  145.4131\r\n   7 SgdCalibratedBinary                    0.9034    0.9606    0.9556    0.9044   33.7678 *\r\n   8 AveragedPerceptronBinary               0.4983    0.7931    0.7769    0.0000   62.3400\r\n   9 LbfgsLogisticRegressionBinary          0.8876    0.9558    0.9496    0.8893   53.2443\r\n  10 SgdCalibratedBinary                    0.9031    0.9605    0.9556    0.9040   34.0770\r\n  11 AveragedPerceptronBinary               0.4983    0.7759    0.7782    0.0000   70.6186\r\n  12 LbfgsLogisticRegressionBinary          0.8980    0.9612    0.9563    0.9006   49.4685\r\n  13 SgdCalibratedBinary                    0.8772    0.9493    0.9442    0.8743   30.8654\r\n  14 AveragedPerceptronBinary               0.5048    0.8151    0.8021    0.0317   32.4597\r\n  15 LbfgsLogisticRegressionBinary          0.8891    0.9563    0.9507    0.8912   94.6190\r\n  16 SgdCalibratedBinary                    0.9034    0.9606    0.9556    0.9041   33.7996\r\n  17 AveragedPerceptronBinary               0.5017    0.7522    0.7453    0.6682   32.2783\r\n  18 LbfgsLogisticRegressionBinary          0.8946    0.9583    0.9527    0.8966   94.1862\r\n  19 SgdCalibratedBinary                    0.8961    0.9587    0.9537    0.8957   31.7183\r\n  20 AveragedPerceptronBinary               0.4986    0.8256    0.8027    0.0015   42.6899\r\n  21 LbfgsLogisticRegressionBinary          0.8938    0.9586    0.9528    0.8963   43.6216\r\n  22 SgdCalibratedBinary                    0.9031    0.9604    0.9555    0.9037   33.1641\r\n\r\n\r\n 122 AveragedPerceptronBinary               0.4983    0.8266    0.8285    0.0000   51.6914\r\n 123 LbfgsLogisticRegressionBinary          0.9019    0.9614    0.9564    0.9033   48.7525\r\n 124 SgdCalibratedBinary                    0.9027    0.9604    0.9555    0.9033   33.3645\r\n 125 AveragedPerceptronBinary               0.6771    0.8222    0.8145    0.7431   34.6309\r\n 126 LbfgsLogisticRegressionBinary          0.9046    0.9618    0.9570    0.9063   68.3563 *\r\n 127 SgdCalibratedBinary                    0.9034    0.9605    0.9556    0.9044   33.7517\r\n 128 AveragedPerceptronBinary               0.7126    0.8588    0.8618    0.7650   39.4687\r\n 129 LbfgsLogisticRegressionBinary          0.9023    0.9617    0.9569    0.9041   67.2922\r\n 130 SgdCalibratedBinary                    0.9003    0.9599    0.9551    0.9009   31.9746\r\n 131 AveragedPerceptronBinary               0.6829    0.8260    0.8218    0.7468   34.5324\r\n 132 LbfgsLogisticRegressionBinary          0.9042    0.9620    0.9573    0.9059   62.4062\r\n 133 SgdCalibratedBinary                    0.9031    0.9605    0.9556    0.9039   33.5832\r\n 134 AveragedPerceptronBinary               0.7173    0.8573    0.8521    0.6398   31.4024\r\n 135 LbfgsLogisticRegressionBinary          0.9027    0.9617    0.9568    0.9045   62.7962\r\n 136 SgdCalibratedBinary                    0.9023    0.9605    0.9555    0.9030   33.3611\r\n 137 AveragedPerceptronBinary               0.5342    0.8236    0.8271    0.6825   32.9347\r\n 138 LbfgsLogisticRegressionBinary          0.8973    0.9605    0.9552    0.8993   80.9124\r\n 139 SgdCalibratedBinary                    0.9031    0.9605    0.9556    0.9041   34.1757\r\n 140 AveragedPerceptronBinary               0.7810    0.8643    0.8585    0.7861   32.6319\r\n 141 LbfgsLogisticRegressionBinary          0.9038    0.9618    0.9570    0.9056   61.3063\r\n 142 SgdCalibratedBinary                    0.9023    0.9605    0.9555    0.9031   34.0737\r\n 143 AveragedPerceptronBinary               0.4990    0.8360    0.8169    0.0031   31.8536\r\n 144 LbfgsLogisticRegressionBinary          0.9034    0.9611    0.9563    0.9049   50.3616\r\n 145 SgdCalibratedBinary                    0.8810    0.9495    0.9447    0.8840   30.7382\r\n 146 AveragedPerceptronBinary               0.7374    0.8331    0.8291    0.6962   31.7820\r\n 147 LbfgsLogisticRegressionBinary          0.9046    0.9620    0.9573    0.9063   62.7225\r\n 148 SgdCalibratedBinary                    0.9011    0.9588    0.9537    0.9016   31.6420\r\n 149 AveragedPerceptronBinary               0.5280    0.8004    0.7997    0.6789   38.1294\r\n 150 LbfgsLogisticRegressionBinary          0.9034    0.9620    0.9572    0.9052   59.0457\r\n 151 SgdCalibratedBinary                    0.8980    0.9586    0.9537    0.8978   31.4805\r\n 152 AveragedPerceptronBinary               0.7771    0.8568    0.8515    0.7761   31.2145\r\n\r\nTotal models produced: 154\r\nBest model's trainer: LbfgsLogisticRegressionBinary\r\nMetrics of best model from validation data --\r\nAccuracy: 0.9045963692545385\r\nAreaUnderPrecisionRecallCurve: 0.9570456314512586\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/5730","RelatedDescription":"Open issue \"AutoML binary experiment continues using poorly performing model\" (#5730)"},{"Id":"837849914","IsPullRequest":false,"CreatedAt":"2021-03-25T22:07:25","Actor":"luisquintanilla","Number":"5726","RawContent":null,"Title":"Why not newer than CUDA 10.0?","State":"closed","Body":"Transferring product question posted in .NET Docs repo from @zleepy\r\n\r\nOriginal Issue (dotnet/docs#23312)\r\n\r\nWhy should i not install CUDA newer than v10.0? 10.0 does not support newer versions of VS 2019.\r\nA newer version of CUDA 10 says it does support VS 2019, see: https://docs.nvidia.com/cuda/archive/10.2/cuda-installation-guide-microsoft-windows/index.html.\r\n\r\nAnd even newer, CUDA 11.2.1 does also say it supports VS, see: https://docs.nvidia.com/cuda/archive/11.2.1/cuda-installation-guide-microsoft-windows/index.html\r\n\r\nWhat is the reason this page explicit says that i should not install anything that Nvidia says is supported by newer versions of VS?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5726","RelatedDescription":"Closed issue \"Why not newer than CUDA 10.0?\" (#5726)"},{"Id":"841047300","IsPullRequest":false,"CreatedAt":"2021-03-25T15:29:44","Actor":"IvoTops","Number":"5729","RawContent":null,"Title":"Support ExpandoObject dynamic members for PredictionEngine<TIn,Out> where TIn is an ExpandoObject","State":"open","Body":"The PredictionEngine raises 'Type should contain a member named xyz' when using dynamic properties from an expandoobject that actually does have the member xyz.\r\n\r\n_var expando = new ExpandoObject();\r\n// generic code to fill object with lots of properties removed\r\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<ExpandoObject, ModelPrediction>(mlModel, mlSchema);                       \r\nvar prediction = predictionEngine.Predict(expando);_\r\n\r\nPlease fix this. I train lots of models with each a different and large set of features. Trying to do this with ML.NET now. For training I have a generic solution with my own IDataView where I create dynamic getter functions and use the schemabuilder. That works to train a model and create a schema dynamically supporting thousands of features.\r\n\r\nFor prediction I have to specify my input as a type like this;\r\n\r\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<**REQUIREDTYPE**, ModelPrediction>(mlModel, mlSchema);                       \r\n\r\nI do not have type definitions with thousands of fields. It has to be generic. I create an expandoobject and add all the members and values that the engine needs, But it complains that the fields are not there -> 'Type should contain a member named xx'.  So that check does not take dynamic properties into account. Support for dynamic properties (or a boolean flag to skip the type check) would open a lot of usecases for flexible featuresets.\r\n\r\nHope someone can fix this test to support also dynamic properties....","Url":"https://github.com/dotnet/machinelearning/issues/5729","RelatedDescription":"Open issue \"Support ExpandoObject dynamic members for PredictionEngine<TIn,Out> where TIn is an ExpandoObject\" (#5729)"},{"Id":"839331529","IsPullRequest":false,"CreatedAt":"2021-03-24T04:24:14","Actor":"ChengYen-Tang","Number":"5728","RawContent":null,"Title":"Does ml.net add a pipeline similar to nvidia deepstream? ","State":"open","Body":"In real-time streaming image analysis, such as rtmp and rtsp, we use emgucv, opencvsharp... or other tools to pull the stream, and capture the image in it for object detection and object classification. Video stream -> GPU decoding -> CPU conversion image format -> ML.net GPU detection, and then returns the result -> C# statistics and drawing the box.\r\n\r\nThis process seems inefficient and the CPU usage is very high. If ML.net's pipelines can pull images -> detection -> drawing are all done on the GPU, it should greatly reduce the load.","Url":"https://github.com/dotnet/machinelearning/issues/5728","RelatedDescription":"Open issue \"Does ml.net add a pipeline similar to nvidia deepstream? \" (#5728)"},{"Id":"829626170","IsPullRequest":true,"CreatedAt":"2021-03-23T19:21:06","Actor":"pgovind","Number":"5711","RawContent":null,"Title":"Improve csv parsing","State":"closed","Body":"This PR implements part 2 of improving our csv parsing:\r\n1) It finishes the implementation of TextFieldParser\r\n2) It makes `LoadCsv` use the new TextFieldParser implementation\r\n\r\nAs a result, we are now able to handle quotes (and quotes split across new lines) in csv files which is a huge improvement over what we are shipping currently.","Url":"https://github.com/dotnet/machinelearning/pull/5711","RelatedDescription":"Closed or merged PR \"Improve csv parsing\" (#5711)"},{"Id":"829489588","IsPullRequest":false,"CreatedAt":"2021-03-23T16:26:59","Actor":"michaelgsharp","Number":"5709","RawContent":null,"Title":"Master to Main rename","State":"closed","Body":"We will be renaming the Master branch to Main next week on Tuesday March 16.","Url":"https://github.com/dotnet/machinelearning/issues/5709","RelatedDescription":"Closed issue \"Master to Main rename\" (#5709)"},{"Id":"838575046","IsPullRequest":false,"CreatedAt":"2021-03-23T10:28:26","Actor":"Xilosof","Number":"5727","RawContent":null,"Title":"[Question] How realize ranking (scoring) images? ","State":"open","Body":"Hi! I didn't have any problems, but I want to ask a question.\r\nI don't know where it is better to ask a question, so I decided to do it in the developer repository. \r\nSorry if I shouldn't have done this here.\r\n\r\nI train in ml and came up with a task for myself.\r\nThe essence of the task:\r\n- **Find images with cars (Using ImageClassification with 2 labels)**\r\n- **Then the images with the cars are additionally tagged, for example, brand, color, purity, etc.**\r\n\r\nI think the best way would be to use a separate model for each tag. Check it out if I'm wrong.\r\nI think that the task of determining the brand or model will be more difficult and decided to start with the ranking.\r\n\r\nThe question is how to implement image ranking in ml.net. Should I use ImageClassification with 10 labels (1, 2, 3, ...), which are the evaluation of the beauty/cleanliness of the car? \r\nOr is there another more concise way to get the output of a single normalized number from 0 to 1 that represents the beauty/cleanliness score of the machine","Url":"https://github.com/dotnet/machinelearning/issues/5727","RelatedDescription":"Open issue \"[Question] How realize ranking (scoring) images? \" (#5727)"},{"Id":"830460540","IsPullRequest":true,"CreatedAt":"2021-03-22T17:09:13","Actor":"pgovind","Number":"5712","RawContent":null,"Title":"IDataView to DataFrame","State":"closed","Body":"An extension method to convert an IDataView to a DataFrame.\r\n\r\ncc @LittleLittleCloud \r\n","Url":"https://github.com/dotnet/machinelearning/pull/5712","RelatedDescription":"Closed or merged PR \"IDataView to DataFrame\" (#5712)"},{"Id":"837515425","IsPullRequest":false,"CreatedAt":"2021-03-22T09:29:09","Actor":"manuelfuchs","Number":"5725","RawContent":null,"Title":"Support for Hierarchical Clustering","State":"open","Body":"### Issue\r\n\r\nThis issue is based on #4961.\r\nIt would be nice to see support for Hierarchical Clustering besides the KMeans implementation in ML.NET.\r\nAn open source implementation of the AGNES algorithm [Kaufman & Rousseeuw, 1990] already exists in this open-source library [Aglomera](https://github.com/pedrodbs/Aglomera) that's licensed under the MIT license.\r\n\r\n> Currently, Aglomera.NET implements program AGNES (AGglomerative NESting) of [Kaufman & Rousseeuw, 1990], i.e., the bottom-up approach, the It supports different linkage criteria and also provides several metrics to perform internal and external evaluation of clustering results. The results of clustering can be exported to a Json file to be visualized as a dendrogram in Dendrogram Viewer, an interactive web-application using D3.js.\r\n\r\nBased on the description of Hierarchical Clustering by Aglomera ...\r\n\r\n> The clustering result is a list containing the cluster-set and the corresponding dissimilarity / distance at which it was created at each step of the algorithm. The result is organized in a hierarchical form, i.e., where each cluster references either the two parents that were merged for its creation (in the agglomerative approach), or the two children resulting from splitting the cluster (in the divisive approach). Due to their hierarchical nature, clustering results can be visualized via a dendrogram.\r\n\r\n... the expected result of this additional Model would not be a fixed amount of clusters (as with KMeans), but rather a tree containing the d.\r\nThe actual clusters can then be obtained by cutting the three at a certain height.\r\nBesides visualizing the hierarchical dependencies between clusters, this would give the developer more control regarding the amount of clusters, since this can be decided after the tree was calculated.\r\n\r\nReferences\r\n\r\n1. Kaufman, L., & Rousseeuw, P. J. (1990). [Finding groups in data: an introduction to cluster analysis](https://books.google.com/books?hl=en&lr=&id=YeFQHiikNo0C&oi=fnd&pg=PR11&ots=5ApcG5OEwC&sig=Sx5Bhqfaymzg1U9aRQVIFxmqiHY). John Wiley & Sons.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5725","RelatedDescription":"Open issue \"Support for Hierarchical Clustering\" (#5725)"},{"Id":"837268639","IsPullRequest":false,"CreatedAt":"2021-03-22T02:52:58","Actor":"trilochan","Number":"5724","RawContent":null,"Title":"Enable multi column group by for Dataframe","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:windows\r\n- **.NET Version (eg., dotnet --info)**: .net core 5.0\r\n\r\n### Issue\r\nI am using the Dataframe object from Microsoft.Data.Analytics, currently GroupBy only allows to group by only one column. There isn’t an option to group by multiple columns. \r\n- **What did you do?**\r\n- created a Dataframe with a few columns\r\n- **What happened?**\r\n- tried to use group by multiple columns \r\n- **What did you expect?**\r\n- Expected a method that took a list of columns names to group the Dataframe by\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5724","RelatedDescription":"Open issue \"Enable multi column group by for Dataframe\" (#5724)"},{"Id":"837222955","IsPullRequest":false,"CreatedAt":"2021-03-22T00:27:06","Actor":"axiom2018","Number":"5723","RawContent":null,"Title":"ML.Net Schema mismatch for feature column 'ImagePath': expected VarVector<Byte>, got String","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI'm learning ML.Net, and this maybe a simple question so forgive me in advance if it is but hardly any tutorials I've watched on youtube take the time to explain the code to the viewer. All I'm trying to do is follow a tutorial found [here](https://www.youtube.com/watch?v=bXTN-rnwDso&t=421s&ab_channel=JonWood), I got stuck at 6:58 in the video when I'm supposed to call the fit function. \r\n\r\n- **What happened?**\r\nI get the error \"'Schema mismatch for feature column 'ImagePath': expected VarVector<Byte>, got String (Parameter 'inputSchema')'\" Which is weird because of course the video uploader didn't get this.\r\n\r\n- **What did you expect?**\r\nI just expected to get the model when the fit function was called and continue the code.\r\n\r\n### Source code / logs\r\n\r\n1) **Main Code (Program.cs)**\r\n\r\n`            string baseDir = Directory.GetCurrentDirectory();\r\n            string realDir = Path.GetFullPath(Path.Combine(baseDir, @\"..\\..\\..\\\"));\r\n            string imgFolderDir = realDir + \"images\\\\\";\r\n\r\n            // Get ref to images folder.\r\n            //var imgFolder = Path.Combine(Environment.CurrentDirectory, \"..\", \"..\", \"..\", \"images\");\r\n\r\n            // Go to images folder, get all files (*) from both folders.\r\n            var file = Directory.GetFiles(imgFolderDir, \"*\", SearchOption.AllDirectories);\r\n\r\n            /* For each file, create an imagedata object.  */\r\n            var images = file.Select(f => new ImageData\r\n            {\r\n                ImagePath = f,\r\n                Label = Directory.GetParent(f).Name\r\n            });\r\n\r\n\r\n            // Begin algorithm for ML.\r\n            MLContext ml = new MLContext();\r\n\r\n            /* Load the images.\r\n               Shuffle them (for more randomness?)\r\n            */\r\n            var imageData = ml.Data.LoadFromEnumerable(images);\r\n            var imgDataShuffle = ml.Data.ShuffleRows(imageData);\r\n\r\n            // Split because we'd like to get a portion for training and another for testing.\r\n            var testTrainData = ml.Data.TrainTestSplit(imgDataShuffle, testFraction: 0.2);\r\n\r\n\r\n            var validateData = ml.Transforms.Conversion.MapValueToKey(\"LabelKey\", \"Label\",\r\n                keyOrdinality: Microsoft.ML.Transforms.ValueToKeyMappingEstimator.KeyOrdinality.ByValue)\r\n                .Fit(testTrainData.TestSet)\r\n                .Transform(testTrainData.TestSet);\r\n\r\n\r\n            var pipeline = ml.MulticlassClassification.Trainers.ImageClassification(featureColumnName: \"ImagePath\")\r\n                .Append(ml.Transforms.Conversion.MapKeyToValue(outputColumnName: \"PredictedLabel\",\r\n                inputColumnName: \"PredictedLabel\"));\r\n\r\n            var model = pipeline.Fit(testTrainData.TrainSet);\r\n\r\n            var predictions = model.Transform(testTrainData.TestSet);\r\n            var metrics = ml.MulticlassClassification.Evaluate(predictions, labelColumnName: \"LabelKey\",\r\n                predictedLabelColumnName: \"PredictedLabel\");\r\n\r\n            Console.WriteLine(\"Log loss: {0}.\", metrics.LogLoss);\r\n\r\n            var predictionEngine = ml.Model.CreatePredictionEngine<ImageData, ImagePrediction>(model);\r\n\r\n\r\n\r\n            var testImagesFolder = Path.Combine(Environment.CurrentDirectory, \"..\", \"..\", \"..\", \"test\");\r\n            var testFiles = Directory.GetFiles(testImagesFolder, \"*\", SearchOption.AllDirectories);\r\n            var testImages = testFiles.Select(file => new ImageData\r\n            {\r\n                ImagePath = file\r\n            });\r\n\r\n\r\n\r\n            VBuffer<ReadOnlyMemory<char>> keys = default;\r\n            predictionEngine.OutputSchema[\"LabelKey\"].GetKeyValues(ref keys);\r\n            var originalLabels = keys.DenseValues().ToArray();\r\n\r\n            foreach (var image in testImages)\r\n            {\r\n                // Get the prediction using the prediction engine itself of course.\r\n                var prediction = predictionEngine.Predict(image);\r\n\r\n                // And get the label.\r\n                var labelIndex = prediction.PredictedLabel;\r\n\r\n                // Write it out.\r\n                Console.WriteLine(\"-Image Path:- {0}. -Score:- {1}. -Predicted Label- {2}.\",\r\n                    Path.GetFileName(image.ImagePath),\r\n                    prediction.Score.Max(),\r\n                    originalLabels[labelIndex]);\r\n            }\r\n\r\n            Console.ReadLine();\r\n\r\n\r\n\r\n2) **ImageData (Input)**\r\n\r\n`  public class ImageData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string ImagePath;\r\n\r\n        [LoadColumn(1)]\r\n        public string Label;\r\n    }`\r\n\r\n\r\n\r\n\r\n3) **ImagePrediction (Output)**\r\n\r\n`    public class ImagePrediction\r\n    {\r\n        // Scores we get from the model. How sure it is on a guess.\r\n        [ColumnName(\"Score\")]\r\n        public float[] Score;\r\n\r\n        // The actual label. DNN doesn't give us a string for it.\r\n        [ColumnName(\"PredictedLabel\")]\r\n        public uint PredictedLabel;\r\n    }`\r\n\r\n\r\nAlso, here's a [link](https://github.com/jwood803/MLNetExamples/blob/master/MLNetExamples/DeepNeuralNetwork/Program.cs) to the guy in the videos github so you can compare and contrast my code to his. What exactly am I doing wrong?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5723","RelatedDescription":"Open issue \"ML.Net Schema mismatch for feature column 'ImagePath': expected VarVector<Byte>, got String\" (#5723)"},{"Id":"836714288","IsPullRequest":false,"CreatedAt":"2021-03-20T06:34:33","Actor":"Youssef1313","Number":"5722","RawContent":null,"Title":"wikipedia-detox-250-line-data.tsv file has an error","State":"closed","Body":"![image](https://user-images.githubusercontent.com/31348972/111859793-0fc4af00-894c-11eb-977e-52752ecf4f46.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5722","RelatedDescription":"Closed issue \"wikipedia-detox-250-line-data.tsv file has an error\" (#5722)"},{"Id":"836257894","IsPullRequest":false,"CreatedAt":"2021-03-19T18:27:52","Actor":"pgovind","Number":"5721","RawContent":null,"Title":"DataFrame needs to support vector columns.","State":"open","Body":"With https://github.com/dotnet/machinelearning/pull/5712/files, DataFrames can now be constructed from `IDataView`s. However, IDataView supports vector types while DataFrame doesn't, so this will throw an exception. We should add support for vector types. 1 thing to consider here is that Arrow also supports vector types, so the backing memory store for a vector type column is already defined. (ArrowStringDataFrameColumn is the closest reference for how the backing store ought to be implemented)","Url":"https://github.com/dotnet/machinelearning/issues/5721","RelatedDescription":"Open issue \"DataFrame needs to support vector columns.\" (#5721)"},{"Id":"835188253","IsPullRequest":true,"CreatedAt":"2021-03-19T17:34:03","Actor":"michaelgsharp","Number":"5719","RawContent":null,"Title":"Renamed master to main","State":"closed","Body":"Renamed the last references of dotnet/machinelearning-samples/master to main.\r\n\r\nRemoved master a trigger in the yml files.","Url":"https://github.com/dotnet/machinelearning/pull/5719","RelatedDescription":"Closed or merged PR \"Renamed master to main\" (#5719)"},{"Id":"835516580","IsPullRequest":false,"CreatedAt":"2021-03-19T03:33:01","Actor":"alexlee0905","Number":"5720","RawContent":null,"Title":"[Question] How to implement MultiClassClassification with tree data structure using ML.Net","State":"open","Body":"### System information\r\n\r\nML.Net 1.5.2\r\n.Net Framework 4.7.2\r\n\r\n### Issue\r\n\r\nI have hundreds of projects, and they all have tree data structure like this:  \r\n```\r\nA\r\n  AA\r\n     AAA\r\n  BB\r\n     BBB\r\n```\r\nOr like this:\r\n```\r\nA\r\n  AA1\r\n     AAA1\r\n  BB2\r\n     BBB2\r\n```\r\nEach project has its own tree structure which is modified from a standard tree structure. What I am trying to do is to map project's tree structure to the standard tree structure, like this:\r\n```\r\nA          <--- A\r\n  AA       <---   AA1\r\n     AAA   <---      AAA1\r\n  BB       <---   BB2\r\n     BBB   <---      BBB2\r\n```\r\nOr like this:\r\n\r\n![(img)mapping to standard tree][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/QQauK.png\r\n\r\n(The mapping really depends on the text instead of the node's level. )  \r\n    \r\nNow I'm using multi class classification in ML.Net. First I map the existing projects' tree to the standard tree manually and save the results in the database, like this:\r\n\r\n```\r\n| Label      | Level1         | Level2         | Level3         |\r\n| --------   | -------------- | -------------- | -------------- |\r\n| A          | A              |      *         |       *        |\r\n| A-AA       | A              |      AA1       |       *        |\r\n| A-AA-AAA   | A              |      AA1       |      AAA1      |\r\n| A-BB       | A              |      BB2       |       *        |\r\n| A-BB-BBB   | A              |      BB2       |      BBB2      |\r\n| A          | A              |      *         |       *        |\r\n| A-AA-AAA   | A              |      AAA1      |       *        |\r\n| A-BB       | A              |      BB2       |       *        |\r\n| A-BB-BBB   | A              |      BB2       |      BBB2      |  \r\n```\r\n  \r\nBecause data in the column in ML.Net cannot be a missing value, so I replace them with *. And my tree has 15 levels (feature columns).  \r\n  \r\nThe multi class classification algorithm I choose is SdcaMaximumEntropy. Hopefully I can use the prediction to map the tree instead of doing this manually. \r\n   \r\nI successfully implemented the prediction. However, the prediction result is really poor.\r\n\r\nSo my question is:\r\n\r\n1. Is the way I do this right?\r\n2. If yes, should I remove the duplicate rows and should I replace the missing value with `*`?  \r\n  \r\nThanks in advance.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5720","RelatedDescription":"Open issue \"[Question] How to implement MultiClassClassification with tree data structure using ML.Net\" (#5720)"},{"Id":"834473033","IsPullRequest":false,"CreatedAt":"2021-03-18T07:16:51","Actor":"jamsoft","Number":"5718","RawContent":null,"Title":"Loading Existing ML.NET Image Classification Model and Adapting Predict To Use InMemory Images","State":"open","Body":"I originally raised this as a question on SO to which @michaelgsharp asked if I could bring this discussion to an issue here to track against the repo.\r\n-----------------------------------------------------\r\nI've been looking at the various examples for achieving this and struggling to get it working in my situation. It seems the advice used to be to create a completely [Custom IDataView](https://github.com/dotnet/machinelearning/issues/3460#issuecomment-485490908) according to this answer on GitHub.\r\n\r\nBut this was before there was a new attribute denoting Image types making the first example obsolete as far as I can tell. There is a unit test showing this newer approach [here](https://github.com/dotnet/machinelearning/blob/8dd47c13bf815d748a4fa78e9313a83827bb2057/test/Microsoft.ML.Tests/ImagesTests.cs#L220).\r\n\r\nThe issue is these all seem to re-save the MLModel.zip file as part of their setup setting a new input schema whereas I just want to adapt the inputs at runtime. The examples all seem to be much more complex situations where they are either adapting TensorFlow models in the pipelines or standardizing images. My datasets are all already standardized and in ML.NET formats.\r\n\r\nThe original input object looks like this:\r\n\r\n```\r\npublic class ModelInput\r\n{\r\n    [ColumnName(\"Label\"), LoadColumn(0)]\r\n    public string Label { get; set; }    \r\n\r\n    [ColumnName(\"ImageSource\"), LoadColumn(1)]\r\n    public string ImageSource { get; set; }\r\n}\r\n```\r\nAnd I would like to be able to pass in an object like this:\r\n\r\n```\r\npublic class MlClientModelInput\r\n{\r\n    [ColumnName(\"Label\"), LoadColumn(0)]\r\n    public string Label { get; set; }\r\n\r\n\r\n    [ColumnName(\"Image\"), LoadColumn(1), ImageType(328, 256)]\r\n    public Bitmap Image { get; set; }\r\n}\r\n```\r\nI've been trying various things for hours and getting nowhere at all. Even attempting the re-saving option isn't working as I can't get the methodology of not having to process the images and loading the existing model. It always complains about the schema is wrong.\r\n\r\nSo far I've been trying with this code:\r\n\r\n```\r\npublic static PredictionEngine<MlClientModelInput, MlClientModelOutput> Create()\r\n{\r\n    // Create new MLContext\r\n    MLContext mlContext = new MLContext();\r\n\r\n    var dataProcessPipeline = mlContext.Transforms.ResizeImages(\"Image\", 328, 256);\r\n\r\n    //var model = mlContext.Model.Load(MLNetModelPath, out var modelInputSchema);\r\n    //var pipeline = mlContext.Transforms.ConvertToGrayscale(\"GrayImage\", \"Image\");\r\n\r\n    ITransformer model = dataProcessPipeline.Fit(CreateEmptyDataView(mlContext));\r\n    // Load model & create prediction engine\r\n    ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var modelInputSchema);\r\n\r\n    mlContext.Model.Save(mlModel, null, MLNetModelPathEdited);\r\n\r\n    // Create new MLContext\r\n    MLContext mlContext2 = new MLContext();\r\n    ITransformer mlModel2 = mlContext.Model.Load(MLNetModelPathEdited, out var modelInputSchema2);\r\n    var predEngine = mlContext.Model.CreatePredictionEngine<MlClientModelInput, MlClientModelOutput>(mlModel);\r\n\r\n    return predEngine;\r\n}\r\n```\r\nI've now found [an example](https://github.com/ma-gu/machinelearning-samples/blob/bitmap-dataview/samples/csharp/getting-started/DeepLearning_ObjectDetection_Onnx_Visualization/ObjectDetection.Core/OnnxModelScorer.cs) that is almost exactly what I need but it's also loading a model differently so I'm still unsure how to implement a pipeline without having to standardize the data. It's all very confusing.\r\n\r\n```\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Drawing;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing ObjectDetection.Core;\r\n\r\nnamespace ObjectDetection\r\n{\r\n    public class OnnxModelScorer\r\n    {\r\n        private readonly string imagesLocation;\r\n        private readonly string imagesFolder;\r\n        private readonly string modelLocation;\r\n        private readonly MLContext mlContext;\r\n\r\n        private IList<YoloBoundingBox> _boxes = new List<YoloBoundingBox>();\r\n        private readonly YoloWinMlParser _parser = new YoloWinMlParser();\r\n\r\n        public OnnxModelScorer(string modelLocation)\r\n        {\r\n            this.modelLocation = modelLocation;\r\n\r\n            mlContext = new MLContext();\r\n        }\r\n\r\n        public struct ImageNetSettings\r\n        {\r\n            public const int imageHeight = 416;\r\n            public const int imageWidth = 416;\r\n        }\r\n\r\n        public struct TinyYoloModelSettings\r\n        {\r\n            // for checking TIny yolo2 Model input and  output  parameter names,\r\n            //you can use tools like Netron, \r\n            // which is installed by Visual Studio AI Tools\r\n\r\n            // input tensor name\r\n            public const string ModelInput = \"image\";\r\n\r\n            // output tensor name\r\n            public const string ModelOutput = \"grid\";\r\n        }\r\n\r\n        public void Score(Bitmap image)\r\n        {\r\n            var imageData = new BitmapDataView(image);\r\n            var model = LoadModel(imageData);\r\n\r\n            PredictDataUsingModel(imageData, model);\r\n        }\r\n\r\n        private PredictionEngine<BitmapDataView, ImageNetPrediction> LoadModel(BitmapDataView imageData)\r\n        {\r\n            Console.WriteLine(\"Read model\");\r\n            Console.WriteLine($\"Model location: {modelLocation}\");\r\n            Console.WriteLine($\"Images folder: {imagesFolder}\");\r\n            Console.WriteLine($\"Default parameters: image size=({ImageNetSettings.imageWidth},{ImageNetSettings.imageHeight})\");\r\n\r\n            //var data = mlContext.Data.LoadFromTextFile<ImageNetData>(imagesLocation, hasHeader: true);\r\n\r\n            var pipeline = mlContext.Transforms.ResizeImages(outputColumnName: \"image\", imageWidth: ImageNetSettings.imageWidth, imageHeight: ImageNetSettings.imageHeight, inputColumnName: \"image\")\r\n                            .Append(mlContext.Transforms.ExtractPixels(outputColumnName: \"image\"))\r\n                            .Append(mlContext.Transforms.ApplyOnnxModel(modelFile: modelLocation, outputColumnNames: new[] { TinyYoloModelSettings.ModelOutput }, inputColumnNames: new[] { TinyYoloModelSettings.ModelInput }));\r\n\r\n            var model = pipeline.Fit(imageData);\r\n\r\n            var predictionEngine = mlContext.Model.CreatePredictionEngine<BitmapDataView, ImageNetPrediction>(model);\r\n\r\n            return predictionEngine;\r\n        }\r\n\r\n        protected void PredictDataUsingModel(BitmapDataView data, PredictionEngine<BitmapDataView, ImageNetPrediction> model)\r\n        {\r\n            Console.WriteLine($\"Tags file location: {imagesLocation}\");\r\n            Console.WriteLine(\"\");\r\n            Console.WriteLine(\"=====Identify the objects in the images=====\");\r\n            Console.WriteLine(\"\");\r\n\r\n\r\n\r\n            var probs = model.Predict(data).PredictedLabels;\r\n            IList<YoloBoundingBox> boundingBoxes = _parser.ParseOutputs(probs);\r\n            var filteredBoxes = _parser.NonMaxSuppress(boundingBoxes, 5, .5F);\r\n\r\n            //Console.WriteLine(\".....The objects in the image {0} are detected as below....\", sample.Label);\r\n            foreach (var box in filteredBoxes)\r\n            {\r\n                Console.WriteLine(box.Label + \" and its Confidence score: \" + box.Confidence);\r\n            }\r\n            Console.WriteLine(\"\");\r\n\r\n\r\n\r\n            //var testData = ImageNetData.ReadFromCsv(imagesLocation, imagesFolder);\r\n\r\n            //foreach (var sample in testData)\r\n            //{\r\n            //    var probs = model.Predict(sample).PredictedLabels;\r\n            //    IList<YoloBoundingBox> boundingBoxes = _parser.ParseOutputs(probs);\r\n            //    var filteredBoxes = _parser.NonMaxSuppress(boundingBoxes, 5, .5F);\r\n\r\n            //    Console.WriteLine(\".....The objects in the image {0} are detected as below....\", sample.Label);\r\n            //    foreach (var box in filteredBoxes)\r\n            //    {\r\n            //        Console.WriteLine(box.Label + \" and its Confidence score: \" + box.Confidence);\r\n            //    }\r\n            //    Console.WriteLine(\"\");\r\n            //}\r\n        }\r\n    }\r\n}\r\n```\r\nWhat I'm trying to get to is being able to call the prediction engine like this:\r\n\r\n```\r\npublic static MlClientModelOutput Score(Bitmap image)\r\n{\r\n    var imageData = new BitmapDataView(image);\r\n    var model = LoadModel(imageData);\r\n\r\n    return model.Predict(imageData);\r\n}\r\n```\r\n\r\nWhat's so confusing is in every example I can find doing what I'm trying to do, they never seem to load the actual model I have in .ZIP format. Even in this [full example](https://github.com/dotnet/machinelearning/blob/02a857a7646188fec2d1cba5e187a6c9d0838e23/docs/samples/Microsoft.ML.Samples/Dynamic/Transforms/CustomMappingWithInMemoryCustomType.cs#L9) they never load anything from a generated ML.NET model zip file. In my code, if I copied this pattern it would blow up as I wouldn't have executed this code:\r\n\r\n`ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var modelInputSchema);`","Url":"https://github.com/dotnet/machinelearning/issues/5718","RelatedDescription":"Open issue \"Loading Existing ML.NET Image Classification Model and Adapting Predict To Use InMemory Images\" (#5718)"},{"Id":"834086075","IsPullRequest":true,"CreatedAt":"2021-03-17T22:53:20","Actor":"michaelgsharp","Number":"5717","RawContent":null,"Title":"Renamed master to main","State":"closed","Body":"Rename all references to machinelearning/master to machinelearning/main.","Url":"https://github.com/dotnet/machinelearning/pull/5717","RelatedDescription":"Closed or merged PR \"Renamed master to main\" (#5717)"},{"Id":"833249875","IsPullRequest":false,"CreatedAt":"2021-03-16T22:40:57","Actor":"Hulkstance","Number":"5716","RawContent":null,"Title":"[Question] Microsoft.Data.Analysis","State":"open","Body":"I was waiting on `Microsoft.Data.Analysis` for a long time and more specifically `.Shift()`, `.Resample()` operations. I literally saw an issue about that, but not sure what happened. I recently saw that you moved the repo over here. What is the newest repo that I can use?\r\n\r\nhttps://github.com/xadupre/machinelearning_dataframe doesn't seem to be maintained.","Url":"https://github.com/dotnet/machinelearning/issues/5716","RelatedDescription":"Open issue \"[Question] Microsoft.Data.Analysis\" (#5716)"},{"Id":"833126387","IsPullRequest":true,"CreatedAt":"2021-03-16T22:31:12","Actor":"michaelgsharp","Number":"5715","RawContent":null,"Title":"Added main branch to yml files","State":"closed","Body":"This adds the branch \"main\" to the yml files in preparation for the rename of master to main.","Url":"https://github.com/dotnet/machinelearning/pull/5715","RelatedDescription":"Closed or merged PR \"Added main branch to yml files\" (#5715)"},{"Id":"832306389","IsPullRequest":false,"CreatedAt":"2021-03-16T00:34:56","Actor":"iluveu28","Number":"5714","RawContent":null,"Title":"ERROR : Schema mismatch for input column","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Linux\r\n- **.NET Version (eg., dotnet --info)**: 5\r\n\r\n### Issue\r\n\r\nWhen I got to the training step - https://dotnet.microsoft.com/learn/ml-dotnet/get-started-tutorial/train\r\n\r\nIt failed with below error. Why and how to fix it?\r\n\r\n### Source code / logs\r\n\r\nSchema mismatch for input column 'TIU_SOC_tf_CharExtractor': expected Expected known-size vector of Single, got Vector<Single>\r\nParameter name: inputSchema\r\n\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment`3.<ExecuteAsync>d__21.MoveNext()\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__26.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 150\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5714","RelatedDescription":"Open issue \"ERROR : Schema mismatch for input column\" (#5714)"},{"Id":"829516465","IsPullRequest":true,"CreatedAt":"2021-03-15T16:52:19","Actor":"eerhardt","Number":"5710","RawContent":null,"Title":"Update to the latest Microsoft.DotNet.Interactive","State":"closed","Body":"This allows the DataFrame extension to work with the latest .NET Interactive.\r\n\r\nI also needed to change the DataFrame .csproj so it gets packed by including the right Pack.props file. \r\n\r\nAdded an .editorconfig entry so .csproj files are uniform in their spacing.\r\n\r\nThe only meaningful code change is the rows per page going from 10 to 25. 10 is just too small IMO.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5710","RelatedDescription":"Closed or merged PR \"Update to the latest Microsoft.DotNet.Interactive\" (#5710)"},{"Id":"831157625","IsPullRequest":false,"CreatedAt":"2021-03-14T13:34:37","Actor":"neoffer","Number":"5713","RawContent":null,"Title":"Native .NET alternatives of Python's data science and AI libraries","State":"open","Body":"I don't know how to develop on-premise chatbot app using .NET. Because .NET does not provide native data science and ai libraries.\r\n\r\nPlease develop native libraries for data science, machine learning and deep learning in .NET like TensorFlow, NumPy, SciPy, Matplotlab, Keras, NLTK, Pandas so we can develop on-premise ChatBot application in .NET Core using Microsoft's NuGet Packages.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5713","RelatedDescription":"Open issue \"Native .NET alternatives of Python's data science and AI libraries\" (#5713)"},{"Id":"826810260","IsPullRequest":true,"CreatedAt":"2021-03-11T19:48:53","Actor":"michaelgsharp","Number":"5699","RawContent":null,"Title":"Fixes for tlc build breaks","State":"closed","Body":"With the removal of the TLC subscription which was hosting some assets we had errors trying to build. These assets have been moved into another azure devops repo and turned into a nuget package.\r\n\r\nThis pr changes the build process so it uses the nuget instead of directly downloading the assets. This involves some build changes as well as some test file changes.","Url":"https://github.com/dotnet/machinelearning/pull/5699","RelatedDescription":"Closed or merged PR \"Fixes for tlc build breaks\" (#5699)"},{"Id":"828443643","IsPullRequest":true,"CreatedAt":"2021-03-11T19:47:56","Actor":"michaelgsharp","Number":"5701","RawContent":null,"Title":"Nuget feed update","State":"closed","Body":"Renamed nuget feed from mlnet-testdata to mlnet-assets.","Url":"https://github.com/dotnet/machinelearning/pull/5701","RelatedDescription":"Closed or merged PR \"Nuget feed update\" (#5701)"},{"Id":"827023644","IsPullRequest":false,"CreatedAt":"2021-03-10T03:26:17","Actor":"michaelgsharp","Number":"5700","RawContent":null,"Title":"Fix URL and datasets for samples.","State":"open","Body":"With the removal of the TLC subscription, all the URL's in the samples for the datasets need to be fixed.\r\n\r\nIf we don't have access to those datasets anymore, we will need to either create them again or come up with new ones.","Url":"https://github.com/dotnet/machinelearning/issues/5700","RelatedDescription":"Open issue \"Fix URL and datasets for samples.\" (#5700)"},{"Id":"823967636","IsPullRequest":false,"CreatedAt":"2021-03-07T17:18:02","Actor":"WalternativE","Number":"5698","RawContent":null,"Title":"DateTime columns cause schema type lookups to fail in DataFrame","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:  Windows 10 20H2 19042.844\r\n- **.NET Version (eg., dotnet --info)**:  5.0.200\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\n  I tried to use the `Explore()` and `ExploreWithSandDance()` extension methods on the\r\n  `IDataView` type of the underlying `DataFrame` which contained a column of the type\r\n  `PrimitiveDataFrameColumn<DateTime>`.\r\n\r\n- **What happened?**\r\n  I received the following error\r\n  ```\r\n  Error: System.NotSupportedException: Specified method is not supported.\r\n  at Microsoft.Data.Analysis.PrimitiveDataFrameColumn`1.GetDataViewType()\r\n  at Microsoft.Data.Analysis.PrimitiveDataFrameColumn`1.AddDataViewColumn(Builder builder)\r\n  at Microsoft.Data.Analysis.DataFrame.get_DataViewSchema()\r\n  at Microsoft.ML.DataViewExtensions.ToTabularJsonString(IDataView source)\r\n  at Microsoft.ML.DataViewExtensions.ExploreWithSandDance(IDataView source)\r\n  at <StartupCode$FSI_0011>.$FSI_0011.main@()\r\n  ``` \r\n\r\n- **What did you expect?**\r\n  I expected the same behavior as when I tried the same procedure with a `DataFrame` which did not contain a\r\n  `DateTime` column.\r\n\r\n### Source code / logs\r\n\r\nAs explained above I received a `NotSupportedException`. I assume, that it is connected to the execution of this line\r\n`source.Schema.ToDictionary(column => column.Name, column => column.Type.RawType);` in the extension method to create the `TabularJsonObject` [here](https://github.com/dotnet/interactive/blob/4f22e1b0cd1023ee8e4ddff30de6b7c845a674c4/src/Microsoft.DotNet.Interactive.ExtensionLab/DataFrameKernelExtension.cs#L178).\r\n\r\nI created a [notebook](https://github.com/WalternativE/DotnetInteractiveExperiments/blob/main/notebooks/DataFrameDateTimeProblem.ipynb) which showcases how I stumbled upon the error. It should be possible to use the binder link in the readme for this, even though it botches up the last redirect for some reason.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5698","RelatedDescription":"Open issue \"DateTime columns cause schema type lookups to fail in DataFrame\" (#5698)"},{"Id":"823950980","IsPullRequest":false,"CreatedAt":"2021-03-07T16:02:23","Actor":"jamsoft","Number":"5697","RawContent":null,"Title":"Attempting to use In Memory Images for Prediction","State":"open","Body":"### System information\r\n\r\n- Windows 10\r\n\r\n### Issue\r\n\r\n- **I'm trying to use in memory images with an ML Model Loaded from an MLModel.zip file**\r\n- **I cannot work our how to build the pipeline in order to adapt the input schema?**\r\n\r\n### Source code / logs\r\n\r\nI'm following the examples I can find in the ML repository. The such as the WebApp and WebApi Images classification example applications but they all wrap a tensorflow model in order to then be able to pass a Bitmap to the Prediction method.\r\n\r\nI've been trying all day to find either simpler examples or the right syntax and I've completely failed so far. The examples build pipelines to do things like resizing, extracting pixels and recolorising whereas all my images are pre-prepared and I'm using an ML.NET model which should be the simplest use case but there aren't currently any of these simpler examples.\r\n\r\nWhat I cant find out how to do, or even identify if it's the right approach, is create a pipeline that loads an ML.NET \"native\" model created by Model Builder then adapt this to take in a Bitmap using the same type of class as in the [demos](https://github.com/CESARDELATORRE/TensorFlowImageClassificationWebApp):\r\n\r\nSuch as this:\r\n\r\n```\r\n    public class ImageInputData\r\n    {\r\n        [ImageType(227, 227)]\r\n        public Bitmap Image { get; set; }\r\n    }\r\n```\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5697","RelatedDescription":"Open issue \"Attempting to use In Memory Images for Prediction\" (#5697)"}],"ResultType":"GitHubIssue"}},"RunOn":"2021-03-31T05:30:27.4728576Z","RunDurationInMilliseconds":595}