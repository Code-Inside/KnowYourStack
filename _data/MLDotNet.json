{"Data":{"GitHub":{"Issues":[{"Id":"404589225","IsPullRequest":false,"CreatedAt":"2019-01-30T03:46:35","Actor":"wschin","Number":"2319","RawContent":null,"Title":"Accessibility Problem of FastTreeRegressionModelParameters through Dynamic APIs","State":"open","Body":"The following examples shows a way to retrieved the underlying model learned by a trainer, but I failed compiling it. For [static APIs](https://github.com/dotnet/machinelearning/blob/e3830910531f00013c27391914233a085a1394a4/test/Microsoft.ML.StaticPipelineTesting/Training.cs#L434), we are able to assign `FastTreeRegressionModelParameters` to `pred` but in the corresponding dynamic API, the type of `p` becomes \r\n```csharp\r\nMicrosoft.ML.Data.BinaryPredictionTransformer<Microsoft.ML.Internal.Internallearn.IPredictorWithFeatureWeights<float>>\r\n```\r\n, which doesn't publicly expose `FastTreeRegressionModelParameters as one of its field.\r\n```csharp\r\n            var data = new TextLoader(Env,\r\n                    new TextLoader.Arguments()\r\n                    {\r\n                        Separator = \";\",\r\n                        HasHeader = true,\r\n                        Column = new[]\r\n                        {\r\n                            new TextLoader.Column(\"Features\", DataKind.R4, 0, 10),\r\n                            new TextLoader.Column(\"Label\", DataKind.R4, 11)\r\n                        }\r\n                    }).Read(GetDataPath(TestDatasets.generatedRegressionDataset.trainFilename));\r\n\r\n\r\n            var trainer = ML.BinaryClassification.Trainers.FastTree(\r\n                new FastTreeBinaryClassificationTrainer.Options\r\n                {\r\n                    NumThreads = 1,\r\n                    NumTrees = 10,\r\n                    NumLeaves = 5,\r\n                });\r\n\r\n            FastTreeRegressionModelParameters pred = null;\r\n            trainer.WithOnFitDelegate((p) => { pred = p; });\r\n```\r\nAny tricks I can use to make this code example compiled without using internal classes? Or we need to modify our dynamic APIs?","Url":"https://github.com/dotnet/machinelearning/issues/2319","RelatedDescription":"Open issue \"Accessibility Problem of FastTreeRegressionModelParameters through Dynamic APIs\" (#2319)"},{"Id":"404576675","IsPullRequest":false,"CreatedAt":"2019-01-30T02:43:43","Actor":"zeahmed","Number":"2318","RawContent":null,"Title":"Add support for custom missing value in ValueMappingTransformer.","State":"open","Body":"The `ValueMappingTransformer` currently handles missing values. It does so by using the default value for the value type.\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/b4c10662706589426a0a870304e3088dec8077ac/src/Microsoft.ML.Data/Transforms/ValueMapping.cs#L807\r\n\r\nIn some cases, it is desirable to map the value that is missing in the dictionary with the user specified value. For example, when using the following text classification model from TensorFlow\r\nhttps://github.com/tensorflow/models/tree/master/research/sentiment_analysis\r\n\r\n, an `out-of-vocabulary` word (missing value) is mapped to integer `3`. This cannot be done currently using `ValueMappingTransformer`  in ML.NET.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2318","RelatedDescription":"Open issue \"Add support for custom missing value in ValueMappingTransformer.\" (#2318)"},{"Id":"404534964","IsPullRequest":true,"CreatedAt":"2019-01-30T02:02:06","Actor":"artidoro","Number":"2314","RawContent":null,"Title":"Simple fix to make error message more clear","State":"closed","Body":"Fixes #966.\r\n\r\nFirst, I further investigated and we don't use short names in error messages.\r\nThe issue #966 was pointing to an internal utility function that calculates the `probit`. The error message was not particularly useful which probably led to this concern.\r\n\r\nIn this PR, I change the error message to make the error a bit more clear and close the issue.","Url":"https://github.com/dotnet/machinelearning/pull/2314","RelatedDescription":"Closed or merged PR \"Simple fix to make error message more clear\" (#2314)"},{"Id":"404554902","IsPullRequest":true,"CreatedAt":"2019-01-30T01:00:51","Actor":"rogancarr","Number":"2317","RawContent":null,"Title":"Link to the concat transform sample in the catalog","State":"open","Body":"Adding a link to the concat sample; adding a bit more explanation in the concat sample.\r\n\r\nFixes #2316 ","Url":"https://github.com/dotnet/machinelearning/pull/2317","RelatedDescription":"Open PR \"Link to the concat transform sample in the catalog\" (#2317)"},{"Id":"404554268","IsPullRequest":false,"CreatedAt":"2019-01-30T00:58:15","Actor":"rogancarr","Number":"2316","RawContent":null,"Title":"Concat transform is missing a link to its sample","State":"open","Body":"The concat transform is missing a link to the sample.\r\n\r\n#1209 ","Url":"https://github.com/dotnet/machinelearning/issues/2316","RelatedDescription":"Open issue \"Concat transform is missing a link to its sample\" (#2316)"},{"Id":"404125830","IsPullRequest":true,"CreatedAt":"2019-01-30T00:52:13","Actor":"zeahmed","Number":"2302","RawContent":null,"Title":"Added a test showing example of text classification using TensorFlow in ML.Net","State":"closed","Body":"This PR fixes #2301.\r\n\r\nAlso updated the TensorFlow runtime  from 1.10.0 -> 1.12.0","Url":"https://github.com/dotnet/machinelearning/pull/2302","RelatedDescription":"Closed or merged PR \"Added a test showing example of text classification using TensorFlow in ML.Net\" (#2302)"},{"Id":"404124516","IsPullRequest":false,"CreatedAt":"2019-01-30T00:52:13","Actor":"zeahmed","Number":"2301","RawContent":null,"Title":"Create a test for text classification in TensorFlow.","State":"closed","Body":"Create an example test which takes textual features as input and output the probability of being in each class.","Url":"https://github.com/dotnet/machinelearning/issues/2301","RelatedDescription":"Closed issue \"Create a test for text classification in TensorFlow.\" (#2301)"},{"Id":"404543801","IsPullRequest":false,"CreatedAt":"2019-01-30T00:25:22","Actor":"rogancarr","Number":"2315","RawContent":null,"Title":"Add sample link to mutual information feature selection docs","State":"closed","Body":"The mutual information feature selection docs don't contain links to the samples for it.\r\n\r\nRelated to #1209 ","Url":"https://github.com/dotnet/machinelearning/issues/2315","RelatedDescription":"Closed issue \"Add sample link to mutual information feature selection docs\" (#2315)"},{"Id":"404473260","IsPullRequest":true,"CreatedAt":"2019-01-30T00:07:54","Actor":"eerhardt","Number":"2307","RawContent":null,"Title":"Update Microsoft.Data.DataView nuget metadata.","State":"closed","Body":"Fix #2289","Url":"https://github.com/dotnet/machinelearning/pull/2307","RelatedDescription":"Closed or merged PR \"Update Microsoft.Data.DataView nuget metadata.\" (#2307)"},{"Id":"404069354","IsPullRequest":true,"CreatedAt":"2019-01-30T00:04:45","Actor":"eerhardt","Number":"2296","RawContent":null,"Title":"Follow up from Extract IDataView feedback","State":"closed","Body":"@stephentoub left some PR comments on #2220 after it was merged. Addressing those comments here.","Url":"https://github.com/dotnet/machinelearning/pull/2296","RelatedDescription":"Closed or merged PR \"Follow up from Extract IDataView feedback\" (#2296)"},{"Id":"404483802","IsPullRequest":true,"CreatedAt":"2019-01-29T23:56:34","Actor":"codemzs","Number":"2308","RawContent":null,"Title":"Upload coverage files only when all tests pass.","State":"closed","Body":"Sometimes not all tests pass and coverage files with missing data is uploaded to codecov and this changes the baseline of the master repo and causes all sorts of fluctuations in the coverage report both in PR and on the main page.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2308","RelatedDescription":"Closed or merged PR \"Upload coverage files only when all tests pass.\" (#2308)"},{"Id":"404529487","IsPullRequest":false,"CreatedAt":"2019-01-29T23:15:07","Actor":"climosgit","Number":"2313","RawContent":null,"Title":"MulticlassClassification.Trainers.StochasticDualCoordinateAscent","State":"open","Body":"### System information\r\n\r\n- **Windows 7 Enterprise**:\r\n- **.NET Framework 4.6.1**: \r\n\r\n### Issue\r\n\r\n- **What did you do? I'm trying to predict an error classification based on error message. I have three classifications. Dismiss, Immediate and Observe. Trained, evaluated, saved and now consuming the model file. I'm using the MulticlassClassification.Trainers.StochasticDualCoordinateAscent trainer.**\r\n- **What happened? It works fine for errors that exist in the training data. Predicting very well. However, for new error that comes in, it appears to be grabbing the classification with largest population. In my case, it's the Dismiss.**\r\n- **What did you expect? I really wanted to classify the new error to flag as Immediate as at this time it is unknown and needs to be investigated. Perhaps I am using the wrong trainer and instead of StochasticDualCoordinateAscent, I should be using another trainer?**\r\n\r\n### Source code / logs\r\n\r\nmlContext = new MLContext(seed: 0);\r\ntrainErrorsEnumerable = TrainErrors(trainingViewVersion);\r\ntrainErrorsDataView = mlContext.CreateStreamingDataView(trainErrorsEnumerable);\r\ntestErrorsEnumerable = TestErrors();\r\ntestErrorsDataView = mlContext.CreateStreamingDataView(testErrorsEnumerable);\r\n\r\ndataProcessPipeline = mlContext.Transforms.Conversion.MapValueToKey(\"Label\")\r\n.Append(mlContext.Transforms.Categorical.OneHotEncoding(\"Message\", \"MessageEncoded\"))\r\n\r\nmodelBuilder = new Common.ModelBuilder<Error, Models.ErrorPrediction>(mlContext, dataProcessPipeline);\r\ntrainer = mlContext.MulticlassClassification.Trainers.StochasticDualCoordinateAscent(labelColumn: \"Label\",featureColumn: \"Features\");\r\nmodelBuilder.AddTrainer(trainer);\r\nmodelBuilder.Train(trainErrorsDataView);\r\nvar metrics = modelBuilder.EvaluateMultiClassClassificationModel(testErrorsDataView, \"Label\");\r\nmodelBuilder.SaveModelAsFile(modelFilePath);\r\nvar modelScorer = new Common.ModelScorer<Error, Models.ErrorPrediction>(mlContext);\r\nmodelScorer.LoadModelFromZipFile(modelFilePath);\r\nvar predictionScores = modelScorer.PredictSingle(error);\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2313","RelatedDescription":"Open issue \"MulticlassClassification.Trainers.StochasticDualCoordinateAscent\" (#2313)"},{"Id":"404513875","IsPullRequest":true,"CreatedAt":"2019-01-29T22:23:26","Actor":"ganik","Number":"2312","RawContent":null,"Title":"Lockdown Microsoft.ML.TensorFlow public surface","State":"open","Body":"fixes #2280 ","Url":"https://github.com/dotnet/machinelearning/pull/2312","RelatedDescription":"Open PR \"Lockdown Microsoft.ML.TensorFlow public surface\" (#2312)"},{"Id":"404496742","IsPullRequest":false,"CreatedAt":"2019-01-29T21:34:32","Actor":"eerhardt","Number":"2311","RawContent":null,"Title":"Consider changing Pretrained Dnn Image packages to not be built every day/release","State":"open","Body":"The Pretrained Dnn Image packages:\r\n\r\n- Microsoft.ML.DnnImageFeaturizer.ResNet18/\r\n- Microsoft.ML.DnnImageFeaturizer.ResNet50/\r\n- Microsoft.ML.DnnImageFeaturizer.AlexNet/\r\n- Microsoft.ML.DnnImageFeaturizer.ResNet101/\r\n\r\nContain rather large files. The AlexNet package alone is 200MB.\r\n\r\nHowever, we rebuild and republish these same large files every day in our official build:\r\n\r\nhttps://dotnet.myget.org/feed/dotnet-core/package/nuget/Microsoft.ML.DnnImageFeaturizer.AlexNet\r\n\r\nAnd we publish new versions of them every release:\r\n\r\nhttps://www.nuget.org/packages/Microsoft.ML.DnnImageFeaturizer.AlexNet/\r\n\r\nHowever, the large files in these packages haven't changed 1 time since we've enabled this feature.\r\n\r\nWe should consider splitting these packages up, or some other way of not having to republish the same large files over and over.\r\n\r\n/cc @vaeksare @shauheen @glebuk ","Url":"https://github.com/dotnet/machinelearning/issues/2311","RelatedDescription":"Open issue \"Consider changing Pretrained Dnn Image packages to not be built every day/release\" (#2311)"},{"Id":"404492614","IsPullRequest":false,"CreatedAt":"2019-01-29T21:23:15","Actor":"sfilipi","Number":"2310","RawContent":null,"Title":"All namespaces should have a top-level description","State":"open","Body":"Currently none of our namespaces has a top-level description, causing the description column to be completely empty at [the docs site](https://docs.microsoft.com/en-us/dotnet/api/index?view=ml-dotnet)\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2310","RelatedDescription":"Open issue \"All namespaces should have a top-level description\" (#2310)"},{"Id":"404489044","IsPullRequest":true,"CreatedAt":"2019-01-29T21:13:39","Actor":"Ivanidzo4ka","Number":"2309","RawContent":null,"Title":"Internalize IDataLoader","State":"open","Body":"Towards #https://github.com/dotnet/machinelearning/issues/1995","Url":"https://github.com/dotnet/machinelearning/pull/2309","RelatedDescription":"Open PR \"Internalize IDataLoader\" (#2309)"},{"Id":"404434004","IsPullRequest":true,"CreatedAt":"2019-01-29T19:38:21","Actor":"safern","Number":"2304","RawContent":null,"Title":"Re-enable push to myget","State":"closed","Body":"The issue is fixed so we can enable myget push again.\r\n\r\nhttps://github.com/dotnet/core-eng/issues/5070","Url":"https://github.com/dotnet/machinelearning/pull/2304","RelatedDescription":"Closed or merged PR \"Re-enable push to myget\" (#2304)"},{"Id":"404451038","IsPullRequest":false,"CreatedAt":"2019-01-29T19:30:06","Actor":"eerhardt","Number":"2306","RawContent":null,"Title":"Add a Functional.Tests project that doesn't have InternalsVisibleTo","State":"open","Body":"Today, our ML.NET project has `InternalsVisibleTo` all of our tests projects. This is not ideal because we can't ensure that our public API meets scenarios that our customers can actually use. We could easily internalize something that is necessary to a scenario, but we wouldn't catch it by our tests because our tests all have internal-access.\r\n\r\nWe should add a new test project - or set of test projects - that do not have `InternalsVisibleTo` access. We can put all our public API tests in this project, and we can ensure that customers can use the same code to meet those scenarios. At first we should have at least one test in the project(s), and we can migrate and add new tests over time.\r\n\r\n/cc @TomFinley @shauheen @glebuk ","Url":"https://github.com/dotnet/machinelearning/issues/2306","RelatedDescription":"Open issue \"Add a Functional.Tests project that doesn't have InternalsVisibleTo\" (#2306)"},{"Id":"404447239","IsPullRequest":false,"CreatedAt":"2019-01-29T19:20:26","Actor":"daholste","Number":"2305","RawContent":null,"Title":"Change default # of iterations in Averaged Perceptron to 10","State":"open","Body":"@justinormont figured out that setting default # of iterations to 10 in the Averaged Perceptron learner would lead to better results\r\n\r\nFrom: Justin Ormont\r\nSent: Monday, April 3, 2017 2:52:13 PM\r\nSubject: Re: Move AveragedPerceptron defaults to iter=10 \r\n \r\nGreetings folks,\r\n \r\nI had a chance to run larger datasets, and I think my conclusion holds. \r\n \r\nI did a sweep of the 15GB dataset, and the 2.7TB dataset. \r\n \r\nSweep: 1 to 20 iterations; while it's still running; it's finished most of the experiments and the pattern is pretty clear.\r\n \r\n**15GB text** (note x-axis is number of iterations, not time; y-axis AUC)\r\n![image](https://user-images.githubusercontent.com/43974253/51938308-9cedc800-23c1-11e9-855d-2c08c35de2ad.png)\r\nAlso run (not shown) was **FastTreeBinary**, its AUC is below this graph at 89.1%, and much, much slower.\r\n \r\n**2.7TB numeric** (note x-axis is number iterations, not time; y-axis AUC)\r\n![image](https://user-images.githubusercontent.com/43974253/51938318-a24b1280-23c1-11e9-872e-62a9dedec045.png)\r\n \r\nIt doesn't appear that I've hit overfitting thus far in either dataset. AUC continues to increase from a low at iter=1 (far left), to a high on the right (iter=15)\r\n \r\n## How does AP iterations affect time?\r\n \r\nTime was a bit odd (not a smooth graph) but generally increasing as the number of iterations increases.\r\n \r\n**15GB text** (note x-axis is iteration count, y-axis is time)\r\n\r\n \r\n![image](https://user-images.githubusercontent.com/43974253/51938564-40d77380-23c2-11e9-90d1-0a1027d5a68f.png)\r\n\r\n\r\nTime was almost constant with added iterations (noise is due zooming). There's ~5% runtime difference between fastest and slowest on this graph, with 15 iterations being fastest (likely noise).\r\n\r\nFor 1 iterations: 14,478 (4.0 hours)\r\nFor 10 iterations: 14,623 sec (4.1 hours)\r\nThat's a very sub-linear 1.01x growth from 1 to 10 iterations\r\n \r\n \r\n**2.7TB numeric**  (note x-axis is iteration count, y-axis is time)\r\n \r\n![image](https://user-images.githubusercontent.com/43974253/51938570-47fe8180-23c2-11e9-8973-3e966a417040.png)\r\n\r\n\r\nSorry, the GUI cuts off the time labels on the left. Time given on next line.\r\nFor 1 iteration: 111,367 sec (1.3 days); \r\nFor 10 iterations: 317,203 sec (3.7 days). \r\nThat's a sub-linear 2.8x growth from 1 to 10 iterations.\r\n \r\n \r\nI think the 15GB text dataset fitting fully in memory causes it to have a near constant runtime vs iterations and it's dominated by another factor, like Text featurization[wild guess].\r\nThe dataset being 2.7TB had to have caching turned off, and each iteration had to fetch the data from CT01; data fetch time may have dominated[wild guess].\r\n \r\nPresented is AUC as the datasets are binary. Accuracy graphs look similar though more noisy indicating perhaps we could look at how we're setting the binary threshold.\r\n \r\n**Memory usage**\r\nIn both datasets, memory usage appears flat (plus noise) as iteration count increases.\r\n \r\n \r\n**Methodology**\r\nBoth datasets are binary classification of larger size than previous experiments w/ AveragedPerceptron's iteration count. All experiments were run on HPC with each experiment taking a full node until finished. Data was stored on CT01.\r\n \r\nFor the 2.7 TB numeric dataset, caching, normalization and shuffling were turned off. Caching was disabled due to size (2.7TB)\r\n \r\n\r\n**Conclusion**\r\nFor AveragedPerceptron, iterations=10 seems to be an OK default for these two larger datasets; it appears the \"best\" (in terms of AUC/Acc) hasn't been hit and is above 15 for these. \r\n \r\nFor 10 iterations, the added duration in the 15GB dataset was negligible and the added runtime for the 2.7TB was an additional 1.8x. \r\n \r\nThe 2.7TB dataset gains ~0.2% AUC w/ 10 iterations (~7% decrease in relative AUC-loss [aka, 1-AUC]). The 15G dataset gains ~0.4% AUC w/ 10 iterations (~4% decease in relative AUC-loss).\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2305","RelatedDescription":"Open issue \"Change default # of iterations in Averaged Perceptron to 10\" (#2305)"},{"Id":"404084415","IsPullRequest":true,"CreatedAt":"2019-01-29T18:55:51","Actor":"TomFinley","Number":"2300","RawContent":null,"Title":"Hide much infrastructure in data","State":"closed","Body":"Another of many steps towards #1602. Commits logically structured. No overall theme, just lots of hiding of individual components, most notably command line parsing, entry-point declarations, and other such things.","Url":"https://github.com/dotnet/machinelearning/pull/2300","RelatedDescription":"Closed or merged PR \"Hide much infrastructure in data\" (#2300)"},{"Id":"404222953","IsPullRequest":true,"CreatedAt":"2019-01-29T10:31:12","Actor":"daniel-loudon","Number":"2303","RawContent":null,"Title":"Removed python naming conventions from samples - closes #2155","State":"open","Body":"Fixes #2155 - C# samples should use C# naming conventions and not python naming conventions. Second PR on this issue because last PR had issues\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2303","RelatedDescription":"Open PR \"Removed python naming conventions from samples - closes #2155\" (#2303)"},{"Id":"404033647","IsPullRequest":true,"CreatedAt":"2019-01-29T05:20:08","Actor":"codemzs","Number":"2290","RawContent":null,"Title":"Exclude files not authored by ML.NET from code coverage","State":"closed","Body":"Doesn't make sense to include ONNX ML autogenerated C# to protobuf file generator and Tensorflow sharp files as part of code coverage. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2290","RelatedDescription":"Closed or merged PR \"Exclude files not authored by ML.NET from code coverage\" (#2290)"},{"Id":"404066674","IsPullRequest":true,"CreatedAt":"2019-01-29T03:37:18","Actor":"artidoro","Number":"2295","RawContent":null,"Title":"Fix TextLoader version number for KeyType backward compatibility and added new test","State":"closed","Body":"Fixes #2294.\r\n\r\nI fixed the version number that's used to recognize and load the old `TextLoader` format.\r\n\r\nI also add a test to check that the code for `TextLoader` is actually backward compatible. I created a pipeline that contains a `TextLoader` that loads a `KeyType` using a version of the code prior the changes to `KeyType` and loaded it with the new code checking for the expected behavior.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/2295","RelatedDescription":"Closed or merged PR \"Fix TextLoader version number for KeyType backward compatibility and added new test\" (#2295)"},{"Id":"404065679","IsPullRequest":false,"CreatedAt":"2019-01-29T03:37:18","Actor":"artidoro","Number":"2294","RawContent":null,"Title":"TextLoader backcompat version number is wrong ","State":"closed","Body":"The version number for backwards compatibility comparison in TextLoader is wrong. It should be updated to the correct version number 0x0001000C.\r\n\r\nWe should also add a test for backwards compatibility.\r\n\r\nThis is related to the change #2146.","Url":"https://github.com/dotnet/machinelearning/issues/2294","RelatedDescription":"Closed issue \"TextLoader backcompat version number is wrong \" (#2294)"},{"Id":"404071500","IsPullRequest":false,"CreatedAt":"2019-01-29T00:44:04","Actor":"Ivanidzo4ka","Number":"2299","RawContent":null,"Title":"FastRank MSM sparse test baselines are suspicious ","State":"open","Body":"We shouldn't have this \r\nhttps://github.com/dotnet/machinelearning/blob/master/test/BaselineOutput/Common/FastRank/FastRank-TrainTest-MSM-sparse-sample-out.txt\r\n`Could not find file '%Data%`\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/master/test/BaselineOutput/Common/FastRank/FastRank-TrainTest-MSM-sparse-sample-test-out.txt\r\n`Unexpected exception: Could not find file '%Output% 'System.IO.FileNotFoundException'`\r\n\r\nWe shouldn't have such baselines.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/2299","RelatedDescription":"Open issue \"FastRank MSM sparse test baselines are suspicious \" (#2299)"},{"Id":"404069870","IsPullRequest":false,"CreatedAt":"2019-01-29T00:36:58","Actor":"Anipik","Number":"2298","RawContent":null,"Title":"AvxIntrinsics.DotSU is Slower than the native version ","State":"open","Body":"We can verify this by running the benchmark https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/Text/MultiClassClassification.cs#L62\r\n\r\n``` ini\r\n\r\n\r\n```\r\n|      Method |     (netcoreapp2.1)Mean |    Error |   StdDev |        netcoreapp3.0 |\r\n|------------ |--------------:|---------:|---------:|--------------------:|\r\n| PredictIris | 148.84s | 28.107 s | 1.5 s | 158.3s |\r\n\r\nI verified using the perfview that the cause of regression is DotSU. The exclusive time fot DotSU on netcoreapp3.0  is 70s and on native version of cpumath is 47 s\r\n\r\n\r\ncc @danmosemsft @adamsitnik @tannergooding @eerhardt \r\n","Url":"https://github.com/dotnet/machinelearning/issues/2298","RelatedDescription":"Open issue \"AvxIntrinsics.DotSU is Slower than the native version \" (#2298)"},{"Id":"404069855","IsPullRequest":false,"CreatedAt":"2019-01-29T00:36:56","Actor":"eerhardt","Number":"2297","RawContent":null,"Title":"Naming overhaul for IDataView subsystem","State":"open","Body":"We should make sure the type names in the IDataView subsystem are the names we want to use forever.\r\n\r\nSee \r\n\r\n1. https://github.com/dotnet/machinelearning/pull/2220#discussion_r251141578\r\n\r\n> If all of these types are column types, should they include column in the name? e.g. TextColumnType?\r\n\r\n2. https://github.com/dotnet/machinelearning/pull/2254#discussion_r251259500\r\n\r\n> The idea was broached I know, but resolution never reached: should we rename? Or else perhaps make Schema a nested class of something appropriate, so as to give it definition?\r\n\r\n> We could rename the class to DataViewSchema, or ViewSchema.\r\nWeâ€™d probably want to rename everything then. Row is a pretty generic name. So is ColumnType.","Url":"https://github.com/dotnet/machinelearning/issues/2297","RelatedDescription":"Open issue \"Naming overhaul for IDataView subsystem\" (#2297)"},{"Id":"404058095","IsPullRequest":false,"CreatedAt":"2019-01-28T23:46:22","Actor":"Anipik","Number":"2293","RawContent":null,"Title":"SequencePool.GetCore slower on netcoreapp3.0","State":"open","Body":"https://github.com/dotnet/machinelearning/blob/master/test/Microsoft.ML.Benchmarks/Text/MultiClassClassification.cs#L122 \r\n\r\nBenchmark is slower on netcoreapp3.0. On investigation, I find out the major culprit for the regression is the function below\r\n\r\n\r\n```C#\r\n// Returns the ID of the requested sequence, or -1 if it is not found.\r\nprivate int GetCore(uint[] sequence, int min, int lim, out uint hash)\r\n{\r\n    AssertValid();\r\n    Contracts.Assert(0 <= min && min <= lim && lim <= Utils.Size(sequence));\r\n\r\n    hash = Hashing.HashSequence(sequence, min, lim);\r\n\r\n    for (int idCur = GetFirstIdInBucket(hash); idCur >= 0; idCur = _next[idCur])\r\n    {\r\n        Contracts.Assert(0 <= idCur && idCur < _idLim);\r\n        if (_hash[idCur] != hash)\r\n            continue;\r\n\r\n        var ibCur = _start[idCur];\r\n        var ibLim = _start[idCur + 1];\r\n        for (int i = min; ; i++)\r\n        {\r\n            Contracts.Assert(ibCur <= ibLim);\r\n            if (i >= lim)\r\n            {\r\n                // Need to make sure that we have reached the end of the sequence in the pool at the\r\n                // same time that we reached the end of sequence.\r\n                if (ibCur == ibLim)\r\n                    return idCur;\r\n                break;\r\n            }\r\n            if (ibCur >= ibLim)\r\n                break;\r\n            uint decoded;\r\n            var success = TryDecodeOne(_bytes, ref ibCur, _start[idCur + 1], out decoded);\r\n            Contracts.Assert(success);\r\n            if (sequence[i] != decoded)\r\n                break;\r\n        }\r\n    }\r\n    return -1;\r\n}\r\n```\r\n\r\nThe exclusive time for this function on netcore2.1 is areound 689ms where as on netcoreapp3.0 it takes around 824ms\r\n\r\nThe function is defined here https://github.com/dotnet/machinelearning/blob/master/src/Microsoft.ML.Data/Utils/SequencePool.cs#L151\r\n\r\nI was not able to find any reason behind this regression. cc @eerhardt @danmosemsft @jkotas \r\n","Url":"https://github.com/dotnet/machinelearning/issues/2293","RelatedDescription":"Open issue \"SequencePool.GetCore slower on netcoreapp3.0\" (#2293)"},{"Id":"404050430","IsPullRequest":false,"CreatedAt":"2019-01-28T23:16:35","Actor":"codemzs","Number":"2292","RawContent":null,"Title":"Tensorflow sharp files need to come from a nuget ","State":"open","Body":"The files under Microsoft.ML.Tensorflow/Tensorflow should come from a nuget since ML.NET team does not maintain these files. These files are also included in code coverage when they should not be, PR #2290 removes them.","Url":"https://github.com/dotnet/machinelearning/issues/2292","RelatedDescription":"Open issue \"Tensorflow sharp files need to come from a nuget \" (#2292)"},{"Id":"404043553","IsPullRequest":false,"CreatedAt":"2019-01-28T22:53:04","Actor":"codemzs","Number":"2291","RawContent":null,"Title":"ONNXML.cs needs to be generated at BUILD","State":"open","Body":"Currently ONNXML.cs is generated manually using protobuf definition. It is also included as part of code coverage which should not happen and PR #2290 will remove it. We need to make it such that it is clear that file is not authored by ML.NET team and is coming from an external source. \r\n\r\nCC: @wschin , @shauheen , @TomFinley ","Url":"https://github.com/dotnet/machinelearning/issues/2291","RelatedDescription":"Open issue \"ONNXML.cs needs to be generated at BUILD\" (#2291)"}],"ResultType":"GitHubIssue"}},"RunOn":"2019-01-30T05:30:57.5277391Z","RunDurationInMilliseconds":858}