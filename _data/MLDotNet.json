{"Data":{"GitHub":{"Issues":[{"Id":"755796602","IsPullRequest":true,"CreatedAt":"2020-12-03T04:02:54","Actor":"antoniovs1029","Number":"5526","RawContent":null,"Title":"[Draft] Investigate NugetRestorePath","State":"open","Body":"...","Url":"https://github.com/dotnet/machinelearning/pull/5526","RelatedDescription":"Open PR \"[Draft] Investigate NugetRestorePath\" (#5526)"},{"Id":"755640168","IsPullRequest":true,"CreatedAt":"2020-12-03T01:13:27","Actor":"harishsk","Number":"5525","RawContent":null,"Title":"Merge arcade to master","State":"closed","Body":"Merging Arcade to Master.\r\nThe branch is mostly stable. The following issues are being tracked and the rest of the work will be completed in master.\r\n* Failure in benchmark tests\r\n* Code coverage builds not yet working\r\n* Some warnings associated with nuget packages","Url":"https://github.com/dotnet/machinelearning/pull/5525","RelatedDescription":"Closed or merged PR \"Merge arcade to master\" (#5525)"},{"Id":"755526139","IsPullRequest":true,"CreatedAt":"2020-12-02T21:46:26","Actor":"harishsk","Number":"5523","RawContent":null,"Title":"[Draft] Testing arcade branch merge to master","State":"closed","Body":"This is a draft pull request to prepare merging arcade to master. I may abandon this PR and redo it once the remaining fixes are in. \r\nThis is a test.","Url":"https://github.com/dotnet/machinelearning/pull/5523","RelatedDescription":"Closed or merged PR \"[Draft] Testing arcade branch merge to master\" (#5523)"},{"Id":"754934613","IsPullRequest":true,"CreatedAt":"2020-12-02T20:32:19","Actor":"harishsk","Number":"5521","RawContent":null,"Title":"Fixed leak in object pool","State":"closed","Body":"I noticed this issue when running `OneHotHashEncodingOnnxConversionTest` for several iterations. Even after the Onnx related memory leaks were fixed, memory usage kept increasing at each iteration. When I took memory snapshots at the beginning of each iteration I noticed that about 1400 `Single[]` objects were being leaked (amounting to about 180MB). \r\nThe allocation of these objects can be traced to the object pool implemented using `ConcurrentBag`. It appears that the `ConcurrentBag` objects stay on in memory associated with the threads. (I haven't figured how these should be disposed off correctly yet). But removing the objects in the pool gets rid of those objects from the managed heap by the start of the second iteration and memory usage remains far more stable across iterations.\r\n\r\nThis also fixes memory leaks in my local x86 builds.\r\n\r\nSince this is part of core ML.NET code that has been untouched for a long time, it is possible I may have overlooked something. Please review this.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5521","RelatedDescription":"Closed or merged PR \"Fixed leak in object pool\" (#5521)"},{"Id":"750087868","IsPullRequest":true,"CreatedAt":"2020-12-02T19:33:06","Actor":"antoniovs1029","Number":"5509","RawContent":null,"Title":"Handle integration tests and nightly build testing","State":"closed","Body":"1. To enable running the \"Integration tests\" (formerly known as Functional tests) by using \"build.cmd -integrationTest\"\r\n2. Also enabling the nightly build that is triggered everyday at midnight to run the integration tests","Url":"https://github.com/dotnet/machinelearning/pull/5509","RelatedDescription":"Closed or merged PR \"Handle integration tests and nightly build testing\" (#5509)"},{"Id":"755539672","IsPullRequest":true,"CreatedAt":"2020-12-02T19:11:06","Actor":"LeoGaunt","Number":"5524","RawContent":null,"Title":"Fixed Spelling on stopwords","State":"open","Body":"Relates to issue #5514\r\n\r\nChanges stopwrods -> stopwords within the StopWordsRemovingTransformer.cs\r\nFixed the spelling  \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5524","RelatedDescription":"Open PR \"Fixed Spelling on stopwords\" (#5524)"},{"Id":"754973123","IsPullRequest":false,"CreatedAt":"2020-12-02T06:05:44","Actor":"khteh","Number":"5522","RawContent":null,"Title":"Taxi Fare value prediction tutorial ModelOutput does not have the prediction value property!","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:\r\n```\r\nC:\\>dotnet --info\r\n.NET SDK (reflecting any global.json):\r\n Version:   5.0.100\r\n Commit:    5044b93829\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.18363\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\5.0.100\\\r\n\r\nHost (useful for support):\r\n  Version: 5.0.0\r\n  Commit:  cf258a14b7\r\n\r\n.NET SDKs installed:\r\n  1.0.0-preview1-002702 [C:\\Program Files\\dotnet\\sdk]\r\n  1.0.0-preview2-003121 [C:\\Program Files\\dotnet\\sdk]\r\n  1.0.0-preview2-003131 [C:\\Program Files\\dotnet\\sdk]\r\n  2.0.2 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.2 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.4 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.200 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.302 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.400 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.401 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.402 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.403 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.602 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009597 [C:\\Program Files\\dotnet\\sdk]\r\n  2.1.700-preview-009601 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.202 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.203 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.300-preview-010046 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.300-preview-010050 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.300 [C:\\Program Files\\dotnet\\sdk]\r\n  2.2.401 [C:\\Program Files\\dotnet\\sdk]\r\n  3.0.100 [C:\\Program Files\\dotnet\\sdk]\r\n  3.1.101 [C:\\Program Files\\dotnet\\sdk]\r\n  5.0.100 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.1.23 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.All 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.1.23 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 5.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 1.0.0-rc2-3002702 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 1.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 1.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.7 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.0.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.2 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.3-servicing-26724-03 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.1.23 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.4 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.5 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 2.2.6 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 5.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 3.1.9 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 5.0.0 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\nTo install additional .NET runtimes or SDKs:\r\n  https://aka.ms/dotnet-download\r\n```\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI try to create a Value Prediction for taxi fare based on https://dotnet.microsoft.com/learn/ml-dotnet/get-started-tutorial/next\r\n- **What happened?**\r\nGenerated `ModelOutput` class does not have the `fare_amount` property which is the predicted value. It only contains the `Score` property.\r\n- **What did you expect?**\r\n`ModelOutput` class should contain the `fare_amount` property which is the predicted taxi fare value.\r\n### Source code / logs\r\n\r\nNo source code. It's very straight forward from following the tutorial steps and you will see it immediately at the `Coding` stage of the pipeline.","Url":"https://github.com/dotnet/machinelearning/issues/5522","RelatedDescription":"Open issue \"Taxi Fare value prediction tutorial ModelOutput does not have the prediction value property!\" (#5522)"},{"Id":"754639718","IsPullRequest":true,"CreatedAt":"2020-12-02T04:31:58","Actor":"harishsk","Number":"5518","RawContent":null,"Title":"Fixed memory leaks from OnnxTransformer","State":"closed","Body":"This PR fixes memory leaks originating from the OnnxTransformer. \r\n\r\nThe NamedOnnxValue objects returned from the Run call of InferenceSession were being leaked. To fix, the caching mechanism had to be fixed as well. Briefly, we need to use a single `OnnxRuntimeOutputCacher` when the getters are created for an input row. Only that would allow us to cache the results of executing inference on an input row. The earlier code was creating an `OnnxRuntimeOutputCacher` for each column and that was not really doing any caching. \r\n\r\nIn order to do that, OnnxTransformer needed to implement `IRowMapper` directly instead of inhering from `MapperBase` because we need to override `CreateGetters` and store the `OnnxRuntimeOutputCacher`. The bulk of the changes in this PR are due to this refactor.   \r\n\r\nAlso, from the same getter, multiple rows of can be inferenced. So we need to dispose off the previous results before caching the next results. This PR takes care of both.\r\nIt also fixes a couple of build strips to support testing on x86 from Visual Studio.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5518","RelatedDescription":"Closed or merged PR \"Fixed memory leaks from OnnxTransformer\" (#5518)"},{"Id":"747308715","IsPullRequest":true,"CreatedAt":"2020-12-02T03:53:23","Actor":"guinao","Number":"5502","RawContent":null,"Title":"Fix SR anomaly score calculation at beginning","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n#5491 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/5502","RelatedDescription":"Closed or merged PR \"Fix SR anomaly score calculation at beginning\" (#5502)"},{"Id":"754608782","IsPullRequest":true,"CreatedAt":"2020-12-01T23:41:01","Actor":"michaelgsharp","Number":"5517","RawContent":null,"Title":"fixes ort memory leak","State":"closed","Body":"Fixes the ORT memory leak by disposing of the NamedOnnxValues and makes the OnnxRuntimeOutputCacher disposable and adds a finalizer.","Url":"https://github.com/dotnet/machinelearning/pull/5517","RelatedDescription":"Closed or merged PR \"fixes ort memory leak\" (#5517)"},{"Id":"754697272","IsPullRequest":true,"CreatedAt":"2020-12-01T23:14:00","Actor":"antoniovs1029","Number":"5519","RawContent":null,"Title":"[Draft] Debug Mkl not found on CodeGenerator tests error","State":"closed","Body":"Debugging error","Url":"https://github.com/dotnet/machinelearning/pull/5519","RelatedDescription":"Closed or merged PR \"[Draft] Debug Mkl not found on CodeGenerator tests error\" (#5519)"},{"Id":"754747726","IsPullRequest":true,"CreatedAt":"2020-12-01T22:47:36","Actor":"frank-dong-ms","Number":"5520","RawContent":null,"Title":"fix code generator tests failure","State":"closed","Body":"we are seeing below error after fix mkl components nuget issue:\r\n\r\nmlnet.Tests.TransformGeneratorTests.OneHotHashEncodingTest [FAIL]\r\nSystem.TypeInitializationException : The type initializer for 'Microsoft.ML.TestFramework.BaseTestClass' threw an exception.\r\n---- System.DllNotFoundException : Unable to load shared library 'MklImports' or one of its dependencies. In order to help diagnose loading problems, consider setting the DYLD_PRINT_LIBRARIES environment variable: dlopen(libMklImports, 1): image not found\r\n\r\nadd NativeAssemblyReference to MklImports so MklImports.dll will be copy to output dir of code generator tests project and resolve the dependency failure.","Url":"https://github.com/dotnet/machinelearning/pull/5520","RelatedDescription":"Closed or merged PR \"fix code generator tests failure\" (#5520)"},{"Id":"749362558","IsPullRequest":true,"CreatedAt":"2020-12-01T18:41:22","Actor":"harishsk","Number":"5507","RawContent":null,"Title":"Fixed some of the memory leaks","State":"closed","Body":"Added IDisposable to OnnxRuntimeOutputCacher and added using clauses to tests in OnnxConversionTests.","Url":"https://github.com/dotnet/machinelearning/pull/5507","RelatedDescription":"Closed or merged PR \"Fixed some of the memory leaks\" (#5507)"},{"Id":"749165881","IsPullRequest":true,"CreatedAt":"2020-12-01T03:47:56","Actor":"mstfbl","Number":"5506","RawContent":null,"Title":"Fix AutoFitMaxExperimentTimeTest","State":"closed","Body":"Edited by @antoniovs1029 : This PR now fixes the described problem\r\n\r\n-------\r\nDebugging occasional AutoFitMaxExperimentTimeTest failures, where sometimes the last model being trained is stopped and its provided exception is not \"Operation was canceled\".","Url":"https://github.com/dotnet/machinelearning/pull/5506","RelatedDescription":"Closed or merged PR \"Fix AutoFitMaxExperimentTimeTest\" (#5506)"},{"Id":"751173883","IsPullRequest":true,"CreatedAt":"2020-12-01T00:15:48","Actor":"mstfbl","Number":"5512","RawContent":null,"Title":"Fixed official builds for Arcade SDK","State":"closed","Body":"This PR fixes the official builds for ML.NET's Arcade SDK changes. \r\n\r\nThe failing trusted CI machine DDVSOWINAGE072 has been fixed, more info in this issue: https://github.com/dotnet/core-eng/issues/11513\r\n\r\nLink to the trusted and successful build of these changes: https://devdiv.visualstudio.com/DevDiv/_build/results?buildId=4255993&view=results","Url":"https://github.com/dotnet/machinelearning/pull/5512","RelatedDescription":"Closed or merged PR \"Fixed official builds for Arcade SDK\" (#5512)"},{"Id":"753881813","IsPullRequest":false,"CreatedAt":"2020-11-30T23:36:38","Actor":"nnoradie","Number":"5516","RawContent":null,"Title":"Unexpected anomalies detected","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n![image](https://user-images.githubusercontent.com/69877427/100674957-e3dcd980-331a-11eb-8995-e1ecb7af17d6.png)\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nDetect anomalies on data with obvious anomalies and mostly flat data everywhere else\r\n\r\n- **What happened?**\r\nMany unexpected anomalies were detected (two in image, more in output data in zip attached)\r\n![image](https://user-images.githubusercontent.com/69877427/100677778-9fecd300-3320-11eb-8e90-b09b3735fc7c.png)\r\n\r\n- **What did you expect?**\r\nOnly the obvious anomalies in the middle to be detected\r\n\r\n### Source code / logs\r\n[testdata.zip](https://github.com/dotnet/machinelearning/files/5619308/testdata.zip) \r\n\r\nContents:\r\n1. odd_anomalies_data.csv (input)\r\n2. test_date_out.csv (anomaly detection results using code [here](https://github.com/dotnet/machinelearning/issues/5491#issuecomment-729338262) with edited options below)\r\n\r\n![image](https://user-images.githubusercontent.com/69877427/100677614-3b317880-3320-11eb-8b24-586848d59c98.png)\r\n\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5516","RelatedDescription":"Open issue \"Unexpected anomalies detected\" (#5516)"},{"Id":"753210211","IsPullRequest":false,"CreatedAt":"2020-11-30T07:00:36","Actor":"steentottrup","Number":"5515","RawContent":null,"Title":"Failed getting ML Vision (Tensor) solution running on Windows Server 2016 Std on IIS","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: WINDOWS SERVER 2016\r\n- **.NET Version (eg., dotnet --info)**: dotnetcore/aspnetcore 5\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI'm building an ASP.NET Core Web Application, Razor Pages and Api controllers. I'm using ML.NET, with ML.NET Vision, ML.NET ImageAnalytics and Tensorflow (SciSharp.TensorFlow.Redist).\r\nThe solution has been build on AppVeyor (with MSBuild). I've tried doing a\r\n`dotnet publish -r win-x64 --self-contained false`\r\nand \r\n`dotnet publish -r win-x64 --self-contained true`\r\nand \r\n`dotnet publish -r win-x64`\r\nbut none of it has worked. The tensorflow dll is included in the publish folder, so I'm guessing it's one of it's dependencies that are missing.\r\n\r\n- **What happened?**\r\nEverything is working perfectly on my developer machine, IIS EXpress, Visual Studio 2019, etc. When trying to deploy the finished solution to a server, the ASP.NET Core Web Application runs as expected, but once I hit the endpoint that uses ML.NET, it fails.\r\n- **What did you expect?**\r\nI was expecting the web application to work on the server running on IIS , as it is locally.\r\n\r\n### Source code / logs\r\n\r\n2020-11-29 19:22:10.030 +01:00 [Error] An unhandled exception has occurred while executing the request.\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.DllNotFoundException: Unable to load DLL 'tensorflow' or one of its dependencies: The specified module could not be found. (0x8007007E)\r\n   at Tensorflow.c_api.TF_NewGraph()\r\n   at Tensorflow.Graph..ctor()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSession(IExceptionContext ectx, Byte[] modelBytes, String modelFile)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.MulticlassPredictionTransformer.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at System.Reflection.MethodBase.Invoke(Object obj, Object[] parameters)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstance(IHostEnvironment env, Object args, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)\r\n   at BrickId.ObjectDetection.Torso.TorsoPrediction.Predict(ModelInput input) in C:\\projects\\cmd\\brickid\\src\\BrickId.ObjectDetection.Torso\\TorsoPrediction.cs:line 19\r\n   at BrickId.Core.CQS.Queries.Preditions.Torso.GetTorsoPreditionQueryHandler.HandleAsync(GetTorsoPreditionQuery query, CancellationToken cancellationToken) in C:\\projects\\cmd\\brickid\\src\\BrickId.Core\\CQS\\Queries\\Predictions\\Torso\\GetTorsoPreditionQueryHandler.cs:line 44\r\n   at CreativeMinds.CQS.Permissions.GenericPermissionCheckAsyncQueryHandlerDecorator`2.HandleAsync(TQuery query, CancellationToken cancellationToken)\r\n   at CreativeMinds.CQS.Validators.GenericValidationAsyncQueryHandlerDecorator`2.HandleAsync(TQuery query, CancellationToken cancellationToken)\r\n   at lambda_method386(Closure , Object )\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Awaited|12_0(ControllerActionInvoker invoker, ValueTask`1 actionResultValueTask)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeInnerFilterAsync>g__Awaited|13_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextResourceFilter>g__Awaited|24_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResourceExecutedContextSealed context)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)\r\n   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Logged|17_1(ResourceInvoker invoker)\r\n   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)\r\n   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware.Invoke(HttpContext context)\r\n   at Microsoft.AspNetCore.Diagnostics.ExceptionHandlerMiddleware.<Invoke>g__Awaited|6_0(ExceptionHandlerMiddleware middleware, HttpContext context, Task task)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5515","RelatedDescription":"Open issue \"Failed getting ML Vision (Tensor) solution running on Windows Server 2016 Std on IIS\" (#5515)"},{"Id":"752771574","IsPullRequest":false,"CreatedAt":"2020-11-28T21:28:57","Actor":"justinormont","Number":"5514","RawContent":null,"Title":"Spelling: stopwrods","State":"open","Body":"Our stop word remover has a variable misspelt as `stopwrods` instead of `stopwords`:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/7879849e9ae79f8f40bda65bf7fd7fa6131c454e/src/Microsoft.ML.Transforms/Text/StopWordsRemovingTransformer.cs#L987-L1015","Url":"https://github.com/dotnet/machinelearning/issues/5514","RelatedDescription":"Open issue \"Spelling: stopwrods\" (#5514)"},{"Id":"752690324","IsPullRequest":false,"CreatedAt":"2020-11-28T14:45:56","Actor":"AniaBerthelot","Number":"5513","RawContent":null,"Title":"Is it possible to combine custom and default StopWordsRemoving options?","State":"open","Body":"Actually I use Regex to preclean text after pushing it to ML.NET but my list of stop words is growing, and also I think that if I can leverage on the StopWordsRemoving loop it will be faster to do it once rather than Regex then StopWordsRemoving (do you confirm that? If StopWordsRemoving options are combined one loop of cleaning will be done? or 2 (default and custom).\r\nCustomStopWordsRemovingEstimator.Options StopWordsRemovingEstimator.Options\r\n\r\nDo you provide any way to remove emojis, flags...?\r\n\r\nThank you for this amazing library","Url":"https://github.com/dotnet/machinelearning/issues/5513","RelatedDescription":"Open issue \"Is it possible to combine custom and default StopWordsRemoving options?\" (#5513)"},{"Id":"750996581","IsPullRequest":false,"CreatedAt":"2020-11-25T20:55:41","Actor":"itwithlyam","Number":"5511","RawContent":null,"Title":"Unable to split the file provided into multiple, consistent columns. (.tsv)","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 3.1.402\r\n\r\n### Issue\r\n\r\n- **What did you do?** I was trying to use ML.NET to create a support desk application.\r\n- **What happened?** Once I pressed \"start training\" this error came:\r\n`   Unable to split the file provided into multiple, consistent columns.\r\nat Microsoft.ML.AutoML.ColumnInferenceApi.InferSplit(MLContext context, TextFileSample sample, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse)\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferColumns(MLContext context, String path, ColumnInformation columnInfo, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse, Boolean trimWhitespace, Boolean groupColumns, Boolean hasHeader)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.InferColumns(MLContext context, AutoMLServiceParamater config, ColumnInformation columnInformation)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__30.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 112`\r\n- **What did you expect?**\r\n\r\n### Source code / logs\r\nLogs:\r\nat Microsoft.ML.AutoML.ColumnInferenceApi.InferSplit(MLContext context, TextFileSample sample, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse)\r\n   at Microsoft.ML.AutoML.ColumnInferenceApi.InferColumns(MLContext context, String path, ColumnInformation columnInfo, Nullable`1 separatorChar, Nullable`1 allowQuotedStrings, Nullable`1 supportSparse, Boolean trimWhitespace, Boolean groupColumns, Boolean hasHeader)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.InferColumns(MLContext context, AutoMLServiceParamater config, ColumnInformation columnInformation)\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.<StartTrainingAsync>d__30.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 112\r\nTSV file:\r\nID\tQuestion Category\r\n1\tMy printer isn't working.\tPrinter\r\n1\tPrinter\tPrinter\r\n2\tI can't turn on my computer.\tComputer\r\n3\tI would like to book a chromebook.\tChromebooks\r\n1\tMy printer won't print.\tPrinter\r\n1\tMy printer isn't working.\tPrinter\r\n1\tI can't print\tPrinter\r\n2\tMy computer isn't working\tComputer\r\n2\tMy computer isn't turning on\tComputer\r\n2\tComputer\tComputer\r\n2\tMy computer is malfunctioning.\tComputer\r\n3\tChromebooks\tChromebooks\r\n3\tI would like a chromebook.\tChromebooks\r\n3\tHow can I book a chromebook?\tChromebooks\r\n3\tMy chromebook isn't charging.\r\n\r\n(before you ask, the tabs are formatted correctly in VS)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.","Url":"https://github.com/dotnet/machinelearning/issues/5511","RelatedDescription":"Closed issue \"Unable to split the file provided into multiple, consistent columns. (.tsv)\" (#5511)"},{"Id":"750098208","IsPullRequest":true,"CreatedAt":"2020-11-25T01:45:56","Actor":"antoniovs1029","Number":"5510","RawContent":null,"Title":"Disabling AutoFitMaxExperimentTimeTest","State":"closed","Body":"The test is sometimes causing CI failures which block PRs.\r\nDisabling it temporally, while the root cause is investigated on #5506 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/5510","RelatedDescription":"Closed or merged PR \"Disabling AutoFitMaxExperimentTimeTest\" (#5510)"},{"Id":"749499104","IsPullRequest":false,"CreatedAt":"2020-11-24T08:40:28","Actor":"kennywangjin","Number":"5508","RawContent":null,"Title":"Failed to deploy ML image classification model with aspnetcore webapi:","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: WINDOWS SERVER 2019 \r\n- **.NET Version (eg., dotnet --info)**:  dotnetcore 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI have trained image classification using ML.Net and integrated model to aspnetcore webapi.\r\n- **What happened?**\r\nWebApi worked fine on my local development machine. But it failed to work when i deploy webapi to the server IIS.\r\nwindows showed error:\r\n**Windows cannot access the file  for one of the following reasons: there is a problem with the network connection, the disk that the file is stored on, or the storage drivers installed on this computer; or the disk is missing. Windows closed the program IIS Worker Process because of this error.\r\n\r\nProgram: IIS Worker Process\r\nFile: \r\n\r\nThe error value is listed in the Additional Data section.\r\nUser Action\r\n1. Open the file again. This situation might be a temporary problem that corrects itself when the program runs again.\r\n2. If the file still cannot be accessed and\r\n\t- It is on the network, your network administrator should verify that there is not a problem with the network and that the server can be contacted.\r\n\t- It is on a removable disk, for example, a floppy disk or CD-ROM, verify that the disk is fully inserted into the computer.\r\n3. Check and repair the file system by running CHKDSK. To run CHKDSK, click Start, click Run, type CMD, and then click OK. At the command prompt, type CHKDSK /F, and then press ENTER.\r\n4. If the problem persists, restore the file from a backup copy.\r\n5. Determine whether other files on the same disk can be opened. If not, the disk might be damaged. If it is a hard disk, contact your administrator or computer hardware vendor for further assistance.\r\n\r\nAdditional Data\r\nError value: 00000000\r\nDisk type: 0**\r\n**Faulting application name: w3wp.exe, version: 10.0.17763.1, time stamp: 0xcfdb13d8\r\nFaulting module name: tensorflow.DLL, version: 0.0.0.0, time stamp: 0x5f77815a\r\nException code: 0xc000001d\r\nFault offset: 0x00000000003aec32\r\nFaulting process id: 0x3410\r\nFaulting application start time: 0x01d6c230bdc0bf5c\r\nFaulting application path: c:\\windows\\system32\\inetsrv\\w3wp.exe\r\nFaulting module path: C:\\inetpub\\wwwroot\\runtimes\\win-x64\\native\\tensorflow.DLL\r\nReport Id: 003ff975-a029-4989-96e6-cca406a8b89d\r\nFaulting package full name: \r\nFaulting package-relative application ID: **\r\n- **What did you expect?**\r\nWebApi and ML.net should have same behavior on local machine and remote server.\r\n\r\n### Source code / logs\r\n\r\n[proj.txt](https://github.com/dotnet/machinelearning/files/5588449/proj.txt)\r\n\r\n[file1.txt](https://github.com/dotnet/machinelearning/files/5588455/file1.txt)\r\n[startup.txt](https://github.com/dotnet/machinelearning/files/5588458/startup.txt)\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5508","RelatedDescription":"Open issue \"Failed to deploy ML image classification model with aspnetcore webapi:\" (#5508)"},{"Id":"748030663","IsPullRequest":false,"CreatedAt":"2020-11-21T14:43:24","Actor":"denisdnl","Number":"5505","RawContent":null,"Title":"Import tensorflow model from keras generated one","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**: 5 \r\n\r\n### Issue\r\n\r\n- **What did you do?** Tried to create in keras a simple NN(7 inputs, 10 outputs), freeze the model and import it in ML.Net\r\n- **What happened?** Exception\r\n- **What did you expect?** To be successfully imported \r\n\r\n### Source code / logs\r\n\r\nHi all,\r\nI created a simple neural net using keras in python, and wanted to export it to ML.Net. First try was to save it in \"tf\" format, but as i saw, ML.Net needs a frozen model. So i tried to freeze it using this approach: [https://hellobird.tistory.com/399](https://hellobird.tistory.com/399), i have generated the .pb file, but when i try to **mlContext.Model.LoadTensorFlowModel(pathToModel);** an ** Tensorflow.TensorflowException: 'Could not find meta graph def matching supplied tags: { serve }. To inspect available tag-sets in the SavedModel, please use the SavedModel CLI: `saved_model_cli`' exception is thrown \r\n**\r\n\r\n\r\nThe python code is this attached \r\n\r\n[test.txt](https://github.com/dotnet/machinelearning/files/5577780/test.txt)\r\nand the pb file(I changed it's extension so i could upload):\r\n[model.txt](https://github.com/dotnet/machinelearning/files/5577783/model.txt)\r\n\r\n\r\n\r\nI saved the pb, i imported it to VS and the c# code:\r\n\r\n` \r\n  \r\n             var mlContext = new MLContext();\r\n            \r\n            var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(pathToModel);\r\n            \r\n            var pipeline = mlContext.Transforms.Concatenate(\"Features\",\r\n                    new[] { \"Bathrooms\", \"SqftLiving\", \"SqftLot\", \"Floors\", \"YearBuild\", \"YearRenovated\", \"Price\" })\r\n                .Append(tensorFlowModel.ScoreTensorFlowModel(\"Prediction/Softmax\", \"Features\"))\r\n                .Append(mlContext.Transforms.CopyColumns(\"Scores\", \"Prediction/Softmax\"));\r\n\r\n\r\n            var dataView = mlContext.Data.LoadFromEnumerable(Enumerable.Empty<House>(), tensorFlowModel.GetModelSchema());\r\n            var transformer = pipeline.Fit(dataView);`\r\n\r\nBut on the second line i got that error.\r\n\r\nIs there any known issue about this or any sample code that shows how to export a model from python in ML.Net that works?\r\n\r\nThanks ^_^ \r\n\r\n\r\nL.E: Found the problem. It seems it needs the whole path(including the file name, not only the folder)","Url":"https://github.com/dotnet/machinelearning/issues/5505","RelatedDescription":"Closed issue \"Import tensorflow model from keras generated one\" (#5505)"},{"Id":"747997199","IsPullRequest":false,"CreatedAt":"2020-11-21T11:01:15","Actor":"frankhaugen","Number":"5504","RawContent":null,"Title":"Is it possible to do continuous/incremental learning in ML.net? [question]","State":"open","Body":"I was unsure if I should ask here or on Stack Overflow.  \r\n(SO have less than 400 questions with the `ml.net`-tag, so I doubt there is a critical mass of people who bother to to follow the tag)\r\n\r\n**TL;DR:**  \r\n> Is it possible to do small incremental changes to a trained model?\r\n\r\n**Scenario**  \r\nWhere I work, we have an AI/ML/DL product called Semine, which does classification of invoices for accounting purposes, e.g. detecting what \"accounting code\" a specific invoice line is. We had a brilliant Ph.D. in statistics consult with us and write an optimized algorithm for our needs. I'd love to describe it in details but I'm not contractually allowed to divulge trade secrets, but in general: When an invoice is \"posted\", the relevant values are added to the pile of data which is used by the algorithm. Then there is an \"incremental learning\" on that action, and not a complete re-train of the entire model; Having to retrain an entire model a few thousand times per day would not be financially responsible.\r\n\r\n**Question**  \r\nIs there a way to do this type on learning in ML.net? Just a tweak, based on a small change to the underlying data? `#AskingForAFriend` 😆 \r\n\r\n**My efforts**  \r\nHaving googled, (even with Bing 😆 ), it's evident that there are a lot of questions about this, but no clear answers or examples. So a definitive \"yes/no\" on the question of if it is possible, and if it will be possible\r\n\r\nThank you for your time!","Url":"https://github.com/dotnet/machinelearning/issues/5504","RelatedDescription":"Open issue \"Is it possible to do continuous/incremental learning in ML.net? [question]\" (#5504)"},{"Id":"747872318","IsPullRequest":true,"CreatedAt":"2020-11-21T02:00:54","Actor":"mstfbl","Number":"5503","RawContent":null,"Title":"Fix NetFX builds by ensuring assembly version is set correctly","State":"closed","Body":"Arcade SDK by default sets the version of generated `dll`s to `42.42.42.42`, which breaks some of our unit tests on .Net Frameworks v4.6.1. These failing unit tests are testing backwards compatibility of models by loading them. They are using the `dll`s they came with, which is version `1.0.0.0`. We also generate the same `1.0.0.0` version `dll`s currently, but without this change we make those `dll`s have version `42.42.42.42`.\r\n\r\nCI Build: https://dev.azure.com/dnceng/public/_build/results?buildId=895013&view=results","Url":"https://github.com/dotnet/machinelearning/pull/5503","RelatedDescription":"Closed or merged PR \"Fix NetFX builds by ensuring assembly version is set correctly\" (#5503)"},{"Id":"747121141","IsPullRequest":false,"CreatedAt":"2020-11-20T04:02:42","Actor":"frankhaugen","Number":"5501","RawContent":null,"Title":"Absorb Accord.net as a whole or in parts","State":"open","Body":"[Accord.net](https://github.com/accord-net/framework), (An ML library for .net), has been archived, and will no longer be maintained. The maintainer has done so partly because of ML.net deprecating Accord as a ML framework for .net. (and apparently also because of nasty researchers making fun of people using C# for Machine Learning)\r\n\r\nThe ML.net -team should absorb it, (fork it into dotnet, and move the components piece-by-piece into ML.net), because there are a lot of great stuff there that could really benefit ML.net's future, that now is just adrift, without new releases or active development.\r\n\r\nIt would be a shame for it all to go to \"waste\" or fall into obscurity","Url":"https://github.com/dotnet/machinelearning/issues/5501","RelatedDescription":"Open issue \"Absorb Accord.net as a whole or in parts\" (#5501)"},{"Id":"746829805","IsPullRequest":true,"CreatedAt":"2020-11-19T18:38:33","Actor":"Lynx1820","Number":"5500","RawContent":null,"Title":"Testing Arcade","State":"open","Body":"\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5500","RelatedDescription":"Open PR \"Testing Arcade\" (#5500)"},{"Id":"746035055","IsPullRequest":false,"CreatedAt":"2020-11-19T18:24:42","Actor":"rebecca-burwei","Number":"5497","RawContent":null,"Title":"Are ML .Net models deterministic?","State":"closed","Body":"Some models are inherently stochastic, others are deterministic. Are ML .Net models deterministic? In other words, given the same input, will an ML .Net model always return the same output/prediction? If so, to how many decimal places is this prediction deterministic?","Url":"https://github.com/dotnet/machinelearning/issues/5497","RelatedDescription":"Closed issue \"Are ML .Net models deterministic?\" (#5497)"},{"Id":"746142442","IsPullRequest":true,"CreatedAt":"2020-11-19T18:02:31","Actor":"frank-dong-ms","Number":"5499","RawContent":null,"Title":"fix CpuMathNative dll not found error for netfx project","State":"closed","Body":"fix #5495 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5499","RelatedDescription":"Closed or merged PR \"fix CpuMathNative dll not found error for netfx project\" (#5499)"},{"Id":"746095573","IsPullRequest":false,"CreatedAt":"2020-11-18T22:51:32","Actor":"samsp-msft","Number":"5498","RawContent":null,"Title":"Survey: Repo contribution experience, Fall 2020","State":"open","Body":"We normally focus on how to improve the product, but we’re also turning our focus to improving the open source project. Periodically we are running a survey to collect feedback on your experience working with our repos. We did one back in May, and as its been about 6 months, its about time for another. We’ve created a survey to better understand your individual experience of participating and contributing in this project.\r\n\r\nWe would appreciate your feedback so we can work to address shortcomings and missed opportunities. If you don’t supply contact details, then responses will be anonymous.\r\n\r\n[Survey](https://www.surveymonkey.com/r/92RLF7R?Source=dotnet/machinelearning)\r\n\r\nThank you for your time!","Url":"https://github.com/dotnet/machinelearning/issues/5498","RelatedDescription":"Open issue \"Survey: Repo contribution experience, Fall 2020\" (#5498)"}],"ResultType":"GitHubIssue"}},"RunOn":"2020-12-04T05:30:34.6924275Z","RunDurationInMilliseconds":704}