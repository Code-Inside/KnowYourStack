{"Data":{"GitHub":{"Issues":[{"Id":"2657077805","IsPullRequest":true,"CreatedAt":"2024-11-14T01:19:01","Actor":"github-actions[bot]","Number":"7310","RawContent":null,"Title":"[release/4.0] Fixing tokenizers version","State":"closed","Body":"Backport of #7309 to release/4.0\n\n/cc @michaelgsharp\n\n## Customer Impact\n\n## Testing\n\n## Risk\n","Url":"https://github.com/dotnet/machinelearning/pull/7310","RelatedDescription":"Closed or merged PR \"[release/4.0] Fixing tokenizers version\" (#7310)"},{"Id":"2656637624","IsPullRequest":true,"CreatedAt":"2024-11-13T23:16:30","Actor":"michaelgsharp","Number":"7309","RawContent":null,"Title":"Fixing tokenizers version","State":"closed","Body":"Fixing tokenizers version.","Url":"https://github.com/dotnet/machinelearning/pull/7309","RelatedDescription":"Closed or merged PR \"Fixing tokenizers version\" (#7309)"},{"Id":"2656318848","IsPullRequest":true,"CreatedAt":"2024-11-13T22:54:04","Actor":"tarekgh","Number":"7308","RawContent":null,"Title":"Fix Pre-Release package version","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7308","RelatedDescription":"Closed or merged PR \"Fix Pre-Release package version\" (#7308)"},{"Id":"2654760876","IsPullRequest":true,"CreatedAt":"2024-11-13T09:07:04","Actor":"michaelgsharp","Number":"7307","RawContent":null,"Title":"Suppress nuget preview warning","State":"closed","Body":"Temporarily suppressing the nuget warning since we need to have a dependency on the preview package.","Url":"https://github.com/dotnet/machinelearning/pull/7307","RelatedDescription":"Closed or merged PR \"Suppress nuget preview warning\" (#7307)"},{"Id":"2654427060","IsPullRequest":true,"CreatedAt":"2024-11-13T06:49:03","Actor":"michaelgsharp","Number":"7306","RawContent":null,"Title":"Suppress warning","State":"closed","Body":"Suppress a warning that shows up in the official build but not CI so that we can release.","Url":"https://github.com/dotnet/machinelearning/pull/7306","RelatedDescription":"Closed or merged PR \"Suppress warning\" (#7306)"},{"Id":"2653759876","IsPullRequest":true,"CreatedAt":"2024-11-13T04:18:39","Actor":"michaelgsharp","Number":"7305","RawContent":null,"Title":"Backport of MP Updates","State":"closed","Body":"Backport of MP updates from main to release/4.0","Url":"https://github.com/dotnet/machinelearning/pull/7305","RelatedDescription":"Closed or merged PR \"Backport of MP Updates\" (#7305)"},{"Id":"2653596427","IsPullRequest":true,"CreatedAt":"2024-11-13T00:39:12","Actor":"michaelgsharp","Number":"7304","RawContent":null,"Title":"Maintenance package version updates.","State":"closed","Body":"Updates to new stable maintenance package versions.","Url":"https://github.com/dotnet/machinelearning/pull/7304","RelatedDescription":"Closed or merged PR \"Maintenance package version updates.\" (#7304)"},{"Id":"2653229179","IsPullRequest":true,"CreatedAt":"2024-11-12T20:25:19","Actor":"github-actions[bot]","Number":"7303","RawContent":null,"Title":"[release/4.0] 4.0 release notes","State":"closed","Body":"Backport of #7302 to release/4.0\n\n/cc @michaelgsharp\n\n## Customer Impact\n\n## Testing\n\n## Risk\n","Url":"https://github.com/dotnet/machinelearning/pull/7303","RelatedDescription":"Closed or merged PR \"[release/4.0] 4.0 release notes\" (#7303)"},{"Id":"2653193725","IsPullRequest":true,"CreatedAt":"2024-11-12T20:19:14","Actor":"michaelgsharp","Number":"7302","RawContent":null,"Title":"4.0 release notes","State":"closed","Body":"Adding in release notes for 4.0 release.","Url":"https://github.com/dotnet/machinelearning/pull/7302","RelatedDescription":"Closed or merged PR \"4.0 release notes\" (#7302)"},{"Id":"2650718778","IsPullRequest":true,"CreatedAt":"2024-11-12T05:23:47","Actor":"carlossanlop","Number":"7301","RawContent":null,"Title":"Update dependencies from maintenance-packages to latest versions","State":"closed","Body":"The latest prerelease versions can be found here: https://dnceng.visualstudio.com/public/_artifacts/feed/dotnet-libraries\r\n\r\nTomorrow we can update to the stable versions after they get published to nuget.","Url":"https://github.com/dotnet/machinelearning/pull/7301","RelatedDescription":"Closed or merged PR \"Update dependencies from maintenance-packages to latest versions\" (#7301)"},{"Id":"2650579551","IsPullRequest":true,"CreatedAt":"2024-11-12T05:23:24","Actor":"github-actions[bot]","Number":"7300","RawContent":null,"Title":"[release/4.0] Fixing native lookup","State":"closed","Body":"Backport of #7282 to release/4.0\n\n/cc @michaelgsharp\n\n## Customer Impact\n\n## Testing\n\n## Risk\n","Url":"https://github.com/dotnet/machinelearning/pull/7300","RelatedDescription":"Closed or merged PR \"[release/4.0] Fixing native lookup\" (#7300)"},{"Id":"2650425461","IsPullRequest":true,"CreatedAt":"2024-11-11T23:57:44","Actor":"github-actions[bot]","Number":"7299","RawContent":null,"Title":"[release/4.0] Updated remote executor","State":"closed","Body":"Backport of #7295 to release/4.0\n\n/cc @michaelgsharp\n\n## Customer Impact\n\n## Testing\n\n## Risk\n","Url":"https://github.com/dotnet/machinelearning/pull/7299","RelatedDescription":"Closed or merged PR \"[release/4.0] Updated remote executor\" (#7299)"},{"Id":"2625063601","IsPullRequest":true,"CreatedAt":"2024-11-11T22:47:59","Actor":"michaelgsharp","Number":"7282","RawContent":null,"Title":"Fixing native lookup","State":"closed","Body":"Fixes native lookup with adds a bunch more testing for M1 and normal mac as well.","Url":"https://github.com/dotnet/machinelearning/pull/7282","RelatedDescription":"Closed or merged PR \"Fixing native lookup\" (#7282)"},{"Id":"2650204813","IsPullRequest":true,"CreatedAt":"2024-11-11T22:47:37","Actor":"michaelgsharp","Number":"7298","RawContent":null,"Title":"Backport GenAI","State":"closed","Body":"â€¦270)\r\n\r\n* leverage MEAI abstraction\r\n\r\n* Update src/Microsoft.ML.GenAI.LLaMA/Llama3CausalLMChatClient.cs\r\n\r\n\r\n\r\n* Update src/Microsoft.ML.GenAI.LLaMA/Llama3CausalLMChatClient.cs\r\n\r\n\r\n\r\n* Update src/Microsoft.ML.GenAI.Phi/Phi3/Phi3CausalLMChatClient.cs\r\n\r\n\r\n\r\n* fix comments\r\n\r\n* Update Microsoft.ML.GenAI.Core.csproj\r\n\r\n---------\r\n\r\nWe are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7298","RelatedDescription":"Closed or merged PR \"Backport GenAI\" (#7298)"},{"Id":"2645175351","IsPullRequest":true,"CreatedAt":"2024-11-11T21:25:02","Actor":"michaelgsharp","Number":"7295","RawContent":null,"Title":"Updated remote executor","State":"closed","Body":"Updates remote executor so that we can update the maintenance packages.","Url":"https://github.com/dotnet/machinelearning/pull/7295","RelatedDescription":"Closed or merged PR \"Updated remote executor\" (#7295)"},{"Id":"2648829644","IsPullRequest":false,"CreatedAt":"2024-11-11T10:09:14","Actor":"sportbilly21","Number":"7297","RawContent":null,"Title":"Microsoft.ML.OnnxTransformer asking for wrong Microsoft.ML.OnnxRuntime version","State":"open","Body":"**System Information (please complete the following information):**\n - OS & Version: 10\n - ML.NET Version: 3.01\n - ML.OnnxTransformer 3.01\n - .NET Version: Framework 4.7\n\n**Describe the bug**\nI have updated all nuget packages to the latest versions, include Microsoft.ML.OnnxRuntime.Gpu which I now you are not managing version of the package is 1.20 and the version of the produced dll of that package Microsoft.ML.OnnxRuntime is again 1.20.\nWhen I running a unit test I am getting the following error System.IO.FileLoadException: Could not load file or assembly 'Microsoft.ML.OnnxRuntime, Version=0.0.0.0, which comes from the Microsoft.ML.OnnxTransformer nuget package.\n Microsoft.ML.OnnxRuntime.Gpu, before version 1.19, was producing the Microsoft.ML.OnnxRuntime.dll with the version 0.0.0.0 which was a bug from their side, This has been corrected from their side and now it updates the version in the dll. \nThe issue is that ML.OnnxTransforme still needs the 0.0.0.0 so it cannot be used with any of the newests  versions of Microsoft.ML.OnnxRuntime.Gpu \nCan you please advise?\n\n\n**Screenshots, Code, Sample Projects**\n![Image](https://github.com/user-attachments/assets/e5115309-5be6-45e1-865c-35c832198e9a)\n\n\nMany thanks\nVasilis\n","Url":"https://github.com/dotnet/machinelearning/issues/7297","RelatedDescription":"Open issue \"Microsoft.ML.OnnxTransformer asking for wrong Microsoft.ML.OnnxRuntime version\" (#7297)"},{"Id":"2644975582","IsPullRequest":true,"CreatedAt":"2024-11-08T23:30:11","Actor":"github-actions[bot]","Number":"7293","RawContent":null,"Title":"[release/4.0] Update To MacOS 13","State":"closed","Body":"Backport of #7285 to release/4.0\n\n/cc @michaelgsharp\n\n## Customer Impact\n\n## Testing\n\n## Risk\n","Url":"https://github.com/dotnet/machinelearning/pull/7293","RelatedDescription":"Closed or merged PR \"[release/4.0] Update To MacOS 13\" (#7293)"},{"Id":"2645348106","IsPullRequest":false,"CreatedAt":"2024-11-08T23:18:31","Actor":"tonyqus","Number":"7296","RawContent":null,"Title":"Implement DataFrame.Shape method","State":"open","Body":"The dataframe in Python supports shape method. It returns the dimensionality of the DataFrame. \nDoc: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html\n\nDo you have plan to implement this method?\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7296","RelatedDescription":"Open issue \"Implement DataFrame.Shape method\" (#7296)"},{"Id":"2616188188","IsPullRequest":false,"CreatedAt":"2024-11-08T21:44:13","Actor":"tarekgh","Number":"7281","RawContent":null,"Title":"WordPiece and Bert Tokenizer Design review","State":"closed","Body":"## Proposal \n\nThe proposal omitted the overridden properties and method that is defined in the abstraction we already reviewed before.\n\n### *WordPiece Tokenizer*\n\n```C#\nnamespace Microsoft.ML.Tokenizers\n{\n    public partial class WordPieceTokenizer : Tokenizer\n    {\n        public static WordPieceTokenizer Create(\n                        string vocabFilePath,\n                        PreTokenizer? preTokenizer = null,\n                        Normalizer? normalizer = null,\n                        IReadOnlyDictionary<string, int>? specialTokens = null,\n                        string unknownToken = \"[UNK]\",\n                        string continuingSubwordPrefix = DefaultContinuingSubwordPrefix,\n                        int maxInputCharsPerWord = DefaultMaxInputCharsPerWord)\n\n        public static WordPieceTokenizer Create(\n                        Stream vocabStream,\n                        PreTokenizer? preTokenizer = null,\n                        Normalizer? normalizer = null,\n                        IReadOnlyDictionary<string, int>? specialTokens = null,\n                        string unknownToken = \"[UNK]\",\n                        string continuingSubwordPrefix = DefaultContinuingSubwordPrefix,\n                        int maxInputCharsPerWord = DefaultMaxInputCharsPerWord)\n\n        public static async Task<WordPieceTokenizer> CreateAsync(\n                        Stream vocabStream,\n                        PreTokenizer? preTokenizer = null,\n                        Normalizer? normalizer = null,\n                        IReadOnlyDictionary<string, int>? specialTokens = null,\n                        string unknownToken = \"[UNK]\",\n                        string continuingSubwordPrefix = DefaultContinuingSubwordPrefix,\n                        int maxInputCharsPerWord = DefaultMaxInputCharsPerWord,\n                        CancellationToken cancellationToken = default)\n\n        /// <summary>\n        /// Gets the unknown token.\n        /// A token that is not in the vocabulary cannot be converted to an ID and is set to be this token instead.\n        /// </summary>\n        public string UnknownToken { get; }\n\n        /// <summary>\n        /// Gets the unknown token ID.\n        /// A token that is not in the vocabulary cannot be converted to an ID and is set to be this token instead.\n        /// </summary>\n        public int UnknownTokenId { get; }\n\n        /// <summary>\n        /// Gets the prefix to use for sub-words that are not the first part of a word.\n        /// </summary>\n        public string ContinuingSubwordPrefix { get; }\n\n        /// <summary>\n        /// Gets the maximum number of characters to authorize in a single word.\n        /// </summary>\n        public int MaxInputCharsPerWord { get; }\n\n        /// <summary>\n        /// Gets the special tokens and their corresponding ids.\n        /// </summary>\n        public IReadOnlyDictionary<string, int>? SpecialTokens { get; }\n\n        /// <summary>\n        /// Decode the given ids, back to a String.\n        /// </summary>\n        /// <param name=\"ids\">The list of ids that we want to decode.</param>\n        /// <param name=\"skipSpecialTokens\">Indicate whether to skip the special tokens during the decoding.</param>\n        /// <returns>The decoded string.</returns>\n        public string Decode(IEnumerable<int> ids, bool skipSpecialTokens)\n\n        public OperationStatus Decode(IEnumerable<int> ids, Span<char> destination, bool skipSpecialTokens, \n                   out int idsConsumed, out int charsWritten)\n    }\n}\n```\n\n### *Bert Tokenizer*\n\n```C#\nnamespace Microsoft.ML.Tokenizers\n{\n    public sealed partial class BertTokenizer : WordPieceTokenizer\n    {\n        public static BertTokenizer Create(\n                    string vocabFilePath,\n                    bool doLowerCase = true,\n                    bool doBasicTokenization = true,\n                    bool splitOnSpecialTokens = true,\n                    string unknownToken = \"[UNK]\",\n                    string sepToken = \"[SEP]\",\n                    string padToken = \"[PAD]\",\n                    string clsToken = \"[CLS]\",\n                    string maskToken = \"[MASK]\",\n                    bool tokenizeChineseChars = true,\n                    bool stripAccents = false)    \n\n        public static BertTokenizer Create(\n                    Stream vocabStream,\n                    bool doLowerCase = true,\n                    bool doBasicTokenization = true,\n                    bool splitOnSpecialTokens = true,\n                    string unknownToken = \"[UNK]\",\n                    string sepToken = \"[SEP]\",\n                    string padToken = \"[PAD]\",\n                    string clsToken = \"[CLS]\",\n                    string maskToken = \"[MASK]\",\n                    bool tokenizeChineseChars = true,\n                    bool stripAccents = false)\n\n        public static async Task<BertTokenizer> CreateAsync(\n                    Stream vocabStream,\n                    bool doLowerCase = true,\n                    bool doBasicTokenization = true,\n                    bool splitOnSpecialTokens = true,\n                    string unknownToken = \"[UNK]\",\n                    string sepToken = \"[SEP]\",\n                    string padToken = \"[PAD]\",\n                    string clsToken = \"[CLS]\",\n                    string maskToken = \"[MASK]\",\n                    bool tokenizeChineseChars = true,\n                    bool stripAccents = false)\n\n        /// <summary>\n        /// Gets a value indicating whether the tokenizer should lowercase the input text.\n        /// </summary>\n        public bool DoLowerCase { get; }\n\n        /// <summary>\n        /// Gets a value indicating whether the tokenizer should do basic tokenization. Like clean text, normalize it, lowercasing, etc.\n        /// </summary>\n        public bool DoBasicTokenization { get; }\n\n        /// <summary>\n        /// Gets a value indicating whether the tokenizer should split on the special tokens or treat special tokens as normal text.\n        /// </summary>\n        public bool SplitOnSpecialTokens { get; }\n\n        /// <summary>\n        /// Gets the separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for sequence classification \n        /// or for a text and a question for question answering.\n        /// It is also used as the last token of a sequence built with special tokens.\n        /// </summary>\n        public string SepToken { get; }\n\n        /// <summary>\n        /// Gets the separator token Id\n        /// </summary>\n        public int SepTokenId { get; }\n\n        /// <summary>\n        /// Gets the token used for padding, for example when batching sequences of different lengths\n        /// </summary>\n        public string PadToken { get; }\n\n        /// <summary>\n        /// Gets padding token Id\n        /// </summary>\n        public int PadTokenId { get; }\n\n        /// <summary>\n        /// Gets the classifier token which is used when doing sequence classification (classification of the whole sequence \n        /// instead of per-token classification).\n        /// It is the first token of the sequence when built with special tokens.\n        /// </summary>\n        public string ClsToken { get; }\n\n        /// <summary>\n        /// Gets the classifier token Id\n        /// </summary>\n        public int ClsTokenId { get; }\n\n        /// <summary>\n        /// Gets the mask token used for masking values. This is the token used when training this model with masked language modeling.\n        /// This is the token which the model will try to predict.\n        /// </summary>\n        public string MaskToken { get; }\n\n        /// <summary>\n        /// Gets the mask token Id\n        /// </summary>\n        public int MaskTokenId { get; }\n\n        /// <summary>\n        /// Gets a value indicating whether the tokenizer should split the Chinese characters into tokens.\n        /// </summary>\n        public bool TokenizeChineseChars { get; }\n\n        /// <summary>\n        /// Gets a value indicating whether the tokenizer should strip accents characters.\n        /// </summary>\n        public bool StripAccents { get; }\n\n        public IReadOnlyList<int> EncodeToIds(string text, bool addSpecialTokens, \n                      bool considerPreTokenization = true, bool considerNormalization = true)\n\n        public IReadOnlyList<int> EncodeToIds(ReadOnlySpan<char> text, bool addSpecialTokens, \n                      bool considerPreTokenization = true, bool considerNormalization = true)\n\n        public IReadOnlyList<int> EncodeToIds(string text, int maxTokenCount, bool addSpecialTokens, out string? normalizedText, \n                       out int charsConsumed, bool considerPreTokenization = true, bool considerNormalization = true)\n\n        public IReadOnlyList<int> EncodeToIds(ReadOnlySpan<char> text, int maxTokenCount, bool addSpecialTokens, \n                        out string? normalizedText,  out int charsConsumed, bool considerPreTokenization = true, bool considerNormalization = true)\n\n        /// <summary>\n        /// Build model inputs from a sequence or a pair of sequences for sequence classification tasks by concatenating and \n        /// adding special tokens. A BERT sequence has the following format:\n        ///     - single sequence: `[CLS] tokenIds0 [SEP]`\n        ///     - pair of sequences: `[CLS] tokenIds0 [SEP] tokenIds1 [SEP]`\n        /// </summary>\n        /// <param name=\"tokenIds0\">List of IDs to which the special tokens will be added.</param>\n        /// <param name=\"tokenIds1\">Optional second list of IDs for sequence pairs.</param>\n        /// <returns>The list of IDs with special tokens added.</returns>\n        /// <exception cref=\"ArgumentNullException\">When <paramref name=\"tokenIds0\"/> is null.</exception>\n        public IReadOnlyList<int> BuildInputsWithSpecialTokens(IEnumerable<int> tokenIds0, IEnumerable<int>? tokenIds1 = null)\n\n        public OperationStatus BuildInputsWithSpecialTokens(IEnumerable<int> tokenIds0, Span<int> buffer, out int written, \n                             IEnumerable<int>? tokenIds1 = null)\n\n        /// <summary>\n        /// Retrieve sequence tokens mask from a IDs list.\n        /// </summary>\n        /// <param name=\"tokenIds0\">List of IDs.</param>\n        /// <param name=\"tokenIds1\">Optional second list of IDs for sequence pairs.</param>\n        /// <param name=\"alreadyHasSpecialTokens\">Indicate whether or not the token list is already formatted with special tokens \n        /// for the model.</param>\n        /// <returns>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</returns>\n        /// <exception cref=\"ArgumentNullException\"></exception>\n        public IReadOnlyList<int> GetSpecialTokensMask(IEnumerable<int> tokenIds0, IEnumerable<int>? tokenIds1 = null, \n                    bool alreadyHasSpecialTokens = false)\n\n        public OperationStatus GetSpecialTokensMask(IEnumerable<int> tokenIds0, Span<int> buffer, out int written, \n                     IEnumerable<int>? tokenIds1 = null, bool alreadyHasSpecialTokens = false)\n\n        /// <summary>\n        /// Create a mask from the two sequences passed to be used in a sequence-pair classification task. \n        /// A BERT sequence pair mask has the following format:\n        ///         0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n        ///         | first sequence    | second sequence |\n        /// If <paramref name=\"tokenIds1\"/> is null, this method only returns the first portion of the type ids (0s).\n        /// </summary>\n        /// <param name=\"tokenIds0\">List of token IDs for the first sequence.</param>\n        /// <param name=\"tokenIds1\">Optional list of token IDs for the second sequence.</param>\n        /// <returns>List of token type IDs according to the given sequence(s).</returns>\n        /// <exception cref=\"ArgumentNullException\">When <paramref name=\"tokenIds0\"/> is null.</exception>\n        public IReadOnlyList<int> CreateTokenTypeIdsFromSequences(IEnumerable<int> tokenIds0, IEnumerable<int>? tokenIds1 = null)\n\n        public OperationStatus CreateTokenTypeIdsFromSequences(IEnumerable<int> tokenIds0, Span<int> buffer, out int written, \n                         IEnumerable<int>? tokenIds1 = null)\n    }\n}\n```\n\n### *PreTokenizer Factory methods*\n\n```C#\nnamespace Microsoft.ML.Tokenizers\n{\n    public abstract partial class PreTokenizer\n    {\n        // @\"\\w+|[\\p{P}]\"\n        public static PreTokenizer CreateWhiteSpaceOrPunctuationPreTokenizer(IReadOnlyDictionary<string, int>? specialTokensEncoder = null)\n\n        // @\"\\w+|[^\\w\\s]+\"\n        public static PreTokenizer CreateWordOrNonWordPreTokenizer(IReadOnlyDictionary<string, int>? specialTokensEncoder = null)\n\n        // @\"\\S+\"\n        public static PreTokenizer CreateWhiteSpacePreTokenizer(IReadOnlyDictionary<string, int>? specialTokensEncoder = null)\n\n    }\n}\n```\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7281","RelatedDescription":"Closed issue \"WordPiece and Bert Tokenizer Design review\" (#7281)"},{"Id":"2644909662","IsPullRequest":true,"CreatedAt":"2024-11-08T21:31:10","Actor":"tarekgh","Number":"7292","RawContent":null,"Title":"Backport tokenizer changes to Release/4.0","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7292","RelatedDescription":"Closed or merged PR \"Backport tokenizer changes to Release/4.0\" (#7292)"},{"Id":"2645169297","IsPullRequest":false,"CreatedAt":"2024-11-08T21:15:21","Actor":"KasperNissen1997","Number":"7294","RawContent":null,"Title":"Tokenizer for SentencePiece Unigram models","State":"open","Body":"Hi all,\nIs support planned for Tokenizers for SentencePiece models using the Unigram algorithm?\nIf I've checked correctly, I see that there's an Tokenizer implementation for SentencePiece models coming in the 4.0 release, but it seems to be limited to only supporting BPE models, in the form of `LlamaTokenizer`.\n\nSpecifically, I'd like to create a tokenizer for the Helsinki-NLP/opus-mt-xx-xx models from HuggingFace, but I am having difficulty creating tokenizers for those models.","Url":"https://github.com/dotnet/machinelearning/issues/7294","RelatedDescription":"Open issue \"Tokenizer for SentencePiece Unigram models\" (#7294)"},{"Id":"2635373350","IsPullRequest":false,"CreatedAt":"2024-11-08T20:07:20","Actor":"mehdihadeli","Number":"7286","RawContent":null,"Title":"Using pre-train huggingface tokenizers","State":"closed","Body":"Hi,\nIs it possible using pre-train huggingface tokenizers with ML.Net Tokenizer like this?\n\n``` python\nTokenizer.from_pretrained(\"Xenova/llama-3-tokenizer\")\n```","Url":"https://github.com/dotnet/machinelearning/issues/7286","RelatedDescription":"Closed issue \"Using pre-train huggingface tokenizers\" (#7286)"},{"Id":"2642492166","IsPullRequest":true,"CreatedAt":"2024-11-08T18:37:27","Actor":"tarekgh","Number":"7291","RawContent":null,"Title":"Final tokenizer's cleanup","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7291","RelatedDescription":"Closed or merged PR \"Final tokenizer's cleanup\" (#7291)"},{"Id":"2642047855","IsPullRequest":false,"CreatedAt":"2024-11-07T20:00:56","Actor":"jackpotcityco","Number":"7290","RawContent":null,"Title":"How to cancel an Experiment. I don't get that to work.","State":"open","Body":"Hello,\n\nRAM: 64 GB\nCPU: i7-12800h\n\nI am trying to understand how to Cancel an experiment but just can't make it work. I have tried both below lines **(One at a time, not both at the same time)** when: `if (modelsLISTtemp.Count >= 3)`\n\n`MLContextExtensions.CancelExecution(mlContext); //Cancel experiment using \"Microsoft.ML.Experimental`\n`cancellationTokenSource.Cancel();               // Cancel the task running the experiment using: CancellationToken = cts `\n\n1. The first is using `.CancelExecution` from Microsoft.ML.Experimental but the experiment never stops and continues to the end which is more than 4 minutes after the `.CancelExecution` attempt.\n\n2. The second is trying the `CancellationToken = cts` but exactly as in above it never stops and continues to the end which is more than 4 minutes after the `cancellationTokenSource.Cancel();` attempt.\n\nIn both, the experiment continues to return 10,20,30+ models during those 4 minutes.\n\nHow would it be possible to actually cancel the Experiment on demand to not be stuck with the 300 seconds the experiment runs? (MaxExperimentTimeInSeconds = (uint)300)\n\n**_trainData and hold_out_data are populated with data for training when passed to function: testExperiment_**\n\n```\n        void testExperiment(IDataView trainData, IDataView hold_out_data)\n        {\n            Random random = new Random();\n            var mlContext = new MLContext(seed: random.Next());\n            var cancellationTokenSource = new CancellationTokenSource();\n            var cts = new CancellationToken();\n            object obj = new object();\n            var modelsLISTtemp = new List<(string trainerName, object validationMetrics, ITransformer model)>();\n\n            ExperimentBase<RegressionMetrics, RegressionExperimentSettings> regression_Experiment = null;\n            regression_Experiment = mlContext.Auto().CreateRegressionExperiment(new RegressionExperimentSettings\n            {\n                MaxExperimentTimeInSeconds = (uint)300,\n                CacheBeforeTrainer = CacheBeforeTrainer.Off,\n                CacheDirectoryName = \"C:/Aintelligence/temp/cache\",\n                MaximumMemoryUsageInMegaByte = 16384,\n                OptimizingMetric = RegressionMetric.RSquared,\n                CancellationToken = cts\n            });\n\n\n            // Progress handler for regression\n            var regressionProgressHandler = new Progress<RunDetail<RegressionMetrics>>(ph =>\n            {\n                if (ph.ValidationMetrics != null && !ph.TrainerName.Contains(\"FastForest\")) { progress(Math.Round(ph.ValidationMetrics.RSquared, 3), ph.TrainerName, ph.ValidationMetrics, ph.Model); }\n            });\n            void progress(double metricValue, string TrainerName, object ValidationMetrics, ITransformer Model)\n            {\n                    lock (obj) { modelsLISTtemp.Add((TrainerName, ValidationMetrics, Model)); }\n                    if (modelsLISTtemp.Count >= 3)\n                    {\n                        MLContextExtensions.CancelExecution(mlContext); //Cancel experiment using \"Microsoft.ML.Experimental\n                        cancellationTokenSource.Cancel();               // Cancel the task running the experiment using: CancellationToken = cts \n                    }\n            }\n\n            //Execute experiment\n            var results = regression_Experiment.Execute(trainData, hold_out_data, labelColumnName: \"Label\", progressHandler: regressionProgressHandler);\n\n        }\n```\n","Url":"https://github.com/dotnet/machinelearning/issues/7290","RelatedDescription":"Open issue \"How to cancel an Experiment. I don't get that to work.\" (#7290)"},{"Id":"2641365689","IsPullRequest":false,"CreatedAt":"2024-11-07T15:27:00","Actor":"tappanajmera","Number":"7289","RawContent":null,"Title":"Periodicity detection accuracy is very low","State":"open","Body":"**System Information (please complete the following information):**\n - OS & Version: Windows 11\n - ML.NET Version: [e.g. ML.NET v1.5.5]\n - .NET Version: [e.g. .NET 5.0]\n\n**Description**\nThis is probably a question and not a bug.\nWe tested periodicity detection from ML .Net and compared against other approaches. The accuracy is very low.\n![Image](https://github.com/user-attachments/assets/8b9ee337-aa75-472f-8212-0c575705c85c)\n\nAccuracy selected means \"accuracy on those where it gave an answer\". So ML.NET gives a periodicity only on 28% of cases, and on those 28% it's 85% accurate. Kusto gives an answer on 94% of cases, and is 78% accurate on that.\n\nIs this expected behavior?\n","Url":"https://github.com/dotnet/machinelearning/issues/7289","RelatedDescription":"Open issue \"Periodicity detection accuracy is very low\" (#7289)"},{"Id":"2638750356","IsPullRequest":false,"CreatedAt":"2024-11-06T17:26:34","Actor":"LittleLittleCloud","Number":"7288","RawContent":null,"Title":"[WIP] [GenAI] Lora Finetune","State":"open","Body":"Lora fine-tuning is an adapter-based technique to fine-tune an LLM. It changes LLM model architecture by adding learnable lora layers to transformers. During fine-tuning, only lora weights are adjustable and the LLM weights are frozen, so it requires much less GPU memory comparing to a full-layer fine-tuning. Based on [this table](https://github.com/hiyouga/LLaMA-Factory#hardware-requirement), it requires 16GB memory to fine-tuning a 7B size model in 16bits, which can be fit in rtx 3090, 4080 and 4090. A wider range of GPUs can be fit on 3.8B LLMs like phi-3.5-mini\n\n## API design (wip)\n\n### Package: `Microsoft.ML.GenAI.Lora`\n\n```csharp\ninterface ICausalLMLoraPipeline {} // pipeline for loading causal LM + lora layers\n\nclass LoraConfiguration // lora configuration\n```\n\n","Url":"https://github.com/dotnet/machinelearning/issues/7288","RelatedDescription":"Open issue \"[WIP] [GenAI] Lora Finetune\" (#7288)"},{"Id":"2638700351","IsPullRequest":false,"CreatedAt":"2024-11-06T17:01:17","Actor":"LittleLittleCloud","Number":"7287","RawContent":null,"Title":"[WIP][GenAI] Finetune","State":"open","Body":"Enable fine-tune support for MLNet GenAI CausalLM models","Url":"https://github.com/dotnet/machinelearning/issues/7287","RelatedDescription":"Open issue \"[WIP][GenAI] Finetune\" (#7287)"},{"Id":"2634134651","IsPullRequest":true,"CreatedAt":"2024-11-05T00:41:25","Actor":"michaelgsharp","Number":"7285","RawContent":null,"Title":"Update To MacOS 13","State":"closed","Body":"Updates MacOS queues and VMs to use version 13.","Url":"https://github.com/dotnet/machinelearning/pull/7285","RelatedDescription":"Closed or merged PR \"Update To MacOS 13\" (#7285)"},{"Id":"2630099351","IsPullRequest":true,"CreatedAt":"2024-11-04T16:06:54","Actor":"tarekgh","Number":"7284","RawContent":null,"Title":"Add Timeout to Regex used in the tokenizers","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7284","RelatedDescription":"Closed or merged PR \"Add Timeout to Regex used in the tokenizers\" (#7284)"},{"Id":"2627957214","IsPullRequest":true,"CreatedAt":"2024-11-01T22:20:59","Actor":"tarekgh","Number":"7283","RawContent":null,"Title":"Add the components governance file `cgmanifest.json` for tokenizer's vocab files","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7283","RelatedDescription":"Closed or merged PR \"Add the components governance file `cgmanifest.json` for tokenizer's vocab files\" (#7283)"}],"ResultType":"GitHubIssue"}},"RunOn":"2024-11-14T03:30:18.2856467Z","RunDurationInMilliseconds":415}