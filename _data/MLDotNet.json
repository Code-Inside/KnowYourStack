{"Data":{"GitHub":{"Issues":[{"Id":"1358137670","IsPullRequest":true,"CreatedAt":"2022-09-01T01:59:11","Actor":"alexperovich","Number":"6313","RawContent":null,"Title":"Update public pool names","State":"open","Body":"This change is required for builds to continue working in the new org, dev.azure.com/dnceng-public.","Url":"https://github.com/dotnet/machinelearning/pull/6313","RelatedDescription":"Open PR \"Update public pool names\" (#6313)"},{"Id":"1358137613","IsPullRequest":true,"CreatedAt":"2022-09-01T01:59:03","Actor":"alexperovich","Number":"6312","RawContent":null,"Title":"Update public pool names","State":"open","Body":"This change is required for builds to continue working in the new org, dev.azure.com/dnceng-public.","Url":"https://github.com/dotnet/machinelearning/pull/6312","RelatedDescription":"Open PR \"Update public pool names\" (#6312)"},{"Id":"1355647969","IsPullRequest":false,"CreatedAt":"2022-08-30T11:54:00","Actor":"superichmann","Number":"6311","RawContent":null,"Title":"possible wrong value on example table","State":"open","Body":"The example described in the article consists of test data table value that does not exist in the output table.\r\n\r\n`the output of applying this Estimator would keep the first and the third slots only `\r\n\r\nIn the table the value of the last line is\r\n<html>\r\n<body>\r\n<!--StartFragment-->\r\n\r\nFalse | 0,5\r\n-- | --\r\n\r\n\r\n<!--EndFragment-->\r\n</body>\r\n</html>\r\n\r\nWhich perhaps should be\r\n\r\n<html>\r\n<body>\r\n<!--StartFragment-->\r\n\r\nFalse | 0,0\r\n-- | --\r\n\r\n\r\n<!--EndFragment-->\r\n</body>\r\n</html>\r\n\r\nOr maybe the last line of the input table is wrong?\r\n\r\n<html>\r\n<body>\r\n<!--StartFragment-->\r\n\r\nFalse | 0,7,0\r\n-- | --\r\n\r\n\r\n<!--EndFragment-->\r\n</body>\r\n</html>\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 58a8434a-e5b9-a96f-e70a-c281f071d0c9\r\n* Version Independent ID: 26f433a0-138d-54b4-86a8-6c1b0f7088f7\r\n* Content: [MutualInformationFeatureSelectingEstimator Class (Microsoft.ML.Transforms)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.mutualinformationfeatureselectingestimator?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Transforms/MutualInformationFeatureSelectingEstimator.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Transforms/MutualInformationFeatureSelectingEstimator.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/6311","RelatedDescription":"Open issue \"possible wrong value on example table\" (#6311)"},{"Id":"1355457789","IsPullRequest":false,"CreatedAt":"2022-08-30T09:28:51","Actor":"aswin-integration","Number":"6310","RawContent":null,"Title":"High vulnerability alert in Newtonsoft.Json v10.0.3","State":"open","Body":"**System Information :**\r\n - Windows 10\r\n - ML.NET v1.7.1\r\n - .NET 5.0\r\n\r\n**Describe the bug**\r\nThe Microsoft.ML v1.7.1 library currently uses Newtonsoft.Json **v10.0.3** which have a ['high' level vulnerability reported](https://github.com/advisories/GHSA-5crp-9r3c-p9vr) . The vulnerability fix is available in Newtonsoft.Json **v13.0.1** (https://www.nuget.org/packages/Newtonsoft.Json/13.0.1). Is there going to be a official release fixing the dependency of Newtonsoft to the latest ? \r\n\r\n**Screenshots, Code, Sample Projects**\r\nhttps://github.com/advisories/GHSA-5crp-9r3c-p9vr\r\nhttps://www.nuget.org/packages/Microsoft.ML/1.7.1#dependencies-body-tab\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6310","RelatedDescription":"Open issue \"High vulnerability alert in Newtonsoft.Json v10.0.3\" (#6310)"},{"Id":"1353205324","IsPullRequest":false,"CreatedAt":"2022-08-28T00:15:47","Actor":"wil70","Number":"6309","RawContent":null,"Title":"[ML.Net c#, CLI, VS Builder] 1KB csv input file. Not sure what to do ","State":"open","Body":"I'm have simple data set with 2 fields: c10 and c11. c10 is a float, c11 is a string. First row is the header.\r\n\t\tc10,c11\r\n\t\t-1,a-1\r\n\t\t1,a+1\r\n\t\t-1,a-1\r\n\t\t1,a+1\r\n\t\t0,a+0\r\n\t\t1,a+1\r\n\t\t1,a+1\r\n\t\t-1,a-1\r\n\t\t1,a+1\r\n\t\t1,a+1\r\n\t\t-1,a-1\r\n\t\t-1,a-1\r\n\t\t-1,a-1\r\n\t\t1,a+1\r\n\t\t-1,a-1\r\n\t\t-1,a-1\r\n\t\t-1,a-1\r\n\t\t0,a+0\r\n\t\t1,a+1\r\n\t\t1,a+1\r\n\t\t1,a+1\r\n\t\t1,a+1\r\n\t\t-1,a-1\r\n\t\t-1,a-1\r\n\r\nAs you can see this is very easy to solve visually:\r\n  ```\r\n  if -1 is presented the answer is a-1\r\n  if +1 is presented the answer is a+1\r\n  if 0 is presented the answer is a+0\r\n\r\n```\r\nIf I run AutoML with the VS builder UI, it crash at the end with this\r\n\r\n\t   at System.Version.VersionResult.SetFailure(ParseFailureKind failure, String argument)\r\n\t   at System.Version.TryParseVersion(String version, VersionResult& result)\r\n\t   at System.Version.Parse(String input)\r\n\t   at System.Version..ctor(String version)\r\n\t   at Microsoft.ML.ModelBuilder.Utils.Utilities.InstalledVersionNeedsUpdate(String installedString, String requestedString)\r\n\t   at Microsoft.ML.ModelBuilder.Utils.Utilities.<InstallNugetPackageAsync>d__17.MoveNext()\r\n\t--- End of stack trace from previous location where exception was thrown ---\r\n\t   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n\t   at Microsoft.ML.ModelBuilder.ViewModels.TrainViewModel.<UpdateNugetDependenciesAsync>d__105.MoveNext()\r\n\t--- End of stack trace from previous location where exception was thrown ---\r\n\t   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n\t   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n\t   at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n\t   at Microsoft.ML.ModelBuilder.ViewModels.TrainViewModel.<GenerateCodeBehindFilesAsync>d__104.MoveNext()\r\n   \r\nHere is the log\r\n\r\n\t\t\tSet log file path to C:\\Users\\Wilhelm\\AppData\\Local\\Temp\\MLVSTools\\logs\\MLModel1-JSSGYE.txt\r\n\t\t\tstart nni training\r\n\t\t\tExperiment output folder: C:\\Users\\Wilhelm\\AppData\\Local\\Temp\\AutoML-NNI\\Experiment-4BLNIV\r\n\t\t\t|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n\t\t\t|0    SdcaMaximumEntropyMulti                     0.8250         0.8167       1.7          0                     |\r\n\t\t\t|1    SdcaLogisticRegressionOva                   0.8250         0.8167       3.5          1                     |\r\n\t\t\t|2    FastTreeOva                                 0.3967         0.3333       0.9          2                     |\r\n\t\t\t|3    LightGbmMulti                               0.0783         0.1333       0.2          3                     |\r\n\t\t\t|4    FastForestOva                               0.1783         0.2333       0.9          4                     |\r\n\t\t\t|5    SdcaLogisticRegressionOva                   0.8250         0.8167       3.4          5                     |\r\n\t\t\t|6    SdcaMaximumEntropyMulti                     0.8250         0.8167       0.9          6                     |\r\n\t\t\t|7    LbfgsMaximumEntropyMulti                    0.8250         0.8167       0.2          7                     |\r\n\t\t\t|8    LbfgsLogisticRegressionOva                  0.8250         0.8167       0.2          8                     |\r\n\t\t\t|9    FastTreeOva                                 0.8550         0.8167       0.9          9                     |\r\n\t\t\t|10   LightGbmMulti                               0.0783         0.1333       0.1         10                     |\r\n\t\t\t|11   SdcaLogisticRegressionOva                   0.8250         0.8167       3.5         11                     |\r\n\t\t\t|12   FastForestOva                               0.1783         0.2333       1.1         12                     |\r\n\t\t\t|13   SdcaMaximumEntropyMulti                     0.8250         0.8167       0.9         13                     |\r\n\t\t\t|14   LbfgsMaximumEntropyMulti                    0.8250         0.8167       0.1         14                     |\r\n\t\t\t|15   LightGbmMulti                               0.0783         0.1333       0.1         15                     |\r\n\t\t\t|16   FastTreeOva                                 0.3967         0.3333       1.2         16                     |\r\n\t\t\t|17   LbfgsLogisticRegressionOva                  0.6450         0.6667       0.2         17                     |\r\n\t\t\t|18   SdcaMaximumEntropyMulti                     0.3967         0.3333       0.9         18                     |\r\n\t\t\t|19   SdcaLogisticRegressionOva                   0.8250         0.8167       3.6         19                     |\r\n\t\t\t|20   FastForestOva                               0.1783         0.2333       1.2         20                     |\r\n\t\t\t|21   LbfgsMaximumEntropyMulti                    0.0783         0.1333       0.1         21                     |\r\n\t\t\t|22   FastTreeOva                                 0.9000         0.9000       1.3         22                     |\r\n\t\t\t|23   LightGbmMulti                               0.0783         0.1333       0.1         23                     |\r\n\t\t\t|24   SdcaMaximumEntropyMulti                     0.8250         0.8167       0.9         24                     |\r\n\t\t\t|25   LbfgsLogisticRegressionOva                  0.8250         0.8167       0.2         25                     |\r\n\t\t\t|26   FastForestOva                               0.1783         0.2333       1.5         26                     |\r\n\t\t\t|27   SdcaLogisticRegressionOva                   0.8250         0.8167       3.6         27                     |\r\n\t\t\t|28   FastTreeOva                                 0.9000         0.9000       1.8         28                     |\r\n\t\t\t|29   LbfgsMaximumEntropyMulti                    0.8250         0.8167       0.1         29                     |\r\n\t\t\t|30   LbfgsLogisticRegressionOva                  0.8250         0.8167       0.2         30                     |\r\n\t\t\t|31   SdcaMaximumEntropyMulti                     0.8250         0.8167       0.9         31                     |\r\n\t\t\t|32   LightGbmMulti                               0.0783         0.1333       0.1         32                     |\r\n\t\t\t|34   LightGbmMulti                               0.0783         0.1333       0.1         34                     |\r\n\t\t\t|35   SdcaLogisticRegressionOva                   0.8250         0.8167       3.7         35                     |\r\n\t\t\t|36   FastTreeOva                                 0.3967         0.3333       1.7         36                     |\r\n\t\t\t|37   SdcaMaximumEntropyMulti                     0.8250         0.8167       0.9         37                     |\r\n\t\t\t|38   LightGbmMulti                               0.0783         0.1333       0.1         38                     |\r\n\t\t\t|39   LbfgsMaximumEntropyMulti                    0.8250         0.8167       0.1         39                     |\r\n\t\t\t|40   LbfgsLogisticRegressionOva                  0.2283         0.2833       0.2         40                     |\r\n\t\t\t|41   FastForestOva                               0.1783         0.2333       1.9         41                     |\r\n\t\t\t|42   FastForestOva                               0.1783         0.2333       1.8         42                     |\r\n\t\t\t|43   SdcaLogisticRegressionOva                   0.3967         0.3333       3.7         43                     |\r\n\t\t\t|44   FastTreeOva                                 0.3967         0.3333       2.0         44                     |\r\n\t\t\t|45   LbfgsLogisticRegressionOva                  0.8250         0.8167       0.2         45                     |\r\n\t\t\t|46   LbfgsMaximumEntropyMulti                    0.8500         0.8500       0.1         46                     |\r\n\t\t\t|47   SdcaMaximumEntropyMulti                     0.8250         0.8167       1.0         47                     |\r\n\t\t\t|48   LightGbmMulti                               0.0783         0.1333       0.1         48                     |\r\n\t\t\t|49   FastForestOva                               0.1783         0.2333       2.1         49                     |\r\n\r\n\t\t\t===============================================Experiment Results=================================================\r\n\t\t\t------------------------------------------------------------------------------------------------------------------\r\n\t\t\t|                                                     Summary                                                    |\r\n\t\t\t------------------------------------------------------------------------------------------------------------------\r\n\t\t\t|ML Task: Classification                                                                                         |\r\n\t\t\t|Dataset: S:\\CATS\\files\\data_analysis\\output\\AggregatedFile\\small_2.csv                                          |\r\n\t\t\t|Label : c11                                                                                                     |\r\n\t\t\t|Total experiment time : 56.28 Secs                                                                              |\r\n\t\t\t|Total number of models explored: 49                                                                             |\r\n\t\t\t------------------------------------------------------------------------------------------------------------------\r\n\r\n\t\t\t|                                              Top 5 models explored                                             |\r\n\t\t\t------------------------------------------------------------------------------------------------------------------\r\n\t\t\t|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n\t\t\t|28   FastTreeOva                                 0.9000         0.9000       1.8         28                     |\r\n\t\t\t|22   FastTreeOva                                 0.9000         0.9000       1.3         22                     |\r\n\t\t\t|9    FastTreeOva                                 0.8550         0.8167       0.9          9                     |\r\n\t\t\t|45   LbfgsMaximumEntropyMulti                    0.8500         0.8500       0.1         45                     |\r\n\t\t\t|46   SdcaMaximumEntropyMulti                     0.8250         0.8167       1.0         46                     |\r\n\t\t\t------------------------------------------------------------------------------------------------------------------\r\n\r\n\t\t\tGenerate code behind files\r\n\r\n\r\n\t\t\tCopying generated code to project...\r\n\t\t\tCopying MLModel1.consumption.cs to folder: G:\\Users\\Wilhelm\\dev\\MachineLearning\\ML1\r\n\t\t\tCopying MLModel1.training.cs to folder: G:\\Users\\Wilhelm\\dev\\MachineLearning\\ML1\r\n\t\t\tCOMPLETED\r\n\r\n\r\n\t\t\tUpdating nuget dependencies...\r\n\t\t\tStarting update NuGet dependencies async.\r\n\t\t\tInstalling nuget package, package ID: Microsoft.ML, package Version: 1.7.1\r\n\r\nI extended the time to train\r\n\r\nCrash:\r\n\r\n\t   at System.Version.VersionResult.SetFailure(ParseFailureKind failure, String argument)\r\n\t   at System.Version.TryParseVersion(String version, VersionResult& result)\r\n\t   at System.Version.Parse(String input)\r\n\t   at System.Version..ctor(String version)\r\n\t   at Microsoft.ML.ModelBuilder.Utils.Utilities.InstalledVersionNeedsUpdate(String installedString, String requestedString)\r\n\t   at Microsoft.ML.ModelBuilder.Utils.Utilities.<InstallNugetPackageAsync>d__17.MoveNext()\r\n\t--- End of stack trace from previous location where exception was thrown ---\r\n\t   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n\t   at Microsoft.ML.ModelBuilder.ViewModels.TrainViewModel.<UpdateNugetDependenciesAsync>d__105.MoveNext()\r\n\t--- End of stack trace from previous location where exception was thrown ---\r\n\t   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\n\t   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n\t   at System.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\n\t   at Microsoft.ML.ModelBuilder.ViewModels.TrainViewModel.<GenerateCodeBehindFilesAsync>d__104.MoveNext()\r\n\t   \r\nLog:\r\n\r\n\t\t\t\r\n\t\tGenerate code behind files\r\n\r\n\r\n\t\tCopying generated code to project...\r\n\t\tCopying MLModel1.consumption.cs to folder: G:\\Users\\Wilhelm\\dev\\MachineLearning\\ML1\r\n\t\tCopying MLModel1.training.cs to folder: G:\\Users\\Wilhelm\\dev\\MachineLearning\\ML1\r\n\t\tCOMPLETED\r\n\r\n\r\n\t\tUpdating nuget dependencies...\r\n\t\tStarting update NuGet dependencies async.\r\n\t\tInstalling nuget package, package ID: Microsoft.ML, package Version: 1.7.1\r\n\t\tstart nni training\r\n\t\tExperiment output folder: C:\\Users\\Wilhelm\\AppData\\Local\\Temp\\AutoML-NNI\\Experiment-O11PPN\r\n\t\t|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n\t\t|0    SdcaMaximumEntropyMulti                     0.8000         0.8000       1.6          0                     |\r\n\t\t|1    LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.2          1                     |\r\n\t\t|2    FastForestOva                               0.4067         0.4500       0.9          2                     |\r\n\t\t|3    SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9          3                     |\r\n\t\t|4    SdcaLogisticRegressionOva                   0.8000         0.8000       3.4          4                     |\r\n\t\t|5    FastTreeOva                                 0.3400         0.3500       0.8          5                     |\r\n\t\t|6    LbfgsLogisticRegressionOva                  0.8000         0.8000       0.1          6                     |\r\n\t\t|7    LightGbmMulti                               0.3067         0.3500       0.2          7                     |\r\n\t\t|8    FastForestOva                               0.4067         0.4500       0.9          8                     |\r\n\t\t|9    SdcaMaximumEntropyMulti                     0.3400         0.3500       0.9          9                     |\r\n\t\t|10   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         10                     |\r\n\t\t|11   LightGbmMulti                               0.3067         0.3500       0.1         11                     |\r\n\t\t|12   FastTreeOva                                 0.3400         0.3500       1.0         12                     |\r\n\t\t|13   SdcaLogisticRegressionOva                   0.8000         0.8000       3.4         13                     |\r\n\t\t|14   FastForestOva                               0.4067         0.4500       1.0         14                     |\r\n\t\t|15   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.1         15                     |\r\n\t\t|16   FastTreeOva                                 0.3400         0.3500       1.1         16                     |\r\n\t\t|17   LightGbmMulti                               0.3067         0.3500       0.1         17                     |\r\n\t\t|18   SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9         18                     |\r\n\t\t|19   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         19                     |\r\n\t\t|20   FastForestOva                               0.4067         0.4500       1.2         20                     |\r\n\t\t|21   SdcaLogisticRegressionOva                   0.3400         0.3500       3.5         21                     |\r\n\t\t|22   FastTreeOva                                 0.3400         0.3500       1.2         22                     |\r\n\t\t|23   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2         23                     |\r\n\t\t|24   SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9         24                     |\r\n\t\t|25   LightGbmMulti                               0.3067         0.3500       0.1         25                     |\r\n\t\t|26   SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9         26                     |\r\n\t\t|27   FastForestOva                               0.4067         0.4500       1.4         27                     |\r\n\t\t|28   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         28                     |\r\n\t\t|29   SdcaLogisticRegressionOva                   0.8000         0.8000       3.5         29                     |\r\n\t\t|30   SdcaMaximumEntropyMulti                     0.3400         0.3500       1.0         30                     |\r\n\t\t|31   LbfgsLogisticRegressionOva                  0.3067         0.3500       0.2         31                     |\r\n\t\t|32   FastTreeOva                                 0.3400         0.3500       1.5         32                     |\r\n\t\t|33   LightGbmMulti                               0.3067         0.3500       0.1         33                     |\r\n\t\t|34   SdcaLogisticRegressionOva                   0.3400         0.3500       3.5         34                     |\r\n\t\t|35   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         35                     |\r\n\t\t|36   FastForestOva                               0.4067         0.4500       1.7         36                     |\r\n\t\t|37   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2         37                     |\r\n\t\t|38   SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9         38                     |\r\n\t\t|39   LightGbmMulti                               0.3067         0.3500       0.1         39                     |\r\n\t\t|40   FastTreeOva                                 0.3400         0.3500       1.7         40                     |\r\n\t\t|41   FastForestOva                               0.4067         0.4500       1.9         41                     |\r\n\t\t|42   LbfgsMaximumEntropyMulti                    0.3067         0.3500       0.1         42                     |\r\n\t\t|43   SdcaLogisticRegressionOva                   0.3400         0.3500       3.6         43                     |\r\n\t\t|44   LbfgsLogisticRegressionOva                  0.3067         0.3500       0.2         44                     |\r\n\t\t|45   SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0         45                     |\r\n\t\t|46   FastTreeOva                                 0.3400         0.3500       1.9         46                     |\r\n\t\t|47   LightGbmMulti                               0.3067         0.3500       0.1         47                     |\r\n\t\t|48   FastForestOva                               0.4067         0.4500       2.0         48                     |\r\n\t\t|49   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         49                     |\r\n\t\t|50   SdcaMaximumEntropyMulti                     0.3400         0.3500       1.0         50                     |\r\n\t\t|51   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2         51                     |\r\n\t\t|52   SdcaLogisticRegressionOva                   0.8000         0.8000       3.7         52                     |\r\n\t\t|53   FastTreeOva                                 0.3400         0.3500       2.1         53                     |\r\n\t\t|54   SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9         54                     |\r\n\t\t|55   LightGbmMulti                               0.3067         0.3500       0.1         55                     |\r\n\t\t|57   SdcaLogisticRegressionOva                   0.8000         0.8000       3.7         57                     |\r\n\t\t|58   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         58                     |\r\n\t\t|59   SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0         59                     |\r\n\t\t|60   LbfgsLogisticRegressionOva                  0.3067         0.3500       0.2         60                     |\r\n\t\t|61   FastTreeOva                                 0.3400         0.3500       2.4         61                     |\r\n\t\t|62   SdcaLogisticRegressionOva                   0.8000         0.8000       3.6         62                     |\r\n\t\t|63   LightGbmMulti                               0.3067         0.3500       0.1         63                     |\r\n\t\t|64   SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0         64                     |\r\n\t\t|66   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         66                     |\r\n\t\t|67   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2         67                     |\r\n\t\t|68   FastTreeOva                                 0.3400         0.3500       2.5         68                     |\r\n\t\t|69   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         69                     |\r\n\t\t|70   SdcaLogisticRegressionOva                   0.8000         0.8000       3.7         70                     |\r\n\t\t|71   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         71                     |\r\n\t\t|72   FastForestOva                               0.4067         0.4500       2.6         72                     |\r\n\t\t|73   SdcaMaximumEntropyMulti                     0.3400         0.3500       1.0         73                     |\r\n\t\t|74   LightGbmMulti                               0.3067         0.3500       0.1         74                     |\r\n\t\t|75   FastTreeOva                                 0.3400         0.3500       2.6         75                     |\r\n\t\t|76   LbfgsLogisticRegressionOva                  0.3067         0.3500       0.2         76                     |\r\n\t\t|77   FastForestOva                               0.4067         0.4500       2.7         77                     |\r\n\t\t|78   SdcaLogisticRegressionOva                   0.3400         0.3500       3.6         78                     |\r\n\t\t|79   LightGbmMulti                               0.3067         0.3500       0.1         79                     |\r\n\t\t|80   SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0         80                     |\r\n\t\t|81   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         81                     |\r\n\t\t|82   FastForestOva                               0.4067         0.4500       2.8         82                     |\r\n\t\t|83   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2         83                     |\r\n\t\t|84   SdcaLogisticRegressionOva                   0.8000         0.8000       3.6         84                     |\r\n\t\t|85   FastTreeOva                                 0.3400         0.3500       2.9         85                     |\r\n\t\t|86   LightGbmMulti                               0.3067         0.3500       0.1         86                     |\r\n\t\t|87   FastForestOva                               0.4067         0.4500       3.0         87                     |\r\n\t\t|88   LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3         88                     |\r\n\t\t|89   SdcaMaximumEntropyMulti                     0.8000         0.8000       0.9         89                     |\r\n\t\t|90   LbfgsMaximumEntropyMulti                    0.3067         0.3500       0.1         90                     |\r\n\t\t|91   FastForestOva                               0.4067         0.4500       3.1         91                     |\r\n\t\t|92   FastTreeOva                                 0.3400         0.3500       3.1         92                     |\r\n\t\t|93   SdcaLogisticRegressionOva                   0.3400         0.3500       3.7         93                     |\r\n\t\t|94   LbfgsLogisticRegressionOva                  0.3067         0.3500       0.2         94                     |\r\n\t\t|95   LightGbmMulti                               0.3067         0.3500       0.1         95                     |\r\n\t\t|96   LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1         96                     |\r\n\t\t|97   SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0         97                     |\r\n\t\t|98   FastForestOva                               0.4067         0.4500       3.5         98                     |\r\n\t\t|99   SdcaLogisticRegressionOva                   0.8000         0.8000       3.7         99                     |\r\n\t\t|100  FastTreeOva                                 0.3400         0.3500       3.3        100                     |\r\n\t\t|101  LightGbmMulti                               0.3067         0.3500       0.1        101                     |\r\n\t\t|102  SdcaLogisticRegressionOva                   0.8000         0.8000       3.7        102                     |\r\n\t\t|103  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2        103                     |\r\n\t\t|104  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        104                     |\r\n\t\t|105  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        105                     |\r\n\t\t|106  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        106                     |\r\n\t\t|107  FastForestOva                               0.4067         0.4500       3.5        107                     |\r\n\t\t|108  FastTreeOva                                 0.3400         0.3500       3.5        108                     |\r\n\t\t|109  SdcaLogisticRegressionOva                   0.8000         0.8000       3.8        109                     |\r\n\t\t|110  LightGbmMulti                               0.3067         0.3500       0.1        110                     |\r\n\t\t|111  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        111                     |\r\n\t\t|112  FastForestOva                               0.4067         0.4500       3.6        112                     |\r\n\t\t|113  FastTreeOva                                 0.3400         0.3500       3.6        113                     |\r\n\t\t|114  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.2        114                     |\r\n\t\t|115  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        115                     |\r\n\t\t|116  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        116                     |\r\n\t\t|117  LightGbmMulti                               0.3067         0.3500       0.1        117                     |\r\n\t\t|118  SdcaLogisticRegressionOva                   0.3400         0.3500       3.8        118                     |\r\n\t\t|119  FastForestOva                               0.4067         0.4500       3.7        119                     |\r\n\t\t|120  FastTreeOva                                 0.3400         0.3500       4.2        120                     |\r\n\t\t|121  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        121                     |\r\n\t\t|122  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        122                     |\r\n\t\t|123  LightGbmMulti                               0.3067         0.3500       0.1        123                     |\r\n\t\t|124  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        124                     |\r\n\t\t|125  SdcaLogisticRegressionOva                   0.8000         0.8000       3.8        125                     |\r\n\t\t|126  FastForestOva                               0.4067         0.4500       3.8        126                     |\r\n\t\t|127  LightGbmMulti                               0.3067         0.3500       0.1        127                     |\r\n\t\t|128  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        128                     |\r\n\t\t|129  FastTreeOva                                 0.3400         0.3500       4.0        129                     |\r\n\t\t|130  SdcaLogisticRegressionOva                   0.8000         0.8000       3.7        130                     |\r\n\t\t|131  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        131                     |\r\n\t\t|132  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        132                     |\r\n\t\t|133  LightGbmMulti                               0.3067         0.3500       0.2        133                     |\r\n\t\t|134  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        134                     |\r\n\t\t|135  FastForestOva                               0.4067         0.4500       4.6        135                     |\r\n\t\t|136  SdcaLogisticRegressionOva                   0.8000         0.8000       3.8        136                     |\r\n\t\t|137  FastTreeOva                                 0.3400         0.3500       4.5        137                     |\r\n\t\t|138  LightGbmMulti                               0.3067         0.3500       0.1        138                     |\r\n\t\t|139  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        139                     |\r\n\t\t|140  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        140                     |\r\n\t\t|141  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        141                     |\r\n\t\t|142  FastForestOva                               0.4067         0.4500       4.5        142                     |\r\n\t\t|143  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        143                     |\r\n\t\t|144  SdcaLogisticRegressionOva                   0.8000         0.8000       3.9        144                     |\r\n\t\t|145  FastTreeOva                                 0.3400         0.3500       4.2        145                     |\r\n\t\t|146  LightGbmMulti                               0.3067         0.3500       0.1        146                     |\r\n\t\t|147  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        147                     |\r\n\t\t|148  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        148                     |\r\n\t\t|149  FastForestOva                               0.4067         0.4500       4.3        149                     |\r\n\t\t|150  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        150                     |\r\n\t\t|151  LightGbmMulti                               0.3067         0.3500       0.1        151                     |\r\n\t\t|152  SdcaLogisticRegressionOva                   0.8000         0.8000       3.8        152                     |\r\n\t\t|153  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.1        153                     |\r\n\t\t|154  FastTreeOva                                 0.3400         0.3500       4.6        154                     |\r\n\t\t|155  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        155                     |\r\n\t\t|156  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        156                     |\r\n\t\t|157  SdcaLogisticRegressionOva                   0.8000         0.8000       3.8        157                     |\r\n\t\t|158  FastForestOva                               0.4067         0.4500       5.1        158                     |\r\n\t\t|159  LightGbmMulti                               0.3067         0.3500       0.1        159                     |\r\n\t\t|160  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        160                     |\r\n\t\t|161  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        161                     |\r\n\t\t|162  FastTreeOva                                 0.3400         0.3500       5.0        162                     |\r\n\t\t|163  SdcaLogisticRegressionOva                   0.8000         0.8000       3.9        163                     |\r\n\t\t|164  LightGbmMulti                               0.3067         0.3500       0.2        164                     |\r\n\t\t|166  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        166                     |\r\n\t\t|167  LightGbmMulti                               0.3067         0.3500       0.1        167                     |\r\n\t\t|168  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.2        168                     |\r\n\t\t|169  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        169                     |\r\n\t\t|170  SdcaLogisticRegressionOva                   0.8000         0.8000       3.9        170                     |\r\n\t\t|171  FastForestOva                               0.4067         0.4500       4.7        171                     |\r\n\t\t|172  FastTreeOva                                 0.3400         0.3500       5.1        172                     |\r\n\t\t|173  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        173                     |\r\n\t\t|174  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        174                     |\r\n\t\t|175  LightGbmMulti                               0.3067         0.3500       0.2        175                     |\r\n\t\t|177  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        177                     |\r\n\t\t|178  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        178                     |\r\n\t\t|179  SdcaLogisticRegressionOva                   0.8000         0.8000       3.9        179                     |\r\n\t\t|180  FastTreeOva                                 0.3400         0.3500       4.8        180                     |\r\n\t\t|181  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        181                     |\r\n\t\t|182  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.1        182                     |\r\n\t\t|183  FastForestOva                               0.4067         0.4500       5.0        183                     |\r\n\t\t|184  LightGbmMulti                               0.3067         0.3500       0.2        184                     |\r\n\t\t|185  SdcaLogisticRegressionOva                   0.8000         0.8000       3.9        185                     |\r\n\t\t|186  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.1        186                     |\r\n\t\t|187  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        187                     |\r\n\t\t|188  FastTreeOva                                 0.3400         0.3500       5.0        188                     |\r\n\t\t|189  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        189                     |\r\n\t\t|190  SdcaLogisticRegressionOva                   0.8000         0.8000       4.0        190                     |\r\n\t\t|191  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.2        191                     |\r\n\r\n\t\t===============================================Experiment Results=================================================\r\n\t\t------------------------------------------------------------------------------------------------------------------\r\n\t\t|                                                     Summary                                                    |\r\n\t\t------------------------------------------------------------------------------------------------------------------\r\n\t\t|ML Task: Classification                                                                                         |\r\n\t\t|Dataset: S:\\CATS\\files\\data_analysis\\output\\AggregatedFile\\small_2.csv                                          |\r\n\t\t|Label : c11                                                                                                     |\r\n\t\t|Total experiment time : 295.89 Secs                                                                             |\r\n\t\t|Total number of models explored: 188                                                                            |\r\n\t\t------------------------------------------------------------------------------------------------------------------\r\n\r\n\t\t|                                              Top 5 models explored                                             |\r\n\t\t------------------------------------------------------------------------------------------------------------------\r\n\t\t|     Trainer                              MicroAccuracy  MacroAccuracy  Duration #Iteration                     |\r\n\t\t|187  LbfgsMaximumEntropyMulti                    0.8000         0.8000       0.2        187                     |\r\n\t\t|186  SdcaLogisticRegressionOva                   0.8000         0.8000       4.0        186                     |\r\n\t\t|185  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.0        185                     |\r\n\t\t|183  LbfgsLogisticRegressionOva                  0.8000         0.8000       0.3        183                     |\r\n\t\t|182  SdcaMaximumEntropyMulti                     0.8000         0.8000       1.1        182                     |\r\n\t\t------------------------------------------------------------------------------------------------------------------\r\n\r\n\t\tGenerate code behind files\r\n\r\n\r\n\t\tCopying generated code to project...\r\n\t\tCopying MLModel1.consumption.cs to folder: G:\\Users\\Wilhelm\\dev\\MachineLearning\\ML1\r\n\t\tCopying MLModel1.training.cs to folder: G:\\Users\\Wilhelm\\dev\\MachineLearning\\ML1\r\n\t\tCOMPLETED\r\n\r\n\r\n\t\tUpdating nuget dependencies...\r\n\t\tStarting update NuGet dependencies async.\r\n\t\tInstalling nuget package, package ID: Microsoft.ML, package Version: 1.7.1\r\n\r\nI would have excepted it to have found a good results\r\n\r\nSo I tried with 1 algo via c# and I got this:\r\n\r\n\t\tProcessing LightGbm\r\n\t\tBestRun TrainerName:        LightGbmMulti\r\n\t\t\t- MicroAccuracy:        1\r\n\t\t\t- MacroAccuracy:        1\r\n\t\t\t- LogLoss:              0.08765842991120704\r\n\t\t\t- CLogLossReduction:    Infinity\r\n\r\n\t\tClass log loss:\r\n\t\t\t- class 1: 0\r\n\t\t\t- class 2: 0.09051613072327441\r\n\t\t\t- class 3: 0\r\n\r\n\t\tConfusionMatrix.PerClassPrecision:\r\n\t\tclass 1: 0\r\n\t\tclass 2: 1\r\n\t\tclass 3: 0\r\n\r\n\t\tConfusionMatrix.PerClassPrecision:\r\n\t\t\t- class 1: 0, 0, 0,\r\n\t\t\t- class 2: 0, 3, 0,\r\n\t\t\t- class 3: 0, 0, 0,\r\n\t\tSaving model!!!\r\n\t\tDone saving...\r\n\t\t\r\n**Shouldn't the Confusion Matrix look like this?**\r\n\t\t\t- class 1: 11, 0, 0,\r\n\t\t\t- class 2: 0, 11, 0,\r\n\t\t\t- class 3: 0, 0, 2,\r\n\r\nI'm running the other Trainer and will post once done...right now it seems stuck on \tAveragedPerceptronOva, its been 20 min already....\r\n\r\n\t\t\r\nUpdate after some time (I kill the program when too long so it can move to the next trainer):\r\n\r\n  \t\t  Processing LightGbm\r\n\t\t  BestRun TrainerName:        LightGbmMulti\r\n\t\t\t  - MicroAccuracy:        1\r\n\t\t\t  - MacroAccuracy:        1\r\n\t\t\t  - LogLoss:              0.08765842991120704\r\n\t\t\t  - CLogLossReduction:    Infinity\r\n\t\t  \r\n\t\t  Class log loss:\r\n\t\t\t  - class 1: 0\r\n\t\t\t  - class 2: 0.09051613072327441\r\n\t\t\t  - class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t  class 1: 0\r\n\t\t  class 2: 1\r\n\t\t  class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t\t  - class 1: 0, 0, 0,\r\n\t\t\t  - class 2: 0, 3, 0,\r\n\t\t\t  - class 3: 0, 0, 0,\r\n\t\t  Saving model!!!\r\n\t\t  Done saving...\r\n\t\t  \r\n\t\t  Duration: 00:00:00.7684543\r\n\t\t  ---------------------\r\n\t\t  \r\n\t\t \r\n\t\t  Processing AveragedPerceptronOva\r\n\t\t  ^CTerminate batch job (Y/N)? n\r\n\t\t  \r\n\t\t  --------------------------------\r\n\t\t  Processing FastForestOva\r\n\t\t  BestRun TrainerName:        FastForestOva\r\n\t\t\t  - MicroAccuracy:        1\r\n\t\t\t  - MacroAccuracy:        1\r\n\t\t\t  - LogLoss:              0.13785668008671875\r\n\t\t\t  - CLogLossReduction:    Infinity\r\n\t\t  \r\n\t\t  Class log loss:\r\n\t\t\t  - class 1: 0\r\n\t\t\t  - class 2: 0.1283592552410416\r\n\t\t\t  - class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t  class 1: 0\r\n\t\t  class 2: 1\r\n\t\t  class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t\t  - class 1: 0, 0, 0,\r\n\t\t\t  - class 2: 0, 3, 0,\r\n\t\t\t  - class 3: 0, 0, 0,\r\n\t\t  Saving model!!!\r\n\t\t  Done saving...\r\n\t\t  \r\n\t\t  Duration: 00:00:01.3639996\r\n\t\t  ---------------------\r\n\t\t  \r\n\t\t \r\n\t\t  Processing FastTreeOva\r\n\t\t  BestRun TrainerName:        FastTreeOva\r\n\t\t\t  - MicroAccuracy:        1\r\n\t\t\t  - MacroAccuracy:        1\r\n\t\t\t  - LogLoss:              0.38632734814558706\r\n\t\t\t  - CLogLossReduction:    Infinity\r\n\t\t  \r\n\t\t  Class log loss:\r\n\t\t\t  - class 1: 0\r\n\t\t\t  - class 2: 0.3665745755147897\r\n\t\t\t  - class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t  class 1: 0\r\n\t\t  class 2: 1\r\n\t\t  class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t\t  - class 1: 0, 0, 0,\r\n\t\t\t  - class 2: 0, 3, 0,\r\n\t\t\t  - class 3: 0, 0, 0,\r\n\t\t  Saving model!!!\r\n\t\t  Done saving...\r\n\t\t  \r\n\t\t  Duration: 00:00:02.0520908\r\n\t\t  ---------------------\r\n\t\t  \r\n\t\t \r\n\t\t  Processing LinearSupportVectorMachinesOva\r\n\t\t  ^CTerminate batch job (Y/N)? n\r\n\t\t  \r\n\t\t  -----------------------------------------\r\n\t\t  Processing LbfgsMaximumEntropy\r\n\t\t  ^CTerminate batch job (Y/N)? n\r\n\t\t  \r\n\t\t  -----------------------------------------------------------\r\n\t\t  Processing LbfgsLogisticRegressionOva\r\n\t\t  ^CTerminate batch job (Y/N)? n\r\n\t\t  \r\n\t\t -------------------------------------------------------\r\n\t\t  Processing SdcaMaximumEntropy\r\n\t\t  BestRun TrainerName:        SdcaMaximumEntropyMulti\r\n\t\t\t  - MicroAccuracy:        1\r\n\t\t\t  - MacroAccuracy:        1\r\n\t\t\t  - LogLoss:              0.0034730878249029256\r\n\t\t\t  - CLogLossReduction:    Infinity\r\n\t\t  \r\n\t\t  Class log loss:\r\n\t\t\t  - class 1: 0\r\n\t\t\t  - class 2: 0.0021820014848649345\r\n\t\t\t  - class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t  class 1: 0\r\n\t\t  class 2: 1\r\n\t\t  class 3: 0\r\n\t\t  \r\n\t\t  ConfusionMatrix.PerClassPrecision:\r\n\t\t\t  - class 1: 0, 0, 0,\r\n\t\t\t  - class 2: 0, 3, 0,\r\n\t\t\t  - class 3: 0, 0, 0,\r\n\t\t  Saving model!!!\r\n\t\t  Done saving...\r\n\t\t  \r\n\t\t  Duration: 00:00:02.0249306\r\n\t\t  ---------------------\r\n\t\t  \r\n\t\t \r\n\t\t  Processing SgdCalibratedOva\r\n\t\t  ^CTerminate batch job (Y/N)? n\r\n\t\t  \r\n\t\t  -------------------------------\r\n\t\t  Processing SymbolicSgdLogisticRegressionOva\r\n\t\t  ^CTerminate batch job (Y/N)? n\r\n\r\n\r\n\r\n=====================================\r\nMore or less related issues: \r\n- https://github.com/dotnet/machinelearning/issues/6309\r\n- https://github.com/dotnet/machinelearning/issues/6297\r\n- https://github.com/dotnet/machinelearning/issues/6309","Url":"https://github.com/dotnet/machinelearning/issues/6309","RelatedDescription":"Open issue \"[ML.Net c#, CLI, VS Builder] 1KB csv input file. Not sure what to do \" (#6309)"},{"Id":"1352983294","IsPullRequest":false,"CreatedAt":"2022-08-27T08:26:38","Actor":"PerfectEngineer","Number":"6308","RawContent":null,"Title":"Image Prediction : OOM when allocating tensor with shape","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Win 10\r\n- **.NET Version (eg., dotnet --info)**:  6.0\r\n- **ML.NET Version**: ML.NET v1.7.1\r\n- **SciSharp.TensorFlow.Redis: 2.3.1**\r\n\r\n**Issue OOM when allocating tensor**\r\n\r\n \r\n### Code\r\nBitmapImage imageAsBitmap = new BitmapImage(new Uri(\"D:/ImageToGetPrediction.jpeg\"));\r\nvar encoder = new JpegBitmapEncoder();\r\nencoder.Frames.Add(BitmapFrame.Create(imageAsBitmap));\r\nvar input = new Input();\r\n\r\nusing (MemoryStream ms = new MemoryStream())\r\n{\r\nencoder.Save(ms);\r\ninput.Image = ms.ToArray();\r\n}\r\nvar prediction = _predictor.Predict(input);\r\n\r\n\r\n\r\n### Exception \r\nOOM when allocating tensor with shape[1,75,75,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\r\n\t [[{{node resnet_v2_101/block1/unit_1/bottleneck_v2/conv3/BiasAdd}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\nINNERMESSAGE \r\nSTACKTRACE:    at Microsoft.ML.TensorFlow.TensorFlowUtils.Runner.Run()\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters.Classifier.Score(VBuffer`1& image, Span`1 classProbabilities)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters.<>c__DisplayClass22_0`2.<Microsoft.ML.Data.IValueMapper.GetMapper>b__0(VBuffer`1& src, VBuffer`1& dst)\r\n   at Microsoft.ML.Data.SchemaBindablePredictorWrapperBase.<>c__DisplayClass19_0`2.<GetValueGetter>b__0(TDst& dst)\r\n   at Microsoft.ML.Data.PredictedLabelScorerBase.EnsureCachedPosition[TScore](Int64& cachedPosition, TScore& score, DataViewRow boundRow, ValueGetter`1 scoreGetter)\r\n   at Microsoft.ML.Data.MulticlassClassificationScorer.<>c__DisplayClass16_0.<GetPredictedLabelGetter>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)","Url":"https://github.com/dotnet/machinelearning/issues/6308","RelatedDescription":"Open issue \"Image Prediction : OOM when allocating tensor with shape\" (#6308)"},{"Id":"1352968739","IsPullRequest":false,"CreatedAt":"2022-08-27T07:12:42","Actor":"PerfectEngineer","Number":"6307","RawContent":null,"Title":"Exception during Predict ","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version:  ML.NET v1.7.1\r\n - .NET Version:  .NET 6.0\r\n - SciSharp.TensorFlow.Redis: 2.3.1\r\n**Expected behavior**\r\nShould able to get prediction \r\n\r\n**CODE**\r\n\r\nBitmapImage imageAsBitmap = new BitmapImage(new Uri(\"D:/ImageToGetPrediction.jpeg\"));\r\nvar encoder = new JpegBitmapEncoder();\r\nencoder.Frames.Add(BitmapFrame.Create(imageAsBitmap));\r\nvar input = new Input();\r\n\r\nusing (MemoryStream ms = new MemoryStream())\r\n{\r\n    encoder.Save(ms);\r\n    input.Image = ms.ToArray();\r\n}\r\n    var prediction = _predictor.Predict(input);\r\n\r\n**STACKTRACE**\r\n\r\nError: External component has thrown an exception \r\n\r\nSTACKTRACE:    at Tensorflow.c_api.TF_SessionRun(IntPtr session, TF_Buffer* run_options, TF_Output[] inputs, IntPtr[] input_values, Int32 ninputs, TF_Output[] outputs, IntPtr[] output_values, Int32 noutputs, IntPtr[] target_opers, Int32 ntargets, IntPtr run_metadata, SafeStatusHandle status)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.Runner.Run()\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters.Classifier.Score(VBuffer`1& image, Span`1 classProbabilities)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters.<>c__DisplayClass22_0`2.<Microsoft.ML.Data.IValueMapper.GetMapper>b__0(VBuffer`1& src, VBuffer`1& dst)\r\n   at Microsoft.ML.Data.SchemaBindablePredictorWrapperBase.<>c__DisplayClass19_0`2.<GetValueGetter>b__0(TDst& dst)\r\n   at Microsoft.ML.Data.PredictedLabelScorerBase.EnsureCachedPosition[TScore](Int64& cachedPosition, TScore& score, DataViewRow boundRow, ValueGetter`1 scoreGetter)\r\n   at Microsoft.ML.Data.MulticlassClassificationScorer.<>c__DisplayClass16_0.<GetPredictedLabelGetter>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6307","RelatedDescription":"Open issue \"Exception during Predict \" (#6307)"},{"Id":"1352965598","IsPullRequest":false,"CreatedAt":"2022-08-27T06:57:38","Actor":"PerfectEngineer","Number":"6306","RawContent":null,"Title":"0x80004005 during CreatePredictionEngine","State":"open","Body":"### System information\r\n\r\n- **OS  Win 10\r\n- **.NET Version    Dot Net 6.0\r\n\r\n### Issue\r\nException and System Hang \r\n- **What did you do?**\r\nI am getting Prediction from the model generated for Image classification \r\n- **What happened?**\r\nSystem Hangs \r\n- **What did you expect?**\r\nShould predict the result\r\n### Source code / logs\r\n\r\n**Code**\r\n \r\nvar context = new MLContext(seed: 0);\r\nvar model = context.Model.Load(_modelPath, out DataViewSchema schema);\r\nPredictionEngine<Input, Output> _predicto = context.Model.CreatePredictionEngine<Input, Output>(model);\r\n\r\n\r\n**Exception Log**\r\nConstructor  Details: Error during class instantiationINNERMESSAGE System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.InvalidOperationException: Error during class instantiation\r\n ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation.\r\n ---> System.FormatException: Tensorflow exception triggered while loading model.\r\n ---> System.Runtime.InteropServices.SEHException (0x80004005): External component has thrown an exception.\r\n   at Tensorflow.c_api.TF_GraphImportGraphDef(IntPtr graph, SafeBufferHandle graph_def, SafeImportGraphDefOptionsHandle options, SafeStatusHandle status)\r\n   at Tensorflow.Graph.Import(Byte[] bytes, String prefix)\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSession(IExceptionContext ectx, Byte[] modelBytes, String modelFile)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.LoadTFSession(IExceptionContext ectx, Byte[] modelBytes, String modelFile)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Vision.ImageClassificationModelParameters.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Span`1& arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.MulticlassPredictionTransformer.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Span`1& arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   at Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   at Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- End of inner exception stack trace ---\r\n   at System.RuntimeMethodHandle.InvokeMethod(Object target, Span`1& arguments, Signature sig, Boolean constructor, Boolean wrapExceptions)\r\n   at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   at Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6306","RelatedDescription":"Open issue \"0x80004005 during CreatePredictionEngine\" (#6306)"},{"Id":"1352726298","IsPullRequest":true,"CreatedAt":"2022-08-26T20:57:52","Actor":"LittleLittleCloud","Number":"6305","RawContent":null,"Title":"Add SetMaximumMemoryUsageInMegaByte in AutoMLExperiment","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis PR adds `SetMaximumMemoryUsageInMegaByte`, which sets limit to the maximum memory a trial can use, and cancel that running trial if it exceeds the maximum memory limitation.\r\n\r\n#6293 \r\n### Example\r\n```csharp\r\n// set maximum memory usage to 8gb\r\nexperiment.SetMaximumMemoryUsageInMegaByte(8 * 1024);\r\n```\r\n\r\n### How it work\r\n`AutoMLExperiment` monitors the memory and cpu usage periodically (the default period is 2 seconds) using `IPerformanceMonitor`, and once the trial exceed the boundary, `AutoMLExperiment` cancel that trial via `MLContext.CancelExecution` and does clean up.\r\n\r\n### Known limitation\r\nThis requires estimator support cancel during training by checking if context is still alive from time to time, which is not true for all estimators in ML.Net. \r\nFor example, `LGBM` can't  check if context is alive in unmanaged code part, which makes it can't be cancelled during the time when it's calling into native LightGbm dll. In that situation, tiral memory usage might still exceed maximum limit.","Url":"https://github.com/dotnet/machinelearning/pull/6305","RelatedDescription":"Open PR \"Add SetMaximumMemoryUsageInMegaByte in AutoMLExperiment\" (#6305)"},{"Id":"1352701951","IsPullRequest":false,"CreatedAt":"2022-08-26T20:24:28","Actor":"luisquintanilla","Number":"6304","RawContent":null,"Title":"[AutoML API] API Suggestions","State":"open","Body":"- When setting evaluation metrics using methods like `SetBinaryClassificationMetric`, the default value for `labelColumn` parameter is *label*. This is inconsistent with like the `predictColumn` parameter and the rest of ML.NET. Suggest change to `Label`. \r\n- When setting evaluation metrics using methods like `SetBinaryClassificationMetric`, the parameter names are `labelColumn` and `predictColumn`. In ML.NET, typically parameters referring to column names include name. Suggest change of parameter names to `labelColumnName` and `predictColumnName`. ","Url":"https://github.com/dotnet/machinelearning/issues/6304","RelatedDescription":"Open issue \"[AutoML API] API Suggestions\" (#6304)"},{"Id":"1345657959","IsPullRequest":false,"CreatedAt":"2022-08-26T15:53:57","Actor":"luisquintanilla","Number":"6298","RawContent":null,"Title":"NotebookMonitor doesn't display AutoML training progress.","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 0.20.0-preview.22356.1\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\n\r\nNotebookMonitor displays gray box in output window instead of AutoML training progress\r\n\r\n**To Reproduce**\r\n\r\nRun the following notebook https://github.com/dotnet/csharp-notebooks/blob/main/machine-learning/03-Training%20and%20AutoML.ipynb\r\n\r\n**Expected behavior**\r\n\r\nNotebookMonitor displays AutoML training progress\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/185819923-6b2a31e5-0d2c-4050-a9bc-1373a568d03d.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6298","RelatedDescription":"Closed issue \"NotebookMonitor doesn't display AutoML training progress.\" (#6298)"},{"Id":"1351588693","IsPullRequest":true,"CreatedAt":"2022-08-26T00:38:22","Actor":"dakersnar","Number":"6303","RawContent":null,"Title":"Fix problems with DataFrame WriteCsv","State":"open","Body":"https://github.com/dotnet/machinelearning/issues/5647 is no longer present, but while investigating that issue I discovered some bugs with `WriteCsv`. This PR does the following:\r\n\r\n- Fixes bugs where text qualifiers (quotation marks) were not properly added to the CSV output by `WriteCsv` in the following cases:\r\n    - There are separators in a row entry\r\n    - There are separators in a header name\r\n    - There are newlines in a row entry\r\n    - There are newlines in a header name\r\n- Adds test cases both confirming https://github.com/dotnet/machinelearning/issues/5647 is solved and validating that the above bugs are fixed.\r\n\r\nThis is my first contribution to this repo so style criticism appreciated.","Url":"https://github.com/dotnet/machinelearning/pull/6303","RelatedDescription":"Open PR \"Fix problems with DataFrame WriteCsv\" (#6303)"},{"Id":"1343322491","IsPullRequest":false,"CreatedAt":"2022-08-25T21:57:01","Actor":"papyr","Number":"6290","RawContent":null,"Title":"Native ML.NET notebook","State":"closed","Body":"Hello, can we get a native notebook inside Visual Studio or VS Code, since we already have a designer surface with all the drag and drop controls?","Url":"https://github.com/dotnet/machinelearning/issues/6290","RelatedDescription":"Closed issue \"Native ML.NET notebook\" (#6290)"},{"Id":"1342920666","IsPullRequest":true,"CreatedAt":"2022-08-25T14:25:17","Actor":"aseemsahoo","Number":"6289","RawContent":null,"Title":"Update ApacheArrow from 2.0.0 to 3.0.0","State":"closed","Body":"Updated ApacheArrow package from 2.0.0 to 3.0.0\r\n\r\n## ApacheArrow 3.0.0\r\n- [Release Notes](https://arrow.apache.org/release/3.0.0.html)\r\n- [Download and Install](https://www.apache.org/dyn/closer.lua/arrow/arrow-3.0.0/)\r\n\r\n\r\n## ApacheArrow 2.0.0\r\n- [Release Notes](https://arrow.apache.org/release/2.0.0.html)\r\n- [Download and Install](https://www.apache.org/dyn/closer.lua/arrow/arrow-2.0.0/)","Url":"https://github.com/dotnet/machinelearning/pull/6289","RelatedDescription":"Closed or merged PR \"Update ApacheArrow from 2.0.0 to 3.0.0\" (#6289)"},{"Id":"1341005843","IsPullRequest":true,"CreatedAt":"2022-08-25T05:55:46","Actor":"LittleLittleCloud","Number":"6285","RawContent":null,"Title":"Use SweepablePipeline","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n## Check out the spec for `SweepablePipeline` in https://github.com/dotnet/machinelearning/pull/6218\r\n\r\n `SweepablePipeline` is a combination of `MultiModelPipeline` and `SweepableEstimatorPipeline`, which supports a tree-like structure pipeline and support estimator-level search space using nested search space. \r\n\r\nIn another world, `SweepablePipeline` puts estimator candidates as part of its search space and makes it transparent to tuner. In this way, it decouples tuners from the detailed implementation of pipelines or trainers, and replacing them with `Parameter` and `SearchSpace`.  The hyper-parameter optimization process, with the help of `SweepablePipeline`, can be simplified to the following 3 steps\r\n\r\n- `ITuner` sample `parameter` from `search space`\r\n- `ITrialRunner` train model and calculate score from `parameter`\r\n- `ITuner` update associated `parameter` with score.\r\n\r\nAlso, it provides a uniform way to create pipeline that includes multiple estimator candidates with search space.\r\n\r\nAnd with this PR, the class that construct AutoML.Net Sweepable API is simplified to\r\n- `ISweepable`\r\n  - `SweepableEstimator`: Estimator with search space\r\n  - `SweepablePipeline` pipeline with search space\r\n ","Url":"https://github.com/dotnet/machinelearning/pull/6285","RelatedDescription":"Closed or merged PR \"Use SweepablePipeline\" (#6285)"},{"Id":"1348605189","IsPullRequest":true,"CreatedAt":"2022-08-24T17:41:09","Actor":"dakersnar","Number":"6301","RawContent":null,"Title":"Add DataFrame.IO tests with separators in data","State":"closed","Body":"https://github.com/dotnet/machinelearning/issues/5647 is no longer an issue, but there are no existing unit tests that confirm this behavior. Adding them here.","Url":"https://github.com/dotnet/machinelearning/pull/6301","RelatedDescription":"Closed or merged PR \"Add DataFrame.IO tests with separators in data\" (#6301)"},{"Id":"1349798471","IsPullRequest":true,"CreatedAt":"2022-08-24T17:30:27","Actor":"beccamc","Number":"6302","RawContent":null,"Title":"DataFrame: Add DateTime column type","State":"open","Body":"Fixes #6213, #5698, #5676\r\n\r\nAdd the DateTime type as a PrimitiveDataFrameColumn. This will better allow conversion between IDataView and the DataFrame. \r\n\r\nSome DateTime code exists already, like the DateTime computations. However, the partial implementation left bugs, particularly when trying to convert between IDataView and DataFrame. \r\n\r\nI tried to follow the existing patterns but if this shouldn't be bucketed in with the PrimitiveDataFrameColumns I can make changes. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6302","RelatedDescription":"Open PR \"DataFrame: Add DateTime column type\" (#6302)"},{"Id":"1347149536","IsPullRequest":true,"CreatedAt":"2022-08-23T00:16:02","Actor":"LittleLittleCloud","Number":"6300","RawContent":null,"Title":"use parameter to save choice object","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nfix #6299 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/6300","RelatedDescription":"Open PR \"use parameter to save choice object\" (#6300)"},{"Id":"1347027215","IsPullRequest":false,"CreatedAt":"2022-08-22T21:48:09","Actor":"LittleLittleCloud","Number":"6299","RawContent":null,"Title":"ChoiceAttribution doesn't work with int type.","State":"open","Body":"reproduction\r\n\r\n```csharp\r\nclass Param\r\n{\r\n   [Choice(1,2,3)]\r\n   public int Index {get; set;}\r\n}\r\n\r\n// throw exception\r\nvar ss = new SearchSpace<Param>();\r\nvar tuner = new RandomTuner(ss);\r\ntuner.Propose()\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6299","RelatedDescription":"Open issue \"ChoiceAttribution doesn't work with int type.\" (#6299)"},{"Id":"1343507056","IsPullRequest":false,"CreatedAt":"2022-08-22T19:54:35","Actor":"LittleLittleCloud","Number":"6291","RawContent":null,"Title":"AutoFeaturizer puts ReplacingMissingValue transformer to boolean column","State":"closed","Body":"The root cause is `InferColumn` API also infer a boolean column's column purpose as numeric. Which in some way makes sense as there's a direct way of mapping boolean to numeric.\r\n\r\nWhile in `AutoFeaturizer` API, it always put a `ReplacingMissingValue` transformer to numeric feature. This usually works if a column has numeric type. But when it comes to boolean type, `ReplacingMissingValue` won't work any more as there's no Default NA value for a boolean type.\r\n\r\nThe fix for this issue is in `AutoFeaturizer`, check if a column with numeric purpose is boolean type or not, if it is boolean, then use `ConvertType` transformer instead. ","Url":"https://github.com/dotnet/machinelearning/issues/6291","RelatedDescription":"Closed issue \"AutoFeaturizer puts ReplacingMissingValue transformer to boolean column\" (#6291)"},{"Id":"1343508939","IsPullRequest":true,"CreatedAt":"2022-08-21T02:38:07","Actor":"LittleLittleCloud","Number":"6292","RawContent":null,"Title":"transform boolean to numeric when column is numeric feature while is boolean type","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n#6291 ","Url":"https://github.com/dotnet/machinelearning/pull/6292","RelatedDescription":"Closed or merged PR \"transform boolean to numeric when column is numeric feature while is boolean type\" (#6292)"},{"Id":"1344711699","IsPullRequest":false,"CreatedAt":"2022-08-19T17:28:02","Actor":"wil70","Number":"6297","RawContent":null,"Title":"[Issue, ML.net C#] 330GB csv file of data cause a OutOfMemoryException (2/2)","State":"open","Body":"**System Information (please complete the following information):**\r\n\r\n-  OS & Version: Win8, latest version as of this bug entry\r\n- ML.NET Version: 16.13.9\r\n- .NET Version:6.0.303\r\n\r\n**Describe the bug**\r\nWhen I start c# AutoML in c# I get a OutOfMemoryException after the memory reach the maximum of 64GB.\r\nI have 64GB Ram, I have a 330GB csv file of data.\r\n\r\nNote: I couldn't do it with ML.net CLI due to this bug https://github.com/dotnet/machinelearning/issues/6288 so I tried to do it with c# AutoML package. I'm totally new at ML.NET, sorry in adavance for the code quality\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Generate a 330GB file with 4209 columns with random data\r\n2. create a c# project and paste the code below\r\n3. See error log at the end of this message with the OutOfMemoryException\r\n\r\n**Expected behavior**\r\nI expect to be able to be able to handle 2TB files and 100K columns without any issue with ML.Net CLI and also with c# on a 64GB ram computer by streaming the data instead of loading all in memeory.\r\n  \r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n\r\n\r\nI have a 330gb file (64 gb ram). I tried ML.NET CLI but hit a bug see.\r\nSo I'm now trying with c#, the bug is different than the ML.NET CLI issue as it seems to try to load everything in memory \r\n\r\nIDataView trainingData = mlContext.Data.LoadFromTextFile<ModelInput>(\r\n                \"c:\\data.csv\", \r\n                separatorChar: ',', hasHeader: true, trimWhitespace: true);\r\n\r\n            var cts = new CancellationTokenSource();\r\n            var experimentSettings = new MulticlassExperimentSettings();\r\n            //experimentSettings.TrainingData = trainingData;\r\n            experimentSettings.MaxExperimentTimeInSeconds = 3600;\r\n            experimentSettings.CancellationToken = cts.Token;\r\n            experimentSettings.CacheBeforeTrainer = CacheBeforeTrainer.Auto;\r\n\r\n            // Cancel experiment after the user presses any key\r\n            //CancelExperimentAfterAnyKeyPress(cts);\r\n            experimentSettings.CacheDirectoryName = null;\r\n\r\n            MulticlassClassificationExperiment experiment = mlContext.Auto().CreateMulticlassClassificationExperiment(experimentSettings);\r\n            ExperimentResult<MulticlassClassificationMetrics> experimentResult = experiment.Execute(trainingData, \"Entry(Text)\");//, progressHandler: progressHandler);\r\n\r\n\r\n.....\r\n public class ModelInput\r\n        {\r\n            [LoadColumn(0), NoColumn]\r\n            public string _data0 { get; set; }\r\n\r\n            [LoadColumn(1), NoColumn]\r\n            public float ignoreData1 { get; set; }\r\n\r\n            [LoadColumn(2, 4205)]\r\n            public float _data { get; set; }\r\n\r\n            [LoadColumn(4206),NoColumn]//(4206,4208)]\r\n            public float _ignoreData4206 { get; set; }         \r\n\t\t[LoadColumn(4207), NoColumn]//(4206,4208)]\r\n            public float _ignoreData4207 { get; set; }\r\n            [LoadColumn(4208), NoColumn]//(4206,4208)]\r\n            public float _ignoreData4208 { get; set; }\r\n\r\n            [LoadColumn(4209),ColumnName(\"Entry(Text)\")]\r\n            public string _label { get; set; }\r\n        }\r\n\r\n------\r\n\r\nThere is a Exception of type 'System.OutOfMemoryException' was thrown.\r\n(new System.Collections.Generic.Mscorlib_CollectionDebugView<Microsoft.ML.AutoML.RunDetail<Microsoft.ML.Data.MulticlassClassificationMetrics>>(experimentResult.RunDetails).Items[0]).Exception.StackTrace\r\n   at Microsoft.ML.Internal.Utilities.OrderedWaiter.Wait(Int64 position, CancellationToken token)\r\n   at Microsoft.ML.Data.CacheDataView.GetPermutationOrNull(Random rand)\r\n   at Microsoft.ML.Data.CacheDataView.GetRowCursorSetWaiterCore[TWaiter](TWaiter waiter, Func`2 predicate, Int32 n, Random rand)\r\n   at Microsoft.ML.Data.CacheDataView.GetRowCursorSet(IEnumerable`1 columnsNeeded, Int32 n, Random rand)\r\n   at Microsoft.ML.Data.OneToOneTransformBase.GetRowCursorSet(IEnumerable`1 columnsNeeded, Int32 n, Random rand)\r\n   at Microsoft.ML.Data.DataViewUtils.TryCreateConsolidatingCursor(DataViewRowCursor& curs, IDataView view, IEnumerable`1 columnsNeeded, IHost host, Random rand)\r\n   at Microsoft.ML.Data.TransformBase.GetRowCursor(IEnumerable`1 columnsNeeded, Random rand)\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.FactoryBase`1.Create(Random rand, Int32[] extraCols)\r\n   at Microsoft.ML.Trainers.OnlineLinearTrainer`2.TrainCore(IChannel ch, RoleMappedData data, TrainStateBase state)\r\n   at Microsoft.ML.Trainers.OnlineLinearTrainer`2.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.TrainOne(IChannel ch, ITrainerEstimator`2 trainer, RoleMappedData data, Int32 cls)\r\n   at Microsoft.ML.Trainers.OneVersusAllTrainer.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String groupId, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger)\r\n\r\n-----\r\nThere is a Exception of type 'System.OutOfMemoryException' was thrown.\r\n(new System.Collections.Generic.Mscorlib_CollectionDebugView<Microsoft.ML.AutoML.RunDetail<Microsoft.ML.Data.MulticlassClassificationMetrics>>(experimentResult.RunDetails).Items[0]).Exception.InnerException.StackTrace\r\n   at Microsoft.ML.Internal.Utilities.ArrayUtils.EnsureSize[T](T[]& array, Int32 min, Int32 max, Boolean keepOld, Boolean& resized)\r\n   at Microsoft.ML.Internal.Utilities.BigArray`1.AddRange(ReadOnlySpan`1 src)\r\n   at Microsoft.ML.Data.CacheDataView.ColumnCache.ImplVec`1.CacheCurrent()\r\n   at Microsoft.ML.Data.CacheDataView.Filler(DataViewRowCursor cursor, ColumnCache[] caches, OrderedWaiter waiter)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6297","RelatedDescription":"Open issue \"[Issue, ML.net C#] 330GB csv file of data cause a OutOfMemoryException (2/2)\" (#6297)"},{"Id":"1344421181","IsPullRequest":false,"CreatedAt":"2022-08-19T13:08:52","Actor":"prodanovic","Number":"6296","RawContent":null,"Title":"Support loading lightgbm model from a file","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nOur data scientists are training lightgbm models in python, and our inference runtime is in C#. We are very much interested in using ML.NET to run inference, however loading the model from a file is not yet supported in ML.NET. Is there an obstacle in adding this additional binding already available in lightgbm C++ API ?\r\n\r\n**Describe the solution you'd like**\r\nAdd LGBM_BoosterLoadModelFromString binding to [WrappedLightGbmInterface ()](https://github.com/dotnet/machinelearning/blob/510f0112d4fbb4d3ee233b9ca95c83fae1f9da91/src/Microsoft.ML.LightGbm/WrappedLightGbmInterface.cs#L189%7D) available in https://github.com/Microsoft/LightGBM/blob/master/include/LightGBM/c_api.h \r\n\r\n**Describe alternatives you've considered**\r\nAn alternative is to convert our models to ONNX and not use ML.NET runtime. \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6296","RelatedDescription":"Open issue \"Support loading lightgbm model from a file\" (#6296)"},{"Id":"1344070012","IsPullRequest":false,"CreatedAt":"2022-08-19T07:41:33","Actor":"kitosd","Number":"6295","RawContent":null,"Title":"Model Builder Error","State":"open","Body":"Model Builder Version : 16.1.0.20.27905\r\nVisual Studio Version : 16.11.18\r\n\r\nBug description\r\nWith freshly-updated [as of today, 2022-08-19] VS2019 and model builder, I tried to use the new ML builder wizard \"Value prediction\". It failed with an exception: Method not found: 'System.Collections.Generic.IEnumerable1<System.ValueTuple2<Microsoft.ML.AutoML.RunDetail`1<!!0>,Int32>> Microsoft.ML.AutoML.BestResultUtil.GetTopNRunResults\r\n\r\nSteps to Reproduce\r\n\r\nInstalled latest VS 2019 and updated Model Builder to latest version\r\nCreate new project. Right click on project -> Add -> \"Machine Learning\"\r\nChoose image classification, \"Local ML\", Next.\r\nAs input, choose an appropriate folder, observe \"data preview\" looks like I expected, with images being shown under various classifications\r\nTrain, Start Training.\r\nExpected Experience\r\nPretty much what I'd expect from the tutorial, and of a wizard.\r\n\r\nActual Experience\r\nShortly after click \"start training\", I get this:\r\n\"GPU Service not found. Falling back to CPU AutoML Service.\"\r\n\r\nMoments later, this exception:\r\nMethod not found: 'System.Collections.Generic.IEnumerable1<System.ValueTuple2<Microsoft.ML.AutoML.RunDetail1<!!0>,Int32>> Microsoft.ML.AutoML.BestResultUtil.GetTopNRunResults(System.Collections.Generic.IEnumerable1<Microsoft.ML.AutoML.RunDetail1<!!0>>, Microsoft.ML.AutoML.IMetricsAgent1<!!0>, Int32, Boolean)'.\r\nat Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment3.d__21.MoveNext() at System.Runtime.CompilerServices.AsyncTaskMethodBuilder1.Start[TStateMachine](TStateMachine& stateMachine)\r\nat Microsoft.ML.ModelBuilder.AutoMLService.Experiments.AutoMLExperiment3.ExecuteAsync(IDataView trainData, IDataView validateData, ColumnInformation columnInformation, Nullable1 userCancellationToken, Nullable`1 timeout)\r\nat Microsoft.ML.ModelBuilder.AutoMLEngine.d__30.MoveNext() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 147","Url":"https://github.com/dotnet/machinelearning/issues/6295","RelatedDescription":"Open issue \"Model Builder Error\" (#6295)"},{"Id":"1343739912","IsPullRequest":false,"CreatedAt":"2022-08-18T23:10:18","Actor":"luisquintanilla","Number":"6294","RawContent":null,"Title":"Convert TrialResult to DataFrame","State":"open","Body":"## Description\r\n\r\n[TrialResult](https://docs.microsoft.com/dotnet/api/microsoft.ml.automl.trialresult?view=ml-dotnet-preview) gives you important information about each trial AutoML runs as part of an experiment. Although today we have the NotebookMonitor for real-time visualizations and feedback during training, once training is done, to get similar information, users have to write their own code to access each of these pieces of information. \r\n\r\n## Proposal\r\n\r\nGiven an AutoML experiment called `experiment`, when training is done, users should be able to call `ToDataFrame` to convert the results of an AutoML experiment into a `DataFrame`.\r\n\r\n```csharp\r\nTrialResult experimentResults = await experiment.RunAsync();\r\nDataFrame results = experimentResults.ToDataFrame();\r\n```\r\n\r\nThe result should display columns with information for each of the trials in a DataFrame similar to the following:\r\n\r\n| TrialId | DurationInMilliseconds | Metric | Pipeline | Parameter |\r\n| --- | --- | --- | --- | --- |\r\n| 21 | 8.5 | 0.98 | ... | ... |\r\n| 5 | 3.8 | 0.83 | ... | ... |\r\n\r\nFrom there, if users to sort / query the results using the built-in DataFrame methods, they can. Additionally, they can export to CSV using the [WriteCsv](https://docs.microsoft.com/en-us/dotnet/api/microsoft.data.analysis.dataframe.writecsv?view=ml-dotnet-preview) method.","Url":"https://github.com/dotnet/machinelearning/issues/6294","RelatedDescription":"Open issue \"Convert TrialResult to DataFrame\" (#6294)"},{"Id":"1343697930","IsPullRequest":false,"CreatedAt":"2022-08-18T22:06:39","Actor":"LittleLittleCloud","Number":"6293","RawContent":null,"Title":"Add maximum memory usage limit to AutoML experiment","State":"open","Body":"We have a lot of users complaining about OOM error when using AutoML. This is because ML.Net AutoML tends to search larger model as time passes, so it's kind of necessary to put some hard limit on memory usages for AutoML training.","Url":"https://github.com/dotnet/machinelearning/issues/6293","RelatedDescription":"Open issue \"Add maximum memory usage limit to AutoML experiment\" (#6293)"},{"Id":"1342522914","IsPullRequest":false,"CreatedAt":"2022-08-18T03:42:03","Actor":"wil70","Number":"6288","RawContent":null,"Title":"[Issue, ML.net CLI] 330GB csv file of data cause a OutOfMemoryException (1/2)","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Win8, latest version as of this bug entry\r\n - ML.NET Version: 16.13.9\r\n - .NET Version:6.0.303\r\n\r\n**Describe the bug**\r\nWhen I start ML.net from CLI, I get a OutOfMemoryException \r\nI have 64GB Ram, I have a 330GB csv file of data.\r\n\r\nI tried with \r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Generate a 330GB file with 4209 columns with random data\r\n2. open prompt\r\n3. type in command line:\r\nmlnet classification --train-time 75600 --name SampleClassification --log-file-path c:\\Log_data.txt --has-header true --label-col 4209 --ignore-cols 0,1,4206,4207,4208 --dataset \"c:\\data.csv\" --test-dataset \"c:\\test_data.csv\"\r\n4. See error log at the end of this message with the OutOfMemoryException\r\n\r\n**Expected behavior**\r\nI expect ml.net to continue and feed the data as it stream it, so there should be no OutOfMemoryException\r\nWhen I monitor the mknet.exe prices with task manager, the mlnet.exe process doesn't go high at all, like less than ~14GB. So something is not right as I have 64GB and also it shouldn't matter isn't it as .\r\n\r\n**Screenshots, Code, Sample Projects**\r\n**Additional context**\r\nHere is the log\r\nStart Training\r\nstart nni training\r\nExperiment output folder: C:\\Users\\W\\AppData\\Local\\Temp\\AutoML-NNI\\Experiment-GET3JS\r\nSystem.FormatException: Parsing failed with an exception: Stream reading encountered exception\r\n ---> System.FormatException: Stream reading encountered exception\r\n ---> System.OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.\r\n   at System.Text.StringBuilder.ToString()\r\n   at System.IO.StreamReader.ReadLine()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.LineReader.ThreadProc()\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.TextLoader.Cursor.LineReader.GetBatch()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParallelState.Parse(Int32 tid)\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParallelState.ThreadProc(Object obj)\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParseParallel(ParallelState state)+MoveNext()\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Proposer.Controller.CountRows(IDataView data, Int64 maxRows) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Proposer/Controller.cs:line 174\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Proposer.Controller.Initialize() in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Proposer/Controller.cs:line 111\r\n   at Microsoft.ML.ModelBuilder.AutoMLService.Experiments.LocalAutoMLExperiment.ExecuteAsync(IDataView trainData, IDataView validateData, ColumnInformation columnInformation, CancellationToken cancellationToken, CancellationToken timeout) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/Experiments/LocalAutoMLExperiment.cs:line 138\r\n   at Microsoft.ML.ModelBuilder.AutoMLEngine.StartTrainingAsync(TrainingConfiguration config, PathConfiguration pathConfig, CancellationToken userCancellationToken) in /_/src/Microsoft.ML.ModelBuilder.AutoMLService/AutoMLEngineService/AutoMLEngine.cs:line 160\r\n   at Microsoft.ML.CLI.Runners.AutoMLRunner.ExecuteAsync() in /_/src/mlnet/Runners/AutoMLRunner.cs:line 88\r\n   at Microsoft.ML.CLI.Program.TrainAsync(TrainingConfiguration trainingConfiguration, PathConfiguration pathConfig, AutoMLServiceLogLevel logLevel) in /_/src/mlnet/Program.cs:line 348\r\n   at Microsoft.ML.CLI.Program.AutoMLCommandRunner(AutoMLCommand command, Boolean skipGenerateConsoleApp) in /_/src/mlnet/Program.cs:line 329\r\n   at Microsoft.ML.CLI.Program.<>c.<<CreateRootCommandLineBuilder>b__4_0>d.MoveNext() in /_/src/mlnet/Program.cs:line 89\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Invocation.CommandHandler.GetExitCodeAsync(Object value, InvocationContext context)\r\n   at System.CommandLine.Invocation.ModelBindingCommandHandler.InvokeAsync(InvocationContext context)\r\n   at System.CommandLine.Invocation.InvocationPipeline.<>c__DisplayClass4_0.<<BuildInvocationChain>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass23_0.<<UseParseErrorReporting>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at Microsoft.ML.CLI.Program.<>c__DisplayClass4_0.<<CreateRootCommandLineBuilder>b__9>d.MoveNext() in /_/src/mlnet/Program.cs:line 290\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c.<<UseSuggestDirective>b__24_0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass22_0.<<UseParseDirective>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass11_0.<<UseDebugDirective>b__0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c.<<RegisterWithDotnetSuggest>b__10_0>d.MoveNext()\r\n--- End of stack trace from previous location ---\r\n   at System.CommandLine.Builder.CommandLineBuilderExtensions.<>c__DisplayClass14_0.<<UseExceptionHandler>b__0>d.MoveNext()\r\nCheck out log file for more information: c:\\Log_data.txt\r\nExiting ...\r\n\r\nC:\\Users\\W>'\r\n\r\n\r\n\r\n****\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6288","RelatedDescription":"Open issue \"[Issue, ML.net CLI] 330GB csv file of data cause a OutOfMemoryException (1/2)\" (#6288)"},{"Id":"1341935641","IsPullRequest":false,"CreatedAt":"2022-08-17T15:21:35","Actor":"wil70","Number":"6287","RawContent":null,"Title":"[ML.net cli] Early stop and resume/continue","State":"open","Body":"Hello, is there a way to end earlier a long training? Like I put 600000 seconds, and I have good results already, so I would like to finish it sooner. How do I do this? \r\nA way to end earlier and also be able to resume/continue from there would be awesome (Like I could add x extra minutes of training)\r\nTY!\r\nw","Url":"https://github.com/dotnet/machinelearning/issues/6287","RelatedDescription":"Open issue \"[ML.net cli] Early stop and resume/continue\" (#6287)"},{"Id":"1341929992","IsPullRequest":false,"CreatedAt":"2022-08-17T15:17:07","Actor":"wil70","Number":"6286","RawContent":null,"Title":"[ML.net cli] Resume a cli training after a crash ","State":"open","Body":"Hello, is there a way to resume an ML.net cli training to where it was before a crash?\r\nI have a lot of data in the folder C:\\Users\\wwww\\AppData\\Local\\Temp\\AutoML-NNI\\Experiment-9K67B4 but I do not know how to make mlnet start from there.\r\n\r\n\r\nDetail:\r\nI used the cli, ie \"mlnet classicfiaction....\"\r\nI trained for a few days, but I made a mistake which used a lot of memory on my computer, which stopped the mlnet process. I would like to start mlnet to where it left so it can continue from there\r\n\r\nThanks\r\nw\r\n\r\n\r\n2022-08-10 15:03:24.3091 DEBUG System.InvalidOperationException: Event we were waiting on was subject to an exception\r\n ---> System.OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.\r\n   at System.Array.Resize[T](T[]& array, Int32 newSize)\r\n   at Microsoft.ML.Internal.Utilities.ArrayUtils.EnsureSize[T](T[]& array, Int32 min, Int32 max, Boolean keepOld, Boolean& resized)\r\n   at Microsoft.ML.Data.CacheDataView.ColumnCache.ImplOne`1.CacheCurrent()\r\n   at Microsoft.ML.Data.CacheDataView.Filler(DataViewRowCursor cursor, ColumnCache[] caches, OrderedWaiter waiter)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6286","RelatedDescription":"Open issue \"[ML.net cli] Resume a cli training after a crash \" (#6286)"},{"Id":"1340495894","IsPullRequest":false,"CreatedAt":"2022-08-16T15:04:09","Actor":"sportbilly21","Number":"6284","RawContent":null,"Title":"Are Resizing Layers supported in ML.Net?","State":"open","Body":"### System information\r\n\r\n- Windows 10 19044.1826\r\n-  VS 2019, Microsoft.ML 1.71,Microsoft.ML.OnnxRuntime.GPU 12.1\r\n\r\nI am have retrained a Tensorflow/Keras model with a resizing layer are part of the model.\r\nI converted to ONNX with opset 11. In python onnx works as expected. I am feeding with what ever size of image and models does the resizing (224, 224) and delivers the predictions.\r\n\r\nIn ML.Net I have created the pipeline and predictions engine. If I pass to the model with a 224x224 image I am getting the following error\r\nSystem.ArgumentException: 'Length of memory (150528) must match product of dimensions (3).' from DenseTensor.shared.cs\r\nIf I pass to the model any other size of image I am getting the following \r\nSystem.InvalidOperationException: 'Operation is not valid due to the current state of the object.' when try to run prediction engine,\r\n\r\nIs resizing layer not supported yes or I am doing something wrong.Please find below the code for the running the model\r\n\r\n### Source code / logs\r\n```C#\r\n        public void GenerateModel(string modelLocation,string inputLayer, string outputLayer, List<string> cats, int gpuID = 0)\r\n        {\r\n            var pipeline = this.mlContext.Transforms.ExtractPixels(inputLayer, inputColumnName: nameof(ImageData.Image), colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Rgb, orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB, interleavePixelColors: false, outputAsFloatArray: true)\r\n              .Append(this.mlContext.Transforms.ApplyOnnxModel(outputLayer, inputLayer, modelLocation));\r\n\r\n            var data = this.mlContext.Data.LoadFromEnumerable(new List<ImageData>());\r\n   \r\n            this.model = pipeline.Fit(data); //;\r\n            this.categories = cats;\r\n            this. Predictor = this.mlContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(this.model);\r\n\r\n       \r\n        }\r\n\r\n        public void ClassifySingleImage(ImageData imgClassify)\r\n        {\r\n\r\n            this. Prediction = this.predictor.Predict(imgClassify);\r\n            this. Predictions = this.prediction.Preds;\r\n\r\n        }\r\n```\r\nMany thanks ","Url":"https://github.com/dotnet/machinelearning/issues/6284","RelatedDescription":"Open issue \"Are Resizing Layers supported in ML.Net?\" (#6284)"}],"ResultType":"GitHubIssue"}},"RunOn":"2022-09-01T03:30:28.8908239Z","RunDurationInMilliseconds":492}