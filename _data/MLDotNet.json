{"Data":{"GitHub":{"Issues":[{"Id":"1848310341","IsPullRequest":false,"CreatedAt":"2023-08-13T00:10:16","Actor":"ooples","Number":"6795","RawContent":null,"Title":"Schema mismatch for label column 'Label': expected Single, got Vector<Single> (Parameter 'labelCol')","State":"open","Body":"I'm trying out this nuget package and experimenting with the different normalization options for regression and prediction trainers. My code is working perfectly when I use Single values (float) but I saw that there were bunch of normalization options that only seemed to work using a vector of Single values so I get the error when I change all of my float values to a float array. Am I just missing something obvious?\r\n\r\nFYI I'm using ML.NET 3.0.0-preview.23266.6 for this example\r\n\r\n```cs\r\nvar trainingCount = 50;\r\nvar modelInputList = new List<ModelInput>();\r\nvar estCount = valuesList.Any() ? valuesList.First().ValueList.Count : 0;\r\n\r\nfor (int j = 0; j < estCount; j++)\r\n{\r\n    var modelInput = new ModelInput();\r\n\r\n    var actual = j < estCount - 1 ? actualList[j] : 0;\r\n    modelInput.Actual = new float[] { Convert.ToSingle(actual) };\r\n\r\n    for (int k = 0; k < valueCount; k++)\r\n    {\r\n        var rvItem = Convert.ToSingle(valuesList[k].ValueList[j]);\r\n\r\n        switch (k)\r\n        {\r\n            case 0:\r\n                modelInput.Input1 = new float[] { rvItem };\r\n                break;\r\n            case 1:\r\n                modelInput.Input2 = new float[] { rvItem };\r\n                break;\r\n            case 2:\r\n                modelInput.Input3 = new float[] { rvItem };\r\n                break;\r\n            default:\r\n                break;\r\n        }\r\n    }\r\n\r\n    modelInputList.Add(modelInput);\r\n}\r\n\r\nvar firstHalf = mlContext.Data.LoadFromEnumerable(modelInputList.Take(trainingCount));\r\nvar secondHalf = mlContext.Data.LoadFromEnumerable(modelInputList.Skip(trainingCount));\r\nvar dataProcessPipeline = mlContext.Transforms\r\n                    .CopyColumns(\"Label\", nameof(ModelInput.Actual))\r\n                    .Append(mlContext.Transforms.NormalizeBinning(outputColumnName: nameof(ModelInput.Input1)))\r\n                    .Append(mlContext.Transforms.NormalizeBinning(outputColumnName: nameof(ModelInput.Input2)))\r\n                    .Append(mlContext.Transforms.NormalizeBinning(outputColumnName: nameof(ModelInput.Input3)))\r\n                    .Append(mlContext.Transforms.Concatenate(\"Features\", nameof(ModelInput.Input1),\r\n                        nameof(ModelInput.Input2), nameof(ModelInput.Input3)));\r\nvar trainer = mlContext.Regression.Trainers.OnlineGradientDescent();\r\nvar trainingPipeline = dataProcessPipeline.Append(trainer);\r\nvar trainedModel = trainingPipeline.Fit(firstHalf); // getting the exception here\r\nvar trainingData = trainedModel.Transform(firstHalf);\r\nvar predictions = trainedModel.Transform(secondHalf);\r\n\r\npublic class ModelInput\r\n{\r\n    [LoadColumn(0)]\r\n    [VectorType(1)]\r\n    public float[] Actual { get; set; }\r\n\r\n    [LoadColumn(1)]\r\n    [VectorType(1)]\r\n    public float[] Input1 { get; set; }\r\n\r\n    [LoadColumn(2)]\r\n    [VectorType(1)]\r\n    public float[] Input2 { get; set; }\r\n\r\n    [LoadColumn(3)]\r\n    [VectorType(1)]\r\n    public float[] Input3 { get; set; }\r\n}","Url":"https://github.com/dotnet/machinelearning/issues/6795","RelatedDescription":"Open issue \"Schema mismatch for label column 'Label': expected Single, got Vector<Single> (Parameter 'labelCol')\" (#6795)"},{"Id":"1845883949","IsPullRequest":true,"CreatedAt":"2023-08-10T20:51:07","Actor":"Lehonti","Number":"6794","RawContent":null,"Title":"File-scoped namespaces in files directly under `Microsoft.ML.Core`","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6794","RelatedDescription":"Open PR \"File-scoped namespaces in files directly under `Microsoft.ML.Core`\" (#6794)"},{"Id":"1845881904","IsPullRequest":true,"CreatedAt":"2023-08-10T20:49:26","Actor":"Lehonti","Number":"6793","RawContent":null,"Title":"File-scoped namespaces in files under `Utilities` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6793","RelatedDescription":"Open PR \"File-scoped namespaces in files under `Utilities` (`Microsoft.ML.Core`)\" (#6793)"},{"Id":"1845863129","IsPullRequest":true,"CreatedAt":"2023-08-10T20:37:41","Actor":"Lehonti","Number":"6792","RawContent":null,"Title":"File-scoped namespaces in files under `Prediction` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6792","RelatedDescription":"Open PR \"File-scoped namespaces in files under `Prediction` (`Microsoft.ML.Core`)\" (#6792)"},{"Id":"1845856421","IsPullRequest":true,"CreatedAt":"2023-08-10T20:32:54","Actor":"Lehonti","Number":"6791","RawContent":null,"Title":"File-scoped namespaces in files under `Environment` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6791","RelatedDescription":"Open PR \"File-scoped namespaces in files under `Environment` (`Microsoft.ML.Core`)\" (#6791)"},{"Id":"1845853909","IsPullRequest":true,"CreatedAt":"2023-08-10T20:31:22","Actor":"Lehonti","Number":"6790","RawContent":null,"Title":"File-scoped namespaces in files under `EntryPoints` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6790","RelatedDescription":"Open PR \"File-scoped namespaces in files under `EntryPoints` (`Microsoft.ML.Core`)\" (#6790)"},{"Id":"1845851888","IsPullRequest":true,"CreatedAt":"2023-08-10T20:29:37","Actor":"Lehonti","Number":"6789","RawContent":null,"Title":"File-scoped namespaces in files under `Data` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6789","RelatedDescription":"Open PR \"File-scoped namespaces in files under `Data` (`Microsoft.ML.Core`)\" (#6789)"},{"Id":"1845847250","IsPullRequest":true,"CreatedAt":"2023-08-10T20:25:31","Actor":"Lehonti","Number":"6788","RawContent":null,"Title":"File-scoped namespaces in files under `ComponentModel` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6788","RelatedDescription":"Open PR \"File-scoped namespaces in files under `ComponentModel` (`Microsoft.ML.Core`)\" (#6788)"},{"Id":"1845842012","IsPullRequest":true,"CreatedAt":"2023-08-10T20:21:43","Actor":"Lehonti","Number":"6787","RawContent":null,"Title":"File-scoped namespaces in files under `CommandLine` (`Microsoft.ML.Core`)","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6787","RelatedDescription":"Open PR \"File-scoped namespaces in files under `CommandLine` (`Microsoft.ML.Core`)\" (#6787)"},{"Id":"1840516080","IsPullRequest":false,"CreatedAt":"2023-08-09T07:49:58","Actor":"torronen","Number":"6786","RawContent":null,"Title":"CV + SamplingKey: How to drop from being as a training feature?","State":"closed","Body":"I am using cross-validation with a sampling key, because I know the sampling key column is a shortcut and will lead to overfitting.\r\n\r\nI can also observe this by having a look at the global feature index of the trained model:\r\nSampling.1  1\r\nSampling.4  0.85616875\r\n\r\nMy challenge is now how do I drop the sampling key column from being used as a feature to train on?\r\n\r\nSimplified code below:\r\n\r\n```\r\n  experiment\r\n                .SetPipeline(pipeline)\r\n                .SetRegressionMetric(metric, labelColumn: columnInference.ColumnInformation.LabelColumnName)\r\n                .SetTrainingTimeInSeconds(trainingTimeSeconds)\r\n                .SetDataset(data, fold: NumFolds, samplingKeyColumnName: SamplingKeyColumn)\r\n                .SetCostFrugalTuner();\r\n                \r\n            TrialResult experimentResults = await experiment.RunAsync(cts.Token);\r\n```\r\n\r\nIf I drop as part of pipeline, I will get error \"failed with exception Could not find input column 'Sampling' (Parameter 'inputSchema')\"\r\n\r\n\r\nRemoving sampling key from columninformation did not help\r\n```\r\n //Remove sampling column key\r\n columnInference.ColumnInformation.CategoricalColumnNames.Remove(SamplingKeyColumn);\r\n```\r\n                \r\n                ","Url":"https://github.com/dotnet/machinelearning/issues/6786","RelatedDescription":"Closed issue \"CV + SamplingKey: How to drop from being as a training feature?\" (#6786)"},{"Id":"1840363721","IsPullRequest":true,"CreatedAt":"2023-08-08T00:08:05","Actor":"zewditu","Number":"6785","RawContent":null,"Title":"Add TargetType to Type_convert","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6785","RelatedDescription":"Open PR \"Add TargetType to Type_convert\" (#6785)"},{"Id":"1809795496","IsPullRequest":true,"CreatedAt":"2023-08-07T02:49:13","Actor":"Lehonti","Number":"6766","RawContent":null,"Title":"Modernized some argument checks that still used string literals for parameter names","State":"closed","Body":"No changes in behavior, just leveraging more modern syntax","Url":"https://github.com/dotnet/machinelearning/pull/6766","RelatedDescription":"Closed or merged PR \"Modernized some argument checks that still used string literals for parameter names\" (#6766)"},{"Id":"1838289055","IsPullRequest":false,"CreatedAt":"2023-08-06T17:45:12","Actor":"torronen","Number":"6784","RawContent":null,"Title":"AutoML2.0: Ranking ","State":"open","Body":"I believe ranking is current missing from AutoML 2.0 and thus missing from the improved performance. Are there plan to include ranking in AutoML 2.0, and any estimated timeframes?\r\n\r\nctx.Auto().CreateRankingExperiment\r\nbut no ctx.Auto().Regression\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6784","RelatedDescription":"Open issue \"AutoML2.0: Ranking \" (#6784)"},{"Id":"1836532772","IsPullRequest":false,"CreatedAt":"2023-08-04T11:03:01","Actor":"torronen","Number":"6783","RawContent":null,"Title":"Include params in .zip file","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI may have a model that has been in use for a while. If I was not careful, the params are lost. When updating the model, and retraining, I may accidentally use different parameters or AutoML may arrive at different end result. This can lead to a model with different charasteristics. I think it especially happens when calibrator is used, the distribution on scores seems often very different across models.\r\n\r\n**Describe the solution you'd like**\r\nOption A) save params inside the zip. There is already a text file with the version number, so why not also training paramterers. One could also consider including performance metrics, training data stats, or even dataset name.  \r\n\r\nOption B) expose a way to load the model and then read the training parameters, at least those that exists, are readable or can be logically infered (such as how many leafs and trees)\r\n\r\n**Describe alternatives you've considered**\r\nIt is possible to open the contents on the zip file in notepad, and sometimes I can see the params. \r\n\r\n**Additional context**\r\nSaving this information and especially dataset information may cause data leaks. For example a desktop app manufacturer might not want to make it easy to replicate his model. I think this is not big concern in my opinion, but including documentation on what is inside zip file and how to remove it can be useful. However, I do not think many users will extract zip files, perhaps even with .zip removed.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6783","RelatedDescription":"Open issue \"Include params in .zip file\" (#6783)"},{"Id":"1830514689","IsPullRequest":true,"CreatedAt":"2023-08-03T19:24:12","Actor":"zewditu","Number":"6781","RawContent":null,"Title":"Add QA sweepable estimator in AutoML ","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6781","RelatedDescription":"Closed or merged PR \"Add QA sweepable estimator in AutoML \" (#6781)"},{"Id":"1831274496","IsPullRequest":true,"CreatedAt":"2023-08-01T13:20:33","Actor":"asmirnov82","Number":"6782","RawContent":null,"Title":"Allow to define CultureInfo for parsing values on reading DataFrame from csv","State":"open","Body":"Fixes #5652 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/6782","RelatedDescription":"Open PR \"Allow to define CultureInfo for parsing values on reading DataFrame from csv\" (#6782)"},{"Id":"1828040573","IsPullRequest":false,"CreatedAt":"2023-07-30T19:17:58","Actor":"80LevelElf","Number":"6780","RawContent":null,"Title":"Ability to express the maximum variance in the specified properties","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nIt is very common approach (at least at our side) when you train classifier or regression model to sort through the parameters of this model to find out the best combination for biggest predict.\r\n\r\nFor example we have some subscription form on our site and we want to maximize subscription conversion.\r\nWe know:\r\n- Current site page info\r\n- Current user info (device and so on)\r\n- Behavior info (session number)\r\n\r\nAlso we can change:\r\n- Form image\r\n- Form CTA text\r\n- Form text\r\n- Discount type\r\n\r\nSo we train binary classification model with site, user and behavior properties + form image, CTA text, form text, discount type properties to understand how different params combination influence on conversion rate.\r\n\r\nWe assume that different properties are related which each other somehow. So if we train 100 models and check weight of used properties we will have different mostly used properties in each model. Because the same variance could be expressed via different properties.\r\n\r\n**Describe the solution you'd like**\r\nIt would be really great to add some option for AutoML experiments to mark properties we mostly prefer to use. Like in this case - form image, CTA text, form text, discount type properties with some specified epsilon of quality we can lose because of that.\r\n\r\n            var settings = new BinaryExperimentSettings()\r\n            {\r\n                OptimizingMetric = BinaryClassificationMetric.AreaUnderRocCurve,\r\n                PreferedPropertiesSettings = new ExperimentPreferedPropertiesSettings \r\n                        {\r\n                                Properties = new [] {\"Prop1\", \"Prop2\"},\r\n                                AcceptableQualityLossInPercent = 5\r\n                        }\r\n            };","Url":"https://github.com/dotnet/machinelearning/issues/6780","RelatedDescription":"Open issue \"Ability to express the maximum variance in the specified properties\" (#6780)"},{"Id":"1827822888","IsPullRequest":false,"CreatedAt":"2023-07-30T06:27:22","Actor":"aarindam10","Number":"6779","RawContent":null,"Title":"Method 'call' in type 'Microsoft.ML.TorchSharp.NasBert.Models.TransformerEncoder' from assembly 'Microsoft.ML.TorchSharp","State":"open","Body":"the bug was reported earlier in following post.\r\nhttps://github.com/dotnet/machinelearning/issues/6665\r\nthough the bug was marked as resolved and closed the thread, but still the issues is there. \r\n\r\nReopening the issue:\r\n----------------------\r\nNow I am using following versions.\r\n PackageReference Include=\"Microsoft.ML\" Version=\"2.0.1\" \r\n PackageReference Include=\"Microsoft.ML.TorchSharp\" Version=\"0.20.1\" \r\n PackageReference Include=\"TorchSharp\" Version=\"0.100.3\" \r\n PackageReference Include=\"TorchSharp-cpu\" Version=\"0.100.3\" \r\n\r\nstill getting following errors\r\n\r\nSystem.TypeLoadException\r\n  HResult=0x80131522\r\n  Message=Method 'call' in type 'Microsoft.ML.TorchSharp.NasBert.Models.TransformerEncoder' from assembly 'Microsoft.ML.TorchSharp, Version=1.0.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51' does not have an implementation.\r\n  Source=Microsoft.ML.TorchSharp\r\n  StackTrace:\r\n   at Microsoft.ML.TorchSharp.NasBert.NasBertTrainer`2.TrainerBase..ctor(NasBertTrainer`2 parent, IChannel ch, IDataView input)\r\n   at Microsoft.ML.TorchSharp.NasBert.TextClassificationTrainer.Trainer..ctor(NasBertTrainer`2 parent, IChannel ch, IDataView input)\r\n   at Microsoft.ML.TorchSharp.NasBert.TextClassificationTrainer.CreateTrainer(NasBertTrainer`2 parent, IChannel ch, IDataView input)\r\n   at Microsoft.ML.TorchSharp.NasBert.NasBertTrainer`2.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at CustomerReview.CustomerReviewAnalysis.ReviewAnalysis() in F:\\MachineL\\MLNet\\CustomerReviewAnalysis\\CustomerReviewAnalysis.cs:line 80\r\n   at Program.<Main>$(String[] args) in F:\\MachineL\\MLNet\\CustomerReviewAnalysis\\Program.cs:line 6\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6779","RelatedDescription":"Open issue \"Method 'call' in type 'Microsoft.ML.TorchSharp.NasBert.Models.TransformerEncoder' from assembly 'Microsoft.ML.TorchSharp\" (#6779)"},{"Id":"1822764777","IsPullRequest":true,"CreatedAt":"2023-07-28T03:46:14","Actor":"michaelgsharp","Number":"6776","RawContent":null,"Title":"fixed mac build and minor torch sharp changes","State":"closed","Body":"Fixes the mac build issue with the official pipeline.\r\n\r\nAlso adds in specific options classes for SentenceSimilarity and TextClassification so that each can be given their own defaults.","Url":"https://github.com/dotnet/machinelearning/pull/6776","RelatedDescription":"Closed or merged PR \"fixed mac build and minor torch sharp changes\" (#6776)"},{"Id":"1824057406","IsPullRequest":false,"CreatedAt":"2023-07-27T10:12:32","Actor":"TopCat73","Number":"6778","RawContent":null,"Title":" Tensorflow.InvalidArgumentError: Node name contains invalid characters","State":"open","Body":" - OS & Version: [Windows 10] \r\n - ML.NET Version: [ML.NET v2.01]\r\n - .NET Version: [.NET 6.0]\r\n\r\nI have trained a DNN model using TensorFlot.NET (0.110.2) and saved the model to directory on my PC.  I am then attempting to load the saved model using ML.Net.  However, an exception \"Node name contains invalid characters\" is thrown when I attempt to load the saved model using API LoadTensorFlowModel.\r\n\r\nSteps to reproduce :\r\n1. Build a Console App targeting .Net 6.0\r\n2. Using NuGet Package Manager install Microsoft.ML (2.0.1), Microsoft.ML.TensorFlow (2.0.1) and SciSharp.TensorFlow.Redist (2.11.4)\r\n3. Download the attached Zip and extract \r\n4. Call DNNLoader.LoadTensorFlowModel(<filePath>) passing the location of the extracted directory\r\n5. The exception Tensorflow.InvalidArgumentError: 'Node 'dense_2/bias:': Node name contains invalid characters' is thrown\r\n\r\n**Expected **\r\nThe trained model to be loaded\r\n\r\nCode Sample\r\n\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing Microsoft.ML.Transforms;\r\n\r\nnamespace DNNPrediction\r\n{\r\n    internal static class DNNLoader\r\n    {\r\n        internal static void LoadTensorFlowModel(string modelPath)\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n\r\n            TensorFlowModel tensorFlowModel = mlContext.Model.LoadTensorFlowModel(modelPath);\r\n\r\n            DataViewSchema schema = tensorFlowModel.GetModelSchema();\r\n            Console.WriteLine(\" =============== TensorFlow Model Schema =============== \");\r\n            var featuresType = (VectorDataViewType)schema[\"Features\"].Type;\r\n            Console.WriteLine($\"Name: Features, Type: {featuresType.ItemType.RawType}, Size: ({featuresType.Dimensions[0]})\");\r\n            var predictionType = (VectorDataViewType)schema[\"Prediction/Softmax\"].Type;\r\n            Console.WriteLine($\"Name: Prediction/Softmax, Type: {predictionType.ItemType.RawType}, Size: ({predictionType.Dimensions[0]})\");\r\n        }\r\n    }\r\n}\r\n\r\nThe trained model files are here\r\n\r\n[dnn.zip](https://github.com/dotnet/machinelearning/files/12181963/dnn.zip)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6778","RelatedDescription":"Open issue \" Tensorflow.InvalidArgumentError: Node name contains invalid characters\" (#6778)"},{"Id":"1821469414","IsPullRequest":false,"CreatedAt":"2023-07-27T03:19:15","Actor":"RockNHawk","Number":"6774","RawContent":null,"Title":" IDataView.GetColumn throw exception Splitter/consolidator worker encountered exception while consuming source data","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n<PackageReference Include=\"Microsoft.ML\" Version=\"3.0.0-preview.23266.6\" />\r\n<PackageReference Include=\"Microsoft.ML.OnnxRuntime\" Version=\"1.15.1\" />\r\n<PackageReference Include=\"Microsoft.ML.OnnxTransformer\" Version=\"3.0.0-preview.23266.6\" />\r\n\r\n**Describe the bug**\r\nThe single prediction is OK, but multiple predictions throw error when call IDataView.GetColumn<T>().ToArray()\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\n    IEnumerable<TextEmbeddingResult> DoBulkGenerateTextEmbedding(IList<StringFragment> texts)\r\n    {\r\n        var tokenizer = _tokenizer.GetTokenizer();\r\n        var bulkSize = texts.Count;\r\n\r\n        var inputs = InputDataArray(texts, tokenizer).ToArray();\r\n        var maxSize = inputs.Max(x => x.InputIds.Length);\r\n        Shape shape = ShapeFactory.CreateShape(batchSize: texts.Count, maxSize);\r\n\r\n\r\n\r\n            BatchSize = batchSize;\r\n            MaxLength = maxLength;\r\n\r\n  \r\n\r\n          var shapeDictionary = new Dictionary<string, int[]>\r\n            {\r\n                { ColumnNames.Input.InputIds,  new[] { 1, maxSize }},\r\n                { ColumnNames.Input.AttentionMask,  new[] { 1, maxSize}},\r\n                { ColumnNames.Output.LastHiddenState,  new[] { 1, maxSize, EmbeddingConst.TokenResultDim }},\r\n            };\r\n\r\n        MLContext context = new MLContext();\r\n        bool useGpu = false;\r\n        OnnxScoringEstimator pipeline = context.Transforms.ApplyOnnxModel(\r\n            modelFile: _modelInfo.ModelPath,\r\n            shapeDictionary: shapeDictionary,\r\n            inputColumnNames: new[] { ColumnNames.Input.InputIds, ColumnNames.Input.AttentionMask, },\r\n            outputColumnNames: new[] { ColumnNames.Output.LastHiddenState, },\r\n            gpuDeviceId: useGpu ? 0 : (int?)null,\r\n            fallbackToCpu: true\r\n        );\r\n\r\n\r\n        var trainingDataView = context.Data.LoadFromEnumerable(inputs);\r\n\r\n        using var transformer = pipeline.Fit(trainingDataView);\r\n\r\n        var predictions = transformer.Transform(trainingDataView);\r\n        // data type (name: last_hidden_state, type: Vector<Single, 2, 29, 768>) in data to the user-defined type, System.Single. (Parameter 'column')\r\n        var outputColumn = predictions.Schema[ColumnNames.Output.LastHiddenState];\r\n\r\n        var output = predictions.GetColumn<Microsoft.ML.Data.VBuffer<float>>(ColumnNames.Output.LastHiddenState);\r\n\r\n        // Convert the VBuffer<float> to a float array\r\n\r\n        /*\r\noutput.ToArray()  throw Exception\r\nSplitter/consolidator worker encountered exception while consuming source data\r\n\r\n.InnerException: System.ArgumentOutOfRangeException:\r\nIndex was out of range. Must be non-negative and less than the size of the collection. (Parameter 'index')\r\nat System.Collections.Generic.List1.set_Item(Int32 index, T value) at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.NamedOnnxValueGetterVec1.GetNamedOnnxValueUnknownSize()\r\nat Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.NamedOnnxValueGetterVec1.GetNamedOnnxValue() at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, List1 activeOutputColNames, OnnxRuntimeOutputCacher outputCache)\r\nat Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass14_01.<MakeTensorGetter>b__0(VBuffer1& dst)\r\nat Microsoft.ML.Data.DataViewUtils.Splitter.InPipe.Impl`1.Fill()\r\nat Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass7_1.b__2()\r\n*/\r\n        var outputVectorGroups = output.ToArray();\r\n\r\n        float[] outputMergedVectors = outputVectorGroups.SelectMany(x => x.DenseValues()).ToArray();\r\n\r\n        var sentenceEmbeddings = SentenceEmbeddingUtility.BulkToSentenceEmbeddings(\r\n            new EmbeddingContext(bulkSize, maxSize, EmbeddingConst.TokenResultDim, outputMergedVectors, _dense)\r\n            //,inputData.AttentionMask\r\n        );\r\n\r\n        int i = 0;\r\n        foreach (var vectors in sentenceEmbeddings)\r\n        {\r\n            var text = texts[i];\r\n            yield return new(text, vectors);\r\n            i++;\r\n        }\r\n    }\r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/3222379/d1addbec-04cc-4ebd-b301-1e16e204ec5e)\r\n\r\n**Additional context**\r\nThe single prediction is OK.\r\n`\r\nusing var predictionEngine = context.Model.CreatePredictionEngine<InputData, OutputData>(transformer, inputSchemaDefinition: inputSchemaDef, outputSchemaDefinition: outputSchemaDef);\r\n\r\nvar prediction = predictionEngine.Predict(inputData);\r\n`\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6774","RelatedDescription":"Closed issue \" IDataView.GetColumn throw exception Splitter/consolidator worker encountered exception while consuming source data\" (#6774)"},{"Id":"1822946818","IsPullRequest":false,"CreatedAt":"2023-07-26T18:29:38","Actor":"luisquintanilla","Number":"6777","RawContent":null,"Title":"Ignore Columns ColumnInference","State":"open","Body":"When using `InferColumns`, there is now way to specify which columns to exclude.\r\n\r\n```csharp\r\n// Define data path\r\nvar dataPath = Path.GetFullPath(@\"../Data/issues_train.tsv\");\r\n\r\n// Infer column information\r\nColumnInferenceResults columnInference =\r\n    ctx.Auto().InferColumns(dataPath, separatorChar: '\\t', labelColumnName: \"Area\", groupColumns: false);\r\n```\r\n\r\nThat means that you have to do it manually.\r\n\r\n```csharp\r\nvar columnsToExclude = new[]{\"ID\",\"Title\"};\r\n\r\ncolumnInference.TextLoaderOptions.Columns = \r\n    columnInference.TextLoaderOptions.Columns\r\n        .Where(col => !columnsToExclude.Contains(col.Name)).ToArray();\r\n\r\ncolumnInference.ColumnInformation.NumericColumnNames.Remove(\"ID\");\r\ncolumnInference.ColumnInformation.TextColumnNames.Remove(\"Title\");\r\n```\r\n\r\nSince the TextLoaderOptions and ColumnInformation are used downstream\r\n\r\n```csharp\r\n// Create text loader\r\nTextLoader loader = ctx.Data.CreateTextLoader(columnInference.TextLoaderOptions);\r\n\r\n// Load data into IDataView\r\nIDataView data = loader.Load(dataPath);\r\n\r\nSweepablePipeline pipeline =\r\n    ctx.Auto().Featurizer(data, columnInformation: columnInference.ColumnInformation)\r\n        .Append(ctx.Transforms.Conversion.MapValueToKey(columnInference.ColumnInformation.LabelColumnName))\r\n        .Append(ctx.Auto().MultiClassification(labelColumnName: columnInference.ColumnInformation.LabelColumnName))\r\n        .Append(ctx.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n```\r\n\r\nIn the InferColumns API, it might be the best place to set this value","Url":"https://github.com/dotnet/machinelearning/issues/6777","RelatedDescription":"Open issue \"Ignore Columns ColumnInference\" (#6777)"},{"Id":"1821740269","IsPullRequest":false,"CreatedAt":"2023-07-26T07:15:43","Actor":"RockNHawk","Number":"6775","RawContent":null,"Title":"Cannot access internal method 'MLContext.CancelExecution()' ","State":"open","Body":"I have a memory leak issue, and find this similar issue, but `CancelExecution` in internal.\r\n\r\n[BestFriend]\r\ninternal void CancelExecution() => ((ICancelable) this._env).CancelExecution();\r\n\r\n\r\nfull code\r\n\r\n        MLContext context = new MLContext();\r\n        bool useGpu = false;\r\n        OnnxScoringEstimator pipeline = context.Transforms.ApplyOnnxModel(\r\n            modelFile: _modelInfo.ModelPath,\r\n            shapeDictionary: shape.ToDictionary(),\r\n            inputColumnNames: new[] { ColumnNames.Input.InputIds, ColumnNames.Input.AttentionMask, },\r\n            outputColumnNames: new[] { ColumnNames.Output.LastHiddenState, },\r\n            gpuDeviceId: useGpu ? 0 : (int?)null,\r\n            fallbackToCpu: true\r\n        );\r\n\r\n        var inputSchemaDef = ToInputSchemaDefinition<InputData>(shape);\r\n        var trainingDataView = context.Data.LoadFromEnumerable(new List<InputData>() { }, inputSchemaDef);\r\n        using var transformer = pipeline.Fit(trainingDataView);\r\n\r\n        var outputSchemaDef = ToOutputSchemaDefinition<OutputData>(shape);\r\n        using var predictionEngine = context.Model.CreatePredictionEngine<InputData, OutputData>(transformer, inputSchemaDefinition: inputSchemaDef, outputSchemaDefinition: outputSchemaDef);\r\n        var predictionResult = predictionEngine.Predict(inputData);\r\n\r\n\r\n@fischja It could be the last trial still running even after automl experiment times out, could you try cancelling context and run again\r\n\r\n```csharp\r\nfor (int i = 0; i < 5; i++)\r\n{\r\n    MLContext ml = new MLContext();\r\n\r\n    List<MyData> trainingDataList = Enumerable.Range(0, 10000).Select(x => new MyData()).ToList();\r\n    IDataView trainingData = ml.Data.LoadFromEnumerable(trainingDataList);\r\n\r\n    var result = ml\r\n        .Auto()\r\n        .CreateRegressionExperiment(maxExperimentTimeInSeconds: 20)\r\n        .Execute(trainData: trainingData, numberOfCVFolds: 3, labelColumnName: \"Y\");\r\n\r\n    ml.CancelExecution();\r\n}\r\n```\r\n\r\n_Originally posted by @LittleLittleCloud in https://github.com/dotnet/machinelearning/issues/6188#issuecomment-1121407624_\r\n            ","Url":"https://github.com/dotnet/machinelearning/issues/6775","RelatedDescription":"Open issue \"Cannot access internal method 'MLContext.CancelExecution()' \" (#6775)"},{"Id":"1819780883","IsPullRequest":false,"CreatedAt":"2023-07-25T08:07:41","Actor":"xpt5","Number":"6773","RawContent":null,"Title":"Dataframe.LoadCsv() throwing exception","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10 Pro \r\n - Microsfot.Data.Analysis: v0.22.1\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\nI am having the same problem as reported on #5647. The input is the same since I created a csv file with same text and the exception thrown when running the code below is also the same.\r\n\r\n```\r\nSystem.FormatException\r\n  HResult=0x80131537\r\n  Message=Line 1 has less columns than expected\r\n  Source=Microsoft.Data.Analysis\r\n  StackTrace:\r\n   at Microsoft.Data.Analysis.DataFrame.GuessKind(Int32 col, List`1 read)\r\n   at Microsoft.Data.Analysis.DataFrame.ReadCsvLinesIntoDataFrame(WrappedStreamReaderOrStringReader wrappedReader, Char separator, Boolean header, String[] columnNames, Type[] dataTypes, Int64 numberOfRowsToRead, Int32 guessRows, Boolean addIndexColumn)\r\n   at Microsoft.Data.Analysis.DataFrame.LoadCsv(String filename, Char separator, Boolean header, String[] columnNames, Type[] dataTypes, Int32 numRows, Int32 guessRows, Boolean addIndexColumn, Encoding encoding)\r\n   at KeynotesPackagesTest.DataAnalysis.OpenCsvAndExportData(String csvFilePath, String textFile) in C:\\Users\\<user>\\source\\repos\\KeynotesPackagesTest\\KeynotesPackagesTest\\DataAnalysis.cs:line 102\r\n   at Program.<Main>$(String[] args) in C:\\Users\\<user>\\source\\repos\\KeynotesPackagesTest\\KeynotesPackagesTest\\Program.cs:line 35\r\n```\r\n\r\n**Expected behavior**\r\nReading the .csv file without issues\r\n\r\n**Code**\r\n\r\n```\r\n\r\n        public static void OpenCsvAndExportData(string csvFilePath, string textFile)\r\n        {\r\n            var data = DataFrame.LoadCsv(csvFilePath, separator: ',');\r\n```\r\n\r\nAnd then I cal the method from Program.cs\r\nI hope I am not overseeing something basic since I am very new to the c# language.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6773","RelatedDescription":"Open issue \"Dataframe.LoadCsv() throwing exception\" (#6773)"},{"Id":"1812591396","IsPullRequest":true,"CreatedAt":"2023-07-24T22:23:09","Actor":"LittleLittleCloud","Number":"6768","RawContent":null,"Title":"fix issue #2718 from model builder","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\nfix https://github.com/dotnet/machinelearning-modelbuilder/issues/2718\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6768","RelatedDescription":"Closed or merged PR \"fix issue #2718 from model builder\" (#6768)"},{"Id":"1818465370","IsPullRequest":true,"CreatedAt":"2023-07-24T13:46:24","Actor":"asmirnov82","Number":"6772","RawContent":null,"Title":"Fix DataFrame.LoadCsv can not load CSV with duplicate column names","State":"open","Body":"Fixes #6182 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6772","RelatedDescription":"Open PR \"Fix DataFrame.LoadCsv can not load CSV with duplicate column names\" (#6772)"},{"Id":"1816933459","IsPullRequest":false,"CreatedAt":"2023-07-23T00:15:20","Actor":"MIAIONE","Number":"6771","RawContent":null,"Title":"[feature] some suggestions...","State":"open","Body":"Hello! This is a feature suggestion. \r\n\r\n1. It seems that there are no relevant models for generative AI in ML.NET. It always frustrates me when I try to generate what I want, and I have to load external models through ONNX to achieve my needs. However, this is not perfect. In many cases, I can only use existing models and do not have the conditions to try training a Python ONNX model myself. I hope that ML.NET can provide some necessary generative AI basic algorithms and AUTOML templates, which may not directly achieve the goal, but can indirectly implement upper-level complex functions (such as GAN), which can lay a solid foundation for the subsequent ML.NET community ecology. \r\n\r\n2. It seems that ML.NET's AutoML does not provide model continuation training. When I replace new data with the same input format, retraining will start from scratch, which makes it very easy to lose the existing excellent model without backing up the previous model (I personally think that training models is like opening a blind box). It is particularly important to retain the previous training results. As a backup, renaming by date can be used instead of direct overwriting.","Url":"https://github.com/dotnet/machinelearning/issues/6771","RelatedDescription":"Open issue \"[feature] some suggestions...\" (#6771)"},{"Id":"1813643254","IsPullRequest":true,"CreatedAt":"2023-07-20T10:16:58","Actor":"asmirnov82","Number":"6770","RawContent":null,"Title":"Fix inconsistent null handling in DataFrame Arithmetics","State":"open","Body":"Fixes #5650 \r\n","Url":"https://github.com/dotnet/machinelearning/pull/6770","RelatedDescription":"Open PR \"Fix inconsistent null handling in DataFrame Arithmetics\" (#6770)"},{"Id":"1813484022","IsPullRequest":true,"CreatedAt":"2023-07-20T08:46:15","Actor":"asmirnov82","Number":"6769","RawContent":null,"Title":"Fix issue with addIndexColumn in DataFrame.LoadCsv","State":"open","Body":"Fixes #5968 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6769","RelatedDescription":"Open PR \"Fix issue with addIndexColumn in DataFrame.LoadCsv\" (#6769)"},{"Id":"1809930285","IsPullRequest":false,"CreatedAt":"2023-07-18T13:22:55","Actor":"superichmann","Number":"6767","RawContent":null,"Title":"IDataView Filtering does not Improve Performence","State":"open","Body":"I am performing 40 regression experiments (`parallel.foreach`) on a database table by filtering with different column values.\r\n\r\nWhen I SELECT the data directly from the database for each experiment the whole process takes 38 seconds.\r\nWhen I take the data from the database one time, cache it and use `SkipRows` and `TakeRows` for filtering each experiment it takes 42 seconds.\r\n\r\nFrom my standpoint the second method should produce better performance but the opposite occurs. can you please instruct me on how to use `SkipRows` and `TakeRows` in a way which will actually improve my overall performance?","Url":"https://github.com/dotnet/machinelearning/issues/6767","RelatedDescription":"Open issue \"IDataView Filtering does not Improve Performence\" (#6767)"}],"ResultType":"GitHubIssue"}},"RunOn":"2023-08-13T03:30:18.0209441Z","RunDurationInMilliseconds":470}