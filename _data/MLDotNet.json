{"Data":{"GitHub":{"Issues":[{"Id":"1322788307","IsPullRequest":true,"CreatedAt":"2022-07-29T23:19:45","Actor":"michaelgsharp","Number":"6265","RawContent":null,"Title":"Add in support for 1 unknown dimension for ONNX runtime.","State":"open","Body":"Adds support so that you can have 1 unknown dimension for the ONNX runtime models (not including the batch input since we set that to 1).","Url":"https://github.com/dotnet/machinelearning/pull/6265","RelatedDescription":"Open PR \"Add in support for 1 unknown dimension for ONNX runtime.\" (#6265)"},{"Id":"1322598890","IsPullRequest":false,"CreatedAt":"2022-07-29T19:18:22","Actor":"natelowry","Number":"6264","RawContent":null,"Title":"Does the OpenVINO execution provider for ONNX Runtime work in ML.NET?","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm using an ONNX model via `ApplyOnnxModel` and some pre-processing (which is really fast!), but I'd like it to use the OpenVINO execution provider instead of just the CPU.  \r\n\r\nWe are maxing out the CPU and not hitting a high enough framerate with just the CPU.  CUDA with `gpuDeviceId` is not an option due to hardware limitations.\r\n\r\nI can't figure out a way to make the ONNX Runtime called by ML.NET actually use the OpenVINO execution provider.  Is there something simple I'm missing?\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like the ONNX Runtime used by ML.NET to allow OpenVINO as an execution provider.  Maybe that's in the `ApplyOnnxModel` options as something like `OnnxRuntime = OnnxRuntimes.OpenVINO`, `OnnxRuntime = OnnxRuntimes.CUDA`, or `OnnxRuntime = OnnxRuntimes.oneDNN`, etc.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI can run OpenVINO using the ONNX Runtime Nuget packages built with OpenVINO using `AppendExecutionProvider_OpenVINO`, but the pre-processing is much slower and the level of abstraction is way lower than I'd like (making the pipeline harder to manage).  The inference runs at least 2x faster on the GPU though, so I want to use the GPU via that runtime.\r\n\r\nI've tried dropping in all the onnxruntime/openvino dlls to the executable directory to see if it uses those at runtime, but no luck.  Do I need to do a custom build of ML.NET?\r\n\r\n**Additional context**\r\n\r\nI can provide some more source code or examples if that's helpful, but I think it's more of a concept question than code question.\r\n\r\nThis is a great project and I appreciate everyone that's working on it.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6264","RelatedDescription":"Open issue \"Does the OpenVINO execution provider for ONNX Runtime work in ML.NET?\" (#6264)"},{"Id":"1317122342","IsPullRequest":true,"CreatedAt":"2022-07-28T18:19:51","Actor":"michaelgsharp","Number":"6259","RawContent":null,"Title":"Don't need label column for inference TextClassification.","State":"closed","Body":"Makes the TextClassification transformer save/load the label metadata so that we can use the transformer scope to remove the need for the label column during inferencing.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6259","RelatedDescription":"Closed or merged PR \"Don't need label column for inference TextClassification.\" (#6259)"},{"Id":"1321299991","IsPullRequest":false,"CreatedAt":"2022-07-28T18:06:10","Actor":"tarekgh","Number":"6263","RawContent":null,"Title":"Method not found: 'Void Module.train()'.","State":"open","Body":"This [issue](https://github.com/dotnet/TorchSharp/issues/666) is originally reported by @drGarbinsky in TorchSharp repo and ported here. \r\n\r\nI'm currently trying to get the same running from this page: [devblogs.microsoft.com/dotnet/introducing-the-ml-dotnet-text-classification-api-preview](https://devblogs.microsoft.com/dotnet/introducing-the-ml-dotnet-text-classification-api-preview/)\r\nworking with:\r\ndotnet: 7.0.100-preview.6.22352.1\r\nMicrosoft.ML Version=\"2.0.0-preview.22313.1\"\r\nMicrosoft.ML.TorchSharp Version=\"0.20.0-preview.22313.1\"\r\nTorchSharp-cpu Version=\"0.97.0\"\r\n\r\nWSL ubuntu: 20.04.3 LTS\r\n\r\ncode:\r\n\r\n```C#\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.TorchSharp;\r\n\r\n// Initialize MLContext\r\nvar mlContext = new MLContext();\r\n\r\n// Load your data\r\nvar reviews = new[]\r\n{\r\nnew {Text = \"This is a bad steak\", Sentiment = \"Negative\"},\r\nnew {Text = \"I really like this restaurant\", Sentiment = \"Positive\"}\r\n};\r\n\r\nvar reviewsDV = mlContext.Data.LoadFromEnumerable(reviews);\r\n\r\n//Define your training pipeline\r\nvar pipeline =\r\nmlContext.Transforms.Conversion.MapValueToKey(\"Label\", \"Sentiment\")\r\n.Append(mlContext.MulticlassClassification.Trainers.TextClassification(numberOfClasses: 2, sentence1ColumnName: \"Text\"))\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n\r\n// Train the model\r\nvar model = pipeline.Fit(reviewsDV);\r\n\r\n```\r\n\r\n@KernAlan wrote:\r\n\r\nI'm experiencing the same issue right now.\r\n\r\n@JReed221 wrote:\r\n\r\nI am experiencing this issue as well\r\n\r\n@drGarbinsky wrote:\r\n\r\nI've noticed that this [notebook ](https://github.com/dotnet/csharp-notebooks/blob/main/machine-learning/E2E-Text-Classification-API-with-Yelp-Dataset.ipynb?rgh-link-date=2022-07-27T19%3A30%3A45Z)references a newer version of the packages but I am unable to locate them\r\n\r\n> #i \"nuget:[pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json](https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json)\"\r\n> #r \"nuget:Microsoft.ML,2.0.0-preview.22324.1\"\r\n> #r \"nuget:Microsoft.ML.TorchSharp,0.20.0-preview.22324.1\"\r\n> #r \"nuget:TorchSharp-cpu,0.96.7\"\r\n> #r \"nuget:Microsoft.Data.Analysis,0.20.0-preview.22324.1\"\r\n\r\nI have also reproduced this issue within the nightly docker image so I don't think it is an environment issue\r\n\r\n\r\n@drGarbinsky wrote\r\n\r\nI was able to work around the issue by rolling back package versions:\r\n\r\n```Xml\r\n<PackageReference Include=\"libtorch-cpu-linux-x64\" Version=\"1.11.0.1\" />\r\n<PackageReference Include=\"Microsoft.Data.Analysis\" Version=\"0.20.0-preview.22313.1\" />\r\n<PackageReference Include=\"Microsoft.ML\" Version=\"2.0.0-preview.22313.1\" />\r\n<PackageReference Include=\"Microsoft.ML.TorchSharp\" Version=\"0.20.0-preview.22313.1\" />\r\n<PackageReference Include=\"TorchSharp-cpu\" Version=\"0.96.3\" />\r\n```\r\n\r\n@JReed221 wrote\r\n\r\nthat worked! thank you!\r\n\r\n@NiklasGustafsson wrote\r\n\r\nI believe that this is likely due to the fact that there was a breaking change made to Module.train() -- the previous version did not take an optional bool, which the Pytorch version does. That does not break source code dependencies, but breaks any binary dependency, since the signature has changed.\r\n\r\nAdding @luisquintanilla and @michaelgsharp to consult on what to do about this.\r\n\r\n@NiklasGustafsson wrote\r\n\r\nA potential fix is to not make the bool optional, but to have two train() declarations -- one with, and one without. The latter would unbreak the binary dependency, I believe.\r\n\r\n@luisquintanilla wrote:\r\n\r\nHi all,\r\n\r\nSorry to hear you ran into issues.\r\n\r\nI want to add clarity to the versions used in the notebook. The version in the notebook comes from the ML.NET daily feed. That version enables the use of the built-in Evaluate method in ML.NET and also makes it easier to work with the API. Previously you had to manually enter the number of classes you wanted to predict and couldn't use the evaluate method. This is the link to the daily feed if you want to get access to the latest versions of the ML.NET packages.\r\n\r\n[pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json](https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json)\r\n\r\nThat's a good suggestion @NiklasGustafsson. I also wonder if another alternative would be to instruct users to reference a specific version of TorchSharp (as @drGarbinsky has done to work around the issue). We've done something similar with TensorFlow.NET in the past. What would be the disadvantages of doing that (other than your code won't run using the latest version of TorchSharp)?\r\n\r\n@NiklasGustafsson wrote:\r\n\r\n> What would be the disadvantages of doing that (other than your code won't run using the latest version of TorchSharp)?\r\n\r\nThat would be the disadvantage, in addition to the inconvenience of having to keep track of which version numbers work and not.\r\n\r\n@NiklasGustafsson wrote:\r\n\r\nHmmm.\r\n\r\nThe change I was thinking of was introduced in 0.97.0 last week, so if you have to go all the way back to 0.96.3 to fix it, that's very odd. @luisquintanilla -- is there any way you could try it out with 0.96.8?\r\n\r\n@tarekgh wrote:\r\n\r\n@NiklasGustafsson [Changes that affect compatibility](https://docs.microsoft.com/en-us/dotnet/core/compatibility/?ranMID=43674&ranEAID=rl2xnKiLcHs&ranSiteID=rl2xnKiLcHs-Vk6trHPJPdwOyqxWVzHUQQ&epi=rl2xnKiLcHs-Vk6trHPJPdwOyqxWVzHUQQ&irgwc=1&OCID=AID2200057_aff_7795_1243925&tduid=(ir__2m3q0nl02wkf6gcatnnkkvci0e2xve3sx63xgf9200)(7795)(1243925)(rl2xnKiLcHs-Vk6trHPJPdwOyqxWVzHUQQ)()&irclickid=_2m3q0nl02wkf6gcatnnkkvci0e2xve3sx63xgf9200) doc mentioning the following:\r\n\r\n‚ùå DISALLOWED: Removing the [virtual](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/virtual) keyword from a member\r\n\r\nI guess the compiler will not bind to the method if the virtual removed from the member.\r\n\r\n@luisquintanilla should we just publish the latest of ML.NET to the NuGet instead of having it in the internal feed and recommend the users to use the latest?\r\n\r\n@NiklasGustafsson wrote:\r\n\r\nAnother approach is to rebuild the ML.NET preview with 0.97.0 and pick up the new method definition.\r\n\r\n@NiklasGustafsson wrote:\r\n\r\nWe should probably track this as an issue with ML.NET, too.\r\n\r\n@tarekgh wrote:\r\n\r\n> We should probably track this as an issue with ML.NET, too.\r\n\r\nYes.\r\n\r\n> Another approach is to rebuild the ML.NET preview with 0.97.0 and pick up the new method definition.\r\n\r\nIs this the same as what I suggested to publish the latest ML.NET to NuGet which will make it works with Torch Sharp 0.97.0? and we recommend users use the latest version of ML.NET.\r\n\r\n@NiklasGustafsson wrote:\r\n\r\n> Is this the same as what I suggested to publish the latest ML.NET to NuGet which will make it works with Torch Sharp 0.97.0? and we recommend users use the latest version of ML.NET.\r\n\r\nNot sure. The issue should only affect binary dependencies, so if ML.NET is rebuilt against 0.97.0, how it is distributed is orthogonal, I believe.\r\n\r\n@tarekgh wrote:\r\n\r\nWhat I meant is update the Torch Sharp version in the file [dotnet/machinelearning@4aad15b/eng/Versions.props#L52](https://github.com/dotnet/machinelearning/blob/4aad15b8f35b94554b2c5f7062d65a71e1b379b0/eng/Versions.props#L52) and then publish the new built ML.NET to NuGet.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6263","RelatedDescription":"Open issue \"Method not found: 'Void Module.train()'.\" (#6263)"},{"Id":"1318641471","IsPullRequest":true,"CreatedAt":"2022-07-26T19:02:30","Actor":"LittleLittleCloud","Number":"6261","RawContent":null,"Title":"add image featurizer to AutoFeaturizer","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis PR adds featurizer for image path. When there's a column, or multiple columns that are referred as image path, a set of estimators with search space will be added for those columns which featurizes image using one of DNN featurizers (ResNet18, ResNet50, AlexNet...)\r\n\r\nThe initial idea comes from @justinormont, which is a great cross-platform solution to leverage automl in image classification, and can be a more efficient way compared with deep learning, especially on small datasets. \r\n\r\nThe estimators that use to featurize images are\r\n```\r\nLoadImage -> ResizeImage(224, 224) -> ExtractPixels -> DnnFeaturizer(one of resnet18, resnet50, alexnet, resnet 101)\r\n```\r\nwhich transfers an image into a numeric feature array for classifiers to learn and transform.\r\n\r\nAnd while training, the search space from those estimators will be added to the global search space and will be optimized by the selected tuner","Url":"https://github.com/dotnet/machinelearning/pull/6261","RelatedDescription":"Open PR \"add image featurizer to AutoFeaturizer\" (#6261)"},{"Id":"1318475088","IsPullRequest":false,"CreatedAt":"2022-07-26T16:15:18","Actor":"PajLe","Number":"6260","RawContent":null,"Title":"Save IDataView to a database table","State":"open","Body":"I am formatting this issue as a feature suggestion, however, I am also looking for a workaround - a way to do it without implementing this feature suggestion, as I haven't found a solid one yet (referencing to my [SO question][3]).\r\n\r\n## Is your feature request related to a problem? Please describe.\r\nI have a transformed `IDataView` with prediction (`Score`) column, input columns and one-hot encoded columns (working with regression task). I want to save only prediction and input values to a database table (i.e., I want to be able to choose which columns to save). \r\n\r\nMy main obstacle seems to be not having a class ([POCO][1]) representing the structure of the db model, but the main issue (trying to avoid the [XY problem][5]) seems to be not having a convenient way to save it to a table (like [there is for a text file][7] for example).\r\n\r\n## Describe the solution you'd like\r\nAn ideal experience would be something like\r\n```c#\r\nIDataView.SaveToDatabase(/*db connection/connection string*/, /*list of columns*/)\r\n```\r\nor\r\n```c#\r\nmlContext.Data.SaveToDatabase(IDataView, /*db connection/connection string*/, /*list of columns*/)\r\n```\r\nand possibly without loading the data into memory to be able to handle large data sets.\r\n\r\nA less ideal solution would be create an extension to `DataFrame` for the same functionality - something similar to [pandas.DataFrame.to_sql][4]. So the user experience would be:\r\n```c#\r\nIDataView predictions = trainedModel.Transform(...);\r\nvar df = predictions.ToDataFrame(...);\r\ndf.ToSql(/*db connection/connection string*/, /*list of columns*/, /*possibly other parameters*/)\r\n```\r\n\r\nAdditional convenience (although this could be considered a completely separate feature):\r\nMy `IDataView` is transformed using one-hot encoding, but I want to write the original input values to a db table. I couldn't leave the same column names for the output after transformation (i.e., I had to do `new InputOutputColumnPair(col.Name + \"_onehot\", col.Name)`) because the input columns would then be hidden, and I couldn't easily get their value. It would be nice to have a way to do this without renaming the transformed columns i.e., something like\r\n```c#\r\nIDataView predictions = ...\r\nvar columns = predictions.InputColumns + prediction.ScoreColumn \r\n/* returns a list of columns, where \r\nInputColumns are the original columns without transformation, \r\nScoreColumn are the predicted values, \r\nThe plus operator means appending to the list \r\n*/\r\npredictions.SaveToDb(... , columns)\r\n```\r\nI am aware of the [SchemaAnnotationsExtensions.GetSlotNames][6] but that doesn't seem to cover my use-case conveniently.\r\n\r\n## Describe alternatives you've considered\r\n<details> \r\n  <summary>1. Create an `IEnumerable` from `IDataView` and write that to the DB</summary>\r\n\r\nI used \r\n```c#\r\nIEnumerable<SomeType> predictionsEnumerable = \r\n    mlContext.Data.CreateEnumerable<SomeType>(predictions, reuseRowObject: true);\r\n```\r\nin order to try and write it to a DB table. \r\nFirst problem is that I don't have the `SomeType`. I tried using `dynamic` or `object`, but neither of them work - possibly related to\r\n- #3829\r\n- #5895 (although this one is for creating the IDataView, which wasn't a problem for me)\r\n(probably unrelevant) I also tried reflection but I didn't manage to make anything work .\r\n\r\nSecond problem is that even when I have the `SomeType`, I only managed to write it with Dapper converting the `IEnumerable` to a list. Without that I usually get the error\r\n`The incoming tabular data stream (TDS) remote procedure call (RPC) protocol stream is incorrect. Parameter 4 (\"\"): Data type 0x40 is unknown.`\r\n</details>\r\n\r\n<details>\r\n  <summary>2. Convert `IDataView` to `DataFrame` and write that to DB</summary>\r\n\r\nI used \r\n```c#\r\nvar df = predictions.ToDataFrame(long.MaxValue, columns.ToArray());\r\n```\r\nto create a `DataFrame` and tried to write that to the DB. I didn't manage to find a nice solution.\r\n</details>\r\n\r\n<details>\r\n  <summary>3. Manual type mapping</summary>\r\n\r\nTried to manually check the column type and get its value with the appropriate `ValueGetter<>`, to later convert it to a row and save it to a db table. I later saw that `.ToDataFrame(...)` does something similar, although much better in every aspect. Still, I failed to use the result  in combination with Dapper to insert it into a table (in my case, I failed to make a use of the `rows` list). This also takes too much memory (didn't go too much into details, but around 2.5GB (half of it is \"just my code\") was on the heap, and 5.1GB of RAM taken). Compared to converting it to a `DataFrame` which takes just 1.1GB of RAM, (didn't check the heap). I assume my solution could be optimized, but that's not the point here.\r\n\r\n```c#\r\n\r\ncolumns = // list of columns\r\nIDataView predictions = ...\r\n\r\nIEnumerable<DataViewSchema.Column> dvColumns = columns.Select(col => predictions.Schema[col]);\r\nIList<object> rows = new List<object>();\r\nusing (var cursor = predictions.GetRowCursor(dvColumns))\r\n{\r\n    Dictionary<string, ValueGetter<ReadOnlyMemory<char>>> colGettersString = new();\r\n    Dictionary<string, ValueGetter<float>> colGettersSingle = new();\r\n    foreach (var col in dvColumns)\r\n    {\r\n        var colType = col.Type.RawType;\r\n        if (col.Type.RawType == typeof(ReadOnlyMemory<char>))\r\n        {\r\n            colGettersString.Add(col.Name, cursor.GetGetter<ReadOnlyMemory<char>>(col));\r\n        }\r\n\r\n        if (col.Type.RawType == typeof(float))\r\n        {\r\n            colGettersSingle.Add(col.Name, cursor.GetGetter<float>(col));\r\n        }\r\n    }\r\n\r\n    while (cursor.MoveNext())\r\n    {\r\n        ExpandoObject colValues = new(); // could use a regular dictionary here\r\n        foreach (var col in dvColumns)\r\n        {\r\n            ReadOnlyMemory<char> colValueString = default;\r\n            float colValueFloat = default;\r\n\r\n            if (colGettersString.ContainsKey(col.Name))\r\n                colGettersString[col.Name](ref colValueString);\r\n            else if (colGettersSingle.ContainsKey(col.Name))\r\n                colGettersSingle[col.Name](ref colValueFloat);\r\n\r\n            string colValueStringString = colValueString.ToString();\r\n            if (string.IsNullOrEmpty(colValueStringString))\r\n                colValues.TryAdd(col.Name, colValueFloat);\r\n            else\r\n                colValues.TryAdd(col.Name, colValueStringString);\r\n        }\r\n\r\n        rows.Add(colValues);\r\n    }\r\n}\r\n```\r\n</details>\r\n\r\n<details>\r\n  <summary>4. Some other ideas</summary>\r\n\r\n**Using 3. and converting to JSON**\r\nThis seems to be like one of the workarounds, which I didn't complete. The idea is to take `rows` list from 3. and convert it to JSON. Then, manipulate the JSON through SQL, which I gave up on as it seems too complicated. This also uses more memory as the JSON can be a large string with a lot of data.\r\n\r\n**Using reflection Emit**\r\nCreate a class dynamically and use that to create a db model class, to be used in `CreateEnumerable`. I'm not sure how this works or if it is possible.\r\n</details>\r\n\r\n\r\n\r\n## Additional context\r\n\r\n- I am trying to insert data with Dapper into a SQL Server db\r\n- Using .NET 6\r\n- I am working with ~5 million rows of data with 5 columns\r\n\r\n  [1]: https://en.wikipedia.org/wiki/Plain_old_CLR_object\r\n  [2]: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataviewschema?view=ml-dotnet\r\n  [3]: https://stackoverflow.com/questions/73080930/save-ml-net-idataview-to-a-database-table-without-poco\r\n  [4]: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\r\n  [5]: https://en.wikipedia.org/wiki/XY_problem\r\n  [6]: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.schemaannotationsextensions.getslotnames?view=ml-dotnet\r\n  [7]: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.textloadersavercatalog.saveastext?view=ml-dotnet","Url":"https://github.com/dotnet/machinelearning/issues/6260","RelatedDescription":"Open issue \"Save IDataView to a database table\" (#6260)"},{"Id":"1316641177","IsPullRequest":false,"CreatedAt":"2022-07-25T10:54:23","Actor":"derekdiamond","Number":"6258","RawContent":null,"Title":"Model.Transform returns results in different order than the input DataView","State":"open","Body":"**System Information (please complete the following information):**\r\nWindows 11\r\nML.NET 1.70\r\n.NET 4.8\r\n\r\n**Describe the bug**\r\n\r\nI have the following code:\r\n\r\n                var res = Model.Transform(dataView);\r\n                var resSchema = res.Schema;\r\n                var resCsr = res.GetRowCursor(resSchema);\r\n\r\nWhen stepping through the result cursor the order of the results does not match the input order of the dataview. I need them in order so that I can match with the original dataset.\r\n\r\nAs a work around I am doing the transform one by one, that is creating dataviews that return one row, so it can easily then match to the input dataset. However this is very very slow, taking half an hour to transform 2000 records.\r\n\r\nI either need a mechanism to pass a key value per record that is passed through the transform, without it being used in the training process.\r\n \r\n**To Reproduce**\r\nCreate a regression model on a simple set of data say some random values x,y, x + 2 * y.\r\nThen create a test set of x,y's containing say 50 records. Then do a transform on the dataview and then traverse the result cursor and see that the x,y's are returned in a different order. However the first record always comes through first. Subsequent records come back in some random order.\r\n\r\n**Expected behavior**\r\n\r\nReturned records from the result cursor should come through in the same order as the input dataview, or have a way to identify what record in the source the result record comes from. Note: trying to match on the input record column values could possibly be done, but the floating point values may not match exactly due to conversions from double to float and if there are many columns this becomes a slow process.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6258","RelatedDescription":"Open issue \"Model.Transform returns results in different order than the input DataView\" (#6258)"},{"Id":"1310481162","IsPullRequest":true,"CreatedAt":"2022-07-22T21:40:08","Actor":"feiyun0112","Number":"6255","RawContent":null,"Title":"fix Dead link in FastTreeRegressionTrainerClass Documentation","State":"closed","Body":"#6254","Url":"https://github.com/dotnet/machinelearning/pull/6255","RelatedDescription":"Closed or merged PR \"fix Dead link in FastTreeRegressionTrainerClass Documentation\" (#6255)"},{"Id":"1313141549","IsPullRequest":false,"CreatedAt":"2022-07-21T11:55:22","Actor":"rzechu","Number":"6257","RawContent":null,"Title":"CreateEnumerable - System.IndexOutOfRangeException","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET v1.7.1\r\n - .NET Version: Framework 4.8\r\n\r\n**Describe the bug**\r\nI am receiving Index out of range exception after trying convert transformedData into enumerable.\r\nSame line of code works fine for same code but using method  - DetectIidSpike and its parameters\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n```\r\n    internal class LogsPrediction\r\n    {\r\n        //vector to hold alert,score,p-value values\r\n        [VectorType(3)]\r\n        public double[] Prediction { get; set; }\r\n    }\r\n```\r\n\r\n\r\nSent parameters\r\nList<SourceRequestData> SourceDatas /*12025 records but filtered inside loop to 517 records*/, \r\nint windowSize = 6, \r\nint backAddWindowSize = 5,\r\n int lookaheadWindowSize = 5, \r\nint averagingWindowSize = 5,\r\n int judgementWindowSize = 6, \r\ndouble threshold = 0.01\r\n```\r\npublic void DetectanAnomalyEnumerable(ref List<SourceRequestData> SourceDatas, int windowSize = 64, int backAddWindowSize = 5, int lookaheadWindowSize = 5, int averagingWindowSize = 5, int judgementWindowSize = 21, double threshold = 0.3)\r\n        {\r\n            try\r\n            {\r\n                var lambdaWorkAround = SourceDatas;\r\n                var differentDefinitions = SourceDatas.Select(s => new { RdMethodType = s.Rd_MethodType, RdMethodID = s.Rd_MethodId }).Distinct().ToList();\r\n\r\n                Parallel.ForEach(differentDefinitions, definitionID =>\r\n                {\r\n                    if (windowSize < 5)\r\n                        return;\r\n\r\n                    var dataToCheck = lambdaWorkAround.Where(w => w.Rd_MethodType == definitionID.RdMethodType && w.Rd_MethodId == definitionID.RdMethodID).OrderBy(o => o.Rd_ID).ToList();\r\n\r\n                    IDataView dataView = mlContext.Data.LoadFromEnumerable<SourceRequestData>(dataToCheck);\r\n\r\n                    lookaheadWindowSize = lookaheadWindowSize> windowSize  ? windowSize : lookaheadWindowSize;\r\n                    averagingWindowSize = averagingWindowSize > windowSize  ? windowSize : averagingWindowSize;\r\n                    judgementWindowSize = judgementWindowSize > windowSize  ? windowSize : judgementWindowSize;\r\n                    threshold = threshold == 0 ? 0.01 : threshold;\r\n                    threshold = threshold == 1 ? 0.99 : threshold;\r\n\r\n                    var iidSpikeEstimator = mlContext.Transforms.DetectAnomalyBySrCnn(\r\n                        outputColumnName: nameof(LogsPrediction.Prediction),\r\n                        inputColumnName: nameof(SourceRequestData.Rd_DurationPerObject),\r\n                        windowSize: windowSize,\r\n                        backAddWindowSize: backAddWindowSize,\r\n                        lookaheadWindowSize: lookaheadWindowSize,\r\n                        averagingWindowSize: averagingWindowSize,\r\n                        judgementWindowSize: judgementWindowSize,\r\n                        threshold: threshold);\r\n                    ITransformer iidSpikeTransform = iidSpikeEstimator.Fit(dataView);\r\n\r\n                    IDataView transformedData = iidSpikeTransform.Transform(dataView);\r\n//EXCEPTION HERE VVVVV\r\n                    var predictions = mlContext.Data.CreateEnumerable<LogsPrediction>(transformedData, reuseRowObject: false).ToList();\r\n//EXCEPTION HERE ^^^^^^^\r\n\r\n                    var objectID = dataView.GetColumn<float>(nameof(SourceRequestData.Rd_ID)).ToArray();\r\n\r\n                    for (int i = 0; i < predictions.Count(); i++)\r\n                    {\r\n                        if (predictions[i].Prediction[0] == 1)\r\n                        {\r\n                            var recordToChange = dataToCheck.Where(w => w.Rd_ID == objectID[i]).FirstOrDefault();\r\n                            recordToChange.IsSpike = true;\r\n                        }\r\n                    }\r\n                });\r\n                SourceDatas = lambdaWorkAround;\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                Console.WriteLine(ex);\r\n            }\r\n```\r\n\r\n\r\n   at Microsoft.ML.Transforms.TimeSeries.SrCnnAnomalyDetectionBase.SrCnnAnomalyDetectionBaseCore.State.BackAdd(FixedSizeQueue`1 data)\r\n   at Microsoft.ML.Transforms.TimeSeries.SrCnnAnomalyDetectionBase.SrCnnAnomalyDetectionBaseCore.State.SpectralResidual(Single input, FixedSizeQueue`1 data, VBufferEditor`1& result)\r\n   at Microsoft.ML.Transforms.TimeSeries.SrCnnTransformBase`2.SrCnnStateBase.TransformCore(TInput& input, FixedSizeQueue`1 windowedBuffer, Int64 iteration, VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.TimeSeries.SequentialTransformerBase`3.StateBase.Process(TInput& input, TOutput& output)\r\n   at Microsoft.ML.Transforms.LambdaTransform.<>c__DisplayClass5_0`3.<CreateMap>b__0(TSrc src, TDst dst, TState state)\r\n   at Microsoft.ML.Transforms.StatefulFilterTransform`3.Cursor.RunLambda(Boolean& isRowAccepted)\r\n   at Microsoft.ML.Transforms.StatefulFilterTransform`3.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowCursorImplementation.MoveNext()\r\n   at Microsoft.ML.PipeEngine`1.<RunPipe>d__2.MoveNext()\r\n   at System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at MLNet.AnomalyDetection.<>c__DisplayClass5_1.<DetectanAnomalyEnumerable>b__1(<>f__AnonymousType0`2 definitionID) in C:\\Users\\xyz.zys\\Desktop\\ML_NET\\Common\\MLNet\\AnomalyDetection.cs:line 178\r\n   at System.Threading.Tasks.Parallel.<>c__DisplayClass17_0`1.<ForWorker>b__1()\r\n```\r\n\r\n**Expected behavior**\r\nEnumerable object is returned (same code works for same method with DetectIidSpike and its own parameters)","Url":"https://github.com/dotnet/machinelearning/issues/6257","RelatedDescription":"Open issue \"CreateEnumerable - System.IndexOutOfRangeException\" (#6257)"},{"Id":"1311850878","IsPullRequest":false,"CreatedAt":"2022-07-20T20:22:32","Actor":"luisquintanilla","Number":"6256","RawContent":null,"Title":"[Azure ML] Azure training environment for supported training scenarios","State":"closed","Body":"Currently in Model Builder, we support the following scenarios and environments:\r\n\r\n| Scenarios | Local | Azure |\r\n| --- | --- | --- |\r\n| Data classification | ‚úÖ | ‚ùå|\r\n| Value Prediction | ‚úÖ | ‚ùå|\r\n| Recommendation | ‚úÖ | ‚ùå|\r\n| Forecasting | ‚úÖ | ‚ùå|\r\n| Image classification | ‚úÖ | ‚úÖ |\r\n| Object detection | ‚ùå| ‚úÖ |\r\n\r\n\r\nEnable Azure as a training environment for all supported scenarios:\r\n\r\n- [ ] Data classification\r\n- [ ] Value prediction\r\n- [ ] Recommendation\r\n- [ ] Forecasting","Url":"https://github.com/dotnet/machinelearning/issues/6256","RelatedDescription":"Closed issue \"[Azure ML] Azure training environment for supported training scenarios\" (#6256)"},{"Id":"1296319728","IsPullRequest":true,"CreatedAt":"2022-07-18T22:57:21","Actor":"LittleLittleCloud","Number":"6246","RawContent":null,"Title":"reimplement binary experiment using AutoMLExperiment","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis PR reimplements binary classification experiment using AutoMLExperiment, while keeping all the API unchanged so the existing documents don't need to be updated.","Url":"https://github.com/dotnet/machinelearning/pull/6246","RelatedDescription":"Closed or merged PR \"reimplement binary experiment using AutoMLExperiment\" (#6246)"},{"Id":"1308355241","IsPullRequest":false,"CreatedAt":"2022-07-18T18:27:45","Actor":"avcarr2","Number":"6254","RawContent":null,"Title":"Dead link in FastTreeRegressionTrainerClass Documentation","State":"open","Body":"The link to an article describing greedy function evaluation is broken: https://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aos/1013203451. \r\n\r\n---\r\n#### Document Details\r\n\r\n‚ö† *Do not edit this section. It is required for docs.microsoft.com ‚ûü GitHub issue linking.*\r\n\r\n* ID: 9f7b4cf1-c7bf-8141-180b-ea4474964153\r\n* Version Independent ID: 6ba65d38-7383-fdfb-ada4-12caf50f71ab\r\n* Content: [FastTreeRegressionTrainer Class (Microsoft.ML.Trainers.FastTree)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.fasttree.fasttreeregressiontrainer?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML.Trainers.FastTree/FastTreeRegressionTrainer.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML.Trainers.FastTree/FastTreeRegressionTrainer.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/6254","RelatedDescription":"Open issue \"Dead link in FastTreeRegressionTrainerClass Documentation\" (#6254)"},{"Id":"1307132928","IsPullRequest":false,"CreatedAt":"2022-07-17T15:45:29","Actor":"CBrauer","Number":"6253","RawContent":null,"Title":"Error in code on this web page","State":"open","Body":"\r\nWhy am I getting this error?\r\n![error](https://user-images.githubusercontent.com/1317234/179406005-8a411a21-07a4-4c76-9bd2-edbaa9013e36.PNG)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6253","RelatedDescription":"Open issue \"Error in code on this web page\" (#6253)"},{"Id":"1305043379","IsPullRequest":false,"CreatedAt":"2022-07-17T15:27:58","Actor":"torronen","Number":"6252","RawContent":null,"Title":"KMeansTrainer can not be set single-threaded (NumberOfThreads=1)","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows Server 2022\r\n - ML.NET Version: 1.7.1\r\n - .NET Version: .NET 6\r\n\r\n\r\n_Sorry, I do not have more details at this time, but I will file this because I probably will forget about this otherwise._\r\nMy immediate issue is resolved by setting NumnberOfThreads = 2.\r\n\r\n**Describe the bug**\r\nI have a parallel app (Parallel.ForEach as main loop).\r\nInside it I do clustering. I try to set to only use on thread:\r\n\r\n```\r\n      var options = new KMeansTrainer.Options\r\n            {\r\n                NumberOfClusters = NumberOfClusters,\r\n                OptimizationTolerance = 1e-6f,\r\n                NumberOfThreads = 1, \r\n            };\r\n\r\n```\r\n\r\nHowever, I see spike in CPU usage on every clustering call when running only one thread from main app. The performance is very low if I enable multithreading on main app with low (5-10%) CPU consumption. There is also some deadlock or infinte loop etc. which, when inspected, shows lots of threads doing some sub-tasks of clustering but I could not find the root cause yet.\r\n\r\nAfter I set NumberOfThreads = 2, I see much smaller spike on CPU consumpition (in debug) and much better performance with 16 threads from the main loop. I still only reach about 18% CPU consumption, though, but it may be due to other issues. I can not yet confirm the deadlocks (or infinite loops etc) are gone.\r\n\r\nMy suspect is that for whichever reason NumberOfThreads = 1 may be considered same as NumberOfThread=null (automatic). \r\n","Url":"https://github.com/dotnet/machinelearning/issues/6252","RelatedDescription":"Closed issue \"KMeansTrainer can not be set single-threaded (NumberOfThreads=1)\" (#6252)"},{"Id":"1288383209","IsPullRequest":false,"CreatedAt":"2022-07-14T08:00:22","Actor":"IzzyHibbert","Number":"6240","RawContent":null,"Title":"Could not load file or assembly 'System.Runtime.CompilerServices.Unsafe, Version=4.0.4.1","State":"closed","Body":"System Info :\r\n - OS : Win 2019\r\n - ML.NET Version: 1.5, tried already 1.7.1\r\n - .NET Version: 4.7.2\r\n\r\nIssue : \r\nI am trying to use ML in my .NET 4.7.2 class library project. \r\nI imported ML with Nuget, created the model, and when I use the dll I get the following error :\r\n\r\n```\r\nSystem.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---> System.IO.FileLoadException: Could not load file or assembly 'System.Runtime.CompilerServices.Unsafe, Version=4.0.4.1, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a' or one of its dependencies. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040)\r\nat System.MemoryExtensions.AsSpan(String text)\r\n```\r\nthe app.config file has the entry:\r\n\r\n```\r\n        <dependentAssembly>\r\n            <assemblyIdentity name=\"System.Runtime.CompilerServices.Unsafe\" publicKeyToken=\"b03f5f7f11d50a3a\" culture=\"neutral\" />\r\n            <bindingRedirect oldVersion=\"0.0.0.0-4.0.4.1\" newVersion=\"4.0.4.1\" />\r\n        </dependentAssembly>\r\n```\r\n\r\nand the installed unsafe package is 4.5.3 \r\nI also tried to solve this by using other versions of ML.net, but still getting the same error.\r\nAlso, running a unit test on this was fine without any error.\r\n\r\nIs there anything more that could be done ?\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6240","RelatedDescription":"Closed issue \"Could not load file or assembly 'System.Runtime.CompilerServices.Unsafe, Version=4.0.4.1\" (#6240)"},{"Id":"1303935379","IsPullRequest":false,"CreatedAt":"2022-07-13T20:54:07","Actor":"80LevelElf","Number":"6251","RawContent":null,"Title":"Memory leak by Auto ML","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET 2.0 preview (but have the same results when using 1.7.1 versions)\r\n - .NET Version: NET 5.0\r\n\r\n**Describe the bug**\r\nI have noticed that time to time my kubernetas pod faced Out of memory exception. Regarding to Grafana it starts with 500 Mb and reach 6 Gb after some times of processing of queue of learning.\r\n\r\nThen I have tried to reproduce the problem on my local machine and looks like I have found a problem by memory profiling:\r\n\r\n    // Call AutoML learning inside\r\n    await container.Resolve<IMlModelLearningPartTrainer>().Learn(Guid.Parse(\"43f60690-a594-4e8a-93bd-a91a2d836139\"));\r\n    \r\n    // After learning finishing forcely call the garbage collector\r\n    GC.Collect();\r\n\r\n    // Here I make a memory profiling\r\n\r\nAnd this is what I found:\r\n\r\n![Leak](https://user-images.githubusercontent.com/3397048/178831225-d3c95eb4-c1ba-4e72-8ba2-549206f9d598.jpg)\r\n\r\nLooks like AutoML use some timer callback inside to stop the learning. But for some reason it's not disposing event after learning is already finished. This timer lambda catch the outer context of learning and this is why GC can't dispose learning data.\r\n\r\nAnd after 1 hour after end of the learning - this learning data are still in the memory. It's a memory leak.\r\n\r\nHope this snapshots of our code help you. This is how we start the learning:\r\n\r\n            var settings = new BinaryExperimentSettings\r\n            {\r\n                MaxExperimentTimeInSeconds = (uint) maxExperimentTime,\r\n                OptimizingMetric = trainerAndMetric.Metric\r\n            };\r\n            \r\n            settings.Trainers.Clear();\r\n            settings.Trainers.Add(trainerAndMetric.Trainer);\r\n\r\n            var experiment = mlContext.Auto().CreateBinaryClassificationExperiment(settings);\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Start an AutoML learning for 5-10 minutes\r\n2. Whait the end of the learning\r\n3. Call GC.Collect\r\n4. Take a memory snapshot\r\n5. Check the data. Learning data are still in the memory\r\n\r\n**Expected behavior**\r\nNo data leak :)\r\n\r\n**Additional context**\r\nI reproduce the problem in 2.0 preview version of ML.NET and AutoML. But we upgrade the version tomorrow tring to solve the memory problem. We have the same out of memory problem at 2.0 preview and 1.7.1 versions. So I assume that the 1.7.1 version have the same memory leak problem.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6251","RelatedDescription":"Open issue \"Memory leak by Auto ML\" (#6251)"},{"Id":"1292208303","IsPullRequest":false,"CreatedAt":"2022-07-12T15:57:00","Actor":"QuinnDamerell","Number":"6244","RawContent":null,"Title":"Exception When Doing Image Prediction On Ubuntu","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Ubuntu 20.04.4 LTS\r\n - ML.NET Version: ML 1.7.1\r\n - .NET Version: NET 6.0\r\n\r\n**Describe the bug**\r\n\r\nI'm running a quite standard version of Ubuntu, using the latest dotnet 6.0 and latest ML libs, but for some reason, I'm getting this exception while trying to do an image clarification prediction on Linux. This logic work just fine on Windows. \r\n\r\nI looked up the issue and found this old bug from before dotnet 3.0. \r\nhttps://github.com/dotnet/runtime/issues/27200\r\n\r\nI did however still ran `apt-get install libgdiplus libc6-dev` and make sure the .so was in the /usr/lib dir where it should have been, yet I still get this issue.\r\n\r\nError: Exception throw in GadgetMl perdict.; TypeInitializationException - The type initializer for 'Gdip' threw an exception. -    at System.Drawing.SafeNa>\r\n    at System.Drawing.Image.InitializeFromStream(Stream stream)\r\n    at System.Drawing.Image.LoadFromStream(Stream stream, Boolean keepAlive)\r\n    at System.Drawing.Image.FromStream(Stream stream, Boolean useEmbeddedColorManagement, Boolean validateImageData)\r\n    at System.Drawing.Image.FromStream(Stream stream, Boolean useEmbeddedColorManagement)\r\n    at System.Drawing.Image.FromStream(Stream stream)\r\n    at Microsoft.ML.Data.ImageLoadingTransformer.Mapper.<>c__DisplayClass4_0.<MakeGetterImageDataViewType>b__1(Bitmap& dst)\r\n    at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\r\n    at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n    at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.NamedOnnxValueGetterVec`1.GetNamedOnnxValue()\r\n    at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, INamedOnnxValueGetter[] srcNamedOnnxValueGetters, List`1 activ>\r\n    at Microsoft.ML.Transforms.Onnx.OnnxTransformer.Mapper.<>c__DisplayClass14_0`1.<MakeTensorGetter>b__0(VBuffer`1& dst)\r\n    at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n    at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n    at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n    at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n    at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6244","RelatedDescription":"Closed issue \"Exception When Doing Image Prediction On Ubuntu\" (#6244)"},{"Id":"1301582401","IsPullRequest":false,"CreatedAt":"2022-07-12T06:07:01","Actor":"elisaho","Number":"6250","RawContent":null,"Title":"Prediction engine outputs only one class","State":"open","Body":"**System Information (please complete the following information):**\r\n - Windows 10 build 19044.1766\r\n - ML.NET v1.7.1\r\n - .NET 6.0\r\n\r\n**Describe the bug**\r\nFor a given image input to the prediction engine, the output schema only allows for one output detected class (and a single corresponding score). However, I would like for all detected classes to be returned. \r\nI am working on consuming the tensorflow model for object detection (exported from Custom Vision as GeneralCompactS1) in .Net using ML.NET. I have closely referenced:  \r\n[https://github.com/dotnet/machinelearning-samples/tree/main/samples/csharp/end-to-end-apps/DeepLearning_ImageClassification_TF/TFImageClassification ](url)\r\nI know the model can return multiple detected classes as I have consumed the same tensorflow model with python, tensorflowsharp, and tensorflow.net. I have tried appending column names with ':0' and ':1'(e.g. detected_classes:0) and changing the output tensor types (e.g. for detected_classes, change long to long[]), both to no avail. \r\n\r\n**Expected behavior**\r\nI expect all detected classes and their corresponding scores to be returned. \r\n\r\n**Screenshots, Code, Sample Projects**\r\n![image](https://user-images.githubusercontent.com/82560572/178418379-6fa91a35-5518-47b6-af35-c5f2fc2c89f4.png)\r\n![image](https://user-images.githubusercontent.com/82560572/178418911-2ffebbb3-aa80-48ca-890f-eec5362cc251.png)\r\n![image](https://user-images.githubusercontent.com/82560572/178419006-30a660f7-0f7e-487b-b6a9-77b0ccc928ef.png)\r\n![image](https://user-images.githubusercontent.com/82560572/178419132-3d1d4a47-7514-4b63-96ad-a63df6314c6b.png)\r\n![image](https://user-images.githubusercontent.com/82560572/178419196-bf0bfe97-fd83-4dec-aa61-50f9beb13b61.png)\r\n![image](https://user-images.githubusercontent.com/82560572/178419998-148f837e-8884-4643-9217-7101974259ea.png)\r\n<img width=\"766\" alt=\"Screenshot 2022-07-12 160630\" src=\"https://user-images.githubusercontent.com/82560572/178420335-968c8ae3-6dbd-42b9-9507-027de7675011.png\">\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6250","RelatedDescription":"Open issue \"Prediction engine outputs only one class\" (#6250)"},{"Id":"1299623466","IsPullRequest":false,"CreatedAt":"2022-07-11T17:20:59","Actor":"wangLinWuYing","Number":"6248","RawContent":null,"Title":"Tensorflow's hardware CPu requirements, such as the minimum REQUIRED CPu configuration, do not use the GPU ","State":"closed","Body":"Tensorflow's hardware CPu requirements, such as the minimum REQUIRED CPu configuration, do not use the GPU ","Url":"https://github.com/dotnet/machinelearning/issues/6248","RelatedDescription":"Closed issue \"Tensorflow's hardware CPu requirements, such as the minimum REQUIRED CPu configuration, do not use the GPU \" (#6248)"},{"Id":"1300656056","IsPullRequest":true,"CreatedAt":"2022-07-11T12:40:54","Actor":"dotnet-maestro[bot]","Number":"6249","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 97926d79-6b8b-4d32-c8db-08d9d479971c\r\n- **Build**: 20220722.1\r\n- **Date Produced**: July 22, 2022 2:57:33 PM UTC\r\n- **Commit**: 11672d906390046e77a34b6406d9e02229fd7e45\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 7.0.0-beta.22327.2 to 7.0.0-beta.22372.1][3]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 7.0.0-beta.22327.2 to 7.0.0-beta.22372.1][3]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 7.0.0-beta.22327.2 to 7.0.0-beta.22372.1][3]\r\n  - **Microsoft.DotNet.SignTool**: [from 7.0.0-beta.22327.2 to 7.0.0-beta.22372.1][3]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 7.0.0-beta.22327.2 to 7.0.0-beta.22372.1][3]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 7.0.0-beta.22327.2 to 7.0.0-beta.22372.1][3]\r\n\r\n[3]: https://github.com/dotnet/arcade/compare/a264eb1...11672d9\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6249","RelatedDescription":"Open PR \"[main] Update dependencies from dotnet/arcade\" (#6249)"},{"Id":"1293104884","IsPullRequest":true,"CreatedAt":"2022-07-06T23:58:50","Actor":"dotnet-maestro[bot]","Number":"6245","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 97926d79-6b8b-4d32-c8db-08d9d479971c\r\n- **Build**: 20220627.2\r\n- **Date Produced**: June 27, 2022 5:10:02 PM UTC\r\n- **Commit**: a264eb13fea14125f3ef8d4056586cd66fa55309\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 7.0.0-beta.22327.1 to 7.0.0-beta.22327.2][1]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 7.0.0-beta.22327.1 to 7.0.0-beta.22327.2][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 7.0.0-beta.22327.1 to 7.0.0-beta.22327.2][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 7.0.0-beta.22327.1 to 7.0.0-beta.22327.2][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 7.0.0-beta.22327.1 to 7.0.0-beta.22327.2][1]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 7.0.0-beta.22327.1 to 7.0.0-beta.22327.2][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/640c1cc...a264eb1\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6245","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#6245)"},{"Id":"1289422403","IsPullRequest":true,"CreatedAt":"2022-07-06T18:55:22","Actor":"JakeRadMSFT","Number":"6243","RawContent":null,"Title":"Add AutoML Interactive Extension","State":"closed","Body":"This PR is going to add a Visualizer for AutoML experiments to track AutoML progress while it's running in a Notebook.\r\n\r\nIt's not perfect but it's a start:\r\n\r\n<img width=\"1005\" alt=\"image\" src=\"https://user-images.githubusercontent.com/31937616/176798313-5d58be4f-3326-4ca9-8b2a-5ed9cac05e29.png\">\r\n\r\n\r\n----------------------\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6243","RelatedDescription":"Closed or merged PR \"Add AutoML Interactive Extension\" (#6243)"},{"Id":"1289416461","IsPullRequest":true,"CreatedAt":"2022-06-30T21:50:27","Actor":"michaelgsharp","Number":"6242","RawContent":null,"Title":"Fixes Onnx Export for Column Copy Transformer.","State":"closed","Body":"Fixes #6237. Column Copy Transformer was checking the wrong thing during the onnx export. It was checking if the intermediate variable exists in the input dataset when it needed to check if the original column name existed in the original dataset.\r\n\r\nWhen Column Copy Transformer is using a column that hasn't been used by another transformer this bug was not encountered. It only shows up when a column (with the same name) is used by a previews transformer. Because this change only affects the internal onnx state, not really a good way to test it automatically.","Url":"https://github.com/dotnet/machinelearning/pull/6242","RelatedDescription":"Closed or merged PR \"Fixes Onnx Export for Column Copy Transformer.\" (#6242)"},{"Id":"1283873717","IsPullRequest":false,"CreatedAt":"2022-06-30T21:50:26","Actor":"jonathanpeppers","Number":"6237","RawContent":null,"Title":"Issue saving model to .onnx format","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version:  Windows 10\r\n - ML.NET Version: 1.7.1\r\n - .NET Version: .NET 6\r\n\r\n**Describe the bug**\r\n\r\nI trained a model with:\r\n\r\n```\r\nmlnet classification --dataset classified.csv --label-col 1 --has-header true --train-time 60\r\n```\r\n\r\nOpened the resulting project, and tried to change it to save the model file as `.onnx` format:\r\n\r\n[SampleClassification.zip](https://github.com/dotnet/machinelearning/files/8977193/SampleClassification.zip)\r\n\r\nInstalled the NuGet:\r\n\r\n```xml\r\n<PackageReference Include=\"Microsoft.ML.OnnxConverter\" Version=\"0.19.1\" />\r\n```\r\n\r\nTrying something like:\r\n\r\n```csharp\r\nprivate static void SaveModel(MLContext mlContext, IDataView dataView, ITransformer mlModel, string modelRelativePath, DataViewSchema modelInputSchema)\r\n{\r\n    // Save/persist the trained model to a .ZIP file\r\n    Console.WriteLine($\"=============== Saving the model  ===============\");\r\n    //mlContext.Model.Save(mlModel, modelInputSchema, GetAbsolutePath(modelRelativePath));\r\n    using var fileStream = File.Create(modelRelativePath);\r\n    mlContext.Model.ConvertToOnnx(mlModel, dataView, fileStream);\r\n\r\n    Console.WriteLine(\"The model is saved to {0}\", GetAbsolutePath(modelRelativePath));\r\n}\r\n```\r\n\r\nThrows an exception:\r\n```\r\nSystem.Collections.Generic.KeyNotFoundException\r\n  HResult=0x80131577\r\n  Message=The given key 'text_TextNormalizer' was not present in the dictionary.\r\n  Source=System.Private.CoreLib\r\n  StackTrace:\r\n   at System.ThrowHelper.ThrowKeyNotFoundException[T](T key)\r\n   at System.Collections.Generic.Dictionary`2.get_Item(TKey key)\r\n   at Microsoft.ML.Model.OnnxConverter.OnnxContextImpl.GetVariableName(String colName)\r\n   at Microsoft.ML.Transforms.Text.WordTokenizingTransformer.Mapper.SaveAsOnnx(OnnxContext ctx)\r\n   at Microsoft.ML.Data.RowToRowMapperTransform.Microsoft.ML.Model.OnnxConverter.ISaveAsOnnx.SaveAsOnnx(OnnxContext ctx)\r\n   at Microsoft.ML.Model.OnnxConverter.SaveOnnxCommand.ConvertTransformListToOnnxModel(OnnxContextImpl ctx, IChannel ch, IDataView inputData, IDataView outputData, LinkedList`1 transforms, HashSet`1 inputColumnNamesToDrop, HashSet`1 outputColumnNamesToDrop)\r\n   at Microsoft.ML.OnnxExportExtensions.ConvertToOnnxProtobufCore(IHostEnvironment env, OnnxContextImpl ctx, ITransformer transform, IDataView inputData, String[] outputColumnNamesToKeep)\r\n   at Microsoft.ML.OnnxExportExtensions.ConvertToOnnxProtobuf(ModelOperationsCatalog catalog, ITransformer transform, IDataView inputData, String[] outputColumns)\r\n   at Microsoft.ML.OnnxExportExtensions.ConvertToOnnx(ModelOperationsCatalog catalog, ITransformer transform, IDataView inputData, Stream stream)\r\n   at SampleClassification.ConsoleApp.ModelBuilder.SaveModel(MLContext mlContext, IDataView dataView, ITransformer mlModel, String modelRelativePath, DataViewSchema modelInputSchema) in C:\\Users\\jopepper\\Downloads\\SampleClassification (2)\\SampleClassification.ConsoleApp\\ModelBuilder.cs:line 92\r\n   at SampleClassification.ConsoleApp.ModelBuilder.CreateModel() in C:\\Users\\jopepper\\Downloads\\SampleClassification (2)\\SampleClassification.ConsoleApp\\ModelBuilder.cs:line 47\r\n   at SampleClassification.ConsoleApp.Program.Main(String[] args) in C:\\Users\\jopepper\\Downloads\\SampleClassification (2)\\SampleClassification.ConsoleApp\\Program.cs:line 16\r\n```\r\n\r\n**To Reproduce**\r\n\r\n1. Open the above project in VS\r\n2. Run it\r\n\r\n**Expected behavior**\r\n\r\nWe need to convert our model to `.onnx` format, to be able to use it from JavaScript, and I think this is the best option? Let me know otherwise.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\nSample above.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6237","RelatedDescription":"Closed issue \"Issue saving model to .onnx format\" (#6237)"},{"Id":"1276858840","IsPullRequest":true,"CreatedAt":"2022-06-30T16:03:33","Actor":"dotnet-maestro[bot]","Number":"6234","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 97926d79-6b8b-4d32-c8db-08d9d479971c\r\n- **Build**: 20220627.1\r\n- **Date Produced**: June 27, 2022 8:28:47 AM UTC\r\n- **Commit**: 640c1cc2a140b322c4f30f6d6b85f35f0c4c7313\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 7.0.0-beta.22313.1 to 7.0.0-beta.22327.1][2]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 7.0.0-beta.22313.1 to 7.0.0-beta.22327.1][2]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 7.0.0-beta.22313.1 to 7.0.0-beta.22327.1][2]\r\n  - **Microsoft.DotNet.SignTool**: [from 7.0.0-beta.22313.1 to 7.0.0-beta.22327.1][2]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 7.0.0-beta.22313.1 to 7.0.0-beta.22327.1][2]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 7.0.0-beta.22313.1 to 7.0.0-beta.22327.1][2]\r\n\r\n[2]: https://github.com/dotnet/arcade/compare/569a3f0...640c1cc\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6234","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#6234)"},{"Id":"1288741302","IsPullRequest":false,"CreatedAt":"2022-06-29T13:37:39","Actor":"zhangfeibao","Number":"6241","RawContent":null,"Title":"load ONNX model(RNN[LSTM]) can not work ","State":"open","Body":"**System Information**\r\n - OS & Version: Windows 10]\r\n - ML.NET Version: ML.NET v1.5.5\r\n - .NET Version: NET 6.0\r\n\r\nI got the onnx model from tf2.\r\nThe model infomation is:\r\n![image](https://user-images.githubusercontent.com/12379132/176447293-f3e6f9f2-cba6-4dfc-a53f-f3a6f7932c08.png)\r\nI load the onnx model follow the [document.](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-automl-onnx-model-dotnet)\r\n\r\n```c#\r\nprivate static ITransformer GetPredictionPipeline(MLContext mlContext)\r\n{\r\n    var inputColumns = new string[]\r\n    {\r\n        \"model\"\r\n    };\r\n\r\n    var outputColumns = new string[] { \"dense\" };\r\n\r\n    var onnxPredictionPipeline =\r\n        mlContext\r\n        .Transforms\r\n        .ApplyOnnxModel(\r\n        outputColumnNames: outputColumns,\r\n        inputColumnNames: inputColumns,\r\n        ONNX_MODEL_PATH);\r\n\r\n    var emptyDv = mlContext.Data.LoadFromEnumerable(new OnnxInput[] {});    //the line will throw the exception\r\n\r\n    return onnxPredictionPipeline.Fit(emptyDv);\r\n}\r\n\r\n```\r\n\r\n\r\nwhen i ran the app,I got the exception at the line.\r\n> **System.InvalidOperationException:‚ÄúInput** shape mismatch: Input 'model' has shape 1,50,4, but input data is of length 1.‚Äù\r\n\r\nI have tryed many time to resove the problem.but it just can't work!\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6241","RelatedDescription":"Open issue \"load ONNX model(RNN[LSTM]) can not work \" (#6241)"},{"Id":"1286604130","IsPullRequest":false,"CreatedAt":"2022-06-28T00:30:46","Actor":"luisquintanilla","Number":"6238","RawContent":null,"Title":"[DataFrame] Allow quote escaping","State":"open","Body":"Loading data from a column containing quotes inside a string shouldn't break. \r\n\r\n```text\r\n\"this is one column value which includes a \"\" character\" \r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6238","RelatedDescription":"Open issue \"[DataFrame] Allow quote escaping\" (#6238)"},{"Id":"1283467806","IsPullRequest":false,"CreatedAt":"2022-06-27T06:36:51","Actor":"paul1610","Number":"6236","RawContent":null,"Title":"Can¬¥t make prediction with code trained model","State":"closed","Body":"**System Information (please complete the following information):**\r\n - Windows 10\r\n - ML.NET Version: ML.NET v1.7.1\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\nWhen I tried to get a prediction from a new trained model, the error \r\n```\r\nSystem.ArgumentOutOfRangeException: 'Could not find input column 'ImagePath'\r\nParameter name: inputSchema'\r\n```\r\n**Expected behavior**\r\nThe final model should be saved & used for prediction.\r\n\r\n**Additional context**\r\nGitHub Repository: https://github.com/paul1610/csharp-faceid\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6236","RelatedDescription":"Closed issue \"Can¬¥t make prediction with code trained model\" (#6236)"},{"Id":"1282919068","IsPullRequest":true,"CreatedAt":"2022-06-24T15:28:18","Actor":"michaelgsharp","Number":"6235","RawContent":null,"Title":"Added score column. Auto count unique labels.","State":"closed","Body":"This PR fixes #6227, fixes #6225, and fixes #6226.\r\n\r\nIt adds in the score column, truncates the input tokens at 512, and auto calculates the number of classes.\r\n\r\nIt also gets the row count to correctly set the Learning Rate Scheduler. In my offline testing this increased accuracy by up to 20% based on the dataset, batch size, and number of epochs. Mileage will vary per dataset, but all datasets should see an increase in accuracy.\r\n\r\nIt also adds in row caching similar to how the OnnxTransformer does row caching.","Url":"https://github.com/dotnet/machinelearning/pull/6235","RelatedDescription":"Closed or merged PR \"Added score column. Auto count unique labels.\" (#6235)"},{"Id":"1275370888","IsPullRequest":false,"CreatedAt":"2022-06-17T19:05:11","Actor":"vadd98","Number":"6233","RawContent":null,"Title":"Can't make image classification prediction on MacOS using a Tensorflow model","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: MacOS 12.4\r\n - ML.NET Version: Microsoft.ML 1.7.1\r\n - .NET Version: NET 6.0\r\n\r\n**Describe the bug**\r\nIt seems impossible to make prediction based on images using a Tensorflow model on Mac.\r\nI'm always getting this error:\r\n\r\n`Unhandled exception. System.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.TensorValueGetterVec`1.GetTensor()\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, ITensorValueGetter[] srcTensorGetters, String[] activeOutputColNames, OutputCache outputCache)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass11_0`1.<MakeGetter>b__4(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n`\r\n\r\nThe exact same code with same model and same images to predict works flawlessly on Windows 10.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Train a Tensorflow Model (I trained the model using Python)\r\n2. Import the trained model in ML.NET\r\n3. Try to make a prediction starting from an image\r\n4. See error\r\n\r\n**Expected behavior**\r\nMake predictions without exceptions.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6233","RelatedDescription":"Open issue \"Can't make image classification prediction on MacOS using a Tensorflow model\" (#6233)"}],"ResultType":"GitHubIssue"}},"RunOn":"2022-07-30T03:30:23.1206909Z","RunDurationInMilliseconds":548}