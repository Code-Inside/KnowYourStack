{"Data":{"GitHub":{"Issues":[{"Id":"2370650837","IsPullRequest":false,"CreatedAt":"2024-06-24T16:28:30","Actor":"LittleLittleCloud","Number":"7182","RawContent":null,"Title":"Helix test fail on latest torchsharp (0.102.5) and its runtime","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n - .NET Version: [e.g. .NET 5.0]\r\n\r\n**Describe the bug**\r\n\r\nThe Microsoft.ML.Torchsharp.Tests fails in the following helix tests if I update torchsharp and its runtime to 0.102.5 and 2.2.1.1.\r\n- centos x64\r\n- ubuntu x64\r\n\r\nThe error message from helix tests indicates some dependencies of `liblibtorchsharp` is missing. After turning on `LD_Debug`, it seems that one of the missing dependencies is `GLIBC_2.34`. Note that the image for helix test is still `centos 8 streaming` which glib version is 2.28. This could be the why the torchsharp test failures.\r\n\r\n```bash\r\nfile=/temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libtorch_cpu.so\r\n       260:\r\n       260:     find library=libgomp-98b21ff3.so.1 [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/libgomp-98b21ff3.so.1\r\n       260:       trying file=/usr/local/lib64/libgomp-98b21ff3.so.1\r\n       260:      search path=/temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native            (RUNPATH from file /temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libtorch_cpu.so)\r\n       260:       trying file=/temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libgomp-98b21ff3.so.1\r\n       260:\r\n       260:     /lib64/libc.so.6: error: version lookup error: version `GLIBC_2.34' not found (required by /temp/workitems/Microsoft.ML.TorchSharp.Tests/runtimes/linux-x64/native/libLibTorchSharp.so) (fatal)\r\n       260:     find library=libLibTorchSharp.so [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/libLibTorchSharp.so\r\n       260:       trying file=/usr/local/lib64/libLibTorchSharp.so\r\n       260:      search cache=/etc/ld.so.cache\r\n       260:      search path=/lib64/tls:/lib64:/usr/lib64/tls:/usr/lib64                (system search path)\r\n       260:       trying file=/lib64/tls/libLibTorchSharp.so\r\n       260:       trying file=/lib64/libLibTorchSharp.so\r\n       260:       trying file=/usr/lib64/tls/libLibTorchSharp.so\r\n       260:       trying file=/usr/lib64/libLibTorchSharp.so\r\n       260:\r\n       260:     find library=LibTorchSharp [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/LibTorchSharp\r\n       260:       trying file=/usr/local/lib64/LibTorchSharp\r\n       260:      search cache=/etc/ld.so.cache\r\n       260:      search path=/lib64/tls:/lib64:/usr/lib64/tls:/usr/lib64                (system search path)\r\n       260:       trying file=/lib64/tls/LibTorchSharp\r\n       260:       trying file=/lib64/LibTorchSharp\r\n       260:       trying file=/usr/lib64/tls/LibTorchSharp\r\n       260:       trying file=/usr/lib64/LibTorchSharp\r\n       260:\r\n       260:     find library=libLibTorchSharp [0]; searching\r\n       260:      search path=/usr/local/lib:/usr/local/lib64            (LD_LIBRARY_PATH)\r\n       260:       trying file=/usr/local/lib/libLibTorchSharp\r\n       260:       trying file=/usr/local/lib64/libLibTorchSharp\r\n       260:      search cache=/etc/ld.so.cache\r\n       260:      search path=/lib64/tls:/lib64:/usr/lib64/tls:/usr/lib64                (system search path)\r\n       260:       trying file=/lib64/tls/libLibTorchSharp\r\n       260:       trying file=/lib64/libLibTorchSharp\r\n       260:       trying file=/usr/lib64/tls/libLibTorchSharp\r\n       260:       trying file=/usr/lib64/libLibTorchSharp\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7182","RelatedDescription":"Open issue \"Helix test fail on latest torchsharp (0.102.5) and its runtime\" (#7182)"},{"Id":"2331509888","IsPullRequest":false,"CreatedAt":"2024-06-24T16:21:25","Actor":"jackpotcityco","Number":"7166","RawContent":null,"Title":"When training with AutoML, I encounter a Win32Exception: The wait operation timed out after 30 seconds.","State":"closed","Body":"CPU: i7-12800h (14 cores, Total Threads: 20)\r\nRAM: 32 GB\r\nSSD: Samsung 980 Pro, 2 TB\r\nWindows Server 2019 Datacenter Evaluation\r\nNET Framework: 4.8\r\nMicrosoft.ML: 3.0.1\r\nMicrosoft.ML.AutoML: 0.21.1\r\n\r\n**Issue:**\r\nWhen I start to train a model using AutoML, I get a timeout after exactly 30 seconds and the application breaks/stops with below error message: (CPU working at 15%. RAM has 50% avaliable memory at the exception)\r\n\r\n_System.AggregateException: 'One or more errors occurred.'\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\nSqlException: Execution Timeout Expired.  The timeout period elapsed prior to completion of the operation or the server is not responding.\r\n**Win32Exception: The wait operation timed out**_\r\n\r\nNormally, the training of the Model should continue but I don't understand why I get this timeout after 30 seconds. It seems to be a default value and this must be possible to increase and change but I have not found out where to change this default value or how to solve this problem?\r\n\r\n**Datasets looks like this:**\r\ntrainData: Rows: 384846, Columns: 64\r\nhold_out_data:  Rows: 33958, Columns: 64\r\n\r\n**Below is the code I use:** \r\n_(You might mention to use \"MaxModels\" but the root problem is about be able to change the timeout period, I beleive)_\r\n```\r\n        void trainer_function(IDataView trainData, IDataView hold_out_data)\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n            var experiment = mlContext.Auto().CreateBinaryClassificationExperiment(new BinaryExperimentSettings\r\n            {\r\n                MaxExperimentTimeInSeconds = 600,\r\n                CacheBeforeTrainer = CacheBeforeTrainer.On,\r\n                CacheDirectoryName = \"C:/Aintelligence/temp/cache\",\r\n                MaximumMemoryUsageInMegaByte = 8192,\r\n                OptimizingMetric = BinaryClassificationMetric.PositivePrecision,\r\n                CancellationToken = CancellationToken.None\r\n            });\r\n            var progressHandler = new Progress<RunDetail<BinaryClassificationMetrics>>(ph =>\r\n            {\r\n                if (ph.ValidationMetrics != null && !ph.TrainerName.Contains(\"FastForest\"))\r\n                {\r\n                    double positivePrecision = Math.Round(ph.ValidationMetrics.PositivePrecision, 3); //Do something with: \"positivePrecision\"\r\n                }\r\n            });\r\n            //Start the experiment/Training\r\n            var results = experiment.Execute(trainData, hold_out_data, labelColumnName: \"Label\", progressHandler: progressHandler);\r\n        }\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7166","RelatedDescription":"Closed issue \"When training with AutoML, I encounter a Win32Exception: The wait operation timed out after 30 seconds.\" (#7166)"},{"Id":"2364422816","IsPullRequest":false,"CreatedAt":"2024-06-20T13:14:29","Actor":"lopango","Number":"7181","RawContent":null,"Title":"Possible bug in DoubleParser.cs","State":"open","Body":"In Microsoft.ML.Core\\Utilities\\DoubleParser.cs near lines 143 and 195\r\n\r\n```csharp\r\n            int ichEnd;\r\n            if (!DoubleParser.TryParse(span.Slice(ich, span.Length - ich), out value, out ichEnd, flags))\r\n            {\r\n                value = default(Double);\r\n                return Result.Error;\r\n            }\r\n\r\n            // Make sure everything was consumed.\r\n            while (ichEnd < span.Length)\r\n            {\r\n                if (!char.IsWhiteSpace(span[ichEnd]))\r\n                    return Result.Extra;\r\n                ichEnd++;\r\n            }\r\n```\r\nthe ichEnd is indexed on the sliced span. \r\nIf ich is not 0 there will be an offset when for \"ichEnd < span.Length\" and \"span[ichEnd]\"\r\n\r\nExample : for an input like \"  1.234  \" the method will return Result.Extra\r\n\r\nPÃ¶ssible solutions:\r\n* ichEnd += ich;\r\n* modify the tryparse to accept an offset and use the original span","Url":"https://github.com/dotnet/machinelearning/issues/7181","RelatedDescription":"Open issue \"Possible bug in DoubleParser.cs\" (#7181)"},{"Id":"2363994834","IsPullRequest":false,"CreatedAt":"2024-06-20T09:39:48","Actor":"RossHNPC","Number":"7180","RawContent":null,"Title":"Cuda v11.8 support for image classification problems?","State":"open","Body":"Current implementations for Image classification, following [MS guidance](https://learn.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/install-gpu-model-builder) restricts us to using Cuda SDK v10.1. This in turn limits the available Nvidia cards that can be used. Going to a production install we need to use cards supported/supplied by IT vendors, DELL, etc. These tend to be newer cards that are beyond the Turing architecture: Ampere, Ada Lovelace, etc.\r\n\r\nWe would like for the Cuda SDK support to be raised to v11.8 to take advantage of a wider range of supported cards.\r\n\r\nAlternatives at present are code fixes to block inference from happening before the models are loaded and available, this can be anywhere from 1 - 20 mins for a basic image classification model. Older cards, my laptop has a lowly T500, are loading in 10's of seconds. As a real time implementation this is a lot of missed classifications.\r\n\r\nIf there is no intention to update Cuda support please do let us know as we can then look at alternatives.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7180","RelatedDescription":"Open issue \"Cuda v11.8 support for image classification problems?\" (#7180)"},{"Id":"2361667361","IsPullRequest":true,"CreatedAt":"2024-06-19T08:09:18","Actor":"asmirnov82","Number":"7179","RawContent":null,"Title":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations  (.net8)","State":"open","Body":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations (.net8)\r\n\r\nFixes #7178\r\n\r\nThe aim of this PR to use new library for DataFrame arithmetic operations instead of custom implemtation. At the same time provide backward compatibility for pre-.Net8.0 versions of the package. To achive this, all .,net version specific code is localised in nested private classes of `static class Arithmetic` that implements `IArithmetic<T>` interface and are not used directly by any other DataFrame classes","Url":"https://github.com/dotnet/machinelearning/pull/7179","RelatedDescription":"Open PR \"Use new System.Numerics.Tensors library for DataFrame arithmetic operations  (.net8)\" (#7179)"},{"Id":"2361642204","IsPullRequest":false,"CreatedAt":"2024-06-19T08:01:17","Actor":"asmirnov82","Number":"7178","RawContent":null,"Title":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations (.net8)","State":"open","Body":"Use new System.Numerics.Tensors library for DataFrame arithmetic operations instead of custom implementation\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7178","RelatedDescription":"Open issue \"Use new System.Numerics.Tensors library for DataFrame arithmetic operations (.net8)\" (#7178)"},{"Id":"2360285660","IsPullRequest":true,"CreatedAt":"2024-06-18T16:43:44","Actor":"LittleLittleCloud","Number":"7177","RawContent":null,"Title":"Add GenAI core package","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n#7169 Task 2","Url":"https://github.com/dotnet/machinelearning/pull/7177","RelatedDescription":"Open PR \"Add GenAI core package\" (#7177)"},{"Id":"2355269973","IsPullRequest":false,"CreatedAt":"2024-06-15T21:10:30","Actor":"IntegerMan","Number":"7176","RawContent":null,"Title":"Make class labels on the ConfusionMatrix publicly readable for custom charting support","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI'm trying to build a library of data science charts for visualizing the results of ML.NET model training. One of those is a graphical confusion matrix pictured below (no offense to the wonderful built-in formatted table option present in ML.NET already).\r\n![image](https://github.com/dotnet/machinelearning/assets/5049957/c43f9a6d-c508-448d-a6c1-e2a2e08c5090)\r\n\r\nUnfortunately, there's no public way of getting the names of classes for the matrix as `ConfusionMatrix.PredictedClassesIndicators` is internal. This means that class labels in multi-class classification charts must:\r\n\r\n1. Use an arbitrary label like \"Class 1\"\r\n2. Require the caller to specify an array of class names\r\n3. Call the public `ConfusionMatrix.GetFormattedConfusionMatrix` and parse the output to get the class names from the generated output.\r\n\r\n**Describe the solution you'd like**\r\nEither make `PredictedClassesIndicators` publicly gettable or provide a `GetClassLabel(int classIndex): string` method for accessing this information.\r\n\r\n**Describe alternatives you've considered**\r\nRight now I am requiring callers to provide an array of class names for multi-class classification. However, if this feature goes some time before it is implemented, I may decide to write code to parse the results of `GetFormattedConfusionMatrix` which does include those internal labels.\r\n\r\n**Additional context**\r\nMy goal is for ML.NET to be as viable as SciKit-Learn in as many contexts as possible. Right now, I'm using ML.NET for my master's program and I'd much rather turn in a report with a graphical confusion matrix than a formatted text confusion matrix. Also, I'm running these charts in a Polyglot Notebook.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7176","RelatedDescription":"Open issue \"Make class labels on the ConfusionMatrix publicly readable for custom charting support\" (#7176)"},{"Id":"2355255440","IsPullRequest":false,"CreatedAt":"2024-06-15T20:59:28","Actor":"IntegerMan","Number":"7175","RawContent":null,"Title":"Support text/vnd.mermaid MIME Type in Formatters","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI'd like to be able to easily write formatters for built-in and custom types that use Mermaid markdown to render a custom diagram for an object. My specific case in wanting this at the moment is a `Microsoft.ML.ITransformer` object where I want to visualize the chain of transformers from a machine learning model.\r\n\r\nI can generate a valid mermaid string, but outputting it from a Formatter either results in the mermaid string appearing as text if plain text or HTML mime types are used, or with my formatter not being used at all if I specify \"text/markdown\" or \"text/vnd.mermaid\" (Mermaid's official MIME type).\r\n\r\nThere are ways of manually passing things off to the Mermaid kernel via extensions, but those are a lot more work than a simple Formatter, and it'd be ideal to avoid having to write a magic command just to process something.\r\n\r\n**Describe the solution you'd like**\r\nFormatters with a MIME type of `text/vnd.mermaid` should have their output piped to the Mermaid kernel and the result of that operation should be rendered below the cell when the formatter is in use.\r\n\r\nYou should be able to set up a formatter in a manner like this:\r\n\r\n```cs\r\nFormatter.Register<ITransformer>((transformer, writer) =>\r\n{\r\n    writer.Write(MattEland.ML.Interactive.TransformerExtensions.ToMermaid(transformer));\r\n}, \"text/vnd.mermaid\");\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nI've considered finding an external rendering library to transform mermaid to a supported MIME type, writing a custom magic command to connect things directly to the Mermaid kernel, and considered avoiding Mermaid entirely here and building something in SVG.\r\n\r\n**Additional context**\r\nThis is part of a larger effort I'm making to try to improve the data analysis and data science workflow in a Polyglot Notebook based on things I've observed in book / course creation and while using this toolset pursuing my master's degree.\r\n\r\nSee https://github.com/IntegerMan/MattEland.ML/blob/main/MattEland.ML/MattEland.ML.Interactive/TransformerExtensions.cs and neighboring files for details on my early transformer mermaid visualization attempt.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7175","RelatedDescription":"Open issue \"Support text/vnd.mermaid MIME Type in Formatters\" (#7175)"},{"Id":"2354970257","IsPullRequest":false,"CreatedAt":"2024-06-15T15:57:34","Actor":"superichmann","Number":"7174","RawContent":null,"Title":"Add AutoEncoder as a Feature Selection Method","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nNo.\r\nCurrently the only **practical** option for feature selection in ML.net is MI. maybe PFI (post fit post transform) and maybe PCA (dimensionality reduction).\r\n\r\n**Describe the solution you'd like**\r\nMy online research shows that autoencoders for feature selection can be highly accurate and add another layer to the feature selection catalog.\r\n\r\n**Describe alternatives you've considered**\r\nUsing already implemented feature importance methods.\r\n\r\n**Additional context**\r\nResearch:\r\nhttps://hex.tech/blog/autoencoders-for-feature-selection/\r\nhttps://deepai.org/publication/autoencoder-feature-selector\r\nRelates to issues:\r\n[4254](https://github.com/dotnet/machinelearning/issues/4254)\r\n[5777](https://github.com/dotnet/machinelearning/issues/5777)\r\n\r\nNote: Perhaps utilizing autoencoders is actually possible in ml.net with importing external models or something like that, if it does I would love a to see how :) Thanks for everything guys!\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7174","RelatedDescription":"Open issue \"Add AutoEncoder as a Feature Selection Method\" (#7174)"},{"Id":"2337878692","IsPullRequest":true,"CreatedAt":"2024-06-13T19:14:03","Actor":"asmirnov82","Number":"7168","RawContent":null,"Title":"Add targeting .Net 8.0 for DataFrame package","State":"closed","Body":"Fixes #7167 \r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7168","RelatedDescription":"Closed or merged PR \"Add targeting .Net 8.0 for DataFrame package\" (#7168)"},{"Id":"2337874552","IsPullRequest":false,"CreatedAt":"2024-06-13T19:14:03","Actor":"asmirnov82","Number":"7167","RawContent":null,"Title":"Add targeting .Net 8.0 for DataFrame package","State":"closed","Body":"1. Add targeting .Net 8.0 for DataFrame package\r\n2. Update dependency to Apache.Arrow to use newer version\r\n3.  Fix code that uses Apache.Arrow obsolete methods","Url":"https://github.com/dotnet/machinelearning/issues/7167","RelatedDescription":"Closed issue \"Add targeting .Net 8.0 for DataFrame package\" (#7167)"},{"Id":"2338979869","IsPullRequest":true,"CreatedAt":"2024-06-13T18:35:12","Actor":"LittleLittleCloud","Number":"7170","RawContent":null,"Title":"add document for GenAI","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n- [ ] \r\nAdd desgin document for #7169 ","Url":"https://github.com/dotnet/machinelearning/pull/7170","RelatedDescription":"Closed or merged PR \"add document for GenAI\" (#7170)"},{"Id":"2342372801","IsPullRequest":true,"CreatedAt":"2024-06-09T16:36:48","Actor":"ErikApption","Number":"7173","RawContent":null,"Title":"create unique temporary directories to prevent permission issues","State":"open","Body":"Fixes #7172\r\n\r\nThis is a tentative fix for #7172 where ml.net fails when multiple users are using same directory. This fix checks if there is already a ml_dotnet<number> if so, it will increase the number until the path is available.\r\n\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [X] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7173","RelatedDescription":"Open PR \"create unique temporary directories to prevent permission issues\" (#7173)"},{"Id":"2342371566","IsPullRequest":false,"CreatedAt":"2024-06-09T16:33:34","Actor":"ErikApption","Number":"7172","RawContent":null,"Title":"Directory permission exception with multiple concurrent users on linux","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Linux Ubuntu 22.04.4 LTS\r\n - ML.NET Version: ML.NET 3.0.1\r\n - .NET Version: .NET 8.0\r\n\r\n**Describe the bug**\r\n\r\nWhen multiple users are running ML.NET on the same server. each process seems to require a temporary directory - however its name is hardcoded and the second user running ml.net will fail because /tmp/ml_dotnet is not accessible.\r\n\r\n```\r\n2024-06-08 20:00:31.5387|FATAL|Datahunter.Core.Helpers.MLHelper|Error initializing ML Model System.UnauthorizedAccessException: Access to the path '/tmp/ml_dotnet/hetgfm5v.kvn' is denied.\r\n ---> System.IO.IOException: Permission denied\r\n   --- End of inner exception stack trace ---\r\n   at System.IO.FileSystem.CreateDirectory(String fullPath, UnixFileMode unixCreateMode)\r\n   at System.IO.Directory.CreateDirectory(String path)\r\n   at Microsoft.ML.Repository.GetShortTempDir(IExceptionContext ectx)\r\n   at Microsoft.ML.Repository..ctor(Boolean needDir, IExceptionContext ectx)\r\n   at Microsoft.ML.RepositoryReader..ctor(Stream stream, IExceptionContext ectx, Boolean useFileSystem)\r\n   at Microsoft.ML.RepositoryReader.Open(Stream stream, IExceptionContext ectx, Boolean useFileSystem)\r\n   at Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Launch one process with user one\r\n2. Launch same process with user two\r\n3. User two will get an IOException\r\n\r\n**Expected behavior**\r\nTemporary directory should be unique for each user\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7172","RelatedDescription":"Open issue \"Directory permission exception with multiple concurrent users on linux\" (#7172)"},{"Id":"2340674188","IsPullRequest":true,"CreatedAt":"2024-06-07T15:07:08","Actor":"directhex","Number":"7171","RawContent":null,"Title":"Add a stub packageSourceMapping","State":"open","Body":"Without packageSourceMapping, you may receive NuGet warning NU1507. Building with WarnAsError will elevate this to a fatal error.\r\n\r\n```\r\nC:\\d\\source-indexer\\bin\\repo\\machinelearning\\test\\Microsoft.ML.CpuMath.UnitTests\\Microsoft.ML.CpuMath.UnitTests.csproj : error NU1507: Warning As Error: There are 9 package sources defined in your configuration. When using central package management, please map your package sources with package source mapping (https://aka.ms/nuget-package-source-mapping) or specify a single package source. The following sources are defined: dotnet-public, dotnet-tools, dotnet-libraries, dotnet-eng, vs-buildservices, dotnet5-roslyn, mlnet-daily, mlnet-assets, dotnet8 [C:\\d\\source-indexer\\bin\\repo\\machinelearning\\Microsoft.ML.sln]\r\n```\r\n\r\nUsing * as a pattern means any repo can supply any package, the pattern can be further refined later.","Url":"https://github.com/dotnet/machinelearning/pull/7171","RelatedDescription":"Open PR \"Add a stub packageSourceMapping\" (#7171)"},{"Id":"2338977326","IsPullRequest":false,"CreatedAt":"2024-06-06T19:06:12","Actor":"LittleLittleCloud","Number":"7169","RawContent":null,"Title":"Add GenAI packages","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\n**Describe the solution you'd like**\r\nThe `GenAI` packages will provide torchsharp implementation for a series of popular GenAI models. The goal is to load the same weight from the corresponding python regular model.\r\n\r\n- [x] Add design doc (#7170)\r\n- [ ] Add `Microsoft.ML.GenAI.Core` (#7177)\r\n\r\nThe following models will be added in the first wave\r\n- [ ] Phi-3 (`Microsoft.ML.GenAI.Phi`)\r\n- [ ] LLaMA (`Microsoft.ML.GenAI.LLaMA`)\r\n- [ ] Stable Diffusion (`Microsoft.ML.GenAI.StableDiffusion`)\r\n\r\nAlong with the benchmark\r\n- [ ] Benchmark for Phi-3\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7169","RelatedDescription":"Open issue \"Add GenAI packages\" (#7169)"},{"Id":"2331161144","IsPullRequest":true,"CreatedAt":"2024-06-03T13:27:00","Actor":"dotnet-maestro[bot]","Number":"7165","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: c692823c-b896-437f-4f57-08dc434cc8f6\r\n- **Build**: 20240621.4\r\n- **Date Produced**: June 21, 2024 4:39:36 PM UTC\r\n- **Commit**: 3aba80fecac252e1cdaffcebc0a37a24a960228b\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n  - **Microsoft.DotNet.SignTool**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n  - **Microsoft.DotNet.XliffTasks**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 9.0.0-beta.24272.5 to 9.0.0-beta.24321.4][4]\r\n\r\n[4]: https://github.com/dotnet/arcade/compare/2001d73c8f...3aba80feca\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7165","RelatedDescription":"Open PR \"[main] Update dependencies from dotnet/arcade\" (#7165)"},{"Id":"2323990537","IsPullRequest":false,"CreatedAt":"2024-05-30T06:02:55","Actor":"pjsgsy","Number":"7164","RawContent":null,"Title":"Model builder training appears to leak data somehow into the training set","State":"closed","Body":"Windwos 11\r\nML.Net 3.0.1\r\n.Net 4.8 \r\n\r\nWhen traingin a large csv my model would get consistently high results that I could not replicate in testing outside of model builder. I was letting model builder handle the trainign/validation split, though I tried all those options. Folds, 70/30, 80/20, etc. Always ended up >90% micro accuracy over training time if left, but never got even close when run in real time.  After many days - I today split the SAME data file into 2 different files, telling model builder the validation data is in that separate file, and hey presto, can;t train more than 45%...  This is better (for worse!). The 2 files are a 80/20 split - I just did it myself. Give model builder the whole file and tell it to do the 80/20 split, and it will train to >93% again.  Something in there is broken it seems! So little visibility for me into what is going on, I don't have much more to offer in terms of what. it would appear the validation data is somehow leaked into the training set.\r\n\r\nSeperate validation file\r\n![image](https://github.com/dotnet/machinelearning/assets/439341/2a681847-64b1-41c8-a7fa-e3c11dfc7835)\r\n\r\nCombined file letting model builder do the split will train to >0.93, same data and metrics.\r\n\r\nModel builder version is 17.18.2.2415501\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7164","RelatedDescription":"Closed issue \"Model builder training appears to leak data somehow into the training set\" (#7164)"},{"Id":"2305068455","IsPullRequest":true,"CreatedAt":"2024-05-29T19:35:42","Actor":"dotnet-maestro[bot]","Number":"7156","RawContent":null,"Title":"[release/3.0] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:45c6fd49-3a4f-4675-f3da-08dc0c527e17)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 45c6fd49-3a4f-4675-f3da-08dc0c527e17\r\n- **Build**: 20240516.3\r\n- **Date Produced**: May 16, 2024 10:54:40 PM UTC\r\n- **Commit**: e6f70c7dd528f05cd28cec2a179d58c22e91d9ac\r\n- **Branch**: refs/heads/release/8.0\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 8.0.0-beta.24204.3 to 8.0.0-beta.24266.3][1]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 8.0.0-beta.24204.3 to 8.0.0-beta.24266.3][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 8.0.0-beta.24204.3 to 8.0.0-beta.24266.3][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 8.0.0-beta.24204.3 to 8.0.0-beta.24266.3][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 8.0.0-beta.24204.3 to 8.0.0-beta.24266.3][1]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 8.0.0-beta.24204.3 to 8.0.0-beta.24266.3][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/188340e12c...e6f70c7dd5\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:45c6fd49-3a4f-4675-f3da-08dc0c527e17)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7156","RelatedDescription":"Closed or merged PR \"[release/3.0] Update dependencies from dotnet/arcade\" (#7156)"},{"Id":"2319190214","IsPullRequest":true,"CreatedAt":"2024-05-29T19:35:26","Actor":"dotnet-maestro[bot]","Number":"7161","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: c692823c-b896-437f-4f57-08dc434cc8f6\r\n- **Build**: 20240522.5\r\n- **Date Produced**: May 23, 2024 6:03:20 AM UTC\r\n- **Commit**: 2001d73c8ff942331a73300ba61fa6164805b231\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n  - **Microsoft.DotNet.XliffTasks**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n  - **Microsoft.DotNet.XUnitExtensions**: [from 9.0.0-beta.24260.2 to 9.0.0-beta.24272.5][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/480401b003...2001d73c8f\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:c692823c-b896-437f-4f57-08dc434cc8f6)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7161","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#7161)"},{"Id":"2322959164","IsPullRequest":false,"CreatedAt":"2024-05-29T10:26:22","Actor":"aforoughi1","Number":"7163","RawContent":null,"Title":"Loading a LSTM Model Created in Torchsharp in ML.Net","State":"open","Body":"I can create/train/evaluate/save/load a multilayer LSTM model using Torchsharp but cannot run in ML.NET.\r\n\r\nThe main requirement is to export/import a Torchsharp model to ONNX and run it in ML.NET. However, Torchsharp doesn't implement torch.onnx.export method.  I'm stuck at a point and had to convert everything to pytorch just to export to ONNX. \r\n\r\n I also tried a custom pipeline and  trial runner to train and evaluate the model but I'm struggling with how these models can be saved/Loaded in ML.NET.    \r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7163","RelatedDescription":"Open issue \"Loading a LSTM Model Created in Torchsharp in ML.Net\" (#7163)"},{"Id":"2320948894","IsPullRequest":false,"CreatedAt":"2024-05-28T12:31:53","Actor":"agonzalezm","Number":"7162","RawContent":null,"Title":"Running AI inference of phi3 and other llms from c# using NPU + GPU in comming processors?","State":"open","Body":"Intel, AMD, Qualqomm, etc are getting powerful NPUs (+40TOPS) for inferencing.\r\n\r\nIs there any plan to incluide in ml.net functionality to be able to run and inference these models easily from C# offloading to NPU or GPU or both. Next Intel processors will have 40TOPS NPU and 60TOPS CPU/GPU.\r\n\r\nHow from C# can we easily make the most and inference using all of these TOPS coming from NPU + GPU?\r\n\r\nAll samples i see about this require using python etc, would be great to have all this available in .NET C# directly.\r\n\r\nMaybe including some C# wrapper around https://github.com/intel/intel-npu-acceleration-library but what about AMD and qualcomm?\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7162","RelatedDescription":"Open issue \"Running AI inference of phi3 and other llms from c# using NPU + GPU in comming processors?\" (#7162)"},{"Id":"2318862438","IsPullRequest":false,"CreatedAt":"2024-05-27T10:51:12","Actor":"alkampfergit","Number":"7160","RawContent":null,"Title":"Special Tokens handling seems to be incorrect (at least in my scenario where I'm creating Command R+ tiktoken file from specification)","State":"open","Body":"Windows 11, .NET 8 version of library 0.22.0-preview.24271.1\r\n\r\n**Describe the bug**\r\nI'm trying to use tiktoken class to implement Cohere Command R+ tokenizer from the vocabulary file that cohere produces at https://storage.googleapis.com/cohere-public/tokenizers/command-r-plus.json\r\n\r\n**To Reproduce**\r\nyou can find a playbook here https://github.com/alkampfergit/ai-playground/blob/develop/src/python/langchainVarious/Tokenization/dotnetcohere.dib Actually I downloaded the file, then extract vocabulary node and create tiktoken file, then parse the json file to grab special tokens.\r\n\r\n**Expected behavior**\r\nAfter I've parsed the commandR+ tokenizer specification if I tokenize a special token like <|YES_TOKEN|> it correctly recognize it as a a single token (upper part of the picture), but if I use in a sentence, like good<|YES_TOKEN|>good tokenization does not recognize the special token (lower part of the picture)\r\n\r\nSince I've created the .tiktoken file from the specification it is possible that I've done something wrong, other tokens seems to be recognized just good.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n![image](https://github.com/dotnet/machinelearning/assets/358545/43ab3c71-0d69-4687-a0bb-736413ad3cb2)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7160","RelatedDescription":"Open issue \"Special Tokens handling seems to be incorrect (at least in my scenario where I'm creating Command R+ tiktoken file from specification)\" (#7160)"},{"Id":"2313550032","IsPullRequest":true,"CreatedAt":"2024-05-23T18:07:05","Actor":"ericstj","Number":"7159","RawContent":null,"Title":"Update libmf submodule and reenable CodeQL on it","State":"open","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/7159","RelatedDescription":"Open PR \"Update libmf submodule and reenable CodeQL on it\" (#7159)"},{"Id":"2311876933","IsPullRequest":false,"CreatedAt":"2024-05-23T03:49:04","Actor":"LittleLittleCloud","Number":"7158","RawContent":null,"Title":"Support special tokens in sentence piece bpe","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nThe phi-3 uses llama2 tokenizer with a few special tokens like `<|user|>` and `<|system|>`. But currently there is no way to add special tokens to sentence piece bpe (the llama 2 tokenizer) in mlnet\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7158","RelatedDescription":"Open issue \"Support special tokens in sentence piece bpe\" (#7158)"},{"Id":"2301544637","IsPullRequest":false,"CreatedAt":"2024-05-21T15:32:10","Actor":"Xan-Kun","Number":"7154","RawContent":null,"Title":"Still no o200k_base support","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: all\r\n - OS & Version: all\r\n - ML.NET Version: all\r\n - .NET Version: all\r\n\r\n**Describe the bug**\r\nNo way to tokenize gpt-4o strings!\r\n\r\n**To Reproduce**\r\nTokenize a string for gpt-4o\r\n\r\n**Expected behavior**\r\nThe most recent models are supported.\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7154","RelatedDescription":"Closed issue \"Still no o200k_base support\" (#7154)"},{"Id":"2306994085","IsPullRequest":true,"CreatedAt":"2024-05-21T15:32:09","Actor":"tarekgh","Number":"7157","RawContent":null,"Title":"Support Gpt-4o tokenizer model","State":"closed","Body":"Support the new OpenAI `Gpt-4o` tokenizer model. \r\n\r\n```C#\r\n        Tokenizer GPT4o = Tokenizer.CreateTiktokenForModel(\"gpt-4o\");\r\n         text = \"<|endoftext|>Hello â­ World<|endofprompt|>\";\r\n        \r\n        IReadOnlyList<int> encoded = GPT4o.EncodeToIds(text);\r\n        int idsCount = GPT4o.CountTokens(text);\r\n```\r\n\r\n---\r\n***Notes***\r\n\r\n- We have embedded the new tokenizer vocabulary file `o200k_base.tiktoken` in the tokenizer assembly, just as we did with other Tiktoken models. After compression, the file size is `1,188,794 bytes`. We plan to move the tokenizer vocabulary files into their own packages in the future.\r\n- [OpenAI](https://github.com/openai/tiktoken/tree/main) didn't add tests yet for this new model. All tests added in this PR are manually generated. We can add more validation later when OpenAI enable this model in https://platform.openai.com/tokenizer.\r\n---\r\n\r\nCloses https://github.com/dotnet/machinelearning/issues/7154","Url":"https://github.com/dotnet/machinelearning/pull/7157","RelatedDescription":"Closed or merged PR \"Support Gpt-4o tokenizer model\" (#7157)"},{"Id":"2301548458","IsPullRequest":true,"CreatedAt":"2024-05-17T14:22:18","Actor":"ericstj","Number":"7155","RawContent":null,"Title":"Remove Codeql.SourceRoot","State":"closed","Body":"This was resulting in issues with bug reports and paths as well as with CodeQL honoring our exception config for submodules.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/7155","RelatedDescription":"Closed or merged PR \"Remove Codeql.SourceRoot\" (#7155)"},{"Id":"2300399375","IsPullRequest":false,"CreatedAt":"2024-05-16T13:23:53","Actor":"robalexclark","Number":"7153","RawContent":null,"Title":"Schema mismatch for label column ': expected Boolean, got Single ","State":"open","Body":"I have an AutoML experiment as follows:\r\n```\r\n     List<QuoteModel> quoteModels = new List<QuoteModel>();\r\n\r\n   //...get data from db and load into quoteModels\r\n\r\n     MLContext mlContext = new MLContext();\r\n\r\n     IDataView dataView = mlContext.Data.LoadFromEnumerable(quoteModels);\r\n     TrainTestData splitDataView = mlContext.Data.TrainTestSplit(dataView, testFraction: 0.8);\r\n\r\n     SweepablePipeline pipeline = mlContext.Auto().Featurizer(\r\n         dataView)\r\n         .Append(mlContext.Auto().BinaryClassification(labelColumnName: \"LeadWon\", featureColumnName: \"PreviouslyFlooded\"));\r\n\r\n     AutoMLExperiment experiment = mlContext.Auto().CreateExperiment();\r\n\r\n     experiment\r\n         .SetPipeline(pipeline)\r\n         .SetBinaryClassificationMetric(BinaryClassificationMetric.Accuracy, labelColumn: \"LeadWon\")\r\n         .SetTrainingTimeInSeconds(60)\r\n         .SetDataset(splitDataView);\r\n\r\n     TrialResult experimentResults = await experiment.RunAsync();\r\n```\r\n\r\nThe QuoteModel class is:\r\n\r\n```\r\n\r\npublic class QuoteModel\r\n{\r\n    public string PreviouslyFlooded { get; set; }\r\n\r\n    public Boolean LeadWon { get; set; }\r\n}\r\n\r\n```\r\n\r\nWhen I run the experiment it gives the error:\r\n\r\nSystem.ArgumentOutOfRangeException: 'Schema mismatch for label column 'LeadWon': expected Boolean, got Single \r\n\r\nIf you look at the QuoteModel class, the label column LeadWon is definately a boolean!!\r\n\r\nAny ideas why/how it can give this seemingly impossible error?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/7153","RelatedDescription":"Open issue \"Schema mismatch for label column ': expected Boolean, got Single \" (#7153)"}],"ResultType":"GitHubIssue"}},"RunOn":"2024-06-25T03:30:17.3879009Z","RunDurationInMilliseconds":408}