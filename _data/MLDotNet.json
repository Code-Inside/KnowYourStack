{"Data":{"GitHub":{"Issues":[{"Id":"1108704009","IsPullRequest":false,"CreatedAt":"2022-01-20T00:42:21","Actor":"infinitemind2","Number":"6051","RawContent":null,"Title":"Anomaly detection on rainfall data ","State":"open","Body":"Not exactly a feature request but a 'is it possible' type question. \r\nIf so any ideas on the direction to implement.\r\n\r\nHave data for various locations with differing length of records. All locations would have differing seasonality and intensities (very different distributions).\r\nLooking at updating/inserting records and wish to highlight possible anomalies.\r\nThe anomalies could be cause by error in the recording process and may need further investigation. (calibration data, typing error, etc)\r\n\r\nHave had a look at DetectAnomalyBySrCnn and not sure if I implemented it correctly.\r\nOnce I Fit the data and create the TimeSeriesEngine and use Predict I get a zero values in the resultant vector. \r\nIf I run the training data through the Predict function I get results that look promising. However the data appears to be added to the engine and skews further tests. (after I've used known bad data the predict gives different result next time)\r\n\r\nAm I barking up the correct tree? \r\nIf so any suggestions in the direction I should proceed?\r\n\r\nI know this is a big ask, thanks for any help.","Url":"https://github.com/dotnet/machinelearning/issues/6051","RelatedDescription":"Open issue \"Anomaly detection on rainfall data \" (#6051)"},{"Id":"1105132117","IsPullRequest":false,"CreatedAt":"2022-01-18T23:56:28","Actor":"torronen","Number":"6048","RawContent":null,"Title":"Building with VS 2022","State":"closed","Body":"The build script fails to compile with Visual Studio 2022 (Native libraries). Because it seems upgrade to VS2022 is encouraged (for example, VS2019 Community edition no longer available) I think the build script should be updated to support VS2022.","Url":"https://github.com/dotnet/machinelearning/issues/6048","RelatedDescription":"Closed issue \"Building with VS 2022\" (#6048)"},{"Id":"1086726167","IsPullRequest":false,"CreatedAt":"2022-01-18T21:19:04","Actor":"aforoughi1","Number":"6027","RawContent":null,"Title":"New PFI API, inconstancies in return types for Binary vs Regression and MultiClass ","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 1.7\r\n - .NET Version:  NET 5.0\r\n\r\n**Describe the bug**\r\nI tried to write a generic method to Calculate PFI  using the New PFI API which was released  as part of Ml.Net 1.7.\r\nFirstly, The online documentation is not matching the release.\r\nSee https://docs.microsoft.com/enus/dotnet/api/microsoft.ml.permutationfeatureimportanceextensions\r\nSecondly, the return types for Regression and Multiclass is Dictionary but Binary is an Array\r\n ImmutableDictionary<string,RegressionMetricsStatistics>\r\n ImmutableDictionary<string,MulticlassClassificationMetricsStatistics>\r\n Immutable.ImmutableArray<BinaryClassificationMetricsStatistics> \r\n\r\nIs this a bug ?\r\n\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6027","RelatedDescription":"Closed issue \"New PFI API, inconstancies in return types for Binary vs Regression and MultiClass \" (#6027)"},{"Id":"1099144952","IsPullRequest":false,"CreatedAt":"2022-01-18T18:51:06","Actor":"PMGruber","Number":"6040","RawContent":null,"Title":"TensorFlow: Unable to find entry point 'TF_StringDecode'","State":"closed","Body":"### System information\r\n\r\n- **OS version/distro**: Win10 x64\r\n- **.NET Version (eg., dotnet --info)**:  .net Core 3.1\r\n- **ML.NET Version**: 1.7.0 with SciSharp.TensorFlow.Redist 2.7.0\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI load a pretrained TensorFlow model and execute it.\r\n\r\n- **What happened?**\r\nWhen executing predict method, I receive an exception \"System.EntryPointNotFoundException: 'Unable to find an entry point named 'TF_StringDecode' in DLL 'tensorflow'.'\"\r\n\r\n- **What did you expect?**\r\nExecution without error\r\n\r\n### Details\r\n\r\nI have a simple Tensorflow model that makes a classification. As input the model gets an image (as float array). As output, the model provides a list of probabilities (one entry for each class. Datatype: float array) and a list of classnames (string array).\r\n\r\nWhen I run the prediction, I receive the exception from above with source \"TensorFlow.NET\" and stack trace \r\n```\r\n   at Tensorflow.c_api.TF_StringDecode(Byte* src, UInt64 src_len, Byte** dst, UInt64& dst_len, SafeStatusHandle status)\r\n   at Tensorflow.Tensor.StringData()\r\n   at Microsoft.ML.TensorFlow.TensorFlowUtils.FetchStringData[T](Tensor tensor, Span`1 result)\r\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass11_0`1.<MakeGetter>b__1(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass7_0`2.<CreateConvertingVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at TensorflowString.Program.Main(String[] args) in \r\n```\r\n\r\nWhen I execute the model and just read the column with float array it executes fine (not suprising, since exception states a problem with string type).\r\n\r\nHere a code snippet from loading, preparing and executing the model:\r\n```\r\n            string _assetsPath = Path.Combine(Environment.CurrentDirectory, \"assets\");\r\n            string _image = Path.Combine(_assetsPath, \"input.png\");\r\n            string _model = Path.Combine(_assetsPath, \"frozen_graph.pb\");\r\n\r\n            var bitmapImage = new Bitmap(_image);\r\n            var floatImage = VerySlowBitmapTo1dFloatArrayConverter(bitmapImage);\r\n\r\n            MLContext mlContext = new MLContext();\r\n            var tensorflowModel = mlContext.Model.LoadTensorFlowModel(_model);\r\n\r\n            var inputSchemaDefinition = SchemaDefinition.Create(typeof(ImageData));\r\n            inputSchemaDefinition[\"Image\"].ColumnType = new VectorDataViewType(NumberDataViewType.Single, 750 *500*3);\r\n            inputSchemaDefinition[\"Image\"].ColumnName = \"x\";\r\n\r\n            var outputSchemaDefinition = SchemaDefinition.Create(typeof(ImagePrediction));\r\n            outputSchemaDefinition[\"Result\"].ColumnType = new VectorDataViewType(NumberDataViewType.Single, 15);\r\n            outputSchemaDefinition[\"Result\"].ColumnName = \"Identity\";\r\n            outputSchemaDefinition[\"Classnames\"].ColumnType = new VectorDataViewType(TextDataViewType.Instance, 15);\r\n            outputSchemaDefinition[\"Classnames\"].ColumnName = \"Identity_1\";\r\n\r\n            var pipeline = tensorflowModel.ScoreTensorFlowModel(outputColumnNames: new[] { \"Identity\", \"Identity_1\" }, inputColumnNames: new[] { \"x\" }, addBatchDimensionInput: false);\r\n            var data = mlContext.Data.LoadFromEnumerable(new List<ImageData>(), inputSchemaDefinition);\r\n            var processingModel = pipeline.Fit(data);\r\n\r\n            var imageData = new ImageData()\r\n            {\r\n                Image = floatImage\r\n            };\r\n\r\n            var predictor = mlContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(processingModel, inputSchemaDefinition: inputSchemaDefinition, outputSchemaDefinition: outputSchemaDefinition);\r\n            var prediction = predictor.Predict(imageData);\r\n```\r\n\r\nI uploaded the test project to a private repository (I'm not allowed to make model public). If somebody wants it for a deeper look, I grant access.\r\n\r\nI downloaded libtensorflow-cpu-windows-x86_64-2.7.0 from googleapis and had a look at the header files. I just found a comment with \"// TF_StringEncode and TF_StringDecode facilitate this encoding.\" but no definition of \"TF_StringDecode\". \r\nMy C/C++ knowlege is quite low level so I'm stuck at this point.\r\n\r\nTherefore I would appreciate any hints or ideas.\r\n\r\nThanks,\r\nPhilipp","Url":"https://github.com/dotnet/machinelearning/issues/6040","RelatedDescription":"Closed issue \"TensorFlow: Unable to find entry point 'TF_StringDecode'\" (#6040)"},{"Id":"1102474072","IsPullRequest":false,"CreatedAt":"2022-01-18T18:47:02","Actor":"shiqiangz-git","Number":"6047","RawContent":null,"Title":"Dllnullexception","State":"closed","Body":" Unab1e to 1oad DLL ' tensorf1ow or one of its dependencies: E);&fH E (DLL) fJx=","Url":"https://github.com/dotnet/machinelearning/issues/6047","RelatedDescription":"Closed issue \"Dllnullexception\" (#6047)"},{"Id":"1106432990","IsPullRequest":false,"CreatedAt":"2022-01-18T03:17:26","Actor":"tankhar","Number":"6050","RawContent":null,"Title":"Fit() method should be optimized when used with  DatabaseLoader or IEnumerable (with sqldatareader)","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nFit() method is not optimized when used with databaseloader or ienumerable(sqldatareader->yield return) and is causing delays in processing.\r\n\r\nThe training data that our ML.Net(v 1.7) project refers to resides in Sql Server database\r\n\r\nI do not want to load the entire data in memory for fitting\r\nIn order to fetch this data while training I have tried 2 ways:\r\n1. using Databaseloader which has a stored procedure as command text\r\n2. using IEnumerable which calls sqldatareader(with yield return)(this also calls a stored procedure)\r\nand then creating IDataView using LoadFromEnumerable()\r\n\r\nThe training data has 6 columns which are transformed as follows:\r\nFeaturizeText is being called for 4 columns\r\nOnehotencoding is being called for 2 columns\r\nConcatenation of all above transformed columns\r\n\r\n**Issue**\r\nIn both above ways of fetching:\r\n**The underlying stored procedure is getting called 15 times during each “Fit” call**\r\nI observed that the calls are due to the transforms being applied\r\nIf I reduce the number of transforms, the calls to stored procedure reduce accordingly\r\nThis causes the Fit() method to take considerable amount of time \r\n\r\n\r\n**Describe the solution you'd like**\r\n1. Ideally the data should be fetched just once and all preprocessing done on the fetched data\r\n2.Please share a sample that uses IEnumerable with sqldatareader, as this is my preferred approach\r\nI would compare it with my implementation\r\n\r\n**Describe alternatives you've considered**\r\nNone\r\n\r\n**Additional context**\r\nNone\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6050","RelatedDescription":"Open issue \"Fit() method should be optimized when used with  DatabaseLoader or IEnumerable (with sqldatareader)\" (#6050)"},{"Id":"1105857928","IsPullRequest":true,"CreatedAt":"2022-01-17T13:27:33","Actor":"dotnet-maestro[bot]","Number":"6049","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"open","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 97926d79-6b8b-4d32-c8db-08d9d479971c\r\n- **Build**: 20220114.25\r\n- **Date Produced**: January 15, 2022 1:07:35 AM UTC\r\n- **Commit**: 511824f9ad21a8bc070b4bad2a95acd119c4afa0\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 7.0.0-beta.22056.6 to 7.0.0-beta.22064.25][1]\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 7.0.0-beta.22056.6 to 7.0.0-beta.22064.25][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 7.0.0-beta.22056.6 to 7.0.0-beta.22064.25][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 7.0.0-beta.22056.6 to 7.0.0-beta.22064.25][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 7.0.0-beta.22056.6 to 7.0.0-beta.22064.25][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/34bc5b1...511824f\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6049","RelatedDescription":"Open PR \"[main] Update dependencies from dotnet/arcade\" (#6049)"},{"Id":"1100617049","IsPullRequest":true,"CreatedAt":"2022-01-14T22:52:05","Actor":"michaelgsharp","Number":"6044","RawContent":null,"Title":"Disable test on ARM for CI stability.","State":"closed","Body":"The test TestBackAndForthConversionWithAlphaNoInterleave has stability issues on ARM/ARM64. Disabling the test only on those legs for CI stability. Tracked in #6043.","Url":"https://github.com/dotnet/machinelearning/pull/6044","RelatedDescription":"Closed or merged PR \"Disable test on ARM for CI stability.\" (#6044)"},{"Id":"1101096522","IsPullRequest":true,"CreatedAt":"2022-01-14T02:39:48","Actor":"michaelgsharp","Number":"6046","RawContent":null,"Title":"Update Onnx Runtime to latest version.","State":"closed","Body":"Just updates the version of ONNX runtime to the latest version.","Url":"https://github.com/dotnet/machinelearning/pull/6046","RelatedDescription":"Closed or merged PR \"Update Onnx Runtime to latest version.\" (#6046)"},{"Id":"1100628394","IsPullRequest":false,"CreatedAt":"2022-01-12T17:52:51","Actor":"torronen","Number":"6045","RawContent":null,"Title":"Long Column names are unexpectedly dropped in training","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version:  Windows 11 \r\n - ML.NET Version: ML.NET 1.6.0\r\n - .NET Version: .NET 6.0\r\n\r\n**Describe the bug**\r\nDataset may include long column names. In my case, they are about 150 characters long. Name includes a-Z 0-9 and the dash character. ColumnInference reports them correctly. However, after starting training with AutoML, the columns are not used for training. If there are only long titles error about missing \"Features\" column is thrown.\r\n\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Create dataset with long column names (numeric in my case)\r\n2.  Column inference reports them correctly:\r\n`ColumnInferenceResults columnInference = mlContext.Auto().InferColumns(TrainDataPath, LabelColumnName, groupColumns: false);`\r\n3. Train:\r\n                 `   experimentResult = experiment.Execute(TrainDataView, ValidationDataView, columnInformation, null, progressHandler);`\r\n4. Observe exception about missing Features.\r\n5. Rename columns to shorter manually, or in a loop to confirm training now works. This can be also used as a workaround for now.\r\n```\r\nvar copyPipeline= mlContext.Transforms.CopyColumns(\"col\" + i, col.Name);\r\nOriginalTrainDataView = pipeline.Fit(OriginalTrainDataView).Transform(OriginalTrainDataView);\r\n\r\n```\r\nNote: I have tree-based algorithms enabled.\r\n\r\n**Expected behavior**\r\nLong column names should be trained normally. \r\nIf not possible, an exception should be received. Now user might think all data is being used to train but actually some columns may be ignored.\r\n\r\nIt is possible Verbose level would give information about this, but it is disabled by default in AutoML. I did not run separately with verbose output.\r\n\r\n**Additional data**\r\nThere may be many reasons why dataset could include long column names. For example, they may have name, id and settings of a measurement device included in the column name.\r\n\r\nIf possible, I'd like to know what is currently the column length limit even if this would be fixed. That helps know which fields have been ignored in earlier models.","Url":"https://github.com/dotnet/machinelearning/issues/6045","RelatedDescription":"Open issue \"Long Column names are unexpectedly dropped in training\" (#6045)"},{"Id":"1100612691","IsPullRequest":false,"CreatedAt":"2022-01-12T17:34:32","Actor":"michaelgsharp","Number":"6043","RawContent":null,"Title":"TestBackAndForthConversionWithAlphaNoInterleave disabled","State":"open","Body":"This issue is to track that the test TestBackAndForthConversionWithAlphaNoInterleave has been disabled for stability in the ARM legs of the CI builds. As soon as we swap away from System.Drawing we can revisit this test (as it will need to be updated anyways).","Url":"https://github.com/dotnet/machinelearning/issues/6043","RelatedDescription":"Open issue \"TestBackAndForthConversionWithAlphaNoInterleave disabled\" (#6043)"},{"Id":"1099431807","IsPullRequest":true,"CreatedAt":"2022-01-12T17:29:27","Actor":"michaelgsharp","Number":"6041","RawContent":null,"Title":"New build pools","State":"closed","Body":"Update the official build to the new pools.","Url":"https://github.com/dotnet/machinelearning/pull/6041","RelatedDescription":"Closed or merged PR \"New build pools\" (#6041)"},{"Id":"1099729367","IsPullRequest":false,"CreatedAt":"2022-01-11T23:58:37","Actor":"xenoverse-us","Number":"6042","RawContent":null,"Title":"ExperimentBase Execute method should take IProgress instead of Progress","State":"open","Body":"**Describe the bug**\r\nhttps://github.com/dotnet/machinelearning/blob/0577957256c296fdea2deb6b6e00e7be9b458167/src/Microsoft.ML.AutoML/API/ExperimentBase.cs#L250\r\n\r\nI think the intention here is to take IProgress rather than the concrete implementation of System.Progress.","Url":"https://github.com/dotnet/machinelearning/issues/6042","RelatedDescription":"Open issue \"ExperimentBase Execute method should take IProgress instead of Progress\" (#6042)"},{"Id":"1098350078","IsPullRequest":true,"CreatedAt":"2022-01-11T02:13:31","Actor":"dotnet-maestro[bot]","Number":"6038","RawContent":null,"Title":"[main] Update dependencies from dotnet/arcade","State":"closed","Body":"This pull request updates the following dependencies\r\n\r\n[marker]: <> (Begin:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n## From https://github.com/dotnet/arcade\r\n- **Subscription**: 97926d79-6b8b-4d32-c8db-08d9d479971c\r\n- **Build**: 20220106.6\r\n- **Date Produced**: January 6, 2022 9:12:49 PM UTC\r\n- **Commit**: 34bc5b1611e13bd0ee6a9f38ab8524d2ee489be5\r\n- **Branch**: refs/heads/main\r\n\r\n[DependencyUpdate]: <> (Begin)\r\n\r\n- **Updates**:\r\n  - **Microsoft.DotNet.Build.Tasks.Feed**: [from 6.0.0-beta.21253.2 to 7.0.0-beta.22056.6][1]\r\n  - **Microsoft.DotNet.Arcade.Sdk**: [from 6.0.0-beta.21253.2 to 7.0.0-beta.22056.6][1]\r\n  - **Microsoft.DotNet.SwaggerGenerator.MSBuild**: [from 6.0.0-beta.21253.2 to 7.0.0-beta.22056.6][1]\r\n  - **Microsoft.DotNet.SignTool**: [from 6.0.0-beta.21253.2 to 7.0.0-beta.22056.6][1]\r\n  - **Microsoft.DotNet.Helix.Sdk**: [from 6.0.0-beta.21253.2 to 7.0.0-beta.22056.6][1]\r\n\r\n[1]: https://github.com/dotnet/arcade/compare/e9fd640...34bc5b1\r\n\r\n[DependencyUpdate]: <> (End)\r\n\r\n\r\n[marker]: <> (End:97926d79-6b8b-4d32-c8db-08d9d479971c)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6038","RelatedDescription":"Closed or merged PR \"[main] Update dependencies from dotnet/arcade\" (#6038)"},{"Id":"1098401535","IsPullRequest":true,"CreatedAt":"2022-01-10T23:19:31","Actor":"ericstj","Number":"6039","RawContent":null,"Title":"Update to latest arcade '7.0.0-beta.22056.6' (from build '20220106.6' of 'https://github.com/dotnet/arcade')","State":"closed","Body":"@michaelgsharp please have a look at this.  I just triggered a darc update of arcade.  I would like to have the product in a state where we regularly take Arcade updates in order to get infrastructure fixes.   Can you please have a look at this and make sure it doesn't undo any manual changes you have made?","Url":"https://github.com/dotnet/machinelearning/pull/6039","RelatedDescription":"Closed or merged PR \"Update to latest arcade '7.0.0-beta.22056.6' (from build '20220106.6' of 'https://github.com/dotnet/arcade')\" (#6039)"},{"Id":"1098033221","IsPullRequest":false,"CreatedAt":"2022-01-10T15:26:46","Actor":"andrasfuchs","Number":"6037","RawContent":null,"Title":"FastForestOva has its prediction value in Score[1] instead on Score[0]","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: ML.NET v1.7\r\n - .NET Version: .NET 6.0\r\n - ML.NET Model Builder: ML.NET Model Builder 2022 v16.9.2.2205603\r\n\r\n**Describe the bug**\r\nUsually the probabilities of the trained models are stored in the Score values of the `ModelOutput` class (generated by ML.NET Model Builder). The first item in that array of floats is the prediction value when we use the `FastTreeOva` or `LightGbmMulti` algorithms, but interestingly it is the second item in that array if we use `FastForestOva`.\r\nI'm not 100% sure that it is a bug, but I would expect consistency in this regard among the different algorithms.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to Solution Explorer\r\n2. Right click on the project, add Machine Learning Model\r\n3. Start training your model, and stop at the different times to have different algorithms as best\r\n4. Test the generated classes by running them with your input data and show the ModelOutput.Score array\r\n5. Observe the different values and their meaning, especially for the `FastForestOva` algorithm\r\n\r\n**Expected behavior**\r\nI would expect all the algorithms to return their prediction values in the same order. \r\n\r\n**Screenshots, Code, Sample Projects**\r\nAccuracy is calculated based on `OutputModel.Score[0]` values and `IsAttached` uses `LightGbmMulti`, `IsNotAttached` uses `FastForestOva`. They both had 99+% accuracy during training.\r\n![image](https://user-images.githubusercontent.com/910321/148792403-a89a6af2-e3c8-4534-b3ce-3b80c05dd83e.png)\r\n\r\n**Additional context**\r\nI could test `FastTreeOva`, `LightGbmMulti` and `FastForestOva`: the first two had their prediction value in Score[0], and `FastForestOva` had its in Score[1].","Url":"https://github.com/dotnet/machinelearning/issues/6037","RelatedDescription":"Open issue \"FastForestOva has its prediction value in Score[1] instead on Score[0]\" (#6037)"},{"Id":"1097991531","IsPullRequest":false,"CreatedAt":"2022-01-10T14:51:22","Actor":"XactaAndy","Number":"6036","RawContent":null,"Title":"File path and/or name are too long when saving training model.","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10 \r\n - ML.NET Version: ML.Net v1.4 & ML.Net 1.7\r\n - .NET Version: .Net Framework 4.7.2 - ASP.Net\r\n\r\n**Describe the bug**\r\nWhen saving a training model in a ASP.Net web application the following error is returned. \r\n\r\n`System.IO.PathTooLongException\r\n  HResult=0x800700CE\r\n  Message=The specified path, file name, or both are too long. The fully qualified file name must be less than 260 characters, and the directory name must be less than 248 characters.\r\n  Source=mscorlib\r\n  StackTrace:\r\n   at System.IO.__Error.WinIOError(Int32 errorCode, String maybeFullPath)\r\n   at System.IO.Directory.InternalCreateDirectory(String fullPath, String path, Object dirSecurityObj, Boolean checkHost)\r\n   at System.IO.Directory.InternalCreateDirectoryHelper(String path, Boolean checkHost)\r\n   at Microsoft.ML.Repository.GetPath(String& pathEnt, String& pathTemp, String dir, String name, Boolean createDir)\r\n   at Microsoft.ML.RepositoryWriter.CreateEntry(String dir, String name)\r\n   at Microsoft.ML.ModelSaveContext..ctor(RepositoryWriter rep, String dir, String name)\r\n   at Microsoft.ML.ModelSaveContext.SaveSubModel(String dir, Action1 fn)\r\n   at Microsoft.ML.Transforms.NormalizingTransformer.SaveModel(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.Data.TransformerChain1.Microsoft.ML.ICanSaveModel.Save(ModelSaveContext ctx)\r\n   at Microsoft.ML.ModelSaveContext.SaveModel[T](RepositoryWriter rep, T value, String path)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, Stream stream)\r\n   at Microsoft.ML.ModelOperationsCatalog.Save(ITransformer model, DataViewSchema inputSchema, String filePath)\r\n   at TPTestWeb.index.Page_Load(Object sender, EventArgs e) in C:\\Users\\Andy\\source\\repos\\TPTest\\TPTestWeb\\index.aspx.cs:line 96\r\nThis exception was originally thrown at this call stack:\r\n    [External Code]\r\n    TPTestWeb.index.Page_Load(object, System.EventArgs) in index.aspx.cs\r\n    [External Code]`\r\n\r\nHowever the same code in a console application works fine. The error happens if I try to save to either a file or a memory stream.\r\n\r\n**To Reproduce**\r\nTo reproduce please see the example solution I have linked to below. It contains both an example console and ASP.Net application.\r\n\r\n**Expected behavior**\r\nThe training model zip file to be saved.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nhttps://github.com/XactaAndy/TPTest","Url":"https://github.com/dotnet/machinelearning/issues/6036","RelatedDescription":"Open issue \"File path and/or name are too long when saving training model.\" (#6036)"},{"Id":"1097736860","IsPullRequest":false,"CreatedAt":"2022-01-10T10:53:03","Actor":"andrasfuchs","Number":"6035","RawContent":null,"Title":"IndexOutOfRangeException at Microsoft.ML.Data.BufferBuilder`1.AddFeature","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11 [Version 10.0.22000.376]\r\n - ML.NET Version: ML.NET v1.7.0\r\n - .NET Version: .NET 6.0\r\n - ML.NET Model Builder: ML.NET Model Builder 2022 v16.9.2.2205303\r\n\r\n**Describe the bug**\r\nI get `IndexOutOfRangeException` when calling `PredictionEngine`'s `Predict` method. The exception is thrown in the [AddFeature method](https://github.com/dotnet/machinelearning/blob/52ddbcd0a57b440e60e43e6cb39b49fe55bdfe55/src/Microsoft.ML.Data/Data/BufferBuilder.cs#L155) of the BufferBuilder class.\r\n\r\n```\r\nat Microsoft.ML.Data.BufferBuilder`1.AddFeature(Int32 index, T value)\r\n   at Microsoft.ML.Transforms.NormalizeTransform.AffineColumnFunction.Sng.ImplVec.FillValues(VBuffer`1& input, BufferBuilder`1 bldr, Single[] scale)\r\n   at Microsoft.ML.Transforms.NormalizeTransform.AffineColumnFunction.Sng.ImplVec.<>c__DisplayClass5_0.<GetGetter>b__0(VBuffer`1& dst)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\r\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\r\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\r\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\r\n   at BBD_SleepLogger.MLModel_IsAttached.Predict(ModelInput input) in C:\\Work\\BioBalanceDetector\\Software\\Source\\BBDProto08\\BBD.SleepLogger\\MLModel_IsAttached.consumption.cs:line 30809\r\n   at BBD.SleepLogger.Program.EvaluateIndicators(ILogger logger, Int32 index, FftData inputData) in C:\\Work\\BioBalanceDetector\\Software\\Source\\BBDProto08\\BBD.SleepLogger\\Program.cs:line 610\r\n   at BBD.SleepLogger.Program.<>c__DisplayClass26_2.<DataAcquisition_SamplesReceived>b__1() in C:\\Work\\BioBalanceDetector\\Software\\Source\\BBDProto08\\BBD.SleepLogger\\Program.cs:line 467\r\n   at System.Threading.Tasks.Task.InnerInvoke()\r\n   at System.Threading.Tasks.Task.<>c.<.cctor>b__272_0(Object obj)\r\n   at System.Threading.ExecutionContext.RunFromThreadPoolDispatchLoop(Thread threadPoolThread, ExecutionContext executionContext, ContextCallback callback, Object state)\r\n```\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to Solution Explorer, select your project\r\n2. Right click, Add, Machine Learning Project\r\n3. Set your data source, and labels, run the training to have the generated code\r\n4. Consume the data by using the generated code, fill the `ModelInput` with values and call `MLModel.Predit(ModelInput)` method\r\n\r\n**Expected behavior**\r\nI was expecting to have a `ModelOutput` object returned, but I got the above exception instead. \r\nIt would be also great to have a more detailed exception to help the bug hunting if it is caused by misconfiguration on the user's part.\r\n\r\n**Screenshots, Code, Sample Projects**\r\n![image](https://user-images.githubusercontent.com/910321/148753662-df21fd3f-14f8-434c-8a88-f34caa3882c3.png)\r\n\r\n**Additional context**\r\nProbably not a critical information, but my data source is a ~360 MB big CSV file with 5120 float feature columns, 6 label columns (of which 5 are ignored for the training) and it has 5500 rows.","Url":"https://github.com/dotnet/machinelearning/issues/6035","RelatedDescription":"Open issue \"IndexOutOfRangeException at Microsoft.ML.Data.BufferBuilder`1.AddFeature\" (#6035)"},{"Id":"1096173858","IsPullRequest":false,"CreatedAt":"2022-01-07T10:09:54","Actor":"isaac12391","Number":"6034","RawContent":null,"Title":"Crashing in UWP Release, but not in Debug","State":"open","Body":" - windows 10.0.19042 Build 19042\r\n - ML.NET Version: v1.7.0\r\n - .NET Version: 2.0\r\n - UWP Version - 2004 - 1803\r\n\r\nML.Net works in debug UWP, but when released in UWP, crashes due to Exception thrown: 'System.ArgumentNullException' in System.Linq.dll.\r\n\r\nThanks for your help, \r\n\r\nIsaac\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6034","RelatedDescription":"Open issue \"Crashing in UWP Release, but not in Debug\" (#6034)"},{"Id":"1094346128","IsPullRequest":false,"CreatedAt":"2022-01-05T13:22:51","Actor":"maheshlokhande","Number":"6033","RawContent":null,"Title":"'Probability' column missing in output schema of NaiveBayes MulticlassClassification trainer","State":"open","Body":" - OS & Version: Windows 2016\r\n - ML.NET Version: ML.NET 1.7.0\r\n - .NET Version: .NET 5.0\r\n\r\n*Issue*\r\nCould not find column 'Probability' exception is thrown when transforming input data with model trained with NaiveBayes MultiClassClassification trainer.\r\n\r\n\r\n**Expected behavior**\r\nSimilar to other trainers, Probability column representing probability for predicted label or array of probabilities representing probability for every label should be present in output of transformation.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6033","RelatedDescription":"Open issue \"'Probability' column missing in output schema of NaiveBayes MulticlassClassification trainer\" (#6033)"},{"Id":"1091858611","IsPullRequest":false,"CreatedAt":"2022-01-01T17:35:55","Actor":"torronen","Number":"6032","RawContent":null,"Title":"BufferBuilder.MakeDense: IndexOutOfRangeException","State":"open","Body":"**System Information:**\r\n - OS & Version:  Windows 11\r\n - ML.NET Version: 1.6.0 (custom build with autoML search space edited)\r\n - .NET Version: .NET 5.0\r\n\r\n**Describe the bug**\r\nI am running AutoML. The below is from logs, probably about 1 out of 50 runs on same dataset. \r\n\r\n**To Reproduce**\r\nUnknown. It might be related to specific model parameters, but they were not logged (the search space is customized).\r\nUnfortunately, not even model is saved, since I am only exploring the weights. Model was trained succesfully.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nAlthough, global feature index works almost always, I have this exception in logs. \r\n\r\n```\r\nSystem.IndexOutOfRangeException: Index was outside the bounds of the array.\r\n   at Microsoft.ML.Data.BufferBuilder`1.MakeDense() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\BufferBuilder.cs:line 322\r\n   at Microsoft.ML.Data.BufferBuilder`1.GetResult(VBuffer`1& buffer) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\BufferBuilder.cs:line 462\r\n   at Microsoft.ML.Trainers.FastTree.TreeEnsembleModelParameters.GetFeatureWeights(VBuffer`1& weights) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.FastTree\\FastTree.cs:line 3242\r\n   at Kwork.AI.AutoML.Experiment.SaveGlobalFeatureIndexFastTree(MLContext mlContext, ITransformer model, String filename, IDataView testDataView, BinaryClassificationTrainer trainer) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src-AutoML-Runner\\Kwork.AI.AutoML.Runner\\Experiment.cs:line 668\r\n```\r\n\r\nLink to BufferBuilder.MakeDense: https://github.com/dotnet/machinelearning/blob/52ddbcd0a57b440e60e43e6cb39b49fe55bdfe55/src/Microsoft.ML.Data/Data/BufferBuilder.cs#L316\r\n\r\n**Additional context**\r\nIt is not blocking my work, only for FYI","Url":"https://github.com/dotnet/machinelearning/issues/6032","RelatedDescription":"Open issue \"BufferBuilder.MakeDense: IndexOutOfRangeException\" (#6032)"},{"Id":"1090273452","IsPullRequest":false,"CreatedAt":"2021-12-29T05:10:25","Actor":"ansarizafar","Number":"6031","RawContent":null,"Title":"Publish ML.NET 1.7.0 on Nuget","State":"open","Body":"Latest version of ML.net CLI is not available on Nuget. Please publish version 1.7 on Nuget.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6031","RelatedDescription":"Open issue \"Publish ML.NET 1.7.0 on Nuget\" (#6031)"},{"Id":"1089993641","IsPullRequest":false,"CreatedAt":"2021-12-28T16:09:20","Actor":"zweistein22","Number":"6030","RawContent":null,"Title":"Microsoft.ML.Parquet","State":"open","Body":"Microsoft.ML.Parquet must use Parquet.net version == 2.1.3   . It may not use the current Parquet.net versions 3.xx (3.91) as the internal structures have changed and Parquet.Data.Dataset does not exist in recent Parquet.net versions.\r\n\r\nWhen a newer Parquet.dll is found   however this newer version is used and causes a crash al Assembly.Load\r\n\r\nhttps://gist.github.com/klesouza/c23781677b03f28128996075ba3e8767#file-parquetloader-cs\r\n\r\nBest solution would be to update Microsoft.ML.Parquet .\r\n\r\nsecond best is to force linkage of exact parquet.net 2.1.3  and not allow >= 2.1.3\r\n\r\nBest regards\r\nAndreas\r\n\r\n\r\n ","Url":"https://github.com/dotnet/machinelearning/issues/6030","RelatedDescription":"Open issue \"Microsoft.ML.Parquet\" (#6030)"},{"Id":"1089898994","IsPullRequest":false,"CreatedAt":"2021-12-28T13:31:36","Actor":"Lee-Cheul-Woo","Number":"6029","RawContent":null,"Title":"When is freed these limitations?","State":"open","Body":"When is freed these limitations?\r\n\r\nWill be they not used in programming forever?\r\nIf you have some roadmap, please let me know.","Url":"https://github.com/dotnet/machinelearning/issues/6029","RelatedDescription":"Open issue \"When is freed these limitations?\" (#6029)"},{"Id":"1088262312","IsPullRequest":false,"CreatedAt":"2021-12-24T09:15:03","Actor":"developervariety","Number":"6028","RawContent":null,"Title":"Upgrade Tensorflow support >2.3","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI'm desktop environment is an iMac with M1 chip. I have been looking on how to build TensorFlow v2.3 so I could use it for image classification, but haven't had much luck. When building with a v2.5 `libtensorflow` I receive the following error message due to breaking changes after v2.3\r\n\r\n`Unable to find an entry point named 'TF_StringEncodedSize' in shared library 'tensorflow'`\r\n\r\n**Describe the solution you'd like**\r\nUpgrade TensorFlow support to v2.5+\r\n\r\n**Describe alternatives you've considered**\r\nNo alternatives really.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6028","RelatedDescription":"Open issue \"Upgrade Tensorflow support >2.3\" (#6028)"},{"Id":"1084204003","IsPullRequest":false,"CreatedAt":"2021-12-19T22:12:47","Actor":"xperiandri","Number":"6026","RawContent":null,"Title":"Add ability to parse position delimited files.","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI need to read a position delimited file (no delimiters)\r\n\r\n**Describe the solution you'd like**\r\nMake TextFieldParser.cs types public\r\n\r\n**Describe alternatives you've considered**\r\nCopy source code of TextFieldParser.cs\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6026","RelatedDescription":"Open issue \"Add ability to parse position delimited files.\" (#6026)"},{"Id":"1083952532","IsPullRequest":false,"CreatedAt":"2021-12-18T21:49:44","Actor":"torronen","Number":"6025","RawContent":null,"Title":"Default parameters not taking into account in GenerateCandidateConfigurations","State":"open","Body":"Per my understanding:\r\n1) Default values for trainers are set based on experience from a wide range of dataset. Therefore, they should be a good starting point.\r\n2) AutoML start by running with default values and then randomly 10 experiments around it.\r\n3) The random values can be used to estimate direction for next parameters search. \r\n\r\nHowever, it seems GenerateCandidateConfigurations does not receive parameters for the 1st run with default parameters in previousRun attribute (SmacSweeper.cs). It likely means forestPredictor and GredyPlusRandomSearch do not know what are the defaults and what was the metrics for the first run, so it can only rely on random experiments. This may have detrimental effect on the next suggested parameters because there have been no known good combinations of parameters in previousRuns. \r\n\r\nI believe the default parameters should be added to history and then previousRuns variable, so that SmacSweeper can use them to propose new parameters. \r\n\r\nIf my understanding is correct it may also affect ModelBuilder, although it probably does not use SmacSweeper.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6025","RelatedDescription":"Open issue \"Default parameters not taking into account in GenerateCandidateConfigurations\" (#6025)"},{"Id":"1083888227","IsPullRequest":false,"CreatedAt":"2021-12-18T18:14:57","Actor":"torronen","Number":"6024","RawContent":null,"Title":"Question: improve performance of reading files?","State":"open","Body":"I am running LightGbmBinaryTrainer through AutoML API. The start of training is slow. \r\nAre there ways to make it faster? CPU usage is less than 1 core, HDD reading is also very low.\r\nThe subsequent experiments seem much faster.\r\n\r\nFor example, should I read the data to memory before starting AutoML.\r\n\r\n```\r\n  var loadOptions = columnInference.TextLoaderOptions;\r\n            loadOptions.UseThreads = true;\r\n            TextLoader textLoader = mlContext.Data.CreateTextLoader(loadOptions);\r\n```\r\n\r\nThis is where it seems to spend most of time, on every pause. I have not run profiling though (it has some issues)\r\n![image](https://user-images.githubusercontent.com/26261427/146651154-22686c8c-fb47-4cb1-8a0f-712a84e78134.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6024","RelatedDescription":"Open issue \"Question: improve performance of reading files?\" (#6024)"},{"Id":"1079836838","IsPullRequest":false,"CreatedAt":"2021-12-14T14:37:06","Actor":"cvergaray","Number":"6023","RawContent":null,"Title":"TensorFlow/ONNX inference on ARM","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nI have a Xamarin, soon to be updated to MAUI, application that we are looking to enhance with some image classification capabilities using ML.Net. The intent is to aid our users in identifying domain-specific objects in photos using their Android or iOS phones. We do not, however, own or maintain the training pipeline and are instead provided with the model in TensorFlow pb format. Adding the ability to make inferences using TensorFlow models would allow us to add the computer vision components using ML.Net.\r\n\r\n**Describe the solution you'd like**\r\nAdd support for inferencing with TensorFlow on ARM devices.\r\n\r\n**Describe alternatives you've considered**\r\n- TensorFlow Lite, but that only works with Xamarin.Android\r\n- Converting the pb to ONNX and then using a custom cross-compiled binary. We haven't tried this, but I suspect it would work\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6023","RelatedDescription":"Open issue \"TensorFlow/ONNX inference on ARM\" (#6023)"},{"Id":"1077434629","IsPullRequest":false,"CreatedAt":"2021-12-11T07:34:36","Actor":"oliver021","Number":"6022","RawContent":null,"Title":"Dynamic Input and Output and data view from json data","State":"open","Body":"I have a problem that despite having some suggestions on how to solve it, the possible solutions are still a bit forced for my taste.\r\nWhat happens is that `prediction engine` does not work to make predictions with an ML.Net model because both the input and the output are dynamically established in a schema stored in a data store, the problem is not to enter the model with data whose fields are dynamic, until I get there. The problem is when it comes to loading the model and using it to predict and make the work for which it was trained. I reiterate the schema of an input is strictly related to its model, but the problem is that the data to enter when predicting is data that is entered in a json. How can I from a json or a `Dictionary <string, string>` create an `IDataView` instance cleanly and without violating the API, to use `ITransform` directly to make predictions or uses of the model?","Url":"https://github.com/dotnet/machinelearning/issues/6022","RelatedDescription":"Open issue \"Dynamic Input and Output and data view from json data\" (#6022)"}],"ResultType":"GitHubIssue"}},"RunOn":"2022-01-20T05:30:27.0248717Z","RunDurationInMilliseconds":580}