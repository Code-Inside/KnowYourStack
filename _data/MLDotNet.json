{"Data":{"GitHub":{"Issues":[{"Id":"1341005843","IsPullRequest":true,"CreatedAt":"2022-08-17T00:18:13","Actor":"LittleLittleCloud","Number":"6285","RawContent":null,"Title":"[wip] Use SweepablePipeline","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6285","RelatedDescription":"Open PR \"[wip] Use SweepablePipeline\" (#6285)"},{"Id":"1340495894","IsPullRequest":false,"CreatedAt":"2022-08-16T15:04:09","Actor":"sportbilly21","Number":"6284","RawContent":null,"Title":"Are Resizing Layers supported in ML.Net?","State":"open","Body":"### System information\r\n\r\n- Windows 10 19044.1826\r\n-  VS 2019, Microsoft.ML 1.71,Microsoft.ML.OnnxRuntime.GPU 12.1\r\n\r\nI am have retrained a Tensorflow/Keras model with a resizing layer are part of the model.\r\nI converted to ONNX with opset 11. In python onnx works as expected. I am feeding with what ever size of image and models does the resizing (224, 224) and delivers the predictions.\r\n\r\nIn ML.Net I have created the pipeline and predictions engine. If I pass to the model with a 224x224 image I am getting the following error\r\nSystem.ArgumentException: 'Length of memory (150528) must match product of dimensions (3).' from DenseTensor.shared.cs\r\nIf I pass to the model any other size of image I am getting the following \r\nSystem.InvalidOperationException: 'Operation is not valid due to the current state of the object.' when try to run prediction engine,\r\n\r\nIs resizing layer not supported yes or I am doing something wrong.Please find below the code for the running the model\r\n\r\n### Source code / logs\r\n\r\n        public void GenerateModel(string modelLocation,string inputLayer, string outputLayer, List<string> cats, int gpuID = 0)\r\n        {\r\n            var pipeline = this.mlContext.Transforms.ExtractPixels(inputLayer, inputColumnName: nameof(ImageData.Image), colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Rgb, orderOfExtraction: ImagePixelExtractingEstimator.ColorsOrder.ARGB, interleavePixelColors: false, outputAsFloatArray: true)\r\n              .Append(this.mlContext.Transforms.ApplyOnnxModel(outputLayer, inputLayer, modelLocation));\r\n\r\n            var data = this.mlContext.Data.LoadFromEnumerable(new List<ImageData>());\r\n   \r\n            this.model = pipeline.Fit(data); //;\r\n            this.categories = cats;\r\n            this.predictor = this.mlContext.Model.CreatePredictionEngine<ImageData, ImagePrediction>(this.model);\r\n\r\n       \r\n        }\r\n\r\n        public void ClassifySingleImage(ImageData imgClassify)\r\n        {\r\n\r\n            this.prediction = this.predictor.Predict(imgClassify);\r\n            this.predictions = this.prediction.Preds;\r\n\r\n        }\r\n\r\nMany thanks ","Url":"https://github.com/dotnet/machinelearning/issues/6284","RelatedDescription":"Open issue \"Are Resizing Layers supported in ML.Net?\" (#6284)"},{"Id":"1340321091","IsPullRequest":false,"CreatedAt":"2022-08-16T13:00:30","Actor":"aforoughi1","Number":"6283","RawContent":null,"Title":"Text Classification API (preview 0.20.0-preview.22313.1) Method not found","State":"open","Body":"**System Information (please complete the following information):**\r\n\r\n    <PackageReference Include=\"Microsoft.Data.Analysis\" Version=\"0.20.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML\" Version=\"2.0.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.AutoML\" Version=\"0.20.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.FastTree\" Version=\"2.0.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.LightGbm\" Version=\"2.0.0-preview.22313.1\" />\r\n    <PackageReference Include=\"Microsoft.ML.TorchSharp\" Version=\"0.20.0-preview.22313.1\" />\r\n    <PackageReference Include=\"TorchSharp-cpu\" Version=\"0.97.2\" />\r\n  \r\n\r\n**Describe the bug**\r\nWhen I call Fit to train the model, I get \r\n\r\nSystem.MissingMethodException\r\n  HResult=0x80131513\r\n  Message=Method not found: 'Void Module.train()'.\r\n  Source=Microsoft.ML.TorchSharp\r\n  StackTrace:\r\n   at Microsoft.ML.TorchSharp.NasBert.TextClassificationTrainer.Trainer..ctor(TextClassificationTrainer parent, IChannel ch)\r\n   at Microsoft.ML.TorchSharp.NasBert.TextClassificationTrainer.Fit(IDataView input)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n\r\n**To Reproduce**\r\n\r\npublic class SentimentData\r\n    {\r\n        [LoadColumn(0)]\r\n        public string Sentence { get; set; }\r\n\r\n        //Sentiment is a string: 'positive', 'negative' or 'neutral'\r\n        [LoadColumn(1)]\r\n        public string Sentiment { get; set; }\r\n\r\n        // Label = {0:'neutral', 1:'positive',-1:'negative'}\r\n        [LoadColumn(2)]\r\n        public float Label { get; set; }\r\n    }\r\n\r\n\r\nMLContext mlContext = new MLContext(seed: null);\r\nIDataView data = mlContext.Data.LoadFromTextFile<SentimentData>(@\"..\\..\\..\\FinancialPhraseBank.txt\", separatorChar: '\\t',  hasHeader: true);\r\nvar preview = data.Preview(6000);\r\n\r\nvar trainTestSplit = mlContext.Data.TrainTestSplit(data, testFraction: 0.2);\r\nvar trainSet = trainTestSplit.TrainSet;\r\n var validationSet = trainTestSplit.TestSet;\r\n\r\n            //Sentence is input\r\n            //Sentiment is a string: 'positive', 'negative' or 'neutral'\r\n            //Label = {0:'neutral', 1:'positive',-1:'negative'}\r\n\r\n            // Define your training pipeline\r\n            \r\n            var pipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"KeyColumn\", \"Label\")\r\n                                     .Append(mlContext.MulticlassClassification.Trainers.TextClassification(3, labelColumnName: \"KeyColumn\", sentence1ColumnName: \"Sentence\"));\r\n                                     \r\n\r\n            //Train the model\r\n            var model = pipeline.Fit(trainSet); // System.MissingMethodException\r\n\r\n            // Evaluate the model\r\n            var predictions = model.Transform(validationSet);\r\n\r\n\r\n**Additional context**\r\n\r\n[FinancialPhraseBank.txt](https://github.com/dotnet/machinelearning/files/9351179/FinancialPhraseBank.txt)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6283","RelatedDescription":"Open issue \"Text Classification API (preview 0.20.0-preview.22313.1) Method not found\" (#6283)"},{"Id":"1336826615","IsPullRequest":false,"CreatedAt":"2022-08-12T06:55:42","Actor":"acrigney","Number":"6282","RawContent":null,"Title":"Permutation Feature Importance for MulticlassClassification still seems to have issues","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n - .NET Version: [e.g. .NET 5.0]\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\nI see that new code for a new API for this has been released with the \r\nPermutationFeatureImportanceExtensions.cs extension \r\n\r\nhttps://github.com/dotnet/machinelearning/blob/main/src/Microsoft.ML.Transforms/PermutationFeatureImportanceExtensions.cs\r\n\r\nBut it uses MulticlassClassificationCatalog which is an internal class.\r\nSo I am trying to get the old way to work. But I have an error getting incompatible feature column types.\r\nHere is an example.\r\n\r\n'Incompatible features column type: 'Vector<Single, 2>' vs 'Vector<Single, 4>''\r\n\r\nHere is some example code, I get the same type of error with my actual code.\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add scree\r\n[PFI.txt](https://github.com/dotnet/machinelearning/files/9314310/PFI.txt)\r\nnshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6282","RelatedDescription":"Open issue \"Permutation Feature Importance for MulticlassClassification still seems to have issues\" (#6282)"},{"Id":"1329274445","IsPullRequest":true,"CreatedAt":"2022-08-10T21:43:13","Actor":"tarekgh","Number":"6272","RawContent":null,"Title":"Tokenizers Support","State":"closed","Body":"This PR introduces the first version of Tokenizers support. This version will include the following:\r\n\r\n- Tokenizer APIs (creation and encoding).\r\n- Abstraction for tokenizers Normalization, pre-processing, and models.\r\n- Bpe model including training support.\r\n-  EnglishRoberta model which is used with the text classification machine learning model.\r\n- Lower and upper casing normalization.\r\n- White space and English roberta pre-processors.\r\n- The integration of the tokenizer with the text classification model.\r\n\r\nFeatures to add later to teh tokenizers:\r\n- More tokenization models (e.g. WordPiece, Unigram,...etc.)\r\n- Save and Load the whole tokenizer. We support saving/loading models but not the whole tokenizer.\r\n- Post-Processing. We support pre-processing only for now. Supporting post processing is good to support too.\r\n- Batch Processing. Support encoding multiple sentences.\r\n- Adding more normalizers and pre-processors.","Url":"https://github.com/dotnet/machinelearning/pull/6272","RelatedDescription":"Closed or merged PR \"Tokenizers Support\" (#6272)"},{"Id":"1334580565","IsPullRequest":false,"CreatedAt":"2022-08-10T12:52:44","Actor":"ML-pixel","Number":"6281","RawContent":null,"Title":"Error while using Model.Save()","State":"open","Body":"**System Information (please complete the following information):**\r\n - Checked on multiple systems (win 10, win 2019,2021 server)\r\n - ML.NET Version: ML.NET 1.7.0\r\n\r\n\r\n - .NET Core 2.2.3\r\n\r\n**Describe the bug**\r\nWhen saving trained model of very large size, xx GB the exception is thrown with the inner exception \"The length cannot be greater than the capacity. ParameterName valueCount at System.Text.StringBuilder.Append() at Microsoft.Ml.Data.ReadOnlyMemoryUtils.AppendSpan ...etc \r\nWhat I think is that the Save() uses StringBuilder.Append(char*,Int32) method and the int32 is a problem. \r\n\r\n**To Reproduce**\r\n1.Train extra large model\r\n2.Try to save it with Model.Save()\r\n\r\n![error_Cut](https://user-images.githubusercontent.com/110897666/183905634-e9f78564-e360-4c76-8aa0-d9edd5f96d7b.png)","Url":"https://github.com/dotnet/machinelearning/issues/6281","RelatedDescription":"Open issue \"Error while using Model.Save()\" (#6281)"},{"Id":"1327835855","IsPullRequest":false,"CreatedAt":"2022-08-09T19:52:41","Actor":"vpenades","Number":"6271","RawContent":null,"Title":"Dummy Estimator / Transformer ?","State":"closed","Body":"When creating a pipeline, the common practice is to write this sort of spaguetti code:\r\n\r\n```c#\r\n\r\nvar pipeline = mlContext.Transforms.Something( .... )\r\n    .Append( mlContext.Transforms.SomethingElse(...) )\r\n    .Append( mlContext.Transforms.SomethingElse(...) )\r\n    .Append( mlContext.Transforms.SomethingElse(...) )\r\n    .Append( mlContext.Transforms.SomethingElse(...) )\r\n    .Append( mlContext.Transforms.SomethingElse(...) )\r\n```\r\n\r\nIf I want to split this into separated functions, each funcion will usually return some variation of `EstimatorChain<SomeTransformer>`\r\n\r\nThe problem is every time I need to refactor which estimators I slice and move from one function to another, I need to continuosly change the returning type, because it depends on what was returned by the last .Append, and it's a complete pain.\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nI was wondering if there's some sort of \"does nothing\" \"NoOp\", null, or Dummy Estimator/Transformer pair that does absolutely nothing, so it can always be returned by a function, by appending it as the last element, something like this:\r\n\r\n```c#\r\n\r\npublic EstimatorChain<DummyTransformer> GetPipeline1()\r\n{\r\n    var pipeline = mlContext.Transforms.Something( .... )\r\n      .Append( mlContext.Transforms.SomethingElse(...) )\r\n      .Append( mlContext.Transforms.SomethingElse(...) )\r\n      .Append( mlContext.Transforms.DummyEstimator() );\r\n}\r\n\r\npublic EstimatorChain<DummyTransformer> GetPipeline1()\r\n{\r\n    var pipeline = mlContext.Transforms.Something( .... )\r\n      .Append( mlContext.Transforms.SomethingElse(...) )\r\n      .Append( mlContext.Transforms.DummyEstimator() );\r\n}\r\n```\r\n\r\nSo all the funcions will return the same type, which will help a lot in refactoring, and moving away from spaguetti code.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nRight now I'm using a SelectColumns estimator, and selecting all current columns, which is the closest alternative I've found.\r\n\r\nI also considered implementing my own \"dummy\" estimator, by deriving from TrivialEstimator, but I don't have the knowledge to dig so deep.","Url":"https://github.com/dotnet/machinelearning/issues/6271","RelatedDescription":"Closed issue \"Dummy Estimator / Transformer ?\" (#6271)"},{"Id":"1332838885","IsPullRequest":false,"CreatedAt":"2022-08-09T07:34:49","Actor":"rzechu","Number":"6280","RawContent":null,"Title":"How to make prediction of custom data with loaded model? Problem with Model.CreatePredictionEngine<TSrc, TDst> Is it possible to avoid strongly typed input/output","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**:  .NET 4.8\r\n\r\n### Issue\r\n- **What did you do?** \r\n- Hello I'd like to implement \"model creator\" and \"dynamic model\" usage in our application to allow users to write SQL statements or use wizard to check database fields, prepare/train model (pick 3 columns and 1 as label - similiar to MLModelBuilder in VisualStudio), save model to disk/db, then use it later to predict values.\r\nI made dynamic model preparation with AutoML (I guess it works fine with just plain sql / sql schema creation).\r\nBut problem is with implementing predictions\r\nIts propably possible with dynamic data types (or not?) or reflection (I want to avoid this) \r\n\r\nModel.CreatePredictionEngine<**TSrc, TDst**> requires strongly typed input and outputs. Is there any workaround?\r\nI'd like to put predictions model on custom forms with custom fields. I can load it, I know the fields used to predict/label but Its not possible without developer writing custom methods for each form type and recompilling application. \r\n\r\n- **What did you expect?** Create dynamic input/output by adding columns with types. I guess it should be possible in similliar way to generating DataTable, columns and datatypes during runtime. \r\nOr something like Model.CreationPredictionEngine(model, inputschema, inputColumns, outputColumns)\r\nWhere columns are  column + type property + attributes if necessary","Url":"https://github.com/dotnet/machinelearning/issues/6280","RelatedDescription":"Open issue \"How to make prediction of custom data with loaded model? Problem with Model.CreatePredictionEngine<TSrc, TDst> Is it possible to avoid strongly typed input/output\" (#6280)"},{"Id":"1330377710","IsPullRequest":true,"CreatedAt":"2022-08-08T20:58:50","Actor":"ericstj","Number":"6277","RawContent":null,"Title":"Update Newtonsoft.Json to 13.0.1 (#6276)","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6277","RelatedDescription":"Closed or merged PR \"Update Newtonsoft.Json to 13.0.1 (#6276)\" (#6277)"},{"Id":"1332222082","IsPullRequest":true,"CreatedAt":"2022-08-08T18:14:46","Actor":"jordi1215","Number":"6279","RawContent":null,"Title":"Bringing Fairlearn - GridSearch to ML.NET","State":"open","Body":"\r\nRelated to: #1912  \r\nRelated to: [Issue 1091 on the Fairlearn Repo](https://github.com/fairlearn/fairlearn/issues/1091)\r\n\r\nAs part of my summer internship project, I have created several classes that will provide a foundation for the further inclusion of Fairlearn algorithms into ML.NET.\r\n\r\nFor the first PR, I have included an end-to-end working solution for the gridSearch method in Fairlearn which leverages AutoML for parameter searching. The example is included in the Unit test.\r\n\r\n\r\nWe are excited to review your PR.\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6279","RelatedDescription":"Open PR \"Bringing Fairlearn - GridSearch to ML.NET\" (#6279)"},{"Id":"1313141549","IsPullRequest":false,"CreatedAt":"2022-08-08T16:23:23","Actor":"rzechu","Number":"6257","RawContent":null,"Title":"CreateEnumerable - System.IndexOutOfRangeException","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: ML.NET v1.7.1\r\n - .NET Version: Framework 4.8\r\n\r\n**Describe the bug**\r\nI am receiving Index out of range exception after trying convert transformedData into enumerable.\r\nSame line of code works fine for same code but using method  - DetectIidSpike and its parameters\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\nHere's minimal working example https://github.com/dotnet/machinelearning/issues/6257#issuecomment-1196329421\r\n\r\n```\r\n    internal class LogsPrediction\r\n    {\r\n        //vector to hold alert,score,p-value values\r\n        [VectorType(3)]\r\n        public double[] Prediction { get; set; }\r\n    }\r\n```\r\n\r\n\r\nSent parameters\r\nList<SourceRequestData> SourceDatas /*12025 records but filtered inside loop to 517 records*/, \r\nint windowSize = 6, \r\nint backAddWindowSize = 5,\r\n int lookaheadWindowSize = 5, \r\nint averagingWindowSize = 5,\r\n int judgementWindowSize = 6, \r\ndouble threshold = 0.01\r\n```\r\npublic void DetectanAnomalyEnumerable(ref List<SourceRequestData> SourceDatas, int windowSize = 64, int backAddWindowSize = 5, int lookaheadWindowSize = 5, int averagingWindowSize = 5, int judgementWindowSize = 21, double threshold = 0.3)\r\n        {\r\n            try\r\n            {\r\n                var lambdaWorkAround = SourceDatas;\r\n                var differentDefinitions = SourceDatas.Select(s => new { RdMethodType = s.Rd_MethodType, RdMethodID = s.Rd_MethodId }).Distinct().ToList();\r\n\r\n                Parallel.ForEach(differentDefinitions, definitionID =>\r\n                {\r\n                    if (windowSize < 5)\r\n                        return;\r\n\r\n                    var dataToCheck = lambdaWorkAround.Where(w => w.Rd_MethodType == definitionID.RdMethodType && w.Rd_MethodId == definitionID.RdMethodID).OrderBy(o => o.Rd_ID).ToList();\r\n\r\n                    IDataView dataView = mlContext.Data.LoadFromEnumerable<SourceRequestData>(dataToCheck);\r\n\r\n                    lookaheadWindowSize = lookaheadWindowSize> windowSize  ? windowSize : lookaheadWindowSize;\r\n                    averagingWindowSize = averagingWindowSize > windowSize  ? windowSize : averagingWindowSize;\r\n                    judgementWindowSize = judgementWindowSize > windowSize  ? windowSize : judgementWindowSize;\r\n                    threshold = threshold == 0 ? 0.01 : threshold;\r\n                    threshold = threshold == 1 ? 0.99 : threshold;\r\n\r\n                    var iidSpikeEstimator = mlContext.Transforms.DetectAnomalyBySrCnn(\r\n                        outputColumnName: nameof(LogsPrediction.Prediction),\r\n                        inputColumnName: nameof(SourceRequestData.Rd_DurationPerObject),\r\n                        windowSize: windowSize,\r\n                        backAddWindowSize: backAddWindowSize,\r\n                        lookaheadWindowSize: lookaheadWindowSize,\r\n                        averagingWindowSize: averagingWindowSize,\r\n                        judgementWindowSize: judgementWindowSize,\r\n                        threshold: threshold);\r\n                    ITransformer iidSpikeTransform = iidSpikeEstimator.Fit(dataView);\r\n\r\n                    IDataView transformedData = iidSpikeTransform.Transform(dataView);\r\n//EXCEPTION HERE VVVVV\r\n                    var predictions = mlContext.Data.CreateEnumerable<LogsPrediction>(transformedData, reuseRowObject: false).ToList();\r\n//EXCEPTION HERE ^^^^^^^\r\n\r\n                    var objectID = dataView.GetColumn<float>(nameof(SourceRequestData.Rd_ID)).ToArray();\r\n\r\n                    for (int i = 0; i < predictions.Count(); i++)\r\n                    {\r\n                        if (predictions[i].Prediction[0] == 1)\r\n                        {\r\n                            var recordToChange = dataToCheck.Where(w => w.Rd_ID == objectID[i]).FirstOrDefault();\r\n                            recordToChange.IsSpike = true;\r\n                        }\r\n                    }\r\n                });\r\n                SourceDatas = lambdaWorkAround;\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                Console.WriteLine(ex);\r\n            }\r\n```\r\n\r\n\r\n   at Microsoft.ML.Transforms.TimeSeries.SrCnnAnomalyDetectionBase.SrCnnAnomalyDetectionBaseCore.State.BackAdd(FixedSizeQueue`1 data)\r\n   at Microsoft.ML.Transforms.TimeSeries.SrCnnAnomalyDetectionBase.SrCnnAnomalyDetectionBaseCore.State.SpectralResidual(Single input, FixedSizeQueue`1 data, VBufferEditor`1& result)\r\n   at Microsoft.ML.Transforms.TimeSeries.SrCnnTransformBase`2.SrCnnStateBase.TransformCore(TInput& input, FixedSizeQueue`1 windowedBuffer, Int64 iteration, VBuffer`1& dst)\r\n   at Microsoft.ML.Transforms.TimeSeries.SequentialTransformerBase`3.StateBase.Process(TInput& input, TOutput& output)\r\n   at Microsoft.ML.Transforms.LambdaTransform.<>c__DisplayClass5_0`3.<CreateMap>b__0(TSrc src, TDst dst, TState state)\r\n   at Microsoft.ML.Transforms.StatefulFilterTransform`3.Cursor.RunLambda(Boolean& isRowAccepted)\r\n   at Microsoft.ML.Transforms.StatefulFilterTransform`3.Cursor.MoveNextCore()\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext()\r\n   at Microsoft.ML.Data.TypedCursorable`1.RowCursorImplementation.MoveNext()\r\n   at Microsoft.ML.PipeEngine`1.<RunPipe>d__2.MoveNext()\r\n   at System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)\r\n   at System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)\r\n   at MLNet.AnomalyDetection.<>c__DisplayClass5_1.<DetectanAnomalyEnumerable>b__1(<>f__AnonymousType0`2 definitionID) in C:\\Users\\xyz.zys\\Desktop\\ML_NET\\Common\\MLNet\\AnomalyDetection.cs:line 178\r\n   at System.Threading.Tasks.Parallel.<>c__DisplayClass17_0`1.<ForWorker>b__1()\r\n```\r\n\r\n**Expected behavior**\r\nEnumerable object is returned (same code works for same method with DetectIidSpike and its own parameters)","Url":"https://github.com/dotnet/machinelearning/issues/6257","RelatedDescription":"Closed issue \"CreateEnumerable - System.IndexOutOfRangeException\" (#6257)"},{"Id":"1331038288","IsPullRequest":false,"CreatedAt":"2022-08-07T15:37:17","Actor":"mandar1jn","Number":"6278","RawContent":null,"Title":"ML.net trainer keeps going back to bottleneck computation","State":"closed","Body":"### System information\r\n\r\n- **Windows 10**:\r\n- **Dotnet 6.0.302**: \r\n\r\n### Issue\r\n\r\n- **I tried to create an image classification model**\r\n- **ML.net goes to Bottleneck Computation, then to Training, then logs a lot of things about channels, and then restarts. this continues in an infinite log**\r\n- **I expected it to continue training instead of going back to the start**\r\n\r\nThis happened on windows with the visual studio 2022 model builder and on Linux with the ml.net cli\r\n\r\n### Source code / logs\r\n\r\n[ImageModel-R4IFKW.txt](https://github.com/dotnet/machinelearning/files/9276989/ImageModel-R4IFKW.txt)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6278","RelatedDescription":"Closed issue \"ML.net trainer keeps going back to bottleneck computation\" (#6278)"},{"Id":"1330177826","IsPullRequest":true,"CreatedAt":"2022-08-05T20:30:56","Actor":"ericstj","Number":"6276","RawContent":null,"Title":"Update Newtonsoft.Json to 13.0.1","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6276","RelatedDescription":"Closed or merged PR \"Update Newtonsoft.Json to 13.0.1\" (#6276)"},{"Id":"1330173792","IsPullRequest":false,"CreatedAt":"2022-08-05T17:09:54","Actor":"luisquintanilla","Number":"6275","RawContent":null,"Title":"[DataFrame] Head should return min(DF length, param)","State":"open","Body":"## Problem\r\n\r\nGiven a DataFrame with 3 rows, calling `Head(5)` throws an error. \r\n\r\n![image](https://user-images.githubusercontent.com/46974588/183127094-cb6b8a88-b0b0-4412-a871-faa3f8691fcb.png)\r\n\r\n\r\n## Suggested solution\r\n\r\nHead should return the minimum of the number provided as a parameter and the length of a DataFrame","Url":"https://github.com/dotnet/machinelearning/issues/6275","RelatedDescription":"Open issue \"[DataFrame] Head should return min(DF length, param)\" (#6275)"},{"Id":"1330167887","IsPullRequest":false,"CreatedAt":"2022-08-05T17:02:59","Actor":"luisquintanilla","Number":"6274","RawContent":null,"Title":"[DataFrame] Info method display should be the same for DataFrame and DataFrameColumn","State":"open","Body":"The `Info` method on a `DataFrame` behaves different from that of a `DataFrameColumn`. The DataFrame displays an `Info` column with labels for each column's data point (DataType, Length). The DataFrameColumn displays the same information, without the labels. Update `DataFrameColumn.Info()` method to display data with labels like `DataFrame`\r\n\r\n![image](https://user-images.githubusercontent.com/46974588/183125945-4a4da61b-716b-4d6f-9662-bd72eaaf9005.png)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6274","RelatedDescription":"Open issue \"[DataFrame] Info method display should be the same for DataFrame and DataFrameColumn\" (#6274)"},{"Id":"1329597995","IsPullRequest":false,"CreatedAt":"2022-08-05T08:06:19","Actor":"acrigney","Number":"6273","RawContent":null,"Title":"Help with Custom VarVector to Vector mapping (does it have to so hard?)","State":"open","Body":"### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: \r\nML.NET v4.0.30319\r\n### Issue\r\n\r\n- **What did you do?**\r\n- I have a data class that contains single fields and fields that are arrays\r\n- **What happened?**\r\n- How to custom map the the varvector generated into a single vector\r\n- similar to https://github.com/dotnet/machinelearning/issues/4977\r\n- \r\n- **What did you expect?**\r\n-  Easy way to convert the varvectors into a single vector\r\n- \r\n### Source code / logs\r\n\r\n\t// Code abbreviated\r\n\r\n\tMLContext mlContext = new MLContext();\r\n\r\n    SchemaDefinition definedSchema;            \r\n\r\n    // For fixed array dimension sizes use\r\n    definedSchema = SchemaDefinition.Create(typeof(MLDataForAnalysisFactored));\r\n\r\n    // If we can use variable array dimension sizes we can use this\r\n    int featuresCount = SetFeatureArrayDimensions(mlDataList, out definedSchema);\r\n\r\n    IDataView trainDataView = mlContext.Data.LoadFromEnumerable<MLDataForAnalysisFactored>(mlDataList, definedSchema);\r\n\r\n    // The label must not be in the input features\r\n    string[] features = typeof(MLDataForAnalysisFactored).GetProperties().ToList().\r\n            Where(p => p.Name != labelColumnName).Select(x => x.Name).ToArray();\r\n\r\n    var estimatorChain = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: \"Label\", inputColumnName: \r\n        nameof(MLDataForAnalysisFactored.Call))\r\n        .Append(mlContext.Transforms.Concatenate(\"Features\", features));\r\n\r\n    var transformedTrainData = estimatorChain.Fit(trainDataView);\r\n\r\n    trainDataView = transformedTrainData.Transform(trainDataView);\r\n\r\n    // check the data\r\n    var rowEnumerable = mlContext.Data\r\n        .CreateEnumerable<MLDataForAnalysisFactored>(trainDataView,\r\n        reuseRowObject: true).ToList();\r\n   \r\n    var schema = trainDataView.Schema;\r\n\r\n    //var featureColumns = trainDataView.GetColumn<float[]>(trainDataView.Schema[\"Features\"]).Take(4);\r\n\r\n    //create a custom schema-definition that overrides the type for the Values field...  \r\n\tvar singleVectorSchemaDef = SchemaDefinition.Create(typeof(SingleVector));\r\n\tsingleVectorSchemaDef[nameof(SingleVector.Values)].ColumnType\r\n                  = new VectorDataViewType(NumberDataViewType.Single, featuresCount);\r\n\r\n    // How to do a custom transform to map the varvectors to a single vector?\r\n    // otherwise you have to do this.\r\n    ////use that schema definition when creating the training dataview  \r\n    //trainDataView = mlContext.Data.LoadFromEnumerable(mlDataList, singleVectorSchemaDef);\r\n\r\n    // check the data\r\n\r\n    //        var someRows = mlContext.Data.  // Convert to an enumerable of user-defined type. \r\n    //                .CreateEnumerable<MLDataForAnalysisFactored>(trainDataView, reuseRowObject: false)\r\n    //// Take a couple values as an array.\r\n    //.Take(4).ToArray();\r\n\r\n    // Extract the 'AllFeatures' column.\r\n    // This will give the entire dataset: make sure to only take several row\r\n    // in case the dataset is huge. The is similar to the static API, except\r\n    // you have to specify the column name and type.\r\n\r\n    //var featureColumns = estimatorChain.GetColumn<float[]>(trainDataView.Schema[\"Features\"]);\r\n    \r\n    // STEP 2: Run AutoML experiment\r\n    Console.WriteLine($\"Running AutoML multiclass classification experiment for {ExperimentTime} seconds...\");            \r\n\r\n    ExperimentResult<MulticlassClassificationMetrics> experimentResult = mlContext.Auto()\r\n        .CreateMulticlassClassificationExperiment(ExperimentTime)\r\n        .Execute(trainDataView, LabelColumnName, null, estimatorChain);\r\n\r\nwhere SingleVector is\r\n\r\n\t  public class SingleVector\r\n\t  {\r\n\t      //it's not required to specify the type here since we will override in our custom schema \r\n\t      public float[] Values;\r\n\t  }\r\n\t  // Above function SetFeatureArrayDimensions\r\n\t  // You would expect that once the size of the var vectors has been set then that is all you should have to do but ML.NET needs\r\n\t  // a single vector.\r\n\t  private int SetFeatureArrayDimensions(List<MLDataForAnalysisFactored> mlDataList, out SchemaDefinition definedSchema)\r\n\t      {\r\n\t          int totalFeatureCount = 0;\r\n\t          // STEP 1: Load data\r\n\t  \r\n\t          // The feature dimension (typically this will be the Count of the array \r\n\t          // of the features vector known at runtime).\r\n\t          int featureArrayDimension = 0;\r\n\t          definedSchema = SchemaDefinition.Create(typeof(MLDataForAnalysisFactored));\r\n\t  \r\n\t          var properties = typeof(MLDataForAnalysisFactored).GetProperties();\r\n\t  \r\n\t          foreach (var property in properties)\r\n\t          {\r\n\t              if (property.PropertyType.IsArray)\r\n\t              {\r\n\t                  Array array = property.GetValue(mlDataList[0]) as Array;\r\n\t                  featureArrayDimension = array.Length;\r\n\t                  totalFeatureCount += featureArrayDimension;\r\n\t  \r\n\t                  //// Set the column type to be a known-size vector.\r\n\t                  var vectorItemType = ((VectorDataViewType)definedSchema[property.Name].ColumnType)\r\n\t                              .ItemType;\r\n\t  \r\n\t                  definedSchema[property.Name].ColumnType = new VectorDataViewType(vectorItemType,\r\n\t                      featureArrayDimension);\r\n\t  \r\n\t                  var featureColumn = definedSchema[property.Name]\r\n\t                  .ColumnType as VectorDataViewType;\r\n\t  \r\n\t                  Diag.Debug.WriteLine($\"Is the size of the Feature array {property.Name} column known: \" +\r\n\t                      $\"{featureColumn.IsKnownSize}.\\nSize: {featureColumn.Size}\");\r\n\t              }\r\n\t              else\r\n\t              {\r\n\t                  totalFeatureCount++;\r\n\t              }\r\n\t          }\r\n\t          return (totalFeatureCount);\r\n\t      }        \r\n\r\nAnyway I can get away with using fixed array sizes.\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6273","RelatedDescription":"Open issue \"Help with Custom VarVector to Vector mapping (does it have to so hard?)\" (#6273)"},{"Id":"1325134976","IsPullRequest":true,"CreatedAt":"2022-08-03T19:24:16","Actor":"michaelgsharp","Number":"6269","RawContent":null,"Title":"FUNCTIONAL BREAKING CHANGE. Transform chooses score scope by default. ","State":"closed","Body":"Users have the (undocumented) ability to specify the scope of a transformer when they add it to the chain. It defaults to `Everything` if nothing is specified. This allows them to get a `TransformerChain` for specific scopes. The default when running the `Transform` method was to include all scopes, but since `Transform` is typically used for scoring this PR changes the default to only run the transformers for the \"Score\" scope. The user can still use the default behavior by specifying the scope when they call transform.","Url":"https://github.com/dotnet/machinelearning/pull/6269","RelatedDescription":"Closed or merged PR \"FUNCTIONAL BREAKING CHANGE. Transform chooses score scope by default. \" (#6269)"},{"Id":"1326337803","IsPullRequest":true,"CreatedAt":"2022-08-02T19:57:39","Actor":"LittleLittleCloud","Number":"6270","RawContent":null,"Title":"improve multiclassification using AutoMLExperiment","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6270","RelatedDescription":"Open PR \"improve multiclassification using AutoMLExperiment\" (#6270)"},{"Id":"1322788307","IsPullRequest":true,"CreatedAt":"2022-08-02T18:00:49","Actor":"michaelgsharp","Number":"6265","RawContent":null,"Title":"Add in support for 1 unknown dimension for ONNX runtime.","State":"closed","Body":"Adds support so that you can have 1 unknown dimension for the ONNX runtime models (not including the batch input since we set that to 1).","Url":"https://github.com/dotnet/machinelearning/pull/6265","RelatedDescription":"Closed or merged PR \"Add in support for 1 unknown dimension for ONNX runtime.\" (#6265)"},{"Id":"1318641471","IsPullRequest":true,"CreatedAt":"2022-08-02T18:00:28","Actor":"LittleLittleCloud","Number":"6261","RawContent":null,"Title":"add image featurizer to AutoFeaturizer","State":"closed","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [x] There's a descriptive title that will make sense to other developers some time from now. \r\n- [x] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [x] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [x] You have included any necessary tests in the same PR.\r\n\r\nThis PR adds featurizer for image path. When there's a column, or multiple columns that are referred as image path, a set of estimators with search space will be added for those columns which featurizes image using one of DNN featurizers (ResNet18, ResNet50, AlexNet...)\r\n\r\nThe initial idea comes from @justinormont, which is a great cross-platform solution to leverage automl in image classification, and can be a more efficient way compared with deep learning, especially on small datasets. \r\n\r\nThe estimators that use to featurize images are\r\n```\r\nLoadImage -> ResizeImage(224, 224) -> ExtractPixels -> DnnFeaturizer(one of resnet18, resnet50, alexnet, resnet 101)\r\n```\r\nwhich transfers an image into a numeric feature array for classifiers to learn and transform.\r\n\r\nAnd while training, the search space from those estimators will be added to the global search space and will be optimized by the selected tuner","Url":"https://github.com/dotnet/machinelearning/pull/6261","RelatedDescription":"Closed or merged PR \"add image featurizer to AutoFeaturizer\" (#6261)"},{"Id":"1322984079","IsPullRequest":true,"CreatedAt":"2022-08-02T17:16:34","Actor":"Youssef1313","Number":"6268","RawContent":null,"Title":"Simplify NameFixProvider","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6268","RelatedDescription":"Closed or merged PR \"Simplify NameFixProvider\" (#6268)"},{"Id":"1322955957","IsPullRequest":true,"CreatedAt":"2022-08-02T16:49:54","Actor":"Youssef1313","Number":"6266","RawContent":null,"Title":"Simplify ParameterVariableNameAnalyzer","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6266","RelatedDescription":"Closed or merged PR \"Simplify ParameterVariableNameAnalyzer\" (#6266)"},{"Id":"1322962740","IsPullRequest":true,"CreatedAt":"2022-08-02T00:41:57","Actor":"Youssef1313","Number":"6267","RawContent":null,"Title":"Minor refactoring in BaseTestClassAnalyzer","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6267","RelatedDescription":"Closed or merged PR \"Minor refactoring in BaseTestClassAnalyzer\" (#6267)"},{"Id":"1322598890","IsPullRequest":false,"CreatedAt":"2022-07-29T19:18:22","Actor":"natelowry","Number":"6264","RawContent":null,"Title":"Does the OpenVINO execution provider for ONNX Runtime work in ML.NET?","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm using an ONNX model via `ApplyOnnxModel` and some pre-processing (which is really fast!), but I'd like it to use the OpenVINO execution provider instead of just the CPU.  \r\n\r\nWe are maxing out the CPU and not hitting a high enough framerate with just the CPU.  CUDA with `gpuDeviceId` is not an option due to hardware limitations.\r\n\r\nI can't figure out a way to make the ONNX Runtime called by ML.NET actually use the OpenVINO execution provider.  Is there something simple I'm missing?\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like the ONNX Runtime used by ML.NET to allow OpenVINO as an execution provider.  Maybe that's in the `ApplyOnnxModel` options as something like `OnnxRuntime = OnnxRuntimes.OpenVINO`, `OnnxRuntime = OnnxRuntimes.CUDA`, or `OnnxRuntime = OnnxRuntimes.oneDNN`, etc.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI can run OpenVINO using the ONNX Runtime Nuget packages built with OpenVINO using `AppendExecutionProvider_OpenVINO`, but the pre-processing is much slower and the level of abstraction is way lower than I'd like (making the pipeline harder to manage).  The inference runs at least 2x faster on the GPU though, so I want to use the GPU via that runtime.\r\n\r\nI've tried dropping in all the onnxruntime/openvino dlls to the executable directory to see if it uses those at runtime, but no luck.  Do I need to do a custom build of ML.NET?\r\n\r\n**Additional context**\r\n\r\nI can provide some more source code or examples if that's helpful, but I think it's more of a concept question than code question.\r\n\r\nThis is a great project and I appreciate everyone that's working on it.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6264","RelatedDescription":"Open issue \"Does the OpenVINO execution provider for ONNX Runtime work in ML.NET?\" (#6264)"},{"Id":"1317122342","IsPullRequest":true,"CreatedAt":"2022-07-28T18:19:51","Actor":"michaelgsharp","Number":"6259","RawContent":null,"Title":"Don't need label column for inference TextClassification.","State":"closed","Body":"Makes the TextClassification transformer save/load the label metadata so that we can use the transformer scope to remove the need for the label column during inferencing.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6259","RelatedDescription":"Closed or merged PR \"Don't need label column for inference TextClassification.\" (#6259)"},{"Id":"1321299991","IsPullRequest":false,"CreatedAt":"2022-07-28T18:06:10","Actor":"tarekgh","Number":"6263","RawContent":null,"Title":"Method not found: 'Void Module.train()'.","State":"open","Body":"This [issue](https://github.com/dotnet/TorchSharp/issues/666) is originally reported by @drGarbinsky in TorchSharp repo and ported here. \r\n\r\nI'm currently trying to get the same running from this page: [devblogs.microsoft.com/dotnet/introducing-the-ml-dotnet-text-classification-api-preview](https://devblogs.microsoft.com/dotnet/introducing-the-ml-dotnet-text-classification-api-preview/)\r\nworking with:\r\ndotnet: 7.0.100-preview.6.22352.1\r\nMicrosoft.ML Version=\"2.0.0-preview.22313.1\"\r\nMicrosoft.ML.TorchSharp Version=\"0.20.0-preview.22313.1\"\r\nTorchSharp-cpu Version=\"0.97.0\"\r\n\r\nWSL ubuntu: 20.04.3 LTS\r\n\r\ncode:\r\n\r\n```C#\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.TorchSharp;\r\n\r\n// Initialize MLContext\r\nvar mlContext = new MLContext();\r\n\r\n// Load your data\r\nvar reviews = new[]\r\n{\r\nnew {Text = \"This is a bad steak\", Sentiment = \"Negative\"},\r\nnew {Text = \"I really like this restaurant\", Sentiment = \"Positive\"}\r\n};\r\n\r\nvar reviewsDV = mlContext.Data.LoadFromEnumerable(reviews);\r\n\r\n//Define your training pipeline\r\nvar pipeline =\r\nmlContext.Transforms.Conversion.MapValueToKey(\"Label\", \"Sentiment\")\r\n.Append(mlContext.MulticlassClassification.Trainers.TextClassification(numberOfClasses: 2, sentence1ColumnName: \"Text\"))\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedLabel\"));\r\n\r\n// Train the model\r\nvar model = pipeline.Fit(reviewsDV);\r\n\r\n```\r\n\r\n@KernAlan wrote:\r\n\r\nI'm experiencing the same issue right now.\r\n\r\n@JReed221 wrote:\r\n\r\nI am experiencing this issue as well\r\n\r\n@drGarbinsky wrote:\r\n\r\nI've noticed that this [notebook ](https://github.com/dotnet/csharp-notebooks/blob/main/machine-learning/E2E-Text-Classification-API-with-Yelp-Dataset.ipynb?rgh-link-date=2022-07-27T19%3A30%3A45Z)references a newer version of the packages but I am unable to locate them\r\n\r\n> #i \"nuget:[pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json](https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json)\"\r\n> #r \"nuget:Microsoft.ML,2.0.0-preview.22324.1\"\r\n> #r \"nuget:Microsoft.ML.TorchSharp,0.20.0-preview.22324.1\"\r\n> #r \"nuget:TorchSharp-cpu,0.96.7\"\r\n> #r \"nuget:Microsoft.Data.Analysis,0.20.0-preview.22324.1\"\r\n\r\nI have also reproduced this issue within the nightly docker image so I don't think it is an environment issue\r\n\r\n\r\n@drGarbinsky wrote\r\n\r\nI was able to work around the issue by rolling back package versions:\r\n\r\n```Xml\r\n<PackageReference Include=\"libtorch-cpu-linux-x64\" Version=\"1.11.0.1\" />\r\n<PackageReference Include=\"Microsoft.Data.Analysis\" Version=\"0.20.0-preview.22313.1\" />\r\n<PackageReference Include=\"Microsoft.ML\" Version=\"2.0.0-preview.22313.1\" />\r\n<PackageReference Include=\"Microsoft.ML.TorchSharp\" Version=\"0.20.0-preview.22313.1\" />\r\n<PackageReference Include=\"TorchSharp-cpu\" Version=\"0.96.3\" />\r\n```\r\n\r\n@JReed221 wrote\r\n\r\nthat worked! thank you!\r\n\r\n@NiklasGustafsson wrote\r\n\r\nI believe that this is likely due to the fact that there was a breaking change made to Module.train() -- the previous version did not take an optional bool, which the Pytorch version does. That does not break source code dependencies, but breaks any binary dependency, since the signature has changed.\r\n\r\nAdding @luisquintanilla and @michaelgsharp to consult on what to do about this.\r\n\r\n@NiklasGustafsson wrote\r\n\r\nA potential fix is to not make the bool optional, but to have two train() declarations -- one with, and one without. The latter would unbreak the binary dependency, I believe.\r\n\r\n@luisquintanilla wrote:\r\n\r\nHi all,\r\n\r\nSorry to hear you ran into issues.\r\n\r\nI want to add clarity to the versions used in the notebook. The version in the notebook comes from the ML.NET daily feed. That version enables the use of the built-in Evaluate method in ML.NET and also makes it easier to work with the API. Previously you had to manually enter the number of classes you wanted to predict and couldn't use the evaluate method. This is the link to the daily feed if you want to get access to the latest versions of the ML.NET packages.\r\n\r\n[pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json](https://pkgs.dev.azure.com/dnceng/public/_packaging/MachineLearning/nuget/v3/index.json)\r\n\r\nThat's a good suggestion @NiklasGustafsson. I also wonder if another alternative would be to instruct users to reference a specific version of TorchSharp (as @drGarbinsky has done to work around the issue). We've done something similar with TensorFlow.NET in the past. What would be the disadvantages of doing that (other than your code won't run using the latest version of TorchSharp)?\r\n\r\n@NiklasGustafsson wrote:\r\n\r\n> What would be the disadvantages of doing that (other than your code won't run using the latest version of TorchSharp)?\r\n\r\nThat would be the disadvantage, in addition to the inconvenience of having to keep track of which version numbers work and not.\r\n\r\n@NiklasGustafsson wrote:\r\n\r\nHmmm.\r\n\r\nThe change I was thinking of was introduced in 0.97.0 last week, so if you have to go all the way back to 0.96.3 to fix it, that's very odd. @luisquintanilla -- is there any way you could try it out with 0.96.8?\r\n\r\n@tarekgh wrote:\r\n\r\n@NiklasGustafsson [Changes that affect compatibility](https://docs.microsoft.com/en-us/dotnet/core/compatibility/?ranMID=43674&ranEAID=rl2xnKiLcHs&ranSiteID=rl2xnKiLcHs-Vk6trHPJPdwOyqxWVzHUQQ&epi=rl2xnKiLcHs-Vk6trHPJPdwOyqxWVzHUQQ&irgwc=1&OCID=AID2200057_aff_7795_1243925&tduid=(ir__2m3q0nl02wkf6gcatnnkkvci0e2xve3sx63xgf9200)(7795)(1243925)(rl2xnKiLcHs-Vk6trHPJPdwOyqxWVzHUQQ)()&irclickid=_2m3q0nl02wkf6gcatnnkkvci0e2xve3sx63xgf9200) doc mentioning the following:\r\n\r\n❌ DISALLOWED: Removing the [virtual](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/virtual) keyword from a member\r\n\r\nI guess the compiler will not bind to the method if the virtual removed from the member.\r\n\r\n@luisquintanilla should we just publish the latest of ML.NET to the NuGet instead of having it in the internal feed and recommend the users to use the latest?\r\n\r\n@NiklasGustafsson wrote:\r\n\r\nAnother approach is to rebuild the ML.NET preview with 0.97.0 and pick up the new method definition.\r\n\r\n@NiklasGustafsson wrote:\r\n\r\nWe should probably track this as an issue with ML.NET, too.\r\n\r\n@tarekgh wrote:\r\n\r\n> We should probably track this as an issue with ML.NET, too.\r\n\r\nYes.\r\n\r\n> Another approach is to rebuild the ML.NET preview with 0.97.0 and pick up the new method definition.\r\n\r\nIs this the same as what I suggested to publish the latest ML.NET to NuGet which will make it works with Torch Sharp 0.97.0? and we recommend users use the latest version of ML.NET.\r\n\r\n@NiklasGustafsson wrote:\r\n\r\n> Is this the same as what I suggested to publish the latest ML.NET to NuGet which will make it works with Torch Sharp 0.97.0? and we recommend users use the latest version of ML.NET.\r\n\r\nNot sure. The issue should only affect binary dependencies, so if ML.NET is rebuilt against 0.97.0, how it is distributed is orthogonal, I believe.\r\n\r\n@tarekgh wrote:\r\n\r\nWhat I meant is update the Torch Sharp version in the file [dotnet/machinelearning@4aad15b/eng/Versions.props#L52](https://github.com/dotnet/machinelearning/blob/4aad15b8f35b94554b2c5f7062d65a71e1b379b0/eng/Versions.props#L52) and then publish the new built ML.NET to NuGet.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6263","RelatedDescription":"Open issue \"Method not found: 'Void Module.train()'.\" (#6263)"},{"Id":"1318475088","IsPullRequest":false,"CreatedAt":"2022-07-26T16:15:18","Actor":"PajLe","Number":"6260","RawContent":null,"Title":"Save IDataView to a database table","State":"open","Body":"I am formatting this issue as a feature suggestion, however, I am also looking for a workaround - a way to do it without implementing this feature suggestion, as I haven't found a solid one yet (referencing to my [SO question][3]).\r\n\r\n## Is your feature request related to a problem? Please describe.\r\nI have a transformed `IDataView` with prediction (`Score`) column, input columns and one-hot encoded columns (working with regression task). I want to save only prediction and input values to a database table (i.e., I want to be able to choose which columns to save). \r\n\r\nMy main obstacle seems to be not having a class ([POCO][1]) representing the structure of the db model, but the main issue (trying to avoid the [XY problem][5]) seems to be not having a convenient way to save it to a table (like [there is for a text file][7] for example).\r\n\r\n## Describe the solution you'd like\r\nAn ideal experience would be something like\r\n```c#\r\nIDataView.SaveToDatabase(/*db connection/connection string*/, /*list of columns*/)\r\n```\r\nor\r\n```c#\r\nmlContext.Data.SaveToDatabase(IDataView, /*db connection/connection string*/, /*list of columns*/)\r\n```\r\nand possibly without loading the data into memory to be able to handle large data sets.\r\n\r\nA less ideal solution would be create an extension to `DataFrame` for the same functionality - something similar to [pandas.DataFrame.to_sql][4]. So the user experience would be:\r\n```c#\r\nIDataView predictions = trainedModel.Transform(...);\r\nvar df = predictions.ToDataFrame(...);\r\ndf.ToSql(/*db connection/connection string*/, /*list of columns*/, /*possibly other parameters*/)\r\n```\r\n\r\nAdditional convenience (although this could be considered a completely separate feature):\r\nMy `IDataView` is transformed using one-hot encoding, but I want to write the original input values to a db table. I couldn't leave the same column names for the output after transformation (i.e., I had to do `new InputOutputColumnPair(col.Name + \"_onehot\", col.Name)`) because the input columns would then be hidden, and I couldn't easily get their value. It would be nice to have a way to do this without renaming the transformed columns i.e., something like\r\n```c#\r\nIDataView predictions = ...\r\nvar columns = predictions.InputColumns + prediction.ScoreColumn \r\n/* returns a list of columns, where \r\nInputColumns are the original columns without transformation, \r\nScoreColumn are the predicted values, \r\nThe plus operator means appending to the list \r\n*/\r\npredictions.SaveToDb(... , columns)\r\n```\r\nI am aware of the [SchemaAnnotationsExtensions.GetSlotNames][6] but that doesn't seem to cover my use-case conveniently.\r\n\r\n## Describe alternatives you've considered\r\n<details> \r\n  <summary>1. Create an `IEnumerable` from `IDataView` and write that to the DB</summary>\r\n\r\nI used \r\n```c#\r\nIEnumerable<SomeType> predictionsEnumerable = \r\n    mlContext.Data.CreateEnumerable<SomeType>(predictions, reuseRowObject: true);\r\n```\r\nin order to try and write it to a DB table. \r\nFirst problem is that I don't have the `SomeType`. I tried using `dynamic` or `object`, but neither of them work - possibly related to\r\n- #3829\r\n- #5895 (although this one is for creating the IDataView, which wasn't a problem for me)\r\n(probably unrelevant) I also tried reflection but I didn't manage to make anything work .\r\n\r\nSecond problem is that even when I have the `SomeType`, I only managed to write it with Dapper converting the `IEnumerable` to a list. Without that I usually get the error\r\n`The incoming tabular data stream (TDS) remote procedure call (RPC) protocol stream is incorrect. Parameter 4 (\"\"): Data type 0x40 is unknown.`\r\n</details>\r\n\r\n<details>\r\n  <summary>2. Convert `IDataView` to `DataFrame` and write that to DB</summary>\r\n\r\nI used \r\n```c#\r\nvar df = predictions.ToDataFrame(long.MaxValue, columns.ToArray());\r\n```\r\nto create a `DataFrame` and tried to write that to the DB. I didn't manage to find a nice solution.\r\n</details>\r\n\r\n<details>\r\n  <summary>3. Manual type mapping</summary>\r\n\r\nTried to manually check the column type and get its value with the appropriate `ValueGetter<>`, to later convert it to a row and save it to a db table. I later saw that `.ToDataFrame(...)` does something similar, although much better in every aspect. Still, I failed to use the result  in combination with Dapper to insert it into a table (in my case, I failed to make a use of the `rows` list). This also takes too much memory (didn't go too much into details, but around 2.5GB (half of it is \"just my code\") was on the heap, and 5.1GB of RAM taken). Compared to converting it to a `DataFrame` which takes just 1.1GB of RAM, (didn't check the heap). I assume my solution could be optimized, but that's not the point here.\r\n\r\n```c#\r\n\r\ncolumns = // list of columns\r\nIDataView predictions = ...\r\n\r\nIEnumerable<DataViewSchema.Column> dvColumns = columns.Select(col => predictions.Schema[col]);\r\nIList<object> rows = new List<object>();\r\nusing (var cursor = predictions.GetRowCursor(dvColumns))\r\n{\r\n    Dictionary<string, ValueGetter<ReadOnlyMemory<char>>> colGettersString = new();\r\n    Dictionary<string, ValueGetter<float>> colGettersSingle = new();\r\n    foreach (var col in dvColumns)\r\n    {\r\n        var colType = col.Type.RawType;\r\n        if (col.Type.RawType == typeof(ReadOnlyMemory<char>))\r\n        {\r\n            colGettersString.Add(col.Name, cursor.GetGetter<ReadOnlyMemory<char>>(col));\r\n        }\r\n\r\n        if (col.Type.RawType == typeof(float))\r\n        {\r\n            colGettersSingle.Add(col.Name, cursor.GetGetter<float>(col));\r\n        }\r\n    }\r\n\r\n    while (cursor.MoveNext())\r\n    {\r\n        ExpandoObject colValues = new(); // could use a regular dictionary here\r\n        foreach (var col in dvColumns)\r\n        {\r\n            ReadOnlyMemory<char> colValueString = default;\r\n            float colValueFloat = default;\r\n\r\n            if (colGettersString.ContainsKey(col.Name))\r\n                colGettersString[col.Name](ref colValueString);\r\n            else if (colGettersSingle.ContainsKey(col.Name))\r\n                colGettersSingle[col.Name](ref colValueFloat);\r\n\r\n            string colValueStringString = colValueString.ToString();\r\n            if (string.IsNullOrEmpty(colValueStringString))\r\n                colValues.TryAdd(col.Name, colValueFloat);\r\n            else\r\n                colValues.TryAdd(col.Name, colValueStringString);\r\n        }\r\n\r\n        rows.Add(colValues);\r\n    }\r\n}\r\n```\r\n</details>\r\n\r\n<details>\r\n  <summary>4. Some other ideas</summary>\r\n\r\n**Using 3. and converting to JSON**\r\nThis seems to be like one of the workarounds, which I didn't complete. The idea is to take `rows` list from 3. and convert it to JSON. Then, manipulate the JSON through SQL, which I gave up on as it seems too complicated. This also uses more memory as the JSON can be a large string with a lot of data.\r\n\r\n**Using reflection Emit**\r\nCreate a class dynamically and use that to create a db model class, to be used in `CreateEnumerable`. I'm not sure how this works or if it is possible.\r\n</details>\r\n\r\n\r\n\r\n## Additional context\r\n\r\n- I am trying to insert data with Dapper into a SQL Server db\r\n- Using .NET 6\r\n- I am working with ~5 million rows of data with 5 columns\r\n\r\n  [1]: https://en.wikipedia.org/wiki/Plain_old_CLR_object\r\n  [2]: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.dataviewschema?view=ml-dotnet\r\n  [3]: https://stackoverflow.com/questions/73080930/save-ml-net-idataview-to-a-database-table-without-poco\r\n  [4]: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\r\n  [5]: https://en.wikipedia.org/wiki/XY_problem\r\n  [6]: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.data.schemaannotationsextensions.getslotnames?view=ml-dotnet\r\n  [7]: https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.textloadersavercatalog.saveastext?view=ml-dotnet","Url":"https://github.com/dotnet/machinelearning/issues/6260","RelatedDescription":"Open issue \"Save IDataView to a database table\" (#6260)"},{"Id":"1316641177","IsPullRequest":false,"CreatedAt":"2022-07-25T10:54:23","Actor":"derekdiamond","Number":"6258","RawContent":null,"Title":"Model.Transform returns results in different order than the input DataView","State":"open","Body":"**System Information (please complete the following information):**\r\nWindows 11\r\nML.NET 1.70\r\n.NET 4.8\r\n\r\n**Describe the bug**\r\n\r\nI have the following code:\r\n\r\n                var res = Model.Transform(dataView);\r\n                var resSchema = res.Schema;\r\n                var resCsr = res.GetRowCursor(resSchema);\r\n\r\nWhen stepping through the result cursor the order of the results does not match the input order of the dataview. I need them in order so that I can match with the original dataset.\r\n\r\nAs a work around I am doing the transform one by one, that is creating dataviews that return one row, so it can easily then match to the input dataset. However this is very very slow, taking half an hour to transform 2000 records.\r\n\r\nI either need a mechanism to pass a key value per record that is passed through the transform, without it being used in the training process.\r\n \r\n**To Reproduce**\r\nCreate a regression model on a simple set of data say some random values x,y, x + 2 * y.\r\nThen create a test set of x,y's containing say 50 records. Then do a transform on the dataview and then traverse the result cursor and see that the x,y's are returned in a different order. However the first record always comes through first. Subsequent records come back in some random order.\r\n\r\n**Expected behavior**\r\n\r\nReturned records from the result cursor should come through in the same order as the input dataview, or have a way to identify what record in the source the result record comes from. Note: trying to match on the input record column values could possibly be done, but the floating point values may not match exactly due to conversions from double to float and if there are many columns this becomes a slow process.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6258","RelatedDescription":"Open issue \"Model.Transform returns results in different order than the input DataView\" (#6258)"},{"Id":"1310481162","IsPullRequest":true,"CreatedAt":"2022-07-22T21:40:08","Actor":"feiyun0112","Number":"6255","RawContent":null,"Title":"fix Dead link in FastTreeRegressionTrainerClass Documentation","State":"closed","Body":"#6254","Url":"https://github.com/dotnet/machinelearning/pull/6255","RelatedDescription":"Closed or merged PR \"fix Dead link in FastTreeRegressionTrainerClass Documentation\" (#6255)"},{"Id":"1311850878","IsPullRequest":false,"CreatedAt":"2022-07-20T20:22:32","Actor":"luisquintanilla","Number":"6256","RawContent":null,"Title":"[Azure ML] Azure training environment for supported training scenarios","State":"closed","Body":"Currently in Model Builder, we support the following scenarios and environments:\r\n\r\n| Scenarios | Local | Azure |\r\n| --- | --- | --- |\r\n| Data classification | ✅ | ❌|\r\n| Value Prediction | ✅ | ❌|\r\n| Recommendation | ✅ | ❌|\r\n| Forecasting | ✅ | ❌|\r\n| Image classification | ✅ | ✅ |\r\n| Object detection | ❌| ✅ |\r\n\r\n\r\nEnable Azure as a training environment for all supported scenarios:\r\n\r\n- [ ] Data classification\r\n- [ ] Value prediction\r\n- [ ] Recommendation\r\n- [ ] Forecasting","Url":"https://github.com/dotnet/machinelearning/issues/6256","RelatedDescription":"Closed issue \"[Azure ML] Azure training environment for supported training scenarios\" (#6256)"}],"ResultType":"GitHubIssue"}},"RunOn":"2022-08-17T03:30:22.6732936Z","RunDurationInMilliseconds":555}