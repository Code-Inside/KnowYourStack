{"Data":{"GitHub":{"Issues":[{"Id":"1075435514","IsPullRequest":false,"CreatedAt":"2021-12-09T10:57:39","Actor":"torronen","Number":"6021","RawContent":null,"Title":"Question: Re-train a model: should I feed all data or only the new one?","State":"open","Body":"I am trying online learning based on https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net\r\n\r\nIs it expected to send all relevant data for re-training, or should I only send a the new data, or even just a single new observation?\r\n\r\n\r\nBackground:\r\n1. Model makes predictions based on initial learning data\r\n2. User corrects wrong predictions based on his needs and preferences. This data becomes now additional training data.\r\nNote: it might be that user only corrects one more observation.\r\n\r\nDoes re-train only expect new data from step (2) or should I send initial training data with the new data (1) + (2)?\r\n\r\nIf no clear anwer then I probably need to do some experimentation but it seems complex and compute-intensive to get reliable results.","Url":"https://github.com/dotnet/machinelearning/issues/6021","RelatedDescription":"Open issue \"Question: Re-train a model: should I feed all data or only the new one?\" (#6021)"},{"Id":"1075414721","IsPullRequest":false,"CreatedAt":"2021-12-09T10:35:24","Actor":"niyazidageek","Number":"6020","RawContent":null,"Title":"CLI with SQL Database","State":"open","Body":"When using Model Builder via Graphical User Interface in Visual Studio 2019 on Windows, one is able to read data straight from SQL Database, however there is no such possibility when creating a Model Builder via CLI. Please, consider this. Thank you in advance!\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6020","RelatedDescription":"Open issue \"CLI with SQL Database\" (#6020)"},{"Id":"1075386570","IsPullRequest":true,"CreatedAt":"2021-12-09T10:07:18","Actor":"naphtalidavies","Number":"6019","RawContent":null,"Title":"Training","State":"open","Body":"We are excited to review your PR.\r\n\r\nSo we can do the best job, please check:\r\n\r\n- [ ] There's a descriptive title that will make sense to other developers some time from now. \r\n- [ ] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [ ] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [ ] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6019","RelatedDescription":"Open PR \"Training\" (#6019)"},{"Id":"1074416869","IsPullRequest":true,"CreatedAt":"2021-12-08T13:33:09","Actor":"Srujana-Oruganti","Number":"6018","RawContent":null,"Title":"Basic Agglomerative clustering implementation  #5725","State":"open","Body":" #5725\r\nBasic Agglomerative clustering implementation:\r\n1. Implement basic agglomerative clustering.\r\n2. Distance measure is Euclidean distance.\r\n3. Included 3 Linkage Criteria implementations : Single Link, Complete Link, Average Link.\r\n4. Simple testcase\r\n\r\nToDo:\r\n1. Implement other Linkage Criteria like: Ward, Centriod based linkage.\r\n2. Add support for other distance metrics.\r\n2. Implement agglomerative clustering using efficient heap based approach.\r\n3. Implement model saving and reloading.\r\n4. Implement visualization of dendrogram.\r\n5. Implement cluster prediction capability.\r\n6. Include more test cases.\r\n7. Refactor common code for different Clustering projects to a common project.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6018","RelatedDescription":"Open PR \"Basic Agglomerative clustering implementation  #5725\" (#6018)"},{"Id":"1074125140","IsPullRequest":false,"CreatedAt":"2021-12-08T08:10:06","Actor":"gkukucska91","Number":"6017","RawContent":null,"Title":"Problems with convolutional neural networks loaded from Keras model","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: 1.6.0\r\n - .NET Version: .NET Framework 4.7.1\r\n\r\n**Describe the bug**\r\nWhen attempting to load convolutional neural networks, with a non predetermined size required for input (*,*,1 size), we encounter the following problems:\r\n- When we attempt to run the network on a (n,1,1) sized input, only n values which are dividable by 4 are accepted, although the network should be capable of processing such an input, the following exception is thrown:\r\n`System.InvalidOperationException: 'Input shape mismatch: Input 'serving_default_input_6' has shape (None, None, 1), but input data is of length 257.`\r\n\r\n\r\n- Even when the input is accepted, the results are not equivalent to the ones resulted from keras, seemingly smaller parts of the input is considered input for the network (see later in screenshots)\r\n\r\n**Expected behavior**\r\nSame behaviour to the Keras environment\r\n\r\n**Screenshots, Code, Sample Projects**\r\nCode for reproduction of the bugs:\r\n\r\n```C#\r\nusing System;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System.IO;\r\n\r\nnamespace KerasMLNET_demo\r\n{\r\n    class Program\r\n    {\r\n        static void Main(string[] args)\r\n        {\r\n\r\n            //loading the trained model\r\n            string modellocation = @\"./model/noisefilter\";\r\n            var mlContext = new MLContext();\r\n            using var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(modellocation);\r\n            var inputschema = tensorFlowModel.GetInputSchema();\r\n            var inputlayer_ID = inputschema[0].Name;\r\n\r\n            //generating input data:\r\n            var rand = new Random();\r\n            float[] inputdata = new float[256];\r\n            for (int i = 0; i < inputdata.Length; i++)\r\n            {\r\n                inputdata[i] = (float)(rand.NextDouble() + 25*Math.Exp(-0.025*((128.0 - i) * (128.0 - i))));\r\n            }\r\n            File.WriteAllLines(\"input.csv\", inputdata.Select(d => d.ToString(System.Globalization.CultureInfo.CreateSpecificCulture(\"en-US\"))));\r\n            var datalist = new SpectrumCollection[]\r\n            {\r\n                new SpectrumCollection(){Spectrum = inputdata }\r\n            };\r\n            var dataView = mlContext.Data.LoadFromEnumerable<SpectrumCollection>(datalist);\r\n\r\n\r\n            //generating ML model from the keras network\r\n            var pipeline = mlContext.Transforms.CopyColumns(inputlayer_ID, \"Spectrum\").Append(tensorFlowModel.ScoreTensorFlowModel(\"StatefulPartitionedCall\", inputlayer_ID)).Append(mlContext.Transforms.CopyColumns(\"Spectrum\", \"StatefulPartitionedCall\"));\r\n            ITransformer model = pipeline.Fit(dataView);\r\n            var engine = mlContext.Model.CreatePredictionEngine<SpectrumCollection, SpectrumCollection>(model);\r\n            // Predict with TensorFlow pipeline.\r\n            SpectrumCollection prediction;\r\n            float[] PredSpectrum;\r\n            datalist[0].Spectrum = inputdata;\r\n            prediction = engine.Predict(datalist[0]);\r\n            PredSpectrum = prediction.Spectrum;\r\n            File.WriteAllLines(\"prediction.csv\", PredSpectrum.Select(d => d.ToString(System.Globalization.CultureInfo.CreateSpecificCulture(\"en-US\"))));\r\n        }\r\n\r\n        public class SpectrumCollection\r\n        {\r\n            [VectorType(256, 1, 1)]\r\n            [ColumnName(\"Spectrum\")]\r\n            public float[] Spectrum { get; set; }\r\n        }\r\n\r\n    }\r\n}\r\n```\r\nScreenshot with expected results:\r\n\r\n\r\n![pythonVSmlnet](https://user-images.githubusercontent.com/95739641/145171969-f2ed4a87-b252-4de3-a0df-281a71ad8f52.png)\r\n\r\nModel for reproduction:\r\n\r\n[model.zip](https://github.com/dotnet/machinelearning/files/7674358/model.zip)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6017","RelatedDescription":"Open issue \"Problems with convolutional neural networks loaded from Keras model\" (#6017)"},{"Id":"1072088355","IsPullRequest":false,"CreatedAt":"2021-12-06T12:20:40","Actor":"anunakkiSelva","Number":"6016","RawContent":null,"Title":"MS Document referencing ML v1.6.0 but the latest nuget version is v1.7.0 ,  Document Misleading .  https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml?view=ml-dotnet","State":"open","Body":"\r\n[Enter feedback here]\r\n\r\n\r\n---\r\n#### Document Details\r\n\r\n⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.*\r\n\r\n* ID: 42959613-fbc6-a84e-149a-667e551cc361\r\n* Version Independent ID: 6b1d75df-a911-5e41-120b-da824f003497\r\n* Content: [TimeSeriesCatalog.DetectIidSpike Method (Microsoft.ML)](https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml.timeseriescatalog.detectiidspike?view=ml-dotnet)\r\n* Content Source: [dotnet/xml/Microsoft.ML/TimeSeriesCatalog.xml](https://github.com/dotnet/ml-api-docs/blob/live/dotnet/xml/Microsoft.ML/TimeSeriesCatalog.xml)\r\n* Product: **dotnet-ml-api**\r\n* GitHub Login: @natke\r\n* Microsoft Alias: **nakersha**","Url":"https://github.com/dotnet/machinelearning/issues/6016","RelatedDescription":"Open issue \"MS Document referencing ML v1.6.0 but the latest nuget version is v1.7.0 ,  Document Misleading .  https://docs.microsoft.com/en-us/dotnet/api/microsoft.ml?view=ml-dotnet\" (#6016)"},{"Id":"1071798420","IsPullRequest":false,"CreatedAt":"2021-12-06T07:02:44","Actor":"chasse20","Number":"6015","RawContent":null,"Title":"ML.NET Containerized GPU Support?","State":"open","Body":"**System Information (please complete the following information):**\r\n- Windows 10 (Insider Program with 21H2 preview per Nvidia instructions)\r\n- Latest WSL2 via Docker Desktop\r\n- .NET 5 with ASP.NET as a web application as well\r\n- ML.NET 1.7\r\n- Visual Studio 2019\r\n- GeForce 1080 GTX GPU\r\n- CUDA 10.1\r\n\r\n**Describe the bug**\r\nI want to be able to run my ASP app in a Docker container that also trains models. This works fine for everything using base ML.NET nuget for the CPU. I followed the instructions to setup CUDA 10.1 with Cudnn (https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/install-gpu-model-builder) and NVIDIA's instructions for WSL2 (https://docs.nvidia.com/cuda/wsl-user-guide/index.html). I also added a reference to the GPU tensorflow package for Linux (assuming WSL2). The NVIDIA CUDA tests work fine when I run their containers, but I can't get my ML.NET container to work/use the GPU. Running nvidia-smi works in the container itself, but training still uses the CPU. I want to train models in the container using the GPU and have passed \"--gpus all\" in as a docker argument. I've exhausted everything but can't find any documentation or help on achieving this.\r\n\r\nHow would I go about doing this from Visual Studio 2019?\r\n\r\nBelow is my DockerFile (using Debug configuration):\r\n```\r\n#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.\r\n\r\nFROM mcr.microsoft.com/dotnet/aspnet:5.0-buster-slim AS base\r\nWORKDIR /app\r\nEXPOSE 80\r\nEXPOSE 443\r\n\r\nFROM nvidia/cuda:10.1-base as cuda\r\nCMD nvidia-smi\r\n\r\nFROM mcr.microsoft.com/dotnet/sdk:5.0-buster-slim AS build\r\nWORKDIR /src\r\nCOPY [\"CoolNET/CoolNET.csproj\", \"CoolNET/\"]\r\nRUN dotnet restore \"CoolNET/CoolNET.csproj\"\r\nCOPY . .\r\nWORKDIR \"/src/CoolNET\"\r\nRUN dotnet build \"CoolNET.csproj\" -c Debug -o /app/build\r\n\r\nFROM build AS publish\r\nRUN dotnet publish \"CoolNET.csproj\" -c Debug -o /app/publish\r\n\r\nFROM base AS final\r\nWORKDIR /app\r\nCOPY --from=publish /app/publish .\r\nENTRYPOINT [\"dotnet\", \"CoolNET.dll\"]\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6015","RelatedDescription":"Open issue \"ML.NET Containerized GPU Support?\" (#6015)"},{"Id":"1071514206","IsPullRequest":false,"CreatedAt":"2021-12-05T17:32:42","Actor":"jbilbrey","Number":"6014","RawContent":null,"Title":"Consume a tensorflow regression model from .NET","State":"open","Body":"System information\r\n\r\nusing Visual Studio 2022 \r\nPython 3.8.12\r\nTensorflow 2.5\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19043\r\n .NET SDKs installed:\r\n  5.0.400 [C:\\Program Files\\dotnet\\sdk]\r\n  6.0.100 [C:\\Program Files\\dotnet\\sdk]\r\nIssue\r\nI am trying to create a simple end-to-end problem.  I create a simple model in Python and import the saved_model.pb into .NET.  I would like to consume this model.  Please help me by providing the solution that I can solve this problem.\r\n\r\nWhat did you do?\r\nI created a simple Python script in for the data set. Successfuly trained and evaluated the model and then exported it. The model can be loaded but I cannot configure the pipeline to make prediction.\r\nWhat happened?\r\nNow I try to consume the model with ML.NET Console.\r\nWhat did you expect?\r\nCannot consume the model, because not able to create the proper pipeline.\r\n\r\nI included the python script and the .NET program file in this repo.  \r\n[https://github.com/jbilbrey/repo](https://github.com/jbilbrey/repo)\r\n\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System;\r\nusing System.IO;\r\nusing Microsoft.ML.Transforms;\r\nusing System.Linq;\r\n\r\nnamespace TestDeleteMe\r\n{\r\n    class Program\r\n    {\r\n       \r\n        static string dataset = Path.Combine(Directory.GetCurrentDirectory(), \"mpg.txt\");        \r\n        static readonly string _modelPath = Path.Combine(Environment.CurrentDirectory, \"model\");\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            var mlContext = new MLContext();\r\n\r\n            Console.WriteLine(\"The path to the model is... \" + _modelPath.ToString());  // debug only\r\n            //load tensorflow model\r\n            var tensorFlowModel = mlContext.Model.LoadTensorFlowModel(_modelPath);\r\n            \r\n            var schema = tensorFlowModel.GetModelSchema();\r\n            var inputSchema = tensorFlowModel.GetInputSchema();\r\n                               \r\n            Console.WriteLine(\"The data is...\" + inputSchema.ToString());\r\n\r\n            var reader = mlContext.Data.CreateTextLoader(new[] {\r\n                new TextLoader.Column(\"dense_input_1\", DataKind.Single, new[] {new TextLoader.Range(1,9)}),          \r\n            }, separatorChar: '\\t', hasHeader: true);\r\n\r\n            // read the data\r\n            var data = reader.Load(dataset);\r\n\r\n            // print data to screen\r\n            var inputs = mlContext.Data.CreateEnumerable<InputData>(data, reuseRowObject: false).ToArray();\r\n\r\n            // print the data to the console\r\n            for (int i = 0; i < inputs.Length; i++)\r\n            {\r\n                //var predictedLabel = engine.Predict(inputs[i]);\r\n\r\n                for (int j = 0; j < inputs[i].Features.Length; j++)\r\n                {\r\n                    Console.Write(inputs[i].Features[j]);\r\n                    Console.Write(\" \");\r\n                }\r\n                //Console.WriteLine(predictedLabel.Output[0]);\r\n            }\r\n\r\n            ////////////// fit the model /////////////////// NEED HELP HERE to consume/use the model!!!\r\n\r\n            ///var estimator = tensorFlowModel.ScoreTensorFlowModel(\"Predict\", \"dense_input_1\").Fit(data);\r\n\r\n        }\r\n    }\r\n\r\n    class InputData\r\n    {\r\n        [ColumnName(\"dense_input_1\"), VectorType(9)]\r\n        public float[]? Features { get; set; }\r\n    }\r\n\r\n\r\n    class OutputData\r\n    {\r\n        [ColumnName(\"Output\"), VectorType(1)]\r\n        public float[]? Prediction { get; set; }\r\n    }\r\n}\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6014","RelatedDescription":"Open issue \"Consume a tensorflow regression model from .NET\" (#6014)"},{"Id":"1069701242","IsPullRequest":false,"CreatedAt":"2021-12-02T15:47:05","Actor":"torronen","Number":"6013","RawContent":null,"Title":"Suggestion: Set max count for AutoML experiments instead of time","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nSetting time for AutoML for a dataset I dont have previous experience with is not easy. \r\nInstead, I'd like to give SmacSweeper a chance to utilize history of the earlier runs. I believe probably somewhere 20-50 experiments would be adequate, since first 10 are random. \r\n\r\n**Describe the solution you'd like**\r\nAllow setting max iterations, similar to many DL libraries allow settings number of epochs. Possibly with support for early stopping.\r\n\r\n**Additional info**\r\nI think there are not very many occasions where settings the time is important. I can only think of:\r\n- User is waiting for process to finish on a desktop or web app: max few minutes. But, in this case, there is still risk of the experiment completing too early and leading to suboptimal experience for the user.\r\n- Developer wants the run to complete by the time he is back to work next time. For this purpose, manual stopping is better.","Url":"https://github.com/dotnet/machinelearning/issues/6013","RelatedDescription":"Open issue \"Suggestion: Set max count for AutoML experiments instead of time\" (#6013)"},{"Id":"1066954248","IsPullRequest":false,"CreatedAt":"2021-11-30T08:47:18","Actor":"aforoughi1","Number":"6012","RawContent":null,"Title":"FeaturizeText API produces incorrect tokens","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11 \r\n - ML.NET Version: ML.NET v1.7.0\r\n - .NET Version: .NET 5.0\r\n\r\n**Describe the bug**\r\nThe FeaturizeText  API produces incorrect tokens\r\n\r\n**To Reproduce**\r\nApply  mlContext.Transforms.Text.FeaturizeText to the following input data:\r\n\r\n\"There is a shortage of capital and we need extra financing,\" +\r\n\"growth is strong and we have plenty of liquidity,\" +\r\n \"there are doubts about our finances,\" +\r\n\"profits are flat.\"\r\n\r\nUse\r\n\r\nvar options = new TextFeaturizingEstimator.Options()\r\n{\r\n        OutputTokensColumnName = \"OutputTokens\",\r\n\r\n         //Remove the punctuations from the token\r\n         KeepPunctuations = false,\r\n\r\n         // Remove Digits\r\n         KeepNumbers = false,\r\n\r\n        // Make the output character Lower Case\r\n         CaseMode = TextNormalizingEstimator.CaseMode.Lower,\r\n\r\n       // Use ML.NET's built-in stop word remover\r\n        StopWordsRemoverOptions = new StopWordsRemovingEstimator.Options()\r\n        {\r\n               Language = TextFeaturizingEstimator.Language.English\r\n        },\r\n\r\n                    \r\n        // Produces a bag of counts of ngrams(sequences of consecutive words) in a given text.\r\n        WordFeatureExtractor = new WordBagEstimator.Options()\r\n         {\r\n                 NgramLength = 2,\r\n                  UseAllLengths = true\r\n         },\r\n\r\n\r\n          CharFeatureExtractor = null\r\n    };\r\n\r\n\r\n**Expected behavior**\r\nI expected the tokens output to be\r\n\r\nshortage,capital,need,extra,financing,growth,strong,plenty,liquidity,doubts,finances,profits,flat\r\n\r\nhowever, I get\r\n\r\nNumber of Features: 21\r\nFeatures: 0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182  0.2182\r\nTokens: shortage,capital,need,extra,financinggrowth,strong,plenty,liquiditythere,doubts,financesprofits,flat\r\n\r\nThe incorrect tokens are:\r\nfinancinggrowth\r\nfinancesprofits\r\n\r\n\r\n**Screenshots, Code, Sample Projects**\r\n\r\nvar samples = new List<TextData>()\r\n            {\r\n                new TextData() { Text = \"There is a shortage of capital and we need extra financing,\" +\r\n                                \"growth is strong and we have plenty of liquidity,\" +\r\n                                \"there are doubts about our finances,\" +\r\n                                \"profits are flat.\" }\r\n            };\r\n\r\nvar dataview = mlContext.Data.LoadFromEnumerable(samples);\r\nstring outputColumnName = \"Features\";\r\nstring inpuColumnName = \"Text\";\r\nvar textPipeline = mlContext.Transforms.Text.FeaturizeText(outputColumnName, Settings, inpuColumnName);\r\nvar textTransformer = textPipeline.Fit(dataview);\r\n\r\nuse the Settings as provided and  create a prdiction enginee\r\n\r\n\r\n**Additional context**\r\nN/A\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6012","RelatedDescription":"Open issue \"FeaturizeText API produces incorrect tokens\" (#6012)"},{"Id":"1066411010","IsPullRequest":false,"CreatedAt":"2021-11-29T21:16:31","Actor":"atkinsonbg","Number":"6011","RawContent":null,"Title":"LoadRawImageBytes does not load anything","State":"closed","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n    - Tested on MacOS 11.6 Big Sur & Windows 11\r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n    - ML.NET v1.7.0\r\n - .NET Version: [e.g. .NET 5.0]\r\n    - .NET 6.0\r\n\r\n**Describe the bug**\r\nFollowing the tutorial list here, (https://docs.microsoft.com/en-us/samples/dotnet/machinelearning-samples/mlnet-image-classification-transfer-learning/) and the LoadRawImageBytes does not appear to load images from the directory.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\nCode used:\r\n```\r\nIEnumerable<ImageData> images = LoadImagesFromCsv(\"Data/training_data.csv\");\r\n\r\n            IDataView imageData = mlContext.Data.LoadFromEnumerable(images);\r\n            IDataView shuffledData = mlContext.Data.ShuffleRows(imageData, shuffleSource: true);\r\n\r\n            var previewshuffledData = shuffledData.Preview();\r\n\r\n            var preprocessingPipeline = mlContext.Transforms.Conversion\r\n                                                .MapValueToKey(\r\n                                                    inputColumnName: \"Label\",\r\n                                                    outputColumnName: \"LabelAsKey\")\r\n                                                .Append(mlContext.Transforms.LoadRawImageBytes(\r\n                                                    outputColumnName: \"Image\",\r\n                                                    imageFolder: \"Data/LocalImages\",\r\n                                                    inputColumnName: \"ImagePath\"));\r\n\r\n            IDataView preProcessedData = preprocessingPipeline\r\n                    .Fit(shuffledData)\r\n                    .Transform(shuffledData);\r\n\r\n            var previewPreprocessedData = preProcessedData.Preview();\r\n```\r\n**previewshuffledData**:\r\n<img width=\"520\" alt=\"Screen Shot 2021-11-29 at 2 21 21 PM\" src=\"https://user-images.githubusercontent.com/29587193/143929508-5492872f-e716-480f-b894-db5db2814e71.png\">\r\n\r\n<img width=\"351\" alt=\"Screen Shot 2021-11-29 at 2 21 41 PM\" src=\"https://user-images.githubusercontent.com/29587193/143929533-07f3190c-ebc3-4f7b-9773-ede190bba339.png\">\r\n\r\n**previewPreprocessedData**:\r\n<img width=\"570\" alt=\"Screen Shot 2021-11-29 at 2 21 50 PM\" src=\"https://user-images.githubusercontent.com/29587193/143929573-e441ae02-3743-44c3-a407-c97280a669eb.png\">\r\n\r\n**Expected behavior**\r\nExpecting to see a RowView after LoadRawImageBytes of 63, which matches the number of images in the dataset.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6011","RelatedDescription":"Closed issue \"LoadRawImageBytes does not load anything\" (#6011)"},{"Id":"1064853383","IsPullRequest":false,"CreatedAt":"2021-11-26T23:27:23","Actor":"CBrauer","Number":"6010","RawContent":null,"Title":"How can I warm-start a Fast Tree Classifier?","State":"open","Body":"Hey Guys,\r\n\r\nI have found that the Fast Tree trainer works best on my tabular dataset.\r\nPlease show me how to warm start the trainer. \r\nIf this capability does not exist, can you please add it to the new feature wish list.\r\n\r\nThanks\r\nCharles","Url":"https://github.com/dotnet/machinelearning/issues/6010","RelatedDescription":"Open issue \"How can I warm-start a Fast Tree Classifier?\" (#6010)"},{"Id":"1063427640","IsPullRequest":false,"CreatedAt":"2021-11-25T10:47:56","Actor":"torronen","Number":"6009","RawContent":null,"Title":"LightGBMBinary sometimes throws \"Splitter/consolidator worker encountered exception while consuming source data\"","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows Server 2022 Preview\r\n - ML.NET Version: ML.NET 1.6 (custom build, but no changes on text loading)\r\n - .NET Version: NET 5.0\r\n\r\n**Describe the bug**\r\nI have a dataset which I am training on FastTree, FastForest and LightGBM with AutoML.\r\nLightGBM sometimes throws the below exception about boolean field IsPublicHoliday. Error claims it to have a number value (e.g. 3.208). It would indicate the dataset is not correct. However, I do not receive this exception on all runs of LightGBM, never on FastForest and FastTree. (FastForest and FastTree are running on another similar server).\r\n\r\n```\r\nException during AutoML iteration: System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.InvalidOperationException: Could not parse value 3.20852317 in line 1786829, column DtIsPublicHoliday\r\n```\r\n\r\n**To Reproduce**\r\nIt may be related to the specific 120GB dataset. I will update here if I find the cause. \r\n\r\n**Expected behavior**\r\nI expect either the parse error should happen on every run and every algorithm, or it should not happen at all.\r\n\r\n\r\n**Additional context**\r\n\r\n```\r\n|     Trainer                               PosPrec   PosReca  Accuracy      AUC    AUPRC  F1-score  Duration  MaxPosPr|\r\n|1    LightGbmBinary                         0.5340    0.5108    0.5339   0.5516   0.5400    0.5222    1731.1    0.5340|\r\n|2    LightGbmBinary                         0.5190    0.4807    0.5190   0.5343   0.5316    0.4991    2772.3    0.5340|\r\n|3    LightGbmBinary                         0.5335    0.5150    0.5336   0.5554   0.5410    0.5241    7007.1    0.5340|\r\n|4    LightGbmBinary                         0.0000    0.0000    0.5014   0.5132   0.5072    0.0000    1202.4    0.5340|\r\n|5    LightGbmBinary                         0.5278    0.4959    0.5274   0.5467   0.5368    0.5114    3865.4    0.5340|\r\nException during AutoML iteration: System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.InvalidOperationException: Could not parse value 3.20852317 in line 1786829, column DtIsPublicHoliday\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessOne(FieldSet vs, ColInfo info, ColumnPipe v, Int32 irow, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1463\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessItems(RowSet rows, Int32 irow, Boolean[] active, FieldSet fields, Int32 srcLim, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1381\r\n   at Microsoft.ML.Data.TextLoader.Parser.ParseRow(RowSet rows, Int32 irow, Helper helper, Boolean[] active, String path, Int64 line, String text) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 888\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParseSequential()+MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 345\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 298\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass7_1.<ConsolidateCore>b__2() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 426\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 832\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 1101\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerUtils.cs:line 549\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadDataset(IChannel ch, Factory factory, Dataset dataset, Int32 numRow, Int32 batchSize, CategoricalMetaData catMetaData) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 964\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 591\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 386\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 158\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorChain.cs:line 68\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String groupId, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.AutoML\\Experiment\\Runners\\RunnerUtil.cs:line 52\r\nException during AutoML iteration: System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.InvalidOperationException: Could not parse value 17 in line 9976, column DtIsPublicHoliday\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessOne(FieldSet vs, ColInfo info, ColumnPipe v, Int32 irow, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1463\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessItems(RowSet rows, Int32 irow, Boolean[] active, FieldSet fields, Int32 srcLim, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1381\r\n   at Microsoft.ML.Data.TextLoader.Parser.ParseRow(RowSet rows, Int32 irow, Helper helper, Boolean[] active, String path, Int64 line, String text) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 888\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParseSequential()+MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 345\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 298\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass7_1.<ConsolidateCore>b__2() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 426\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 832\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 1101\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerUtils.cs:line 549\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.MoveMany(FloatLabelCursor cursor, Int64 count) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 734\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.CreateDatasetFromSamplingData(IChannel ch, Factory factory, Int32 numRow, String param, Single[] labels, Single[] weights, Int32[] groups, CategoricalMetaData catMetaData, Dataset& dataset) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 836\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 591\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 386\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 158\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorChain.cs:line 68\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String groupId, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.AutoML\\Experiment\\Runners\\RunnerUtil.cs:line 52\r\n|8    LightGbmBinary                         0.5324    0.5304    0.5336   0.5537   0.5454    0.5314    2662.2    0.5340|\r\n|9    LightGbmBinary                         0.0000    0.0000    0.5014   0.5133   0.5082    0.0000    1494.9    0.5340|\r\nException during AutoML iteration: System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.InvalidOperationException: Could not parse value 1.0124658 in line 471358, column DtIsPublicHoliday\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessOne(FieldSet vs, ColInfo info, ColumnPipe v, Int32 irow, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1463\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessItems(RowSet rows, Int32 irow, Boolean[] active, FieldSet fields, Int32 srcLim, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1381\r\n   at Microsoft.ML.Data.TextLoader.Parser.ParseRow(RowSet rows, Int32 irow, Helper helper, Boolean[] active, String path, Int64 line, String text) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 888\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParseSequential()+MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 345\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 298\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass7_1.<ConsolidateCore>b__2() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 426\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 832\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 1101\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerUtils.cs:line 549\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadDataset(IChannel ch, Factory factory, Dataset dataset, Int32 numRow, Int32 batchSize, CategoricalMetaData catMetaData) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 964\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 591\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 386\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 158\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorChain.cs:line 68\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String groupId, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.AutoML\\Experiment\\Runners\\RunnerUtil.cs:line 52\r\n|11   LightGbmBinary                         0.5285    0.4064    0.5233   0.5404   0.5293    0.4595    3290.4    0.5340|\r\nException during AutoML iteration: System.InvalidOperationException: Splitter/consolidator worker encountered exception while consuming source data\r\n ---> System.InvalidOperationException: Could not parse value 0.99942851 in line 1691779, column DtIsPublicHoliday\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessOne(FieldSet vs, ColInfo info, ColumnPipe v, Int32 irow, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1463\r\n   at Microsoft.ML.Data.TextLoader.Parser.ProcessItems(RowSet rows, Int32 irow, Boolean[] active, FieldSet fields, Int32 srcLim, Int64 line) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 1381\r\n   at Microsoft.ML.Data.TextLoader.Parser.ParseRow(RowSet rows, Int32 irow, Helper helper, Boolean[] active, String path, Int64 line, String text) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderParser.cs:line 888\r\n   at Microsoft.ML.Data.TextLoader.Cursor.ParseSequential()+MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 345\r\n   at Microsoft.ML.Data.TextLoader.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\Text\\TextLoaderCursor.cs:line 298\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.<>c__DisplayClass7_1.<ConsolidateCore>b__2() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 426\r\n   --- End of inner exception stack trace ---\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 832\r\n   at Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Data\\DataViewUtils.cs:line 1101\r\n   at Microsoft.ML.Data.RootCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Core\\Data\\RootCursorBase.cs:line 72\r\n   at Microsoft.ML.Trainers.TrainingCursorBase.MoveNext() in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerUtils.cs:line 549\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.MoveMany(FloatLabelCursor cursor, Int64 count) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 734\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.CreateDatasetFromSamplingData(IChannel ch, Factory factory, Int32 numRow, String param, Single[] labels, Single[] weights, Int32[] groups, CategoricalMetaData catMetaData, Dataset& dataset) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 836\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.LoadTrainingData(IChannel ch, RoleMappedData trainData, CategoricalMetaData& catMetaData) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 591\r\n   at Microsoft.ML.Trainers.LightGbm.LightGbmTrainerBase`4.TrainModelCore(TrainContext context) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.LightGbm\\LightGbmTrainerBase.cs:line 386\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\Training\\TrainerEstimatorBase.cs:line 158\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.Data\\DataLoadSave\\EstimatorChain.cs:line 68\r\n   at Microsoft.ML.AutoML.RunnerUtil.TrainAndScorePipeline[TMetrics](MLContext context, SuggestedPipeline pipeline, IDataView trainData, IDataView validData, String groupId, String labelColumn, IMetricsAgent`1 metricsAgent, ITransformer preprocessorTransform, FileInfo modelFileInfo, DataViewSchema modelInputSchema, IChannel logger) in Q:\\git-kwork-microsoft-ml\\Microsoft.ML\\src\\Microsoft.ML.AutoML\\Experiment\\Runners\\RunnerUtil.cs:line 52\r\n|13   LightGbmBinary                         0.5416    0.3927    0.5315   0.5506   0.5405    0.4553    2007.7    0.5416|\r\n|14   LightGbmBinary                         0.0000    0.0000    0.5014   0.5133   0.5048    0.0000    1496.5    0.5416|\r\n|15   LightGbmBinary                         0.5472    0.4911    0.5437   0.5655   0.5480    0.5176    4147.1    0.5472|\r\n\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6009","RelatedDescription":"Open issue \"LightGBMBinary sometimes throws \"Splitter/consolidator worker encountered exception while consuming source data\"\" (#6009)"},{"Id":"1059206306","IsPullRequest":false,"CreatedAt":"2021-11-20T18:48:30","Actor":"dharmatech","Number":"6008","RawContent":null,"Title":"Add the equivalent of pandas.DataFrame.shift","State":"open","Body":"# Documentation\r\n\r\nDocumentation and examples of `shift`:\r\n\r\nhttps://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html\r\n\r\nI posted a question on stackoverflow about `shift` here:\r\n\r\nhttps://stackoverflow.com/questions/70042849/equivalent-of-shift-from-pandas\r\n\r\nI also posted an answer that illustrates a very kludgy workaround. :-)","Url":"https://github.com/dotnet/machinelearning/issues/6008","RelatedDescription":"Open issue \"Add the equivalent of pandas.DataFrame.shift\" (#6008)"},{"Id":"1058427794","IsPullRequest":false,"CreatedAt":"2021-11-19T11:27:54","Actor":"dsavch","Number":"6007","RawContent":null,"Title":"Multiclass text classification: training consume a lot of RAM","State":"open","Body":"[ds example.txt](https://github.com/dotnet/machinelearning/files/7569870/ds.example.txt)\r\n### System information\r\n\r\n- **Windows 10 Home Single Language**\r\n- **.NET Version 5.0.400**\r\n- **Microsoft.ML 1.6.0**\r\n\r\n### Issue\r\n\r\nI'm trying to train model with some dataset. Dataset is about 60 Mb (example in attachments, can't provide full data set because of privacy). It contains some text descriptions about 50-200 chars in each row. Total labels count - 84. There are about 100K rows in dataset for training. After 16-18 hours of training application consume about 32 Gb RAM and terminate with System.OutOfMemory exception (I have only 32 Gb free RAM on my PC). Is this RAM consumption is ok for such kind of task or maybe I'm doing something wrong?\r\n\r\n### Source code / logs\r\nMy data class:\r\n```csharp\r\npublic class SkuInfo\r\n{\r\n  [ColumnName(\"Category\")]\r\n  public string CategoryCode { get; set; }\r\n  \r\n  [ColumnName(\"ManufacturerId\")]\r\n  public float ManufacturerId { get; set; }\r\n  \r\n  [ColumnName(\"ManufacturerPn\")]\r\n  public string ManufacturerPn { get; set; }\r\n  \r\n  [ColumnName(\"Description\")]\r\n  public string Description { get; set; }\r\n}\r\n```\r\n\r\nMy trainig pipeline:\r\n```csharp\r\nprivate IEstimator<ITransformer> BuildPipeline(MLContext mlContext)\r\n{\r\n\tvar pipeline = mlContext.Transforms.ReplaceMissingValues(@\"ManufacturerId\", @\"ManufacturerId\")\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Text.FeaturizeText(@\"ManufacturerPn\", @\"ManufacturerPn\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Text.FeaturizeText(@\"Description\", @\"Description\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Concatenate(@\"Features\", new[] { @\"ManufacturerId\", \"ManufacturerPn\", @\"Description\" }))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Conversion.MapValueToKey(@\"Category\", @\"Category\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.NormalizeMinMax(@\"Features\", @\"Features\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.MulticlassClassification.Trainers.LbfgsMaximumEntropy(l1Regularization: 0.455F, l2Regularization: 0.034F, labelColumnName: @\"Category\", featureColumnName: @\"Features\"))\r\n\t\t\t\t\t\t\t.Append(mlContext.Transforms.Conversion.MapKeyToValue(@\"PredictedLabel\", \"PredictedLabel\"));\r\n\r\n\treturn pipeline;\r\n}\r\n```\r\nTraining method:\r\n```csharp\r\npublic void TrainFromCollection(IEnumerable<SkuInfo> trainData, string outputModelPath)\r\n{\r\n\tvar mlContext = new MLContext(seed: 1);\r\n\tvar dataView = mlContext.Data.LoadFromEnumerable(trainData);\r\n\tvar pipeline = BuildPipeline(mlContext);\r\n\tvar model = pipeline.Fit(dataView);\r\n\tmlContext.Model.Save(model, dataView.Schema, outputModelPath);\r\n}\r\n```\r\n[ds example.txt](https://github.com/dotnet/machinelearning/files/7569878/ds.example.txt)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6007","RelatedDescription":"Open issue \"Multiclass text classification: training consume a lot of RAM\" (#6007)"},{"Id":"1051090293","IsPullRequest":true,"CreatedAt":"2021-11-19T00:15:03","Actor":"x-danma","Number":"6001","RawContent":null,"Title":"Remove Excessive Logging from SymSgdClassificationTrainer","State":"closed","Body":"Fixes #5598 \r\n\r\nI have removed the logging statement as suggested by the issue reporter, and have adjusted the affected BaseLineOutput files for Microsoft.ML.Predictor.Tests.\r\n\r\n\r\nWe are excited to review your PR.\r\n\r\nThe lo\r\nSo we can do the best job, please check:\r\n\r\n- [X] There's a descriptive title that will make sense to other developers some time from now. \r\n- [X] There's associated issues. All PR's should have issue(s) associated - unless a trivial self-evident change such as fixing a typo. You can use the format `Fixes #nnnn` in your description to cause GitHub to automatically close the issue(s) when your PR is merged.\r\n- [X] Your change description explains what the change does, why you chose your approach, and anything else that reviewers should know.\r\n- [X] You have included any necessary tests in the same PR.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6001","RelatedDescription":"Closed or merged PR \"Remove Excessive Logging from SymSgdClassificationTrainer\" (#6001)"},{"Id":"1044172741","IsPullRequest":true,"CreatedAt":"2021-11-18T23:09:37","Actor":"michaelgsharp","Number":"5994","RawContent":null,"Title":"Fixed Nuget Pack warning.","State":"closed","Body":"We were including a file in a NuGet package to designate an empty folder. The folder, however, actually included other files so the `pack` command was throwing an error. This PR removes the file that was causing that error.","Url":"https://github.com/dotnet/machinelearning/pull/5994","RelatedDescription":"Closed or merged PR \"Fixed Nuget Pack warning.\" (#5994)"},{"Id":"1052534757","IsPullRequest":true,"CreatedAt":"2021-11-17T21:36:30","Actor":"michaelgsharp","Number":"6003","RawContent":null,"Title":"Multi-targeting with TargetFrameworks","State":"closed","Body":"With .NET Core 2 no longer in support, we needed to fix the build configurations and frameworks.\r\n\r\nThis PR includes all the changes to switch from the way we used build configuration to specify the target framework for the tests and removes .NET Core 2.1. These changes include:\r\n* No longer using the build configuration to specify the framework (Debug-netcoreapp3_1/Debug-netfx for their associated frameworks) to just using `<TargetFrameworks>` for the test projects. \r\n* Removing all build configurations beyond Debug/Release.\r\n* Removing .NET Core 2.1 as part of this process, so currently only .NET Framework 4.6.1 and  .NET Core 3.1 are used. (.NET 6 will be added in a later PR as it changes some test results slightly).","Url":"https://github.com/dotnet/machinelearning/pull/6003","RelatedDescription":"Closed or merged PR \"Multi-targeting with TargetFrameworks\" (#6003)"},{"Id":"1056379157","IsPullRequest":false,"CreatedAt":"2021-11-17T17:07:17","Actor":"eerhardt","Number":"6006","RawContent":null,"Title":"Remove System.CodeDom reference in Microsoft.ML nuget package","State":"open","Body":"Today Microsoft.ML has a dependency on System.CodeDom, but I don't see anything actually requiring this reference:\r\n\r\nhttps://github.com/dotnet/machinelearning/blob/ea647f43246989334bad69f35b5d60d15171c57e/src/Microsoft.ML/Microsoft.ML.csproj#L44\r\n\r\nThe only references to `System.CodeDom` in the code is to use IndentedTextWriter, which doesn't require a reference to System.CodeDom.\r\n\r\nWe should remove this reference from our core NuGet package.\r\n\r\ncc @ericstj @michaelgsharp ","Url":"https://github.com/dotnet/machinelearning/issues/6006","RelatedDescription":"Open issue \"Remove System.CodeDom reference in Microsoft.ML nuget package\" (#6006)"},{"Id":"1056120535","IsPullRequest":false,"CreatedAt":"2021-11-17T13:16:56","Actor":"ddobric","Number":"6005","RawContent":null,"Title":"TensorFlow model runs in timeout when executed in container","State":"open","Body":"## System Information \r\n - Linux Docker container running on Windows 10 / 11 or in ACI\r\n - ML.NET v1.4.0\r\n - .NET Version: .NET 6.0\r\n\r\n## Problem description\r\nWe have an application that utilizes image classification by using TensorFlow, based on the sample provided in .NET ML. The application executes the following code, which correctly starts, runs, but never completes when running in the Linux docker container on the Windows 10 host.\r\n\r\nWhen the container is started from the command line it simply exists without showing any error. However, when we run the container in VS (F5) the container shows the error in the output window.\r\n\r\n>  TensorFlow .. metaoprimizer.cc 499 ..model_runner exceeded deadline\r\n\r\nHere is the simplified code that fails (crashes) in line N+0. \r\n~~~\r\ntry\r\n{\r\n(N+0) var cvResults = mlContext.MulticlassClassification.CrossValidate(cvDataView, pipeline, numberOfFolds: numOfFolds, labelColumnName: \"LabelAsKey\", seed: 8881);\r\n\r\n(N+1)  Console.Write(\"Never executed\");\r\n}\r\ncatch\r\n{\r\n(N+2)\r\n}\r\n~~~\r\n\r\nThe container simply exists without throwing any exception. The lines N+1 and N+2 are never reached.\r\n\r\n![image](https://user-images.githubusercontent.com/1756871/142205156-cca5a3fa-3194-441f-bf98-c68f94ec6cce.png)\r\n\r\nThe same code works well when executed on the Windows host. We also have been able to execute the same code in the Linux container on Windows 11. We have tested it on multiple machines (same environment setup). The same code at some hosts is sometimes running correctly even if the execution time is longer (see image above).\r\n\r\n## Recap\r\n\r\nQuestion: Is there a way to set the timeout for TensorFlow via ML.NET?\r\n\r\nHowever, this behaviour also raises another question. Is this .NET + Docker + TensorFlow reliable at all if it doesn't show any error and stops the execution?\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6005","RelatedDescription":"Open issue \"TensorFlow model runs in timeout when executed in container\" (#6005)"},{"Id":"1052668299","IsPullRequest":false,"CreatedAt":"2021-11-13T12:13:42","Actor":"juwens","Number":"6004","RawContent":null,"Title":"Why no Polynomial (SVM) Kernel?","State":"open","Body":"Every decent ML lib contains a set of non linear SVM Kernels.\r\n\r\n- RBF\r\n- Polynomial\r\n- CosineSimilarity\r\n- Fourier\r\n- Spline\r\n\r\nIt seems ML.Net contains only Linear and LD.","Url":"https://github.com/dotnet/machinelearning/issues/6004","RelatedDescription":"Open issue \"Why no Polynomial (SVM) Kernel?\" (#6004)"},{"Id":"1052441350","IsPullRequest":false,"CreatedAt":"2021-11-12T22:07:37","Actor":"juwens","Number":"6002","RawContent":null,"Title":"Add ECOC (Error correcting output codes)","State":"open","Body":"**Describe the solution you'd like**\r\nECOC is available as  Trainer/Classifier\r\n\r\n**Describe alternatives you've considered**\r\nUsing other frameworks like scikit-learn via dllimport\r\n\r\n**Additional context**\r\nit might appear under a different name in some sources, for example: (error  correcting) multiclass SVM.\r\n\r\nhttps://machinelearningmastery.com/error-correcting-output-codes-ecoc-for-machine-learning/","Url":"https://github.com/dotnet/machinelearning/issues/6002","RelatedDescription":"Open issue \"Add ECOC (Error correcting output codes)\" (#6002)"},{"Id":"1048060187","IsPullRequest":true,"CreatedAt":"2021-11-11T20:48:59","Actor":"michaelgsharp","Number":"5997","RawContent":null,"Title":"Fixes for ssh cert","State":"closed","Body":"`Hosted MacOs` pool, the old way of specifying your vm image, is having issues with SSH certs. Our CI build had switched entirely to the new way to specify vm image, but the official build hadn't. This PR switches to the new format so that we can fix the SSH issue.\r\n\r\nHosted MacOs is using 10.14, which went out of service about a week ago which is why the cert is expiring now. Switching to 10.15, which is still in support fixes this.","Url":"https://github.com/dotnet/machinelearning/pull/5997","RelatedDescription":"Closed or merged PR \"Fixes for ssh cert\" (#5997)"},{"Id":"1048571465","IsPullRequest":false,"CreatedAt":"2021-11-09T12:52:30","Actor":"MiroslavKabat","Number":"6000","RawContent":null,"Title":" MS ML.NET doesn't work with latest GPU!","State":"open","Body":"I was using station with `Geforce RTX 2080 Ti` (Cuda Compute Capability 7.5) for development and everything was fine and works pretty well. \r\nNow we are publishing our solution on station with `RTX A6000` Cuda Compute Capability 8.6) and MS Model Builder, MS ML.NET and direct programming in python (tensorflow) is super slow or stuck without any error message with same configuration like in dev station. \r\n(for example loading onnx model takes 6 minutes instead of 2 seconds and prediction never start instead of calculate task is several milliseconds)\r\n\r\nTensorflow in python with cuda 11.2 & cudnn 8.1 works fine.\r\nTensorflow in python with cuda 10.1 & cudnn 7.6.4 (which is nessesary for MS ML.NET!) is slow or stuck in TF & MS ML.NET.\r\n\r\nI am not only one with those issues [nvidia - dev forum](https://forums.developer.nvidia.com/t/slow-startup-and-model-loading-time/173398)\r\n\r\nI just wanna ensure if MS ML.NET supports latest GPUs or how can I solve those issues? \r\nThank you for answer.\r\n\r\n```\r\nConfiguration:\r\nWindows 10 Pro - 21H1\r\n\r\nML.NET 1.6 | 1.5.5 | 1.7-Preview\r\nSciSharp.TensorFlow.Redist-Windows-GPU 2.3.1\r\nPython 3.8.10, pip 21.3.1, tensorflow 2.3.1 or 2.7.0\r\n\r\ncuda_10.1.105_418.96_win10\r\ncudnn-10.1-windows10-x64-v7.6.4.38\r\n\r\nor \r\n\r\ncuda_11.2.2_461.33_win10\r\ncudnn-11.2-windows-x64-v8.1.1.33\r\n```","Url":"https://github.com/dotnet/machinelearning/issues/6000","RelatedDescription":"Open issue \" MS ML.NET doesn't work with latest GPU!\" (#6000)"},{"Id":"1048170349","IsPullRequest":false,"CreatedAt":"2021-11-09T04:14:28","Actor":"AbhayGaur","Number":"5999","RawContent":null,"Title":"Binary classification : Tune the model/algorithms to give higher positive recall instead of negative recall","State":"open","Body":"I have a binary classification problem on my hand and on using various models like LBFGS logistic regression, LightGBM, FastTree etc I am getting accuracy above 85% but a positive recall close to 0.7 with a precision of 99% with a negative recall greater than 0.99 with 80% precision.\r\n\r\nTraining Dataset consists of roughly 38% positive class and 62% negative class with 200k rows. Test dataset also has 38% positive class and 62% negative class.\r\n\r\nIdeally, I would like the model to give me decent accuracy but with higher positive recall. I would like to have some method through which I can experiment a bit with accuracy and positive recall.","Url":"https://github.com/dotnet/machinelearning/issues/5999","RelatedDescription":"Open issue \"Binary classification : Tune the model/algorithms to give higher positive recall instead of negative recall\" (#5999)"},{"Id":"1048062410","IsPullRequest":true,"CreatedAt":"2021-11-09T01:21:41","Actor":"michaelgsharp","Number":"5998","RawContent":null,"Title":"Fixes for ssh cert","State":"closed","Body":"`Hosted MacOs` pool, the old way of specifying your vm image, is having issues with SSH certs. Our CI build had switched entirely to the new way to specify vm image, but the official build hadn't. This PR switches to the new format so that we can fix the SSH issue.\r\n\r\nHosted MacOs is using 10.14, which went out of service about a week ago which is why the cert is expiring now. Switching to 10.15, which is still in support fixes this.","Url":"https://github.com/dotnet/machinelearning/pull/5998","RelatedDescription":"Closed or merged PR \"Fixes for ssh cert\" (#5998)"},{"Id":"1047662527","IsPullRequest":false,"CreatedAt":"2021-11-08T16:34:14","Actor":"briacht","Number":"5996","RawContent":null,"Title":"Virtual ML.NET Hackathon: November 11 - 19","State":"open","Body":"All experience levels welcome!\r\n\r\nSolve a unique business problem with ML.NET, contribute to the repo, create your own ML.NET tooling... collaborate with others in the .NET community to create any project using ML.NET!\r\n\r\nLearn more and sign up at [aka.ms/mlnet-hack](https://aka.ms/mlnet-hack).","Url":"https://github.com/dotnet/machinelearning/issues/5996","RelatedDescription":"Open issue \"Virtual ML.NET Hackathon: November 11 - 19\" (#5996)"},{"Id":"1046157432","IsPullRequest":false,"CreatedAt":"2021-11-05T19:07:39","Actor":"torronen","Number":"5995","RawContent":null,"Title":"Suggestion: store optimized hyperparameters in the zip file","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\nDuring various AutoML runs I have generated multiple models with slightly different datasets. After using them in simulations I notice some perform better than others. I would like to re-train the model with slightly improved datasets. However, not all algorithms can be [retrained](https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net). As I understand trees, for example, require me to create a new model. To create the new model I would like to use the hyperparameters from the earlier model.\r\n\r\n**Describe the solution you'd like**\r\nIf the parameters are not stored at the moment, then I would suggest providing a way to store them to the zip file. At the moment, I did not notice any way to access them outside AutoML code. I can access them in Experiment.cs and PipelineSuggester.cs, but my current understanding is that I need customize the library myself to store them. \r\n\r\nI think a good place to store hyperparameters would be inside TrainingInfo folder, in a new text file. Now it only includes version.txt\r\n\r\nIdeally, ExperimentResult would include HyperParameters in the same way as the metrics.\r\n\r\nI might be confused and just unable to find how to do it. If this is already possible, mention at end of https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/retrain-model-ml-net would be nice.\r\n\r\n**Additional context**\r\nGetting the hyperparameters from AutoML experiments would be useful also for manual fine-tuning. \r\n\r\nModel Builder does similar functionality already by creating the training file.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5995","RelatedDescription":"Open issue \"Suggestion: store optimized hyperparameters in the zip file\" (#5995)"},{"Id":"1042824705","IsPullRequest":true,"CreatedAt":"2021-11-02T21:02:55","Actor":"LittleLittleCloud","Number":"5993","RawContent":null,"Title":"Proposal: Sweepable API","State":"open","Body":"This is the initial design/proposal doc for a Sweepable API.\r\n\r\nI would appreciate it if you could each review it and give me your feedback.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/pull/5993","RelatedDescription":"Open PR \"Proposal: Sweepable API\" (#5993)"},{"Id":"1042817236","IsPullRequest":false,"CreatedAt":"2021-11-02T20:59:12","Actor":"LittleLittleCloud","Number":"5992","RawContent":null,"Title":"Proposal: AutoML Sweepable API","State":"closed","Body":"# AutoML.Net Sweepable API proposal\r\n## Overview\r\nSweepable api allows mlnet users to create their own search space and pipeline for hyper-parameter optimization (HPO). It comes with three major part: `search space`, `sweepable estimator/pipeline` and `tuner`. And all API lives under `Sweepable()` extension (for now).\r\n\r\n## search space\r\nSearch space defines a range of hyper-parameter for tuner to search from. Sweepable API provides two way to create a search space.\r\n\r\nvia attribute\r\n```csharp\r\npublic class Option\r\n{\r\n    [Range(2, 32768, init: 2, logBase: true)]\r\n    public int WindowSize {get; set;}\r\n\r\n    // one of [2, 3, 4]\r\n    [Choice(2, 3, 4)]\r\n    public int SeriesLength {get; set;}\r\n\r\n    // one of [true, false]\r\n    [Choice]\r\n    public bool UseSoftmax {get; set;}\r\n\r\n    // nested search space\r\n    [Option]\r\n    public Option AnotherOption {get;set;}\r\n}\r\n\r\nvar ss = new SearchSpace<Option>();\r\n\r\n// each search space has a 1-d feature space where each feature is [0, 1). And search space will handle the mapping between hpo space and feature space so that tuner only needs to perform search on feature space, which both dimension and range are known.\r\nvar parameter = ss.SampleFromFeatureSpace(new []{0,0,0,0,0,0});\r\n\r\n// auto-binding\r\nparameter.WindowSize.Should().Be(2);\r\nparameter.SeriesLength.Should().Be(2);\r\nparameter.UseSoftmax.Should().BeTrue();\r\nparameter.AnotherOption.WindowSize.Should().Be(2);\r\n\r\n// search space can also map parameter back to feature space\r\nss.MappingToFeatureSpace(parameter).Should().BeEquivalantTo(0.0, 0.0, 0.0, 0.0, 0.0, 0.0);\r\n```\r\n\r\nor correspondingly, via scratch\r\n``` csharp\r\nvar ss = new SearchSpace();\r\nss.Add(\"WindowSize\", new UniformIntOption(2, 32768, true, 2));\r\nss.Add(\"SeriesLength\", new ChoiceOption(2,3,4));\r\nss.Add(\"UseSoftmax\", new ChoiceOption(true, false));\r\nss.Add(\"AnotherOption\", ss.Clone());\r\n\r\nvar parameter = ss.SampleFromFeatureSpace(new []{0,0,0,0,0,0});\r\n\r\n// auto-binding doesn't exist for scratch api\r\nparameter[\"WindowSize\"].AsType<int>.Should().Be(2);\r\nparameter[\"SeriesLength\"].AsType<int>.Should().Be(2);\r\nparameter[\"UseSoftmax\"].AsType<bool>.Should().BeTrue();\r\nparameter[\"AnotherOption\"][\"WindowSize\"].AsType<int>.Should().Be(2);\r\n\r\n// search space can also map parameter back to feature space\r\nss.MappingToFeatureSpace(parameter).Should().BeEquivalantTo(0.0, 0.0, 0.0, 0.0, 0.0, 0.0);\r\n```\r\n\r\nCurrently, in order to make auto-binding work, there's a limitation on the parameter type that can be added to search space, which has to be either a Json primitive type or a nested search space.\r\n\r\n## sweepable estimator\r\nsweepable estimator allows user to combine search space with estimators in a similar way how ml.net estimator/pipeline are created. You use `CreateSweepableEstimator`, which accepts a lambda function and a search space to create a sweepable estimator. And it also provides `.Append` extension method so you can append sweepable estimator similiar with how you append other ml.net extimator. The bellow example presents how to create a pipeline with two sweepable estimators, one for text featurizor and the other for fast tree, for `titanic` dataset via `Sweepable()` extension.\r\n\r\n``` csharp\r\nvar context = new MLContext();\r\nvar fastTreeSS = new SearchSpace<FastTreeOption>();\r\nvar textFeaturizeSS = new SearchSpace<FeaturizeTextOption>();\r\n\r\nvar pipeline = context.Transforms.Categorical.OneHotEncoding(new[] { new InputOutputColumnPair(@\"Sex\", @\"Sex\"), new InputOutputColumnPair(@\"Embarked\", @\"Embarked\") })\r\n                .Append(context.Transforms.Concatenate(@\"TextFeature\", @\"Name\", \"Ticket\", \"Cabin\"))\r\n                .Append(context.Sweepable().CreateSweepableEstimator(\r\n                    (mlContext, option) =>\r\n                    {\r\n                        var textOption = new TextFeaturizingEstimator.Options\r\n                        {\r\n                            CaseMode = option.CaseMode,\r\n                            KeepDiacritics = option.KeepDiacritics,\r\n                            KeepNumbers = option.KeepNumbers,\r\n                            KeepPunctuations = option.KeepPunctuations,\r\n                            CharFeatureExtractor = new WordBagEstimator.Options()\r\n                            {\r\n                                NgramLength = option.WordBagEstimatorOption.NgramLength,\r\n                                UseAllLengths = option.WordBagEstimatorOption.UseAllLengths,\r\n                                Weighting = option.WordBagEstimatorOption.WeightingCriteria,\r\n                            },\r\n                        };\r\n\r\n                        return mlContext.Transforms.Text.FeaturizeText(\"TextFeature\", textOption);\r\n                    },\r\n                    textFeaturizeSS))\r\n                .Append(context.Transforms.Concatenate(@\"Features\", new[] { @\"Sex\", @\"Embarked\", @\"Pclass\", @\"Age\", @\"SibSp\", @\"Parch\", @\"Fare\", \"TextFeature\" }))\r\n                .Append(context.Transforms.Conversion.ConvertType(\"Survived\", \"Survived\", Data.DataKind.Boolean))\r\n                .Append(context.Sweepable().CreateSweepableEstimator(\r\n                    (mlContext, option) => mlContext.BinaryClassification.Trainers.FastForest(labelColumnName: \"Survived\", featureColumnName: \"Features\", numberOfLeaves: option.NumberOfLeavenumberOfTrees: option.NumberOfTrees),\r\n                    fastTreeSS))\r\n                .Append(context.BinaryClassification.Calibrators.Naive(labelColumnName: @\"Survived\", scoreColumnName: @\"Score\"));\r\n```\r\n\r\nAfter sweepable pipeline is created, one can call `BuildTrainingPipeline` to convert it to a ml.net pipeline.\r\n\r\n## tuner\r\n\r\ntuner takes in a search space and performs hpo algos. There're a few default tuning alogs provided by Sweepable API (grid search/random search), and there'll be more smart hpo algos coming soon.\r\n\r\nThe way to use a tuner is quite similar with the way to use an enumerator. The code below shows how tuner works with search space and sweepable estimator/pipeline\r\n\r\n```csharp\r\nvar ss = pipeline.SearchSpace\r\nvar tuner = new GridSearchTuner(ss);\r\nvar df = DataFrame.LoadCsv(@\"titanic.csv\");\r\nvar trainTestSplit = context.Data.TrainTestSplit(df, 0.1);\r\nvar bestAccuracy = 0.0;\r\nvar i = 0;\r\nforeach (var param in tuner.Propose())\r\n{\r\n    Console.WriteLine($\"trial {i++}\");\r\n\r\n    // convert sweepable pipeline to ml.net pipeline\r\n    var trainingPipeline = pipeline.BuildTrainingPipeline(context, param);\r\n    var model = trainingPipeline.Fit(trainTestSplit.TrainSet);\r\n    var eval = model.Transform(trainTestSplit.TestSet);\r\n    var accuracy = context.BinaryClassification.Evaluate(eval, \"Survived\").Accuracy;\r\n    if (accuracy > bestAccuracy)\r\n    {\r\n        Console.WriteLine(\"Found best accuracy\");\r\n        Console.WriteLine(\"Current best parameter\");\r\n        Console.WriteLine(JsonConvert.SerializeObject(param));\r\n        bestAccuracy = accuracy;\r\n\r\n        Console.WriteLine($\"Trial {i}: Current Best Accuracy {bestAccuracy}, Current Accuracy {accuracy}\");\r\n    }\r\n}\r\n\r\n```\r\n\r\nYou can visit [here](https://github.com/dotnet/machinelearning-tools/blob/main/src/Microsoft.ML.ModelBuilder.AutoMLService.Example/Program.cs) to try out the complete training code.\r\n\r\n## The difference between sweepable api and existing api in AutoML.Net\r\nThe exsiting API in AutoML.Net performs hpo on pre-defined search space and learners with smac tuning algo while sweepable api allows user to customize those settings: they can define their own search space, they can create pipeline similarly with how it is created in ml.net, and they can pick the tuner which suit their experiment the best.\r\n\r\n## Q & A\r\n\r\nWhat's the difference between Sweepable API and AutoML.Net experiments\r\n- AutoML.Net experiments provide an oobe experience for automl with fixed hpo-related option, while Sweepable API requires user to set up those options (search space, pipeline, tuner) manually before training. Sweepable API is not aimed to replace existing AutoML.Net API, but to provide another options for those customers whose request can't be satified by default automl experiment.\r\n\r\nWill AutoML.Net benefits from Sweepable API\r\n- Yes it will, along with sweepable API, we can also leverage [flaml](https://github.com/microsoft/FLAML) technique in the tuning algothrim, which helps improves tuning speed and performance.\r\n\r\nWhy do we need sweepable API, who will be the beneficaries, what's the most common user-case.\r\n- Sweepable API is prepared for HPO, which is a feature required by community from ever since mlnet being released. ([#613](https://github.com/dotnet/machinelearning/issues/613), [#2260](https://github.com/dotnet/machinelearning/issues/2260), [#5930](https://github.com/dotnet/machinelearning/issues/5930),[#1875](https://github.com/dotnet/machinelearning-modelbuilder/issues/1875) etc...). The major beneficiaries will be those who'd like to run automl on different search space or trainers other than the fixed parameters provided by AutoML.Net. The most common user-case, as I'm imagining, is on Notebook along with DataFrame API.\r\n\r\nWhat's the timeline for intergrating Sweepable API into ML.Net\r\n- it depends. Sweepable API has three major parts and all are available in model builder repo. On top of which is a thin layer which makes the three part work with ML.Net. So if the plan is only moving that thin layer into AutoML.Net first, and make the rest of three parts open source later, it will take 2-3 weeks. If we want to move all parts into mlnet all together, it will cost much more time.\r\n\r\n\r\n## Current feedback\r\n- the lambda function in `CreateSweepableEstimator` should not accept `MLContext` as first parameter.\r\n- Should provide a higher level API for training similar with Experiment API in AutoML.Net.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/5992","RelatedDescription":"Closed issue \"Proposal: AutoML Sweepable API\" (#5992)"}],"ResultType":"GitHubIssue"}},"RunOn":"2021-12-10T05:30:28.5530105Z","RunDurationInMilliseconds":551}