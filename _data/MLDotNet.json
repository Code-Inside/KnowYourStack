{"Data":{"GitHub":{"Issues":[{"Id":"2059676461","IsPullRequest":false,"CreatedAt":"2023-12-29T12:38:39","Actor":"SyntaxEvg","Number":"6931","RawContent":null,"Title":"ML .Net integration with ef core","State":"open","Body":"ML .Net integration with ef core for data generation based on msSql, and building models, так как ваш подход с ado net выдает иногда ошибки, котоые котоые котоые не пропустить не исправить, How do you convert what is the system or how do you know about dnSpy?\r\nMy friend, how to realize the data of the ef core and train the model, based on this Each connection is more than 10 ml per line","Url":"https://github.com/dotnet/machinelearning/issues/6931","RelatedDescription":"Open issue \"ML .Net integration with ef core\" (#6931)"},{"Id":"2055973462","IsPullRequest":false,"CreatedAt":"2023-12-26T03:03:06","Actor":"thomasd3","Number":"6930","RawContent":null,"Title":"Can I get an example for AutoML with in memory data in F#","State":"closed","Body":"I'm trying to do this:\r\n\r\n> mlnet classification --dataset output.csv --label-col 0 --has-header true --name test --train-time 300\r\n\r\nfrom F#\r\n\r\nAnd I find contradicting samples, depending on the ML.net version, but nothing comprehensive.\r\n\r\nI have a custom type with one column being the label and the rest being features. Every field is a float32 but the label which is a bool.\r\n\r\nI have the following code:\r\n\r\n```\r\n    // Initialize MLContext\r\n    let ctx = MLContext()\r\n\r\n    // Load data into IDataView\r\n    let data = ctx.Data.LoadFromEnumerable<ModelInput> (b)\r\n\r\n    // Split data into training and validation sets\r\n    let trainValidationData = ctx.Data.TrainTestSplit(data,0.2)\r\n\r\n    let header =\r\n        \"outcome,side,open0,high0,low0,close0,volume0,open1,high1,low1,close1,volume1,open2,high2,low2,close2,volume2,open3,high3,low3,close3,volume3,open4,high4,low4,close4,volume4,open5,high5,low5,close5,volume5,open6,high6,low6,close6,volume6,open7,high7,low7,close7,volume7,open8,high8,low8,close8,volume8,open9,high9,low9,close9,volume9,open10,high10,low10,close10,volume10,open11,high11,low11,close11,volume11,open12,high12,low12,close12,volume12,open13,high13,low13,close13,volume13,open14,high14,low14,close14,volume14,open15,high15,low15,close15,volume15,open16,high16,low16,close16,volume16,open17,high17,low17,close17,volume17,open18,high18,low18,close18,volume18,open19,high19,low19,close19,volume19,fairPrice,lgH0,lgL0,lgH1,lgL1,obH0,obL0,obH1,obL1,hh0,lh0,hl0,ll0,hh1,lh1,hl1,ll1,bosi0,bose0,coc0,mss0,bosi1,bose1,coc1,mss1\"\r\n            .Split ','\r\n\r\n    let preprocessingPipeline =\r\n        EstimatorChain()\r\n            .Append(ctx.Transforms.Concatenate(\"Features\", header))\r\n\r\n    let autoMLEstimator: SweepablePipeline =\r\n        ctx.Auto().Regression(\"outcome\")\r\n\r\n    let toIEstimator (est: 'a) =\r\n        est :> obj :?> IEstimator<ITransformer>\r\n\r\n    let pipeline =\r\n         (preprocessingPipeline |> toIEstimator)\r\n             .Append(autoMLEstimator)\r\n\r\n    let experiment = ctx.Auto().CreateExperiment()\r\n\r\n    experiment\r\n        .SetPipeline(pipeline)\r\n        .SetRegressionMetric(RegressionMetric.RSquared) //, columnInference.ColumnInformation.LabelColumnName)\r\n        .SetTrainingTimeInSeconds(60u)\r\n        .SetDataset(trainValidationData)\r\n        |> ignore\r\n\r\n    ctx.Log.Add (fun e -> if (e.Source.Equals(\"AutoMLExperiment\")) then info e.RawMessage)\r\n\r\n    let experimentResults = experiment.RunAsync() |> Async.AwaitTask |> Async.RunSynchronously\r\n\r\n```\r\n\r\nBut it tells me it can't find the 'outcome' column.\r\n\r\nThe lack of F# examples is really an issue for me. I spent an entire day trying to load data from memory.\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6930","RelatedDescription":"Closed issue \"Can I get an example for AutoML with in memory data in F#\" (#6930)"},{"Id":"2055112609","IsPullRequest":false,"CreatedAt":"2023-12-24T14:07:13","Actor":"joegoldman2","Number":"6929","RawContent":null,"Title":"TrainTestSplit does not seem to split the dataset according to the given fraction","State":"open","Body":"## Describe the bug\r\nI'm following this tutorial: https://learn.microsoft.com/dotnet/machine-learning/tutorials/image-classification-api-transfer-learning. The assert directory I used contains 24 images.\r\n\r\n```cs\r\nconst string AssetsRelativePath = \"assets\";\r\n\r\nMLContext mlContext = new MLContext();\r\n\r\nIEnumerable<ImageData> images = LoadImagesFromDirectory(folder: AssetsRelativePath, useFolderNameAsLabel: true);\r\nIDataView imageData = mlContext.Data.LoadFromEnumerable(images);\r\nIDataView shuffledData = mlContext.Data.ShuffleRows(imageData);\r\n\r\nvar preprocessingPipeline = mlContext.Transforms.Conversion.MapValueToKey(\r\n        inputColumnName: \"Label\",\r\n        outputColumnName: \"LabelAsKey\")\r\n    .Append(mlContext.Transforms.LoadRawImageBytes(\r\n        outputColumnName: \"Image\",\r\n        imageFolder: AssetsRelativePath,\r\n        inputColumnName: \"ImagePath\"));\r\n\r\nIDataView preProcessedData = preprocessingPipeline\r\n    .Fit(shuffledData)\r\n    .Transform(shuffledData);\r\n\r\nDataDebuggerPreview dataCount = preProcessedData.Preview(); // RowView = 24, correct!\r\n\r\nTrainTestData trainSplit = mlContext.Data.TrainTestSplit(data: preProcessedData, testFraction: 0.3); // Split train data 70%/30%\r\nTrainTestData validationTestSplit = mlContext.Data.TrainTestSplit(trainSplit.TestSet, testFraction: 0.1); // Rest of 30% into 90%/10%\r\n\r\nDataDebuggerPreview trainSplitTrainSetCount = trainSplit.TrainSet.Preview(); // RowView = 19 <= Should be 16 or 17 depending on rounding (70% of 24 images = 16.799999999999997%)\r\nDataDebuggerPreview trainSplitTestSetCount = trainSplit.TestSet.Preview(); // RowView = 5 <= Should be 6 or 7 depending on rounding (30% of 24 images = 7.199999999999999%)\r\nDataDebuggerPreview validationTrainSetCount = validationTestSplit.TrainSet.Preview(); // RowView = 5\r\nDataDebuggerPreview validationTestSetCount = validationTestSplit.TestSet.Preview(); // RowView = 0 <= Not sure to understand why 0 here\r\n```\r\n\r\nFollowing the preprocessing phase, the number of images is correct (24). However, following the various `TrainTestSplit()`, the data doesn't seem to be split correctly according to the fraction requested. Finally, I end up with an empty test dataset. You can find the details of each count at the end of the sample.\r\n\r\nIs this the expected behaviour or did I misunderstand something?\r\n\r\n## System Information (please complete the following information)\r\n - OS & Version: Windows 11\r\n - ML.NET Version: 3.0.0\r\n - .NET Version: .NET 8\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6929","RelatedDescription":"Open issue \"TrainTestSplit does not seem to split the dataset according to the given fraction\" (#6929)"},{"Id":"2054999934","IsPullRequest":true,"CreatedAt":"2023-12-24T06:25:04","Actor":"michaelgsharp","Number":"6928","RawContent":null,"Title":"Fixes NER to correctly expand/shrink the labels","State":"open","Body":"NER now will correctly expand/shrink the labels when a word is split into multiple tokens.","Url":"https://github.com/dotnet/machinelearning/pull/6928","RelatedDescription":"Open PR \"Fixes NER to correctly expand/shrink the labels\" (#6928)"},{"Id":"2053166433","IsPullRequest":true,"CreatedAt":"2023-12-22T20:18:30","Actor":"ericstj","Number":"6923","RawContent":null,"Title":"Make double assertions compare with tolerance instead of precision","State":"closed","Body":"Precision might cause small differences to round to a different number. Instead compare with a tolerance which is not sensitive to rounding.\r\n\r\nSee comment here: https://github.com/dotnet/machinelearning/pull/6703#issuecomment-1866985302","Url":"https://github.com/dotnet/machinelearning/pull/6923","RelatedDescription":"Closed or merged PR \"Make double assertions compare with tolerance instead of precision\" (#6923)"},{"Id":"2052759833","IsPullRequest":false,"CreatedAt":"2023-12-22T20:12:13","Actor":"ericstj","Number":"6921","RawContent":null,"Title":"Failed assert in ImplVec<T>.Fetch on Arm","State":"closed","Body":"This failed 3 separate times for me in one PR on Arm.\r\nhttps://github.com/dotnet/machinelearning/blob/5483ba93c591367e9465884ca23feab79f4bf1f0/src/Microsoft.ML.Data/DataView/CacheDataView.cs#L1389\r\n\r\nWhat's odd to me is that the both `_indexBoundaries` and `_valueBoundaries` should be consistent as they're resized at the same time, yet we only hit the assert for `_valueBoundaries`.\r\n\r\n## Build Information\r\nBuild: https://dev.azure.com/dnceng-public/cbb18261-c48f-4abb-8651-8cdcb5474649/_build/results?buildId=505863\r\nBuild error leg or test failing: Microsoft.ML.RunTests.TestEntryPoints.TestCrossValidationMacro\r\nPull request: https://github.com/dotnet/machinelearning/pull/6917\r\n<!-- Error message template  -->\r\n## Error Message\r\n\r\nFill the error message using [step by step known issues guidance](https://github.com/dotnet/arcade/blob/main/Documentation/Projects/Build%20Analysis/KnownIssues.md#how-to-fill-out-a-known-issue-error-section).\r\n\r\n<!-- Use ErrorMessage for String.Contains matches. Use ErrorPattern for regex matches (single line/no backtracking). Set BuildRetry to `true` to retry builds with this error. Set ExcludeConsoleLog to `true` to skip helix logs analysis. -->\r\n\r\n```json\r\n{\r\n  \"ErrorMessage\": \"Microsoft.ML.Data.CacheDataView.ColumnCache.ImplVec`1.Fetch(Int32 idx, VBuffer`1& value)\",\r\n  \"ErrorPattern\": \"\",\r\n  \"BuildRetry\": false,\r\n  \"ExcludeConsoleLog\": false\r\n}\r\n```\r\n\r\n\r\n<!-- Known issue validation start -->\r\n ### Known issue validation\r\n**Build: :mag_right:** https://dev.azure.com/dnceng-public/public/_build/results?buildId=505863\r\n**Error message validated:** `Microsoft.ML.Data.CacheDataView.ColumnCache.ImplVec`1.Fetch(Int32 idx, VBuffer`1& value)`\r\n**Result validation: :white_check_mark:** Known issue matched with the provided build.\r\n**Validation performed at:** 12/21/2023 4:49:08 PM UTC\r\n<!-- Known issue validation end -->\r\n<!--Known issue error report start -->\r\n### Report\r\n\r\n|Build|Definition|Test|Pull Request|\r\n|---|---|---|---|\r\n|[505850](https://dev.azure.com/dnceng-public/public/_build/results?buildId=505850)|dotnet/machinelearning|[Microsoft.ML.Core.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=505850&view=ms.vss-test-web.build-test-results-tab&runId=11816274&resultId=101954)|dotnet/machinelearning#6703|\r\n|[506779](https://dev.azure.com/dnceng-public/public/_build/results?buildId=506779)|dotnet/machinelearning|[Microsoft.ML.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=506779&view=ms.vss-test-web.build-test-results-tab&runId=11815558&resultId=101954)|dotnet/machinelearning#6794|\r\n|[505863](https://dev.azure.com/dnceng-public/public/_build/results?buildId=505863)|dotnet/machinelearning|[Microsoft.ML.Predictor.Tests.WorkItemExecution](https://dev.azure.com/dnceng-public/public/_build/results?buildId=505863&view=ms.vss-test-web.build-test-results-tab&runId=11815076&resultId=101954)|dotnet/machinelearning#6917|\r\n#### Summary\r\n|24-Hour Hit Count|7-Day Hit Count|1-Month Count|\r\n|---|---|---|\r\n|0|3|3|\r\n<!--Known issue error report end -->","Url":"https://github.com/dotnet/machinelearning/issues/6921","RelatedDescription":"Closed issue \"Failed assert in ImplVec<T>.Fetch on Arm\" (#6921)"},{"Id":"2053169608","IsPullRequest":true,"CreatedAt":"2023-12-22T20:12:12","Actor":"ericstj","Number":"6924","RawContent":null,"Title":"Fix assert by only accessing idx","State":"closed","Body":"Fixes #6921 \r\n\r\nAsserting on `_rowCount <  Utils.Size(_valueBoundaries)` was catching a case where `_rowCount`'s update was reordered before `_valueBoundaries`\r\n\r\nThis was unnecessary, since this method doesn't need to use `_rowCount`.\r\n\r\nInstead, make the asserts use only `idx` which will be maintained consistent with the waiter logic in this cache.  This will lock and synchronize with the main thread to ensure `idx` is always within bounds.\r\n\r\nEnsure we only ever use `_rowCount` from the caching thread, so write reordering won't matter.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6924","RelatedDescription":"Closed or merged PR \"Fix assert by only accessing idx\" (#6924)"},{"Id":"2054065173","IsPullRequest":false,"CreatedAt":"2023-12-22T15:16:59","Actor":"80LevelElf","Number":"6927","RawContent":null,"Title":"OneDAL FastForest training has an \"Array dimensions exceeded supported range\" exception","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Linux Alpine \r\n - ML.NET Version: ML.NET 3.0\r\n - .NET Version: .Net 5.0\r\n\r\n**Describe the bug**\r\n\r\n```\r\nArray dimensions exceeded supported range.   at System.Collections.Generic.List`1.set_Capacity(Int32 value)\r\n   at System.Collections.Generic.List`1.AddWithResize(T item)\r\n   at Microsoft.ML.OneDal.OneDalUtils.GetTrainData(IChannel channel, Factory cursorFactory, List`1& featuresList, List`1& labelsList, Int32 numberOfFeatures)\r\n   at Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer.TrainCoreOneDal(IChannel ch, Factory cursorFactory, Int32 featureCount)\r\n   at Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer.TrainModelCore(TrainContext context)\r\n   at Microsoft.ML.Trainers.TrainerEstimatorBase`2.TrainTransformer(IDataView trainSet, IDataView validationSet, IPredictor initPredictor)\r\n   at Microsoft.ML.Data.EstimatorChain`1.Fit(IDataView input)\r\n   at Microsoft.ML.AutoML.BinaryClassificationRunner.Run(TrialSettings settings)\r\n   at Microsoft.ML.AutoML.BinaryClassificationRunner.RunAsync(TrialSettings settings, CancellationToken ct)\r\n   at Microsoft.ML.AutoML.AutoMLExperiment.RunAsync(CancellationToken ct)\r\n```\r\n\r\nWe have found this error in internal ML.net logs a lot of times. Looks liks it's not related to train set size (in the case I have copied this error we have only 20 000 training rows)","Url":"https://github.com/dotnet/machinelearning/issues/6927","RelatedDescription":"Open issue \"OneDAL FastForest training has an \"Array dimensions exceeded supported range\" exception\" (#6927)"},{"Id":"2053750816","IsPullRequest":false,"CreatedAt":"2023-12-22T10:55:22","Actor":"80LevelElf","Number":"6926","RawContent":null,"Title":"Fail to find available configs for given trainers: SdcaLogisticRegressionBinary (ML.net 3)","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Linux Apline\r\n - ML.NET Version: 3.0\r\n - .NET Version: .Net 5\r\n\r\n**Describe the bug**\r\n\r\n    var settings = new BinaryExperimentSettings\r\n    {\r\n        MaxExperimentTimeInSeconds = 30 * 60,\r\n        MaxModels = 10,\r\n        MaximumMemoryUsageInMegaByte = 7500,\r\n    };\r\n\r\n    ExperimentResult<BinaryClassificationMetrics> experimentResult = experiment\r\n        .Execute(trainDataView, nameof(MlModelRow.Label), nameof(MlModelRow.LearningGroup));\r\n\r\nIf we try to use all trainers via AutoML internally we get \"Fail to find available configs for given trainers: SdcaLogisticRegressionBinary\" and can't use Sdca trainer.","Url":"https://github.com/dotnet/machinelearning/issues/6926","RelatedDescription":"Open issue \"Fail to find available configs for given trainers: SdcaLogisticRegressionBinary (ML.net 3)\" (#6926)"},{"Id":"2053460933","IsPullRequest":false,"CreatedAt":"2023-12-22T06:40:57","Actor":"80LevelElf","Number":"6925","RawContent":null,"Title":"Smart train memory handling for AutoML (ML.net 3)","State":"open","Body":"**Is your feature request related to a problem? Please describe.**\r\n\r\nLet's see the current training settings:\r\n\r\n        var settings = new BinaryExperimentSettings\r\n        {\r\n            MaxExperimentTimeInSeconds = 30 * 60,\r\n            MaxModels = 10,\r\n            MaximumMemoryUsageInMegaByte = 7500,\r\n        };\r\n\r\n        ExperimentResult<BinaryClassificationMetrics> experimentResult = experiment\r\n            .Execute(trainDataView, nameof(MlModelRow.Label), nameof(MlModelRow.LearningGroup));\r\n\r\nWhen the training takes more than 7500 Megabytes it will be canceled. But if we not set MaximumMemoryUsageInMegaByte this training take a lot of memory and in many case it will be more that our current pod memory ( > 36 Gb). \r\n\r\nAnd during to logs it's often different amount of data. The very similar train set learning could set 10 Gb at first time and 30 Gb at second time.\r\n\r\n**Describe the solution you'd like**\r\nIt will be perfect to have memory limitation as max memory ml.net can use for training without canceling. Like we have limitation for 7500 Mb and 1 training takes 2500 Mb so let's start 3 models training.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6925","RelatedDescription":"Open issue \"Smart train memory handling for AutoML (ML.net 3)\" (#6925)"},{"Id":"2052869261","IsPullRequest":true,"CreatedAt":"2023-12-21T23:29:21","Actor":"ericstj","Number":"6922","RawContent":null,"Title":"Testing out the assert we are hitting on ARM","State":"closed","Body":"","Url":"https://github.com/dotnet/machinelearning/pull/6922","RelatedDescription":"Closed or merged PR \"Testing out the assert we are hitting on ARM\" (#6922)"},{"Id":"2051138890","IsPullRequest":true,"CreatedAt":"2023-12-21T18:08:50","Actor":"ericstj","Number":"6917","RawContent":null,"Title":"Rename NameEntity to NamedEntity","State":"closed","Body":"Renaming while obsoleting the public API.  We'll backport this to 3.0, then we'll remove the obsolete members from 4.0.","Url":"https://github.com/dotnet/machinelearning/pull/6917","RelatedDescription":"Closed or merged PR \"Rename NameEntity to NamedEntity\" (#6917)"},{"Id":"2051215010","IsPullRequest":true,"CreatedAt":"2023-12-21T16:37:50","Actor":"ericstj","Number":"6918","RawContent":null,"Title":"Don't include the SDK in our helix payload","State":"closed","Body":"I noticed that the tests included the latest SDK - including the host - in our helix payloads.\r\n\r\nThis is a large amount of unnecessary downloads and it also makes it so we use the latest host on the older frameworks which can fail when the latest host drops support for distros.\r\n\r\nSince our tests shouldn't need the full CLI, remove this from our helix payloads.\r\n\r\nWe'll instead get just the runtime we need through `AdditionalDotNetPackage`","Url":"https://github.com/dotnet/machinelearning/pull/6918","RelatedDescription":"Closed or merged PR \"Don't include the SDK in our helix payload\" (#6918)"},{"Id":"2052529046","IsPullRequest":false,"CreatedAt":"2023-12-21T14:28:32","Actor":"BartNSTCL","Number":"6920","RawContent":null,"Title":"When using the AddPredictionEnginePool, How to Confirm the a Model is accessible if   watchForChanges: true?","State":"open","Body":"### System information\r\nWindows 11, Net 8.0\r\n\r\nWhen setting up a webAPI with a similar command to \r\npredictionEnginePool.AddPredictionEnginePool<InputModel, MulticlassClassificationPrediction>()\r\n.FromFile(modelName: modelName, filePath: $\"MLModels/{modelName}.zip\", watchForChanges: true);\r\n\r\nIs there a way to know the model the code points to has been loaded and being currently used?\r\nI was curious if there some command in the predictionEnginePool that could be read, such as a time stamp or a way to log when the model changes. I'd liked to be able to provide feedback about the model's creation data. I can pull the timestamp from the files, but within the WebApi, I was curious about being able to monitor that part.\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6920","RelatedDescription":"Open issue \"When using the AddPredictionEnginePool, How to Confirm the a Model is accessible if   watchForChanges: true?\" (#6920)"},{"Id":"2051366693","IsPullRequest":false,"CreatedAt":"2023-12-20T22:18:11","Actor":"ErwanL08","Number":"6919","RawContent":null,"Title":"Bugs / ApplyWordEmbedding with custom path not working. ","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 11] \r\n - ML.NET Version: [e.g. ML.NET v3.0.0]\r\n - .NET Version: [e.g. .NET 8.0]\r\n\r\n**Describe the bug**\r\nI try to Embedded a list of sentences in French, the main goal is to generated a embedded dataset for after apply the cosine Similarity. The default FastTextWikipedia300D is the english wiki, so i download the french one  from https://fasttext.cc/docs/en/pretrained-vectors.html (the wiki.fr.vec is in the output build directory and always copy).\r\ni try a lot of code but i cant figure why it s not working , i also try [Issues 5532](https://github.com/dotnet/machinelearning/issues/5532) . the generated output are always the same : \r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/16559628/8f20fca5-a1af-4a89-baa8-4a3c8e0319f4)\r\n\r\nAfter some work i notice that if the wiki.en.vec is manually set in the folder  \"AppData\\Local\\mlnet-resources\\WordVectors\" it s working when i m using FastTextWikipedia300D .\r\n\r\nSo there is an issue when you manually set the full path location in ApplyWordEmbedding.\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n```\r\nvar cast = allDataEnumerable.Select(x => new TextData() { Text = x.TextCleaned }).ToList();\r\nvar dataView = mlContext.Data.LoadFromEnumerable(cast);\r\n\r\nvar pipeline = mlContext.Transforms.Text.NormalizeText(\"Text\")\r\n    .Append(mlContext.Transforms.Text.TokenizeIntoWords(\"Tokens\", \"Text\"))\r\n    .Append(mlContext.Transforms.Text.ApplyWordEmbedding(\"Features\", @\"c:/wiki.fr.vec\", \"Tokens\"));\r\n\r\n\r\nvar transformer = pipeline.Fit(dataView);\r\nvar transformedData = transformer.Transform(dataView);\r\n\r\n\r\nvar predictionEngine = mlContext.Model.CreatePredictionEngine<TextData, TextFeatures>(transformer);\r\n\r\nforeach (var item in allDataEnumerable)\r\n{\r\n    var prediction = predictionEngine.Predict(new TextData() { Text = item.TextCleaned});\r\n\r\n    Console.WriteLine($\"Number of Features: {prediction.Features.Length}\");\r\n\r\n    // Print the embedding vector.\r\n    Console.Write(\"Features: \");\r\n    foreach (var f in prediction.Features)\r\n        Console.Write($\"{f:F4} \");\r\n\r\n    Console.WriteLine(); \r\n}\r\n```\r\n```\r\n  public class TextFeatures \r\n  {\r\n      [VectorType(300)]\r\n      public float[] Features { get; set; }\r\n  }\r\n```\r\n\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6919","RelatedDescription":"Open issue \"Bugs / ApplyWordEmbedding with custom path not working. \" (#6919)"},{"Id":"2049198788","IsPullRequest":false,"CreatedAt":"2023-12-19T18:10:47","Actor":"ericstj","Number":"6916","RawContent":null,"Title":"Unable to update OnnxRuntime","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11 22H2 x64\r\n - ML.NET Version: https://github.com/dotnet/machinelearning/pull/6703\r\n - .NET Version: Net 8\r\n\r\n**Describe the bug**\r\nWhen updating OnnxRuntime to 1.15.0 or later 4 tests fail with \r\n```\r\n  Error Message:\r\n   System.InvalidOperationException : Error initializing model :Microsoft.ML.OnnxRuntime.OnnxRuntimeException: [ErrorCode:Fail] OnnxValueType must either be a tensor or sparse tensor\r\n   at Microsoft.ML.OnnxRuntime.NodeMetadata.CheckTensor()\r\n   at Microsoft.ML.OnnxRuntime.NodeMetadata.get_Dimensions()\r\n   at Microsoft.ML.Transforms.Onnx.OnnxModel.GetOnnxVariablesFromMetadata(IReadOnlyDictionary`2 nodeMetadata, IDictionary`2 shapeDictionary, Dictionary`2 typePool, Dictionary`2 casterPool) in C:\\src\\dotnet\\machinelearning\\src\\Microsoft.ML.OnnxTransformer\\OnnxUtils.cs:line 302\r\n   at Microsoft.ML.Transforms.Onnx.OnnxModel..ctor(String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, Boolean ownModelFile, IDictionary`2 shapeDictionary, Int32 recursionLimit, Nullable`1 interOpNumThreads, Nullable`1 intraOpNumThreads) in C:\\src\\dotnet\\machinelearning\\src\\Microsoft.ML.OnnxTransformer\\OnnxUtils.cs:line 257\r\n   at Microsoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, Options options, Byte[] modelBytes) in C:\\src\\dotnet\\machinelearning\\src\\Microsoft.ML.OnnxTransformer\\OnnxTransform.cs:line 260\r\n```\r\nFailing tests are:\r\nMicrosoft.ML.Tests.OnnxTransformTests.TestOnnxModelNotDisposal\r\nMicrosoft.ML.Tests.OnnxTransformTests.TestOnnxModelDisposal\r\nMicrosoft.ML.Tests.OnnxTransformTests.TestOnnxZipMapWithStringKeys\r\nMicrosoft.ML.Tests.OnnxTransformTests.TestOnnxZipMapWithInt64Keys\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Update MicrosoftMLOnnxRuntimeVersion to 1.16.1.\r\n2. build and run test on Microsoft.ML.OnnxTransformerTest\r\n\r\n**Expected behavior**\r\nAll tests pass\r\n\r\n**Screenshots, Code, Sample Projects**\r\n4 tests above fail\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6916","RelatedDescription":"Open issue \"Unable to update OnnxRuntime\" (#6916)"},{"Id":"2048382766","IsPullRequest":false,"CreatedAt":"2023-12-19T10:38:07","Actor":"superichmann","Number":"6915","RawContent":null,"Title":"mlcontext.Data.Cache is not releasing memory","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10]\r\n - ML.NET Version:ML.NET 3.0.0\r\n - .NET Version: .NET 8\r\n\r\n**Describe the bug**\r\nWhen using mlcontext.Data.Cache on idataview the memory is not released even if GC is called and null is set for the idataview and mlContext.\r\n\r\nWhen not using mlcontext.Data.Cache, the memory is yes released after setting null to idataview and calling GC.\r\n\r\n**To Reproduce**\r\nLoad data into idataview, **DONT** call cache, create model with lgbm (fit, transform test set), destroy idataviews, check memory consumption\r\nLoad data into idataview, **DO** call cache, create model with lgbm(fit, transform test set), destroy idataviews, check memory consumption\r\nSee the difference\r\n\r\n**Expected behavior**\r\nAll memory allocated by an object which no longer can actually be used should be released\r\nIf there is a specific way to release the memory please instruct me on how to do that.\r\n**I must use mlcontext.Data.Cache since its improves performance by 50%**\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6915","RelatedDescription":"Open issue \"mlcontext.Data.Cache is not releasing memory\" (#6915)"},{"Id":"2048008794","IsPullRequest":false,"CreatedAt":"2023-12-19T06:26:38","Actor":"EmmanuelPonnudurai","Number":"6914","RawContent":null,"Title":"Recommendations as shown in the .mbconfig file","State":"open","Body":"I am using the UI options to try out a sample prediction with ML.NET. Everything looks fine except for one part which I am unable to see the generated code for. Can someone tell me how this portion is getting generated. \r\n\r\nMy input model consists of 2 fields. I provide it and it gives me a recommendation for the field im trying to predict. However, it also is able to tell me top 5 recommendations with only 1 field (url). How is this exactly happening cos I do not see this part in the generated code?\r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/14484652/1a0b072e-41c8-4808-b362-84e3d2dc24d3)\r\n\r\nAny pointers will be appreciated. Thank you.","Url":"https://github.com/dotnet/machinelearning/issues/6914","RelatedDescription":"Open issue \"Recommendations as shown in the .mbconfig file\" (#6914)"},{"Id":"2044567981","IsPullRequest":false,"CreatedAt":"2023-12-16T02:20:13","Actor":"tearlant","Number":"6913","RawContent":null,"Title":"Saved model returning a different prediction when using AddPredictionEnginePool","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 10\r\n - ML.NET Version: 3.0.0\r\n - .NET Version: 7.0\r\n\r\n**Describe the bug**\r\nI'm trying to build something with an API endpoint exposed. While prototyping, I'm essentially following the documentation here: https://learn.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/serve-model-web-api-ml-net\r\n\r\nI would expect the following two blocks to give the same result:\r\n\r\n(In a console app)\r\n```\r\nvar mlContext = new MLContext();\r\n            \r\nSentimentIssue sampleStatement = new SentimentIssue { Text = \"I love this movie!\" };\r\n\r\nstring ModelPath = \"path/to/SentimentModel.zip\";\r\n\r\nITransformer loadedModel = mlContext.Model.Load(ModelPath, out var modelInputSchema);\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<SentimentIssue, SentimentPrediction>(loadedModel);\r\nvar resultprediction = predEngine.Predict(sampleStatement);\r\n\r\nConsole.WriteLine($\"=============== Single Prediction  ===============\");\r\nConsole.WriteLine($\"Text: {sampleStatement.Text} | Prediction: {(Convert.ToBoolean(resultprediction.Prediction) ? \"Positive\" : \"Negative\")} sentiment | Probability of being positive: {resultprediction.Probability} \");\r\n```\r\nActual output:\r\n![image](https://github.com/dotnet/machinelearning/assets/105062729/58aa22e5-f368-4231-9769-1ac6c466433b)\r\n\r\nIn an API, in the Program.cs file:\r\n```\r\nbuilder.Services.AddPredictionEnginePool<SentimentAnalysisModelInput, SentimentAnalysisModelOutput>().FromFile(modelName: \"SentimentAnalysisModel\", filePath: \"path/to/SentimentModel.zip\", watchForChanges: true);\r\n\r\n// ...\r\n\r\nvar predictionHandler =\r\n    (PredictionEnginePool<SentimentAnalysisModelInput, SentimentAnalysisModelOutput> predictionEnginePool, SentimentAnalysisModelInput input) =>\r\n    {\r\n        return predictionEnginePool.Predict(modelName: \"SentimentAnalysisModel\", input);\r\n    };\r\n\r\napp.MapPost(\"/predict\", predictionHandler);\r\n\r\napp.Run();\r\n\r\n```\r\n\r\nThe output (for example, using Postman with the same input)\r\n![image](https://github.com/dotnet/machinelearning/assets/105062729/3881d198-6493-40a1-9f37-77c2cf29eed3)\r\n\r\n**Expected behavior**\r\nI would expect the two to be equal, with the same input. Also, I'm getting the same result/probability no matter what input I use:\r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/105062729/34a77e84-b547-477a-8213-5a472641fb7b)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6913","RelatedDescription":"Open issue \"Saved model returning a different prediction when using AddPredictionEnginePool\" (#6913)"},{"Id":"2044205225","IsPullRequest":false,"CreatedAt":"2023-12-15T18:45:37","Actor":"BartNSTCL","Number":"6912","RawContent":null,"Title":"Using AddPredictionEnginePool ModelName difference in Predict shows expected error","State":"open","Body":"\r\n - OS & Version: Windows 11 Insider Build 23606.1000\r\n - ML.NET Version: 3.0.0\r\n - .NET Version: Net 8.0\r\n\r\n**Describe the bug**\r\nI created a PredictionEnginePool in Program.cs as:\r\n            _builder.Services.AddPredictionEnginePool<ModelOutput, ModelOutput>()\r\n            .FromUri( modelName: \"YieldModel\",\r\n            uri: \"/MechPropertiesModels/YieldModel.zip\",\r\n            period: TimeSpan.FromMinutes(10));_\r\n\r\nIn my Controller, after setting up the DI (PredEnginePool),  I had the following code:\r\n_IEnumerable<ModelOutput> yieldOut = sampleData.Select(input => PredEnginePool.Predict<ModelOutput, ModelOutput>(modelName: \"Yield\", example: input)).ToList();_\r\n\r\nWhen I run the code, the error was:\r\n_System.ArgumentNullException: Value cannot be null. (Parameter 'poolOptions')\r\n   at Microsoft.Extensions.ML.PoolLoader`2..ctor(IServiceProvider sp, PredictionEnginePoolOptions`2 poolOptions)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2.AddPool(String modelName)\r\n   at Microsoft.Extensions.ML.PredictionEnginePool`2.GetPredictionEngine(String modelName)\r\n   at Microsoft.Extensions.ML.PredictionEnginePoolExtensions.Predict[TData,TPrediction](PredictionEnginePool`2 predictionEnginePool, String modelName, TData example)\r\n   at CTLWebApi.Controllers.MachineLearningController.<PredictMechProperties>b__11_1(ModelOutput input) in C:\\Users\\bart.lynn\\source\\repos\\CTL Projects\\CTLWebsite_Net\\CTLWebApi\\Controllers\\MachineLearningController.cs:line 91_\r\n\r\nI realized after some time, I had 2 different names for the Model (YieldModel, and Yield). The error pointed to missing 'poolOptions'. I tried any different searches looking for that 'poolOptions' and after a while I noticed the model name differences.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Name the model something in the Program.cs\r\n2. Name the model something different in the Controller.\r\n3. Run\r\n4. See error\r\n\r\n**Expected behavior**\r\nMaybe it should say, Model:\"Yield\" was not found in the pool.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nCode is provided above.","Url":"https://github.com/dotnet/machinelearning/issues/6912","RelatedDescription":"Open issue \"Using AddPredictionEnginePool ModelName difference in Predict shows expected error\" (#6912)"},{"Id":"2042722684","IsPullRequest":false,"CreatedAt":"2023-12-15T01:01:58","Actor":"zewditu","Number":"6911","RawContent":null,"Title":"Splitter/consolidator worker encountered exception while consuming source data in QA","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: [e.g. Windows 10] \r\n - ML.NET Version: [e.g. ML.NET v1.5.5]\r\n - .NET Version: [e.g. .NET 5.0]\r\n\r\n**Describe the bug**\r\nFor [this](https://microsoft.sharepoint.com/teams/Privetbuild/Shared%20Documents/Forms/AllItems.aspx?ga=1&id=%2Fteams%2FPrivetbuild%2FShared%20Documents%2FMode%20Builder%20sample%20projects%2FQASampleDataset&viewid=59c820c6%2D8175%2D4d81%2Dafb2%2Dc421709c2521)  dataset the exception is thrown  after the training is completed  , it seems the issue is in validation  step.\r\nI am able to reproduce it in Ml.Net repo test case   and the issue happed in 'ComputeTopKSpansWithScore' method at  https://github.com/dotnet/machinelearning/blob/main/src/Microsoft.ML.TorchSharp/Utils/MetricUtils.cs#L23\r\n\r\nHere is the test code \r\n```csharp       \r\n        var ml = new Microsoft.ML.MLContext();\r\n\r\n        ml.Log += (object sender, LoggingEventArgs e) =>\r\n        {\r\n            Console.WriteLine(e.Message);\r\n        };\r\n\r\n        ml.GpuDeviceId = 0;\r\n        ml.FallbackToCpu = false;\r\n        Console.WriteLine(\"Hello World!\");\r\n\r\n        var trainFile = GetDataPath(\"squad-train-clean.tsv\");\r\n\r\n        Microsoft.ML.Data.TextLoader textLoader =\r\n            ml.Data.CreateTextLoader(new TextLoader.Options()\r\n            {\r\n                Columns = new[]\r\n                        {\r\nnew TextLoader.Column(\"Context\", DataKind.String,0),\r\nnew TextLoader.Column(\"Question\", DataKind.String,1),\r\nnew TextLoader.Column(\"TrainingAnswer\", DataKind.String,2),\r\nnew TextLoader.Column(\"AnswerIndex\", DataKind.Int32,3)\r\n},\r\n                HasHeader = true,\r\n                Separators = new[] { '\\t' },\r\n            }, new MultiFileSource(trainFile));\r\n\r\n        Microsoft.ML.IDataView dataView = textLoader.Load(new MultiFileSource(trainFile));\r\n        var testTrainSplit = ml.Data.TrainTestSplit(dataView, 0.95);\r\n\r\n        var trainingDataset = testTrainSplit.TrainSet;\r\n        var testDataset = ml.Data.TrainTestSplit(testTrainSplit.TestSet, 0.95).TrainSet;\r\n\r\n        var estimator = ml.MulticlassClassification.Trainers.QuestionAnswer(maxEpochs: 1);\r\n        var model = estimator.Fit(testDataset);\r\n        var transformedData = model.Transform(testDataset);\r\n        var labelCol = transformedData.GetColumn<string[]>(\"Answer\").ToArray();\r\n\r\n```\r\n![image](https://github.com/dotnet/machinelearning/assets/36615490/e25c7e8e-add8-4a17-b4f0-e3a2e149db94)\r\n\r\n**Additional context**\r\nThe reason we used  test dataset to train is  because it seems that the exception is thrown in validation using test dataset.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6911","RelatedDescription":"Open issue \"Splitter/consolidator worker encountered exception while consuming source data in QA\" (#6911)"},{"Id":"2042706844","IsPullRequest":false,"CreatedAt":"2023-12-15T00:39:40","Actor":"luisquintanilla","Number":"6910","RawContent":null,"Title":"NER Remaining Work","State":"open","Body":"- [ ] [Provide E2E sample](https://github.com/dotnet/machinelearning/issues/630#issuecomment-1831961047)\r\n- [ ] Look into Tokenizer questions / concerns\r\n  - [ ] [Data needs to be tokenized](https://github.com/dotnet/machinelearning/issues/630#issuecomment-1812658740)\r\n  - [ ] [Choosing a different tokenizer](https://github.com/dotnet/machinelearning/issues/630#issuecomment-1813563078)\r\n\r\nThe tokenizer may not be possible because it's what the model expects. However, you should be able to use a different vocabulary.","Url":"https://github.com/dotnet/machinelearning/issues/6910","RelatedDescription":"Open issue \"NER Remaining Work\" (#6910)"},{"Id":"2042039131","IsPullRequest":false,"CreatedAt":"2023-12-14T16:24:46","Actor":"Amine-Smahi","Number":"6909","RawContent":null,"Title":"Is it possible to make a CHATGPT Clone with ML.NET ?","State":"open","Body":"Hi team,\r\n\r\nis it possible to create a ChatGPT clone trained on own data using ML.NET ?\r\n\r\nI'm really in need for feedback before deciding to get into ML.NET for my company.\r\n\r\nThanks for the good work","Url":"https://github.com/dotnet/machinelearning/issues/6909","RelatedDescription":"Open issue \"Is it possible to make a CHATGPT Clone with ML.NET ?\" (#6909)"},{"Id":"2040350865","IsPullRequest":false,"CreatedAt":"2023-12-13T19:39:17","Actor":"zewditu","Number":"6908","RawContent":null,"Title":"Deep learning scenarios  json serialization issue in webApp ","State":"open","Body":"**System Information (please complete the following information):**\r\n -Windows 11 Enterprise (10.0.22631 Build)\r\n - ML.NET Version: [3.0.0]\r\n - .NET Version: [e.g. .NET 8.0]\r\n\r\n**Describe the bug**\r\nIn model builder we generate two sample projects console and minimal webApp  to our user to show samples how to consume thier model in application.\r\nHowever  for the weApp if we have non-English characters in Json string we passe we have error ,if we explicitly sterilize it works .\r\nHere is a solution that contain those generated projects https://microsoft.sharepoint.com/:f:/t/Privetbuild/ElKqZFFcA4VDlR8cQVN_PaEB3fRmuet1WOAt7G39rrwtQA?e=haN4H8\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1.  Download the solution\r\n2. Open the solution in VS\r\n3. Run \"MLModel1_WebApi1\"\r\n4. Open \"PowerShell \"\r\n5.  Provide the sample dataset \r\n\"$body =@{\r\n\\>\\> context =\"Beyoncé Giselle Knowles-Carter (/bi:jɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles\"\r\n\\>\\> question =\"What areas did Beyonce compete in when she was growing up?\"\r\n\\>\\> answer_start =207\r\n\\>\\> }\"     \r\n\r\n## Note `>>` are new lines in powershell\r\n\r\n7. Call the method `Invoke-RestMethod \"https://localhost:PORT_NUMBER/predict\"-Method Post -Body ($body | ConvertTo-Json)-ContentType \"application/json\" `\r\n8. See error  as follows \r\n![image](https://github.com/dotnet/machinelearning/assets/36615490/96e41fb6-8bf5-42be-b666-70ba2f49cd0e)\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots, Code, Sample Projects**\r\nIf applicable, add screenshots, code snippets, or sample projects to help explain your problem.\r\n\r\n**Additional context**\r\n\r\n- if I am modifying 'Program.cs` in `MLModel1_WebApi1`  \"app.MapPost\" into the following explicit Json setting option it works.\r\n\r\n```csharp\r\napp.MapPost(\"/predict\", async (HttpRequest request) =>\r\n{\r\n    var options = new JsonSerializerOptions\r\n    {\r\n        Encoder = System.Text.Encodings.Web.JavaScriptEncoder.Default,\r\n        PropertyNameCaseInsensitive = true,\r\n    };\r\n    using (StreamReader reader = new StreamReader(request.Body))\r\n    {\r\n        var jsonString = await reader.ReadToEndAsync();\r\n        var modelInput = JsonSerializer.Deserialize<MLModel1.ModelInput>(jsonString,options);\r\n        var result = MLModel1.Predict(modelInput);\r\n\r\n        // To get only the first best answer.\r\n        result.Predicted_Answer = new string[] { result.Predicted_Answer[0] };\r\n        result.Score = new float[] { result.Score[0] };\r\n        return result;\r\n    }\r\n})\r\n```\r\n\r\n- It happens only for QA, Sentence-similarity and Text-classification.\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6908","RelatedDescription":"Open issue \"Deep learning scenarios  json serialization issue in webApp \" (#6908)"},{"Id":"2038210076","IsPullRequest":true,"CreatedAt":"2023-12-12T20:03:30","Actor":"michaelgsharp","Number":"6907","RawContent":null,"Title":"Updated ml.net versioning","State":"closed","Body":"Updating ML.NET version to 4.\r\n","Url":"https://github.com/dotnet/machinelearning/pull/6907","RelatedDescription":"Closed or merged PR \"Updated ml.net versioning\" (#6907)"},{"Id":"2037043541","IsPullRequest":false,"CreatedAt":"2023-12-12T06:01:18","Actor":"unruledboy","Number":"6906","RawContent":null,"Title":"Complicated recommendation model with multiple optional custom weighted attributes","State":"open","Body":"\r\n### System information\r\n\r\n- OS version/distro: Windows 11\r\n- .NET Version: NET 6\r\n\r\n### Issue\r\n\r\n- **What did you try?**: tried to build a recommendation model with multiple optional custom weighted attributes\r\n- **What happened?**: could not figure out how to apply custom attributes with weight\r\n- **What did you expect?**: build a model with custom weighted attributes\r\n\r\n### Use case\r\nI would like to develop a recommendation system for cars (yes, vehicles), where user can specify what they are interested in most, less important and least important.\r\n\r\nThe importance would be described as:\r\n- High: the weight value is 10\r\n- Medium: the weight value is 6\r\n- Low: the weight value is 3\r\n\r\nAnd for every attribute of the car, a user is able specify the importance to them. Which means every attribute is optional. For those attributes that are not specified by the user, it would have default weight at `Medium`.\r\n\r\nFor example, a user specifies importance as below:\r\n- price: high (more expensive, **lower** the score would be)\r\n- horse power: high (bigger horse power, higher the score would be)\r\n- seats: high (the system consider the number of seats as: the more the seats, the higher the score would be)\r\n- 4WD: low (for those cars that are FWD/4WD, it has higher score)\r\n- tank/fuel range: medium (longer the range, higher the score)\r\n- etc.\r\n- etc.\r\n\r\nNow, to build such model, I would expect **somehow** we could provide user-specified weighted attributes into the model so the result would be user based.\r\n\r\nNot really sure how to do so. Any thoughts?\r\n\r\nYours,\r\nWilson\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6906","RelatedDescription":"Open issue \"Complicated recommendation model with multiple optional custom weighted attributes\" (#6906)"},{"Id":"2035686166","IsPullRequest":false,"CreatedAt":"2023-12-11T13:30:09","Actor":"asmirnov82","Number":"6905","RawContent":null,"Title":"[Proposal] DataFrame Arithmetic and Computation API ","State":"open","Body":"## Background and motivation\r\n\r\nCurrent arithmetic and computation API of the DataFrame is inconsistent and quite slow in scenarios where columns of different types are involved as each column casting to different type requires coping the entire column data. \r\n\r\nMoreover some of the methods of computation API may produce inaccurate results (due to overflow exception).\r\n\r\nMotivation of this change includes \r\n1. reusing generic operators from future TensorPrimitives API for fast computation over DataFrame columns of different types (and possibly even chaining such operations to avoid intensive memory usage for storing intermediate calculation results)\r\n2. accurate calculation of aggregation functions\r\n3. increased performance and using SIMD commands for the significant part of DataFrame operations\r\n4. reduce DataFrame code duplication\r\n\r\n## Details of current implementation limitations\r\n\r\n1. Inconsistency of the API is related to types of data returned by arithmetic operations over `PrimitiveColumn<T>` instances and their concrete aliases (like `DoubleDataFrame` or `Int32DataFrameColumn`)\r\n\r\nFor example\r\n```C#\r\nvar left_column = new ByteDataFrameColumn(\"Left\", new byte[] { 1, 2, 3 });\r\nvar right_column = new Int16DataFrameColumn(\"Right\", new short[] { 1, 2, 3 });\r\n\r\nvar sum = left_column.Add + right_column;\r\n```\r\nresults in sum column containing int values.\r\n\r\nThe same code, but referring columns using parent type\r\n```C#\r\nPrimitiveDataFrameColumn<byte> left_column = new ByteDataFrameColumn(\"Left\", new byte[] { 1, 2, 3 });\r\nPrimitiveDataFrameColumn<short> right_column = new Int16DataFrameColumn(\"Right\", new short[] { 1, 2, 3 });\r\n\r\nvar sum = left_column.Add + right_column;\r\n```\r\nresults in sum column containing double values. \r\n\r\n2.  Inaccurate results of aggregated functions. Currently aggregated functions are calculated using the same type as input column, for example for byte column it’s byte type. \r\nAnd\r\n```C#\r\nvar column = new ByteDataFrameColumn(\"Column\", new byte[] { 128, 129 });\r\n\r\nvar sum = column.Sum();\r\nvar mean = column.Mean();\r\n```\r\nresults in sum equals to 1 and mean to 0.5, which is obviously incorrect.\r\n\r\n3. Performance and excessive coping issues are well known and mentioned in  #5663  \r\n\r\n## Proposal\r\n\r\nProposal is:\r\n\r\n1. to use the common numeric type for the arithmetic output (the smallest numeric type which can accommodate any value of any input). If any input is a floating point type the common numeric type is the widest floating point type among the inputs. Otherwise the common numeric type is integral and is signed if any input is signed.\r\n\r\n2. to return the widest possible type for accumulating aggregation functions (like sum, product and etc). It’s double for floating point types (double, float, Half), long for signed integers (long, int, short, sbyte) and ulong for unsigned integers (ulong, uint, ushort, byte) and input type for other aggregated functions (like min, max, first and etc).\r\n\r\nThis approach is used for example in [Apache Arrow Compute functions](https://arrow.apache.org/docs/cpp/compute.html)\r\n\r\n## Implementation\r\n\r\nImplementation can reuse the low level parts of the future generic TensorPrimitives API, like `IUnaryOperator<T>`, `IBinaryOperator<T>` and their concrete implementations.\r\n\r\nOperators allow to invoke highly efficient vectorized calculations over arguments of the same type. New implementation should extend this functionality by providing efficient vectorized convertors and conversion rules for cases when arguments have different data type.\r\n\r\n## Example\r\n\r\nI created an example of possible implementation [compute-functions](https://github.com/asmirnov82/compute-functions)\r\nApache Arrow doesn’t have a .Net implementation of Compute Functions I took at as an exercise for the POC. DataFrame follows the same paradigm, so all the ideas can be applied to it as well.\r\n\r\nSo, I extend several operators from TensorPrimitive API to have generic version (this is done to illustrate how future Generic Tensor API can be look like and be used). I also created several OperatorExecutors and Functions classes, that provides rules for argument type conversions for several cases (binary arithmetic calculations and two types of aggregating functions). I also created a list of wideners and convertes that leverage SIMD vectorized calculation as an example","Url":"https://github.com/dotnet/machinelearning/issues/6905","RelatedDescription":"Open issue \"[Proposal] DataFrame Arithmetic and Computation API \" (#6905)"},{"Id":"2034549027","IsPullRequest":false,"CreatedAt":"2023-12-10T21:52:49","Actor":"MattiaDurli","Number":"6904","RawContent":null,"Title":"Object Detection speed decreased moving from ML.NET 1.7.0 to 3.0","State":"open","Body":"**System Information (please complete the following information):**\r\n - OS & Version: Windows 11\r\n - ML.NET Version: ML.NET 1.7.0 and 3.0\r\n - .NET Version: .NET 8\r\n\r\n**Describe the bug**\r\nI trained my model last year, with ML Model Builder and ML.NET 1.7 with a set of images annotated with VOTT. The training was in Azure because at that time it wasn't possible to train locally. Then I produced the console sample application that loads my ONNX MLModel1.zip.\r\nWith a reference image, after the first load, it takes 0.58s on my current machine to detect the objects. \r\nMy computer has GPU but I assume it's not used at this stage.\r\n\r\nI retrained my model now, this time locally, with my GPU, with the same image set and annotations, and a file MLModel1.mlnet is created, and the sample console app has tochsharp nuget instead of onnx nugets.\r\nIf I test (after first load) with\r\nmlContext.GpuDeviceId = null;\r\nmlContext.FallbackToCpu = true;\r\nnow it takes 2.1s\r\nIf I test (after first load) with\r\nmlContext.GpuDeviceId = 0;\r\nmlContext.FallbackToCpu = false;\r\nnow it takes 0.68s\r\n\r\nThe older version, even without using CPU, is faster.\r\n\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n\r\n\r\n**Expected behavior**\r\nAn improvement\r\n\r\n**Screenshots, Code, Sample Projects**\r\nThe image I use as reference\r\n![referencetest](https://github.com/dotnet/machinelearning/assets/6052847/0df786ca-95dc-45e4-be05-812f59778265)\r\n\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6904","RelatedDescription":"Open issue \"Object Detection speed decreased moving from ML.NET 1.7.0 to 3.0\" (#6904)"},{"Id":"2033064887","IsPullRequest":false,"CreatedAt":"2023-12-08T17:38:18","Actor":"BartNSTCL","Number":"6903","RawContent":null,"Title":"Support for Microsoft.Data.SqlClient","State":"open","Body":"I always use the Nuget Microsoft.Data.SqlClient since it seems better and its Microsoft's recommendation.\r\n\r\nWhen using the ML.NET Model Builder, it uses System.Sql.SqlClient and that should up as an vulnerable dependency.\r\n\r\nWhile I can could just right code myself, I'd like to see the Model Builder use the new technology. \r\n\r\nI tried searching the Issues for this particular request, but I didn't see it. So if its a duplicate, it can be closed.","Url":"https://github.com/dotnet/machinelearning/issues/6903","RelatedDescription":"Open issue \"Support for Microsoft.Data.SqlClient\" (#6903)"},{"Id":"2031129307","IsPullRequest":false,"CreatedAt":"2023-12-07T16:39:48","Actor":"luisquintanilla","Number":"6902","RawContent":null,"Title":"Publish ML.NET 3.0 API Documentation ","State":"open","Body":"Latest API doc version is 2.0. Add 3.0\r\n\r\nhttps://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.textcatalog.applywordembedding?view=ml-dotnet\r\n\r\n![image](https://github.com/dotnet/machinelearning/assets/46974588/045f66c0-84f9-4680-ab23-56fe145b4fd4)\r\n","Url":"https://github.com/dotnet/machinelearning/issues/6902","RelatedDescription":"Open issue \"Publish ML.NET 3.0 API Documentation \" (#6902)"}],"ResultType":"GitHubIssue"}},"RunOn":"2023-12-30T03:30:17.3084126Z","RunDurationInMilliseconds":416}